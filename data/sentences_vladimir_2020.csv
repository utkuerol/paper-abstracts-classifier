,sentence,background_motivation,aim_contribution,research_object,research_method,results_findings,summary
0,"There is a rapidly increasing amount of Artificial Intelligence (AI) systems developed in recent years, with much expectation on its capacity of innovation and business value generation.",1,0,0,0,0,0
1,"However, the promised value of AI systems in specific business contexts might not be understood, and further integrated into the development processes.",1,0,0,0,0,0
2,"We wanted to understand how software engineering processes and practices can be applied to develop AI systems in a fast-faced, business-driven manner.",0,1,1,0,0,0
3,"As the first step, we explored contextual factors of AI development and the connections between AI developments to business opportunities.",0,0,1,0,0,0
4,"We conducted 12 semi-structured interviews in seven companies in Brazil, Norway and Southeast Asia.",0,0,0,1,0,0
5,Our investigation revealed different types of AI systems and different AI development approaches.,0,0,1,0,0,0
6,"However, it is common that business opportunities involving with AI systems are not validated and there is lack of business-driven metrics that guide the development of AI systems.",1,0,0,0,0,0
7,The findings have implications for future research on business-driven AI development and supporting tools and practices.,0,0,0,0,1,0
8,Expanding abbreviations in source code to their full meanings is very useful for software maintainers to comprehend the source code.,1,0,0,0,0,0
9,"The existing approaches, however, focus on expanding an abbreviation to a single word, i.e., unigram.",1,0,0,0,0,0
10,They do not perform well when dealing with abbreviations of phrases that consist of multiple unigrams.,1,0,0,0,0,0
11,This paper proposes a bigram-based approach for retrieving abbreviated phrases automatically.,0,1,0,0,0,0
12,Key to this approach is a bigram-based inference model for choosing the best phrase from all candidates.,0,0,1,0,0,0
13,It utilizes the statistical properties of unigrams and bigrams as prior knowledge and a bigram language model for estimating the likelihood of each candidate phrase of a given abbreviation.,0,0,1,0,0,0
14,"We have applied the bigram-based approach to 100 phrase abbreviations, randomly selected from eight open source projects.",0,0,0,1,0,0
15,The experiment results show that it has correctly retrieved 78% of the abbreviations by using the unigram and bigram properties of a source code repository.,0,0,0,0,1,0
16,This is 9% more accurate than the unigram-based approach and much better than other existing approaches.,0,0,0,0,1,0
17,The bigram-based approach is also less biased towards specific phrase sizes than the unigram-based approach.,0,0,0,0,1,0
18,Background: Machine Learning (ML) has been widely used as a powerful tool to support Software Engineering (SE).,1,0,0,0,0,0
19,The fundamental assumptions of data characteristics required for specific ML methods have to be carefully considered prior to their applications in SE.,1,0,0,0,0,0
20,"Within the context of Continuous Integration (CI) and Continuous Deployment (CD) practices, there are two vital characteristics of data prone to be violated in SE research.",0,0,1,0,0,0
21,"First, the logs generated during CI/CD for training are imbalanced data, which is contrary to the principles of common balanced classifiers; second, these logs are also time-series data, which violates the assumption of cross-validation.",0,0,1,0,0,0
22,Objective: We aim to systematically study the two data characteristics and further provide a comprehensive evaluation for predictive CI/CD with the data from real projects.,0,1,0,1,0,0
23,Method: We conduct an experimental study that evaluates 67 CI/CD predictive models using both cross-validation and time-series-validation.,0,0,0,1,0,0
24,"Results: Our evaluation shows that cross-validation makes the evaluation of the models optimistic in most cases, there are a few counter-examples as well.",0,0,0,0,1,0
25,"The performance of the top 10 imbalanced models are better than the balanced models in the predictions of failed builds, even for balanced data.",0,0,0,0,1,0
26,The degree of data imbalance has a negative impact on prediction performance.,0,0,0,0,1,0
27,"Conclusion: In research and practice, the assumptions of the various ML methods should be seriously considered for the validity of research.",0,0,0,0,0,1
28,"Even if it is used to compare the relative performance of models, cross-validation may not be applicable to the problems with time-series features.",0,0,0,0,0,1
29,The research community need to revisit the evaluation results reported in some existing research.,0,0,0,0,0,1
30,"Driven by the need for faster time-to-market and reduced development lead-time, large-scale systems engineering companies are adopting agile methods in their organizations.",1,0,0,0,0,0
31,This agile transformation is challenging and it is common that adoption starts bottom-up with agile software teams within the context of traditional company structures.,1,0,0,0,0,0
32,This creates the challenge of agile teams working within a document-centric and plan-driven (or waterfall) environment.,1,0,0,0,0,0
33,"While it may be desirable to take the best of both worlds, it is not clear how that can be achieved especially with respect to managing requirements in large-scale systems.",0,1,0,0,0,0
34,This paper presents an exploratory case study focusing on two departments of a large-scale systems engineering company (automotive) that is in the process of company-wide agile adoption.,0,0,0,1,0,0
35,We present challenges that agile teams face while working within a larger plan-driven context and propose potential strategies to mitigate the challenges.,0,0,0,0,1,0
36,"Challenges relate to, e.g., development teams not being aware of the high-level requirements, difficulties to manage change of these requirements as well as their relationship to backlog items such as user stories.",0,0,0,0,1,0
37,"While we found strategies for solving most of the challenges, they remain abstract and empirical research on their effectiveness is currently lacking.",0,0,0,0,0,1
38,"Context: With the growing popularity of rapid software delivery and deployment, the methods, practices and technologies of Continuous Software Engineering (CSE) are evolving steadily.",1,0,0,0,0,0
39,"This creates the need for understanding the recent trends of the technologies, practitioners' challenges and views in this domain.",1,0,0,0,0,0
40,"Objective: In this paper, we present an empirical study aimed at exploring CSE from the practitioners' perspective by mining discussions from Q&A websites.",0,1,1,1,0,0
41,"Method: We have analyzed 12,989 questions and answers posted on Stack Overflow.",0,0,0,1,0,0
42,Topic modelling is conducted to derive the dominant topics in this domain.,0,0,0,1,0,0
43,"Further, a qualitative analysis was conducted to identify the key challenges discussed.",0,0,0,1,0,0
44,"Findings: Whilst the trend of posted questions is sharply increasing, the questions are becoming more specific to technologies and more difficult to attract answers.",0,0,0,0,1,0
45,"We identified 32 topics of discussions, among which ""Error messages in Continuous Integration/Deployment"" and ""Continuous Integration concepts"" are the most dominant.",0,0,0,0,1,0
46,We also present the most challenging areas in this domain from the practitioners' perspectives.,0,0,0,0,1,0
47,Decisions run through the whole software development and maintenance processes.,1,0,0,0,0,0
48,"Explicitly documenting these decisions helps to organize development knowledge and to reduce its vaporization, thereby controlling the development process and maintenance costs.",1,0,0,0,0,0
49,It can also support the knowledge acquisition process for stakeholders of the project.,1,0,0,0,0,0
50,"Meanwhile, developers (e.g., architects) and managers will be able to rely on the decisions made in the past to solve the problems encountered in their current projects.",1,0,0,0,0,0
51,"However, identifying decisions from massive textual artifacts, which involves considerable human effort, time, and cost, is usually unaffordable due to limited resources.",1,0,0,0,0,0
52,"To address this problem, we conducted an experiment to automatically identify decisions from textual artifacts using machine learning techniques.",0,1,1,1,0,0
53,"We created a dataset of 1,300 sentences labelled from the Hibernate developer mailing list, containing 650 decision sentences and non-decision sentences respectively, and trained machine learning models using 160 configurations regarding text preprocessing, feature extraction, and classification algorithms.",0,0,0,1,0,0
54,"The results show that (1) the text preprocessing method with Including Stop Words, No Stemming and Lemmatization, and No Filtering Out Sentences performs best when preprocessing posts to identify decisions; (2) the simple Bag-of-Words (BoW) model works best when extracting features to identify decisions; (3) the Support Vector Machine (SVM) algorithm gets the best result when training classifiers to identify decisions; and (4) the SVM algorithm with Including Stop Words (ISW), No Stemming and Lemmatization (NSaL), Filtering Out Sentences by Length (FOSbL), and BoW achieves the best performance (with a precision of 0.640, a recall of 0.932, and an F1-score of 0.759), compared with other configurations when identifying decisions from the mailing list.",0,0,0,0,1,0
55,"Context: Design pattern detection is a very important research on software reuse, which can greatly help software maintenance and reconstruction.",1,0,0,0,0,0
56,"At present, many researchers have invested in this work and proposed a variety of methods for detection.",1,0,0,0,0,0
57,Method: This paper extends the graph matching technology based on the past and proposes a new method that combines network analysis and structural matching for detection.,0,1,1,0,0,0
58,"First, we use network level analysis to obtain important nodes, then use the neighborhood path matching algorithm to match the pattern instance.",0,0,1,1,0,0
59,"Result: We describe the detection of five patterns on four open source systems, then analyze and compare with the other three methods, for achieving high precision and recall, which demonstrates that our method is effective.",0,0,0,0,1,0
60,"Conclusion: Using combining network analysis with structural matching can well detect these pattern instances, and these instances are also especially important for future software refactoring.",0,0,0,0,0,1
61,GitHub has become a precious service for storing and managing software source code.,1,0,0,0,0,0
62,"Over the last year, 10M new developers have joined the GitHub community, contributing to more than 44M repositories.",1,0,0,0,0,0
63,"In order to help developers increase the reachability of their repositories, in 2017 GitHub introduced the possibility to classify them by means of topics.",1,0,0,0,0,0
64,"However, assigning wrong topics to a given repository can compromise the possibility of helping other developers approach it, and thus preventing them from contributing to its development.",1,0,0,0,0,0
65,In this paper we investigate the application of Multinomial Naïve Bayesian (MNB) networks to automatically classify GitHub repositories.,0,0,1,0,0,0
66,"By analyzing the README file(s) of the repository to be classified and the source code implementing it, the conceived approach is able to recommend GitHub topics.",0,0,1,0,0,0
67,"To the best of our knowledge, this is the first supervised approach addressing the considered problem.",0,0,0,0,0,1
68,"Consequently, since there exists no suitable baseline for the comparison, we validated the approach by considering different metrics, aiming to study various quality aspects.",0,0,0,1,0,1
69,The software engineering industry is increasingly aware of the role and value of neurodiverse engineers within the workforce.,1,0,0,0,0,0
70,One motivation is the alignment between skills needed for software development and the processing strengths of individuals with autistic spectrum conditions.,1,0,0,0,0,0
71,"One aspect of neurodiversity is dyslexia, typically presenting in individuals through a range of reading deficiencies.",1,0,0,0,0,0
72,In this paper we build on recent work which has sought to investigate if programmers with dyslexia read program code in a way which is different from programmers without dyslexia.,0,1,0,0,0,0
73,The particular focus of this analysis is the nature of saccadic movement and patterns of linearity when reading code.,0,0,1,0,0,0
74,A study is presented in which the eye gaze of 28 programmers (14 with dyslexia and 14 without) was recorded using an eye tracking device while reading and understanding three on-screen Java programs.,0,0,0,1,0,0
75,"Using insights from the wider dyslexia literature, hypotheses are formulated to reflect the expected saccadic gaze behaviour of programmers with dyslexia.",0,0,0,1,0,0
76,A range of existing metrics for linearity of program reading are adapted and used for statistical analysis of the data.,0,0,0,1,0,0
77,Results are consistent with recent work elsewhere and indicate that programmers with dyslexia do not exhibit patterns of linearity significantly different from the control group.,0,0,0,0,1,0
78,Non-linear gaze is shown to be approximately 40% of all saccadic movement.,0,0,0,0,1,0
79,"Some preliminary insights are offered based on the data available, suggesting that the extent of non-linear reading when comprehending program code might complement the processing and problem solving style of the programmer with dyslexia.",0,0,0,0,0,1
80,"In Software Product Lines (SPL), feature extraction from software requirements specifications has been subject to intense research in order to assist domain analysis in a time-saving way.",1,0,0,0,0,0
81,"Although various approaches are proposed to extract features, there still exists a gap to achieve the complete view of features, that is, how to figure out the intention of a feature.",1,0,0,0,0,0
82,Feature terms as the smallest units in a feature can be regarded as vital indicators for describing a feature.,1,0,0,0,0,0
83,"Automated feature term extraction can provide key information regarding the intention of a feature, which improves the efficiency of domain analysis.",1,0,0,0,0,0
84,"In this paper, we propose an approach to train prediction models by using machine learning techniques to identify feature terms.",0,1,1,0,0,0
85,"To this end, we extract candidate terms from requirement specifications in one domain and take six attributes of each term into account to create a labeled dataset.",0,0,0,1,0,0
86,"Subsequently, we apply seven commonly used machine algorithms to train prediction models on the labeled dataset.",0,0,0,1,0,0
87,We then use these prediction models to predict feature terms from the requirements belonging to the other two different domains.,0,0,0,1,0,0
88,"Our results show that (1) feature terms can be predicted with high accuracy of ≈ 90% within a domain (2) prediction across domains leads to a decreased but still good accuracy (≈ 80%), and (3) machine learning algorithms perform differently.",0,0,0,0,1,0
89,Spectrum-Based Fault Localization (SBFL) follows the basic intuitions that the faulty parts are more likely to be covered by failure-revealing test cases and less likely to be covered by passed test cases.,1,0,0,0,0,0
90,"However, due to the diversity of programs and faults, many other characteristics (related to program structure, test suites, and type of faulty components) will influence the practical application of SBFL.",1,0,0,0,0,0
91,"For example, a statement can be covered by numerous failure-revealing test cases, and also covered by numerous passed test cases.",1,0,0,0,0,0
92,"To get more indicators about the faulty components towards a better application of SBFL, we extend the scope of spectrum-based knowledge from the basic intuitions to the Characteristics of Spectra Distribution (CSDs for short).",0,1,0,0,0,0
93,"That is, we explore the relationships between different types of statements and their spectra.",0,0,1,0,0,0
94,"Firstly, we introduce the concepts of Failure-Independent, Failure-Related, and Failure-Exclusionary to describe the relationships between different types of statements and their executions.",0,1,1,0,0,0
95,"Then, we propose two probabilistic models, with and without the noise of fault interference, respectively, to identify various CSDs for each type of statements.",0,0,1,1,0,0
96,"As the analysis results, we introduce a visualization technique to generalize the identified CSDs and provide an overall picture of spectra distribution and its dynamics.",0,0,1,1,0,0
97,"Finally, based on our analysis and also the observation of the program spectra of current benchmarks, we design a technique to filter the potential non-faulty statements to improve the accuracy of SBFL.",0,0,0,0,1,0
98,Context: The vast majority of software engineering research is reported independently of the application domain: techniques and tools usage is reported without any domain context.,1,0,0,0,0,0
99,"As reported in previous research, this has not always been so: early in the computing era, the research focus was frequently application domain specific (for example, scientific and data processing).",1,0,0,0,0,0
100,Objective: We believe determining the research context is often important.,0,1,0,0,0,0
101,"Therefore we propose a code-based approach to identify the application domain of a software system, via its lexicon.",0,1,1,0,0,0
102,We compare its use against the plain textual description attached to the same system.,0,0,1,0,0,0
103,"Method: Using a sample of 50 Java projects, we obtained i) the description of each project (e.g., its ReadMe file), ii) the lexicon extracted from its source code, and iii) a list of its main topics extracted with the Latent Dirichlet Allocation (LDA) modelling technique.",0,0,0,1,0,0
104,"We assigned a random subset of these data items to different researchers (i.e., 'experts'), and asked them to assign each item to one (or more) application domain.",0,0,0,1,0,0
105,We then evaluated the precision and accuracy of the three techniques.,0,0,0,1,0,0
106,"Results: Using the agreement levels between experts, We observed that the 'baseline' dataset (i.e., the ReadMe files) obtained the highest average in terms of agreement between experts, but we also observed that the three techniques had the same mode and median agreement levels.",0,0,0,0,1,0
107,"Additionally, in the cases where no agreement was reached for the baseline dataset, the two other techniques provided sufficient additional support.",0,0,0,0,1,0
108,"Conclusions: We conclude that the source code is sufficient for determining the application domain, so that classification is possible without special documentation requirements.",0,0,0,0,0,1
109,Context: There is considerable diversity in the range and design of computational experiments to assess classifiers for software defect prediction.,1,0,0,0,0,0
110,"This is particularly so, regarding the choice of classifier performance metrics.",1,0,0,0,0,0
111,"Unfortunately some widely used metrics are known to be biased, in particular F1.",1,0,0,0,0,0
112,Objective: We want to understand the extent to which the widespread use of the F1 renders empirical results in software defect prediction unreliable.,0,1,0,0,0,0
113,Method: We searched for defect prediction studies that report both F1 and the Matthews correlation coefficient (MCC).,0,0,0,1,0,0
114,This enabled us to determine the proportion of results that are consistent between both metrics and the proportion that change.,0,0,0,1,0,0
115,Results: Our systematic review identifies 8 studies comprising 4017 pairwise results.,0,0,0,0,1,0
116,"Of these results, the direction of the comparison changes in 23% of the cases when the unbiased MCC metric is employed.",0,0,0,0,1,0
117,"Conclusion: We find compelling reasons why the choice of classification performance metric matters, specifically the biased and misleading F1 metric should be deprecated.",0,0,0,0,0,1
118,Background: Publication bias is the failure to publish the results of a study based on the direction or strength of the study findings.,1,0,0,0,0,0
119,The existence of publication bias is firmly established in areas like medical research.,1,0,0,0,0,0
120,Recent research suggests the existence of publication bias in Software Engineering.,1,0,0,0,0,0
121,Aims: Finding out whether experiments published in the International Workshop on Empirical Software Engineering and Measurement (ESEM) are affected by publication bias.,0,1,0,0,0,0
122,Method: We review experiments published in ESEM.,0,0,1,1,0,0
123,We also survey with experimental researchers to triangulate our findings.,0,0,0,1,0,0
124,Results: ESEM experiments do not define hypotheses and frequently perform multiple testing.,0,0,0,0,1,0
125,One-tailed tests have a slightly higher rate of achieving statistically significant results.,0,0,0,0,1,0
126,We could not find other practices associated with publication bias.,0,0,0,0,0,1
127,"Conclusions: Our results provide a more encouraging perspective of SE research than previous research: (1) ESEM publications do not seem to be strongly affected by biases and (2) we identify some practices that could be associated with p-hacking, but it is more likely that they are related to the conduction of exploratory research.",0,0,0,0,0,1
128,Conclusions that are drawn from experiments are subject to varying degrees of uncertainty.,1,0,0,0,0,0
129,"For example, they might rely on small data sets, employ statistical techniques that make assumptions that are hard to verify, or there may be unknown confounding factors.",1,0,0,0,0,0
130,"In this paper we propose an alternative but complementary mechanism to explicitly incorporate these various sources of uncertainty into reasoning about empirical findings, by applying Subjective Logic.",0,1,1,0,0,0
131,"To do this we show how typical traditional results can be encoded as ""subjective opinions"" -- the building blocks of Subjective Logic.",0,1,0,0,0,0
132,We demonstrate the value of the approach by using Subjective Logic to aggregate empirical results from two large published studies that explore the relationship between programming languages and defects or failures.,0,1,0,1,0,0
133,Many companies have turned towards globally distributed software development in their quest for access to more development capacity.,1,0,0,0,0,0
134,"This paper investigates how a company onboarded distributed teams in a global project, and report experience on how to study such distributed projects.",0,1,1,0,0,0
135,Onboarding is the process of helping new team members adapt to the existing team and ways of working.,0,0,1,0,0,0
136,The goal of the studied onboarding program was to integrate Portuguese developers into two existing Norwegian teams.,0,0,1,0,0,0
137,"Further, due to the growing trend in utilizing globally distributed projects, and the challenge of conducting studies in distributed organizations, it is crucial to find good practices for researching such projects.",0,0,1,0,0,0
138,"We collected qualitative data from interviews, observations, Slack conversations and documents, and quantitative data on Slack activity.",0,0,0,1,0,0
139,"We report experiences on different onboarding practices and techniques, and we suggest guidelines to help other researchers conduct qualitative studies in globally distributed projects.",0,0,0,0,1,0
140,Context: Software testing plays an important role in assuring the reliability of systems.,1,0,0,0,0,0
141,Assessing the efficacy of testing remains challenging with few established test effectiveness metrics.,1,0,0,0,0,0
142,Those metrics that have been used (e.g. coverage and mutation analysis) have been criticised for insufficiently differentiating between the faults detected by tests.,1,0,0,0,0,0
143,Objective: We investigate how effective tests are at detecting different types of faults and whether some types of fault evade tests more than others.,0,1,1,0,0,0
144,Our aim is to suggest to developers specific ways in which their tests need to be improved to increase fault detection.,0,1,0,0,0,0
145,Method: We investigate seven fault types and analyse how often each goes undetected in 10 open source systems.,0,0,1,1,0,0
146,We statistically look for any relationship between the test set and faults.,0,0,0,1,0,0
147,"Results: Our results suggest that the fault detection rates of unit tests are relatively low, typically finding only about a half of all faults.",0,0,0,0,1,0
148,"In addition, conditional boundary and method call removals are less well detected by tests than other fault types.",0,0,0,0,1,0
149,Conclusions: We conclude that the testing of these open source systems needs to be improved across the board.,0,0,0,0,0,1
150,"In addition, despite boundary cases being long known to attract faults, tests covering boundaries need particular improvement.",0,0,0,0,0,1
151,"Overall, we recommend that developers do not rely only on code coverage and mutation score to measure the effectiveness of their tests.",0,0,0,0,0,1
152,Software testing is a crucial activity to check the internal quality of a software.,1,0,0,0,0,0
153,"During testing, developers often create tests for the normal behavior of a particular functionality (e.g., was this file properly uploaded to the cloud?).",1,0,0,0,0,0
154,"However, little is known whether developers also create tests for the exceptional behavior (e.g., what happens if the network fails during the file upload?).",1,0,0,0,0,0
155,"To minimize this knowledge gap, in this paper we design and perform a mixed-method study to understand how 417 open source Java projects are testing the exceptional behavior using the JUnit and TestNG frameworks, and the AssertJ library.",0,0,0,1,0,0
156,We found that 254 (60.91%) projects have at least one test method dedicated to test the exceptional behavior.,0,0,0,0,1,0
157,We also found that the number of test methods for exceptional behavior with respect to the total number of test methods lies between 0% and 10% in 317 (76.02%) projects.,0,0,0,0,1,0
158,"Also, 239 (57.31%) projects test only up to 10% of the used exceptions in the System Under Test (SUT).",0,0,0,0,1,0
159,"When it comes to mobile apps, we found that, in general, developers pay less attention to exceptional behavior tests when compared to desktop/server and multi-platform developers.",0,0,0,0,1,0
160,"In general, we found more test methods covering custom exceptions (the ones created in the own project) when compared to standard exceptions available in the Java Development Kit (JDK) or in third-party libraries.",0,0,0,0,1,0
161,"To triangulate the results, we conduct a survey with 66 developers from the projects we study.",0,0,0,1,0,0
162,"In general, the survey results confirm our findings.",0,0,0,0,1,0
163,"In particular, the majority of the respondents agrees that developers often neglect exceptional behavior tests.",0,0,0,0,1,0
164,"As implications, our numbers might be important to alert developers that more effort should be placed on creating tests for the exceptional behavior.",0,0,0,0,0,1
165,Factors such as app stores or platform choices heavily affect functional and non-functional mobile app requirements.,1,0,0,0,0,0
166,We surveyed 45 companies and interviewed ten experts to explore how factors that impact mobile app requirements are understood by requirements engineers in the mobile app industry.,0,1,1,1,0,0
167,We observed the lack of knowledge in several areas.,0,0,0,0,1,0
168,"For instance, we observed that all practitioners were aware of data privacy concerns, however, they did not know that certain third-party libraries, usage aggregators, or advertising libraries also occasionally leak sensitive user data.",0,0,0,0,1,0
169,"Similarly, certain functional requirements may not be implementable in the absence of a third-party library that is either banned from an app store for policy violations or lacks features, for instance, missing desired features in ARKit library for iOS made practitioners turn to Android.",0,0,0,0,1,0
170,"We conclude that requirements engineers should have adequate technical experience with mobile app development as well as sufficient knowledge in areas such as privacy, security and law, in order to make informed decisions during requirements elicitation.",0,0,0,0,0,1
171,Context.,1,0,0,0,0,0
172,Developers have access to tools like Google Lighthouse to assess the performance of web apps and to guide the adoption of development best practices.,1,0,0,0,0,0
173,"However, when it comes to energy consumption of mobile web apps, these tools seem to be lacking.",1,0,0,0,0,0
174,This study investigates on the correlation between the performance scores produced by Lighthouse and the energy consumption of mobile web apps.,0,1,1,0,0,0
175,Method.,0,0,0,1,0,0
176,We design and conduct an empirical experiment where 21 real mobile web apps are (i) analyzed via the Lighthouse performance analysis tool and (ii) measured on an Android device running a software-based energy profiler.,0,0,0,1,0,0
177,"Then, we statistically assess how energy consumption correlates with the obtained performance scores and carry out an effect size estimation.",0,0,0,1,0,0
178,Results.,0,0,0,0,1,0
179,"We discover a statistically significant negative correlation between performance scores and the energy consumption of mobile web apps (with medium to large effect sizes), implying that an increase of the performance score tend to lead to a decrease of energy consumption.",0,0,0,0,1,0
180,Conclusions.,0,0,0,0,0,1
181,"We recommend developers to strive to improve the performance level of their mobile web apps, as this can also have a positive impact on their energy consumption on Android devices.",0,0,0,0,0,1
182,Open source software (OSS) communities are often able to produce high quality software comparable to proprietary software.,1,0,0,0,0,0
183,"The success of an open source software development (OSSD) community is often attributed to the underlying governance model, and a key component of these models is the decision-making (DM) process.",1,0,0,0,0,0
184,"While there have been studies on the decision-making processes publicized by OSS communities (e.g., through published process diagrams), little has been done to study decision-making processes that can be extracted using a bottom-up, data-driven approach, which can then be used to assess whether the publicized processes conform to the extracted processes.",1,0,0,0,0,0
185,"To bridge this gap, we undertook a large-scale data-driven study to understand how decisions are made in an OSSD community, using the case study of Python Enhancement Proposals (PEPs), which embody decisions made during the evolution of the Python language.",0,1,1,1,0,0
186,"Our main contributions are: (a) the design and development of a framework using information retrieval and natural language processing techniques to analyze the Python email archives (comprising 1.48 million emails), and (b) the extraction of decision-making processes that reveal activities that are neither explicitly mentioned in documentation published by the Python community nor identified in prior research work.",0,1,1,1,0,0
187,Our results provide insights into the actual decision-making process employed by the Python community.,0,0,0,0,1,0
188,Background: Little is known about the practices used for technical debt (TD) payment.,1,0,0,0,0,0
189,"The study of payment practices, as well as the reasons for not applying them, can help practitioners to control and manage TD items.",1,0,0,0,0,0
190,"Aims: To investigate, from the point of view of software practitioners, if TD items have been paid off in software projects, the practices that have been used to pay off TD and the reasons that hamper the implementation of these practices.",0,1,1,0,0,0
191,"Method: We analyzed - both quantitatively and qualitatively - a corpus of responses from a survey of 432 practitioners, from four countries, about the possibility of TD payment.",0,0,0,1,0,0
192,"Results: We found that, for most of the cases, TD items have not been eliminated from software projects.",0,0,0,0,1,0
193,"The main reasons for not paying off TD are lack of organizational interest, low priority on the debt, focus on short-term goals, cost, and lack of time.",0,0,0,0,1,0
194,"On the other hand, we identified that code refactoring, design refactoring, and update system documentation are the most used practices for TD payment.",0,0,0,0,1,0
195,"Practitioners also cited practices related to the prevention, prioritization, and creation of a favorable setting as part of TD payment initiatives.",0,0,0,0,1,0
196,Conclusion: This paper summarizes the identified practices and reasons for not paying off debt items in a map.,0,0,0,0,0,1
197,Our map reveals that the majority of payment practices are of a technical nature while the majority of reasons for not paying off debts are associated with non-technical issues.,0,0,0,0,0,1
198,Pull requests are a method to facilitate review and management of contribution in distributed software development.,1,0,0,0,0,0
199,"Software developers author commits, and present them in a pull request to be inspected by maintainers and reviewers.",1,0,0,0,0,0
200,"The success and sustainability of communities depends on ongoing contributions, but rejections decrease motivation of contributors.",1,0,0,0,0,0
201,We carried out a a qualitative study to understand the mechanisms of evaluating PRs in open source software (FOSS) communities from developers and maintainers perspective.,0,1,0,1,0,0
202,We interviewed 30 participants from five different FOSS communities.,0,0,0,1,0,0
203,"The data shows that acceptance of contributions depends not only on technical criteria, but also significantly on social and strategic aspects.",0,0,0,0,1,0
204,"This paper identifies three PR governance styles found in the studied communities: (1) protective, (2) equitable and (3) lenient.",0,0,0,0,1,0
205,Each one of these styles has its particularities.,0,0,0,0,1,0
206,"While the protective style values trustworthiness and reliability of the contributor, the lenient style believes in creating a positive and welcoming environment where contributors are mentored to evolve contributions until they meet the community standards.",0,0,0,0,1,0
207,"Despite the differences, these governance styles have a commonality, they all safeguard the quality of the software.",0,0,0,0,0,1
208,Background: Using design metrics to predict fault-prone elements of a software design can help to focus attention on classes that need redesign and more extensive testing.,1,0,0,0,0,0
209,"However, some design metrics have been pointed out to be theoretically invalid, and the usefulness of some metrics is questioned.",1,0,0,0,0,0
210,"Aim: To identify a set of object-oriented metrics that are theoretically valid, and useful for identifying fault-prone classes in a design.",0,1,1,0,0,0
211,"Method: Drawing on four well-known sets of design metrics (CK, LK, MOOD and QMOOD), we propose a consolidated set of metrics that covers many aspects of object-oriented software design.",0,0,1,0,0,0
212,"We conduct two experiments, first using a single large system and then considering successive releases of that system, to compare the usefulness of the consolidated set with the other four sets for within-project prediction of fault-prone classes.",0,0,0,1,0,0
213,"Results: Both experiments suggest the consolidated set is effective at identifying fault-prone classes, outperforming the other metric sets (though at a cost of more false alarms).",0,0,0,0,1,0
214,"Conclusion: This paper adds to knowledge about the usefulness of existing sets of design metrics for within-project defect prediction, and identifies a consolidated set of metrics that is more effective than the existing sets at identifying fault-prone classes.",0,0,0,0,0,1
215,"Background: Practitioners would like to take action based on software metrics, as long as they find them reliable.",1,0,0,0,0,0
216,"Existing literature explores how metrics can be made reliable, but remains unclear if there are other conditions necessary for a metric to be actionable.",1,0,0,0,0,0
217,"Context & Method: In the context of a European H2020 Project, we conducted a multiple case study to study metrics' use in four companies, and identified instances where these metrics influenced actions.",0,0,0,1,0,0
218,We used an online questionnaire to enquire about the project participants' views on actionable metrics.,0,0,0,1,0,0
219,"Next, we invited one participant from each company to elaborate on the identified metrics' use for taking actions and the questionnaire responses (N=17).",0,0,0,1,0,0
220,"Result: We learned that a metric that is practical, contextual, and exhibits high data quality characteristics is actionable.",0,0,0,0,1,0
221,"Even a non-actionable metric can be useful, but an actionable metric mostly requires interpretation.",0,0,0,0,1,0
222,"However, the more these metrics are simple and reflect the software development context accurately, the less interpretation required to infer actionable information from the metric.",0,0,0,0,1,0
223,Company size and project characteristics can also influence the type of metric that can be actionable.,0,0,0,0,1,0
224,Conclusion: This exploration of industry's views on actionable metrics help characterize actionable metrics in practical terms.,0,0,0,0,0,1
225,This awareness of what characteristics constitute an actionable metric can facilitate their definition and development right from the start of a software metrics program.,0,0,0,0,0,1
226,Context: Quality requirements (QRs) have a significant role in the success of software projects.,1,0,0,0,0,0
227,"In agile software development (ASD), where working software is valued over comprehensive documentation, QRs are often under-specified or not documented.",1,0,0,0,0,0
228,"Consequently, they may be handled improperly and result in degraded software quality and increased maintenance costs.",1,0,0,0,0,0
229,"Investigating the documentation of QRs in ASD, would provide evidence on existing practices, tools and aspects considered in ASD that other practitioners might utilize to improve documentation and management of QRs in ASD.",1,0,0,0,0,0
230,"Although there are some studies examining documentation in ASD, those that specifically investigate the documentation of QRs in depth are lacking.",1,0,0,0,0,0
231,"Method: we conducted a multiple case study by interviewing 15 practitioners of four ASD cases, to provide empirical evidence on documentation of QRs in ASD.",0,0,0,1,0,0
232,"We also run workshops with two of the cases, to identify important aspects that ASD practitioners consider when documenting QRs in requirements management repositories.",0,0,0,1,0,0
233,Result and conclusions: ASD companies approach documentation of QRs to fit the needs of their context.,0,0,0,0,1,0
234,"They used tools, backlogs, iterative prototypes, and artifacts such as epic, and stories to document QRs, or utilized face-face communication without documenting QRs.",0,0,0,0,1,0
235,"We observed that documentation of QRs in ASD is affected by factors such as context (e.g. product domain, and size) and the experience of practitioners.",0,0,0,0,1,0
236,"Some tools used to document QRs also enhanced customer collaboration, enabling customers report and document QRs.",0,0,0,0,1,0
237,"Aspects such as levels of abstraction, the traceability of QRs, optimal details of information of QRs and verification and validation are deemed important when documenting QRs in ASD requirements management repositories.",0,0,0,0,1,0
238,"Modelling is a fundamental activity in software engineering, which is often performed in collaboration.",1,0,0,0,0,0
239,"For this purpose, on-line tools running on the cloud are frequently used.",1,0,0,0,0,0
240,"However, recent advances in Natural Language Processing have fostered the emergence of chatbots, which are increasingly used for all sorts of software engineering tasks, including modelling.",1,0,0,0,0,0
241,"To evaluate to what extent chatbots are suitable for collaborative modelling, we conducted an experimental study with 54 participants, to evaluate the usability of a modelling chatbot called SOCIO, comparing it with the on-line tool Creately.",0,1,1,1,0,0
242,We employed a within-subjects cross-over design of 2 sequences and 2 periods.,0,0,0,1,0,0
243,"Usability was determined by attributes of efficiency, effectiveness, satisfaction and quality of the results.",0,0,0,1,0,0
244,We found that SOCIO saved time and reduced communication effort over Creately.,0,0,0,0,1,0
245,"SOCIO satisfied users to a greater extent than Creately, while in effectiveness results were similar.",0,0,0,0,1,0
246,"With respect to diagram quality, SOCIO outperformed Creately in terms of precision, while solutions with Creately had better recall and perceived success.",0,0,0,0,1,0
247,"However, in terms of accuracy and error scores, both tools were similar.",0,0,0,0,0,1
248,"We present SAVER, a new memory-error repair technique for C programs.",1,0,0,0,0,0
249,"Memory errors such as memory leak, double-free, and use-after-free are highly prevalent and fixing them requires significant effort.",1,0,0,0,0,0
250,Automated program repair techniques hold the promise of reducing this burden but the state-of-the-art is still unsatisfactory.,1,0,0,0,0,0
251,"In particular, no existing techniques are able to fix those errors in a scalable, precise, and safe way, all of which are required for a truly practical tool.",1,0,0,0,0,0
252,SAVER aims to address these shortcomings.,0,1,0,0,0,0
253,"To this end, we propose a method based on a novel representation of the program called object flow graph, which summarizes the program's heap-related behavior using static analysis.",0,0,1,0,0,0
254,We show that fixing memory errors can be formulated as a graph labeling problem over object flow graph and present an efficient algorithm.,0,0,1,0,0,0
255,"We evaluated SAVER in combination with Infer, an industrial-strength static bug-finder, and show that 74% of the reported errors can be fixed automatically for a range of open-source C programs.",0,0,0,1,1,0
256,Rust is a promising systems programming language that embraces both high-level memory safety and low-level resource manipulation.,1,0,0,0,0,0
257,"However, the dark side of Rust, unsafe Rust, leaves a large security hole as it bypasses the Rust type system in order to support low-level operations.",1,0,0,0,0,0
258,"Recently, several real-world memory corruption vulnerabilities have been discovered in Rust's standard libraries.",1,0,0,0,0,0
259,"We present XRust, a new technique that mitigates the security threat of unsafe Rust by ensuring the integrity of data flow from unsafe Rust code to safe Rust code.",0,1,1,0,0,0
260,"The cornerstone of XRust is a novel heap allocator that isolates the memory of unsafe Rust from that accessed only in safe Rust, and prevents any cross-region memory corruption.",0,0,1,0,0,0
261,Our design of XRust supports both single-and multi-threaded Rust programs.,0,0,1,0,0,0
262,Our extensive experiments on real-world Rust applications and standard libraries show that XRust is both highly efficient and effective in practice.,0,0,0,1,1,0
263,"Code injection attacks, like the one used in the high-profile 2017 Equifax breach, have become increasingly common, now ranking #1 on OWASP's list of critical web application vulnerabilities.",1,0,0,0,0,0
264,Static analyses for detecting these vulnerabilities can overwhelm developers with false positive reports.,1,0,0,0,0,0
265,"Meanwhile, most dynamic analyses rely on detecting vulnerabilities as they occur in the field, which can introduce a high performance overhead in production code.",1,0,0,0,0,0
266,This paper describes a new approach for detecting injection vulnerabilities in applications by harnessing the combined power of human developers' test suites and automated dynamic analysis.,0,1,1,0,0,0
267,"Our new approach, Rivulet, monitors the execution of developer-written functional tests in order to detect information flows that may be vulnerable to attack.",0,0,1,0,0,0
268,"Then, Rivulet uses a white-box test generation technique to repurpose those functional tests to check if any vulnerable flow could be exploited.",0,0,1,0,0,0
269,"When applied to the version of Apache Struts exploited in the 2017 Equifax attack, Rivulet quickly identifies the vulnerability, leveraging only the tests that existed in Struts at that time.",0,0,0,0,1,0
270,"We compared Rivulet to the state-of-the-art static vulnerability detector Julia on benchmarks, finding that Rivulet outperformed Julia in both false positives and false negatives.",0,0,0,1,1,0
271,We also used Rivulet to detect new vulnerabilities.,0,0,0,0,1,0
272,"According to the World Health Organization(WHO), it is estimated that approximately 1.3 billion people live with some forms of vision impairment globally, of whom 36 million are blind.",1,0,0,0,0,0
273,"Due to their disability, engaging these minority into the society is a challenging problem.",1,0,0,0,0,0
274,The recent rise of smart mobile phones provides a new solution by enabling blind users' convenient access to the information and service for understanding the world.,1,0,0,0,0,0
275,"Users with vision impairment can adopt the screen reader embedded in the mobile operating systems to read the content of each screen within the app, and use gestures to interact with the phone.",1,0,0,0,0,0
276,"However, the prerequisite of using screen readers is that developers have to add natural-language labels to the image-based components when they are developing the app.",1,0,0,0,0,0
277,"Unfortunately, more than 77% apps have issues of missing labels, according to our analysis of 10,408 Android apps.",1,0,0,0,0,0
278,Most of these issues are caused by developers' lack of awareness and knowledge in considering the minority.,1,0,0,0,0,0
279,"And even if developers want to add the labels to UI components, they may not come up with concise and clear description as most of them are of no visual issues.",1,0,0,0,0,0
280,"To overcome these challenges, we develop a deep-learning based model, called LabelDroid, to automatically predict the labels of image-based buttons by learning from large-scale commercial apps in Google Play.",0,1,1,0,0,0
281,The experimental results show that our model can make accurate predictions and the generated labels are of higher quality than that from real Android developers.,0,0,0,1,1,0
282,"Screen recordings of mobile applications are easy to obtain and capture a wealth of information pertinent to software developers (e.g., bugs or feature requests), making them a popular mechanism for crowdsourced app feedback.",1,0,0,0,0,0
283,"Thus, these videos are becoming a common artifact that developers must manage.",1,0,0,0,0,0
284,"In light of unique mobile development constraints, including swift release cycles and rapidly evolving platforms, automated techniques for analyzing all types of rich software artifacts provide benefit to mobile developers.",1,0,0,0,0,0
285,"Unfortunately, automatically analyzing screen recordings presents serious challenges, due to their graphical nature, compared to other types of (textual) artifacts.",1,0,0,0,0,0
286,"To address these challenges, this paper introduces V2S, a lightweight, automated approach for translating video recordings of Android app usages into replayable scenarios.",0,1,1,0,0,0
287,"V2S is based primarily on computer vision techniques and adapts recent solutions for object detection and image classification to detect and classify user actions captured in a video, and convert these into a replayable test scenario.",0,0,1,0,0,0
288,"We performed an extensive evaluation of V2S involving 175 videos depicting 3,534 GUI-based actions collected from users exercising features and reproducing bugs from over 80 popular Android apps.",0,0,0,1,0,0
289,"Our results illustrate that V2S can accurately replay scenarios from screen recordings, and is capable of reproducing ≈89% of our collected videos with minimal overhead.",0,0,0,0,1,0
290,A case study with three industrial partners illustrates the potential usefulness of V2S from the viewpoint of developers.,0,0,0,0,1,0
291,"When a program fails to process an input, it need not be the program code that is at fault.",1,0,0,0,0,0
292,"It can also be that the input data is faulty, for instance as result of data corruption.",1,0,0,0,0,0
293,"To get the data processed, one then has to debug the input data---that is, (1) identify which parts of the input data prevent processing, and (2) recover as much of the (valuable) input data as possible.",1,0,0,0,0,0
294,"In this paper, we present a general-purpose algorithm called ddmax that addresses these problems automatically.",0,1,1,0,0,0
295,"Through experiments, ddmax maximizes the subset of the input that can still be processed by the program, thus recovering and repairing as much data as possible; the difference between the original failing input and the ""maximized"" passing input includes all input fragments that could not be processed.",0,0,1,0,0,0
296,"To the best of our knowledge, ddmax is the first approach that fixes faults in the input data without requiring program analysis.",0,0,1,0,0,0
297,"In our evaluation, ddmax repaired about 69% of input files and recovered about 78% of data within one minute per input.",0,0,0,0,1,0
298,"Cognitive biases are hard-wired behaviors that influence developer actions and can set them on an incorrect course of action, necessitating backtracking.",1,0,0,0,0,0
299,"While researchers have found that cognitive biases occur in development tasks in controlled lab studies, we still don't know how these biases affect developers' everyday behavior.",1,0,0,0,0,0
300,"Without such an understanding, development tools and practices remain inadequate.",1,0,0,0,0,0
301,"To close this gap, we conducted a 2-part field study to examine the extent to which cognitive biases occur, the consequences of these biases on developer behavior, and the practices and tools that developers use to deal with these biases.",0,1,1,1,0,0
302,About 70% of observed actions that were reversed were associated with at least one cognitive bias.,0,0,0,0,1,0
303,"Further, even though developers recognized that biases frequently occur, they routinely are forced to deal with such issues with ad hoc processes and sub-optimal tool support.",0,0,0,0,1,0
304,As one participant (IP12) lamented: There is no salvation!,0,0,0,0,0,1
305,"Informal technology 'meetups' have become an important aspect of the software development community, engaging many thousands of practitioners on a regular basis.",1,0,0,0,0,0
306,"However, although local technology meetups are well-attended by developers, little is known about their motivations for participating, the type or usefulness of information that they acquire, and how local meetups might differ from and complement other available communication channels for software engineering information.",1,0,1,0,0,0
307,"We interviewed the leaders of technology-oriented Meetup groups, and collected quantitative information via a survey distributed to participants in technology-oriented groups.",0,1,0,1,0,0
308,"Our findings suggest that participants in these groups are primarily experienced software practitioners, who use Meetup for staying abreast of new developments, building local networks and achieving transfer of rich tacit knowledge with peers to improve their practice.",0,0,0,0,1,0
309,We also suggest that face to face meetings are useful forums for exchanging tacit knowledge and contextual information needed for software engineering practice.,0,0,0,0,0,1
310,"Smart contracts are Turing-complete programs that execute on the infrastructure of the blockchain, which often manage valuable digital assets.",1,0,0,0,0,0
311,Solidity is one of the most popular programming languages for writing smart contracts on the Ethereum platform.,1,0,0,0,0,0
312,"Like traditional programs, smart contracts may contain vulnerabilities.",1,0,0,0,0,0
313,"Unlike traditional programs, smart contracts cannot be easily patched once they are deployed.",1,0,0,0,0,0
314,It is thus important that smart contracts are tested thoroughly before deployment.,1,0,0,0,0,0
315,"In this work, we present an adaptive fuzzer for smart contracts on the Ethereum platform called sFuzz.",0,1,1,0,0,0
316,"Compared to existing Solidity fuzzers, sFuzz combines the strategy in the AFL fuzzer and an efficient lightweight multi-objective adaptive strategy targeting those hard-to-cover branches.",0,0,1,0,0,0
317,"sFuzz has been applied to more than 4 thousand smart contracts and the experimental results show that (1) sFuzz is efficient, e.g., two orders of magnitude faster than state-of-the-art tools; (2) sFuzz is effective in achieving high code coverage and discovering vulnerabilities; and (3) the different fuzzing strategies in sFuzz complement each other.",0,0,0,1,1,0
318,"As deep neural networks are increasingly being deployed in practice, their efficiency has become an important issue.",1,0,0,0,0,0
319,"While there are compression techniques for reducing the network's size, energy consumption and computational requirement, they only demonstrate empirically that there is no loss of accuracy, but lack formal guarantees of the compressed network, e.g., in the presence of adversarial examples.",1,0,0,0,0,0
320,"Existing verification techniques such as Reluplex, ReluVal, and DeepPoly provide formal guarantees, but they are designed for analyzing a single network instead of the relationship between two networks.",1,0,0,0,0,0
321,"To fill the gap, we develop a new method for differential verification of two closely related networks.",0,1,1,0,0,0
322,Our method consists of a fast but approximate forward interval analysis pass followed by a backward pass that iteratively refines the approximation until the desired property is verified.,0,0,1,0,0,0
323,We have two main innovations.,0,0,1,0,0,0
324,"During the forward pass, we exploit structural and behavioral similarities of the two networks to more accurately bound the difference between the output neurons of the two networks.",0,0,1,0,0,0
325,"Then in the backward pass, we leverage the gradient differences to more accurately compute the most beneficial refinement.",0,0,1,0,0,0
326,"Our experiments show that, compared to state-of-the-art verification tools, our method can achieve orders-of-magnitude speedup and prove many more properties than existing tools.",0,0,0,1,1,0
327,Test-based automated program repair has been a prolific field of research in software engineering in the last decade.,1,0,0,0,0,0
328,"Many approaches have indeed been proposed, which leverage test suites as a weak, but affordable, approximation to program specifications.",1,0,0,0,0,0
329,"Although the literature regularly sets new records on the number of benchmark bugs that can be fixed, several studies increasingly raise concerns about the limitations and biases of state-of-the-art approaches.",1,0,0,0,0,0
330,"For example, the correctness of generated patches has been questioned in a number of studies, while other researchers pointed out that evaluation schemes may be misleading with respect to the processing of fault localization results.",1,0,0,0,0,0
331,"Nevertheless, there is little work addressing the efficiency of patch generation, with regard to the practicality of program repair.",1,0,0,0,0,0
332,"In this paper, we fill this gap in the literature, by providing an extensive review on the efficiency of test suite based program repair.",0,1,1,1,0,0
333,"Our objective is to assess the number of generated patch candidates, since this information is correlated to (1) the strategy to traverse the search space efficiently in order to select sensical repair attempts, (2) the strategy to minimize the test effort for identifying a plausible patch, (3) as well as the strategy to prioritize the generation of a correct patch.",0,1,1,0,0,0
334,"To that end, we perform a large-scale empirical study on the efficiency, in terms of quantity of generated patch candidates of the 16 open-source repair tools for Java programs.",0,0,0,1,0,0
335,The experiments are carefully conducted under the same fault localization configurations to limit biases.,0,0,0,1,0,0
336,"Eventually, among other findings, we note that: (1) many irrelevant patch candidates are generated by changing wrong code locations; (2) however, if the search space is carefully triaged, fault localization noise has little impact on patch generation efficiency; (3) yet, current template-based repair systems, which are known to be most effective in fixing a large number of bugs, are actually least efficient as they tend to generate majoritarily irrelevant patch candidates.",0,0,0,0,1,0
337,Heterogeneous computing with field-programmable gate-arrays (FPGAs) has demonstrated orders of magnitude improvement in computing efficiency for many applications.,1,0,0,0,0,0
338,"However, the use of such platforms so far is limited to a small subset of programmers with specialized hardware knowledge.",1,0,0,0,0,0
339,"High-level synthesis (HLS) tools made significant progress in raising the level of programming abstraction from hardware programming languages to C/C++, but they usually cannot compile and generate accelerators for kernel programs with pointers, memory management, and recursion, and require manual refactoring to make them HLS-compatible.",1,0,0,0,0,0
340,"Besides, experts also need to provide heavily handcrafted optimizations to improve resource efficiency, which affects the maximum operating frequency, parallelization, and power efficiency.",1,0,0,0,0,0
341,"We propose a new dynamic invariant analysis and automated refactoring technique, called HeteroRefactor.",0,1,1,0,0,0
342,"First, HeteroRefactor monitors FPGA-specific dynamic invariants---the required bitwidth of integer and floating-point variables, and the size of recursive data structures and stacks.",0,0,1,0,0,0
343,"Second, using this knowledge of dynamic invariants, it refactors the kernel to make traditionally HLS-incompatible programs synthesizable and to optimize the accelerator's resource usage and frequency further.",0,0,1,0,0,0
344,"Third, to guarantee correctness, it selectively offloads the computation from CPU to FPGA, only if an input falls within the dynamic invariant.",0,0,1,0,0,0
345,"On average, for a recursive program of size 175 LOC, an expert FPGA programmer would need to write 185 more LOC to implement an HLS compatible version, while HeteroRefactor automates such transformation.",0,0,0,0,1,0
346,Our results on Xilinx FPGA show that HeteroRefactor minimizes BRAM by 83% and increases frequency by 42% for recursive programs; reduces BRAM by 41% through integer bitwidth reduction; and reduces DSP by 50% through floating-point precision tuning.,0,0,0,0,1,0
347,Automated Program Repair (APR) is very useful in helping developers in the process of software development and maintenance.,1,0,0,0,0,0
348,"Despite recent advances in deep learning (DL), the DL-based APR approaches still have limitations in learning bug-fixing code changes and the context of the surrounding source code of the bug-fixing code changes.",1,0,0,0,0,0
349,These limitations lead to incorrect fixing locations or fixes.,1,0,0,0,0,0
350,"In this paper, we introduce DLFix, a two-tier DL model that treats APR as code transformation learning from the prior bug fixes and the surrounding code contexts of the fixes.",0,1,1,0,0,0
351,The first layer is a tree-based RNN model that learns the contexts of bug fixes and its result is used as an additional weighting input for the second layer designed to learn the bug-fixing code transformations.,0,0,1,0,0,0
352,"We conducted several experiments to evaluate DLFix in two benchmarks: Defect4j and Bugs.jar, and a newly built bug datasets with a total of +20K real-world bugs in eight projects.",0,0,0,1,0,0
353,We compared DLFix against a total of 13 state-of-the-art pattern-based APR tools.,0,0,0,1,0,0
354,"Our results show that DLFix can auto-fix more bugs than 11 of them, and is comparable and complementary to the top two pattern-based APR tools in which there are 7 and 11 unique bugs that they cannot detect, respectively, but we can.",0,0,0,0,1,0
355,"Importantly, DLFix is fully automated and data-driven, and does not require hard-coding of bug-fixing patterns as in those tools.",0,0,1,0,0,0
356,We compared DLFix against 4 state-of-the-art deep learning based APR models.,0,0,0,1,0,0
357,DLFix is able to fix 2.5 times more bugs than the best performing baseline.,0,0,0,0,1,0
358,Existing GUI testing approaches of Android apps usually test apps from a single entry.,1,0,0,0,0,0
359,"In this way, the marginal activities far away from the default entry are difficult to be covered.",1,0,0,0,0,0
360,"The marginal activities may fail to be launched due to requiring a great number of activity transitions or involving complex user operations, leading to uneven coverage on activity components.",1,0,0,0,0,0
361,"Besides, since the test space of GUI programs is infinite, it is difficult to test activities under complete launching contexts using single-entry testing approaches.",1,0,0,0,0,0
362,"In this paper, we address these issues by constructing activity launching contexts and proposing a multiple-entry testing framework.",0,1,1,0,0,0
363,"We perform an inter-procedural, flow-, context- and path-sensitive analysis to build activity launching models and generate complete launching contexts.",0,1,1,0,0,0
364,"By activity exposing and static analysis, we could launch activities directly under various contexts without performing long event sequence on GUI.",0,0,1,0,0,0
365,"Besides, to achieve an in-depth exploration, we design an adaptive exploration framework which supports the multiple-entry exploration and dynamically assigns weights to entries in each turn.",0,0,1,0,0,0
366,"Our approach is implemented in a tool called Fax, with an activity launching strategy Faxla and an exploration strategy Faxex.",0,0,1,0,0,0
367,"The experiments on 20 real-world apps show that Faxla can cover 96.4% and successfully launch 60.6% activities, based on which Faxex further achieves a relatively 19.7% improvement on method coverage compared with the most popular tool Monkey.",0,0,0,1,1,0
368,Our tool also behaves well in revealing hidden bugs.,0,0,0,0,1,0
369,"Fax can trigger over seven hundred unique crashes, including 180 Errors and 539 Warnings, which is significantly higher than those of other tools.",0,0,0,0,1,0
370,"Among the 46 bugs reported to developers on Github, 33 have been fixed up to now.",0,0,0,0,1,0
371,Software engineering involves writing new code or editing existing code.,1,0,0,0,0,0
372,"Recent efforts have investigated the neural processes associated with reading and comprehending code --- however, we lack a thorough understanding of the human cognitive processes underlying code writing.",1,0,0,0,0,0
373,"While prose reading and writing have been studied thoroughly, that same scrutiny has not been applied to code writing.",1,0,0,0,0,0
374,"In this paper, we leverage functional brain imaging to investigate neural representations of code writing in comparison to prose writing.",0,1,1,0,0,0
375,"We present the first human study in which participants wrote code and prose while undergoing a functional magnetic resonance imaging (fMRI) brain scan, making use of a full-sized fMRI-safe QWERTY keyboard.",0,0,0,1,0,0
376,We find that code writing and prose writing are significantly dissimilar neural tasks.,0,0,0,0,1,0
377,"While prose writing entails significant left hemisphere activity associated with language, code writing involves more activations of the right hemisphere, including regions associated with attention control, working memory, planning and spatial cognition.",0,0,0,0,1,0
378,These findings are unlike existing work in which code and prose comprehension were studied.,0,0,0,0,1,0
379,"By contrast, we present the first evidence suggesting that code and prose writing are quite dissimilar at the neural level.",0,0,0,0,1,0
380,"Once a programmer knows one language, they can leverage concepts and knowledge already learned, and easily pick up another programming language.",1,0,0,0,0,0
381,But is that always the case?,1,0,0,0,0,0
382,"To understand if programmers have difficulty learning additional programming languages, we conductedan empirical study of Stack Overflow questions across 18 different programming languages.",0,1,1,1,0,0
383,We hypothesized that previous knowledge could potentially interfere with learning a new programming language.,0,0,0,0,1,0
384,"From our inspection of 450 Stack Overflow questions, we found 276 instances of interference that occurred due to faulty assumptions originating from knowledge about a different language.",0,0,0,0,1,0
385,"To understand why these difficulties occurred, we conducted semi-structured interviews with 16 professional programmers.",0,0,0,1,0,0
386,The interviews revealed that programmers make failed attempts to relate a new programming language with what they already know.,0,0,0,0,1,0
387,"Our findings inform design implications for technical authors, toolsmiths, and language designers, such as designing documentation and automated tools that reduce interference, anticipating uncommon language transitions during language design, and welcoming programmers not just into a language, but its entire ecosystem.",0,0,0,0,0,1
388,Deep Neural Networks (DNNs) are the core component of modern autonomous driving systems.,1,0,0,0,0,0
389,"To date, it is still unrealistic that a DNN will generalize correctly to all driving conditions.",1,0,0,0,0,0
390,Current testing techniques consist of offline solutions that identify adversarial or corner cases for improving the training phase.,1,0,0,0,0,0
391,"In this paper, we address the problem of estimating the confidence of DNNs in response to unexpected execution contexts with the purpose of predicting potential safety-critical misbehaviours and enabling online healing of DNN-based vehicles.",0,1,1,0,0,0
392,"Our approach SelfOracle is based on a novel concept of self-assessment oracle, which monitors the DNN confidence at runtime, to predict unsupported driving scenarios in advance.",0,0,1,0,0,0
393,"SelfOracle uses autoencoder-and time series-based anomaly detection to reconstruct the driving scenarios seen by the car, and to determine the confidence boundary between normal and unsupported conditions.",0,0,1,0,0,0
394,"In our empirical assessment, we evaluated the effectiveness of different variants of SelfOracle at predicting injected anomalous driving contexts, using DNN models and simulation environment from Udacity.",0,0,0,1,0,0
395,"Results show that, overall, SelfOracle can predict 77% misbehaviours, up to six seconds in advance, outperforming the online input validation approach of DeepRoad.",0,0,0,0,1,0
396,The sheer complexity of web applications leaves open a large attack surface of business logic.,1,0,0,0,0,0
397,"Particularly, in some scenarios, developers have to expose a portion of the logic to the client-side in order to coordinate multiple parties (e.g. merchants, client users, and third-party payment services) involved in a business process.",1,0,0,0,0,0
398,"However, such client-side code can be tampered with on the fly, leading to business logic perturbations and financial loss.",1,0,0,0,0,0
399,"Although developers become familiar with concepts that the client should never be trusted, given the size and the complexity of the client-side code that may be even incorporated from third parties, it is extremely challenging to understand and pinpoint the vulnerability.",1,0,0,0,0,0
400,"To this end, we investigate client-side business flow tampering vulnerabilities and develop a dynamic analysis based approach to automatically identifying such vulnerabilities.",0,1,1,0,0,0
401,We evaluate our technique on 200 popular real-world websites.,0,0,0,1,0,0
402,"With negligible overhead, we have successfully identified 27 unique vulnerabilities on 23 websites, such as New York Times, HBO, and YouTube, where an adversary can interrupt business logic to bypass paywalls, disable adblocker detection, earn reward points illicitly, etc.",0,0,0,0,1,0
403,Online chatting is gaining popularity and plays an increasingly significant role in software development.,1,0,0,0,0,0
404,"When discussing functionalities, developers might reveal their desired features to other developers.",1,0,0,0,0,0
405,Automated mining techniques towards retrieving feature requests from massive chat messages can benefit the requirements gathering process.,1,0,0,0,0,0
406,"But it is quite challenging to perform such techniques because detecting feature requests from dialogues requires a thorough understanding of the contextual information, and it is also extremely expensive on annotating feature-request dialogues for learning.",1,0,0,0,0,0
407,"To bridge that gap, we recast the traditional text classification task of mapping single dialog to its class into the task of determining whether two dialogues are similar or not by incorporating few-shot learning.",0,1,0,0,0,0
408,"We propose a novel approach, named FRMiner, which can detect feature-request dialogues from chat messages via deep Siamese network.",0,0,1,0,0,0
409,We design a BiLSTM-based dialog model that can learn the contextual information of a dialog in both forward and reverse directions.,0,0,1,0,0,0
410,"Evaluation on the real-world projects shows that our approach achieves average precision, recall and F1-score of 88.52%, 88.50% and 88.51%, which confirms that our approach could effectively detect hidden feature requests from chat messages, thus can facilitate gathering comprehensive requirements from the crowd in an automated way.",0,0,0,1,1,0
411,Data-driven defect prediction has become increasingly important in software engineering process.,1,0,0,0,0,0
412,"Since it is not uncommon that data from a software project is insufficient for training a reliable defect prediction model, transfer learning that borrows data/konwledge from other projects to facilitate the model building at the current project, namely cross-project defect prediction (CPDP), is naturally plausible.",1,0,0,0,0,0
413,"Most CPDP techniques involve two major steps, i.e., transfer learning and classification, each of which has at least one parameter to be tuned to achieve their optimal performance.",1,0,0,0,0,0
414,This practice fits well with the purpose of automated parameter optimization.,1,0,0,0,0,0
415,"However, there is a lack of thorough understanding about what are the impacts of automated parameter optimization on various CPDP techniques.",1,0,0,0,0,0
416,"In this paper, we present the first empirical study that looks into such impacts on 62 CPDP techniques, 13 of which are chosen from the existing CPDP literature while the other 49 ones have not been explored before.",0,1,1,1,0,0
417,We build defect prediction models over 20 real-world software projects that are of different scales and characteristics.,0,0,1,0,0,0
418,Our findings demonstrate that: (1) Automated parameter optimization substantially improves the defect prediction performance of 77% CPDP techniques with a manageable computational cost.,0,0,0,0,1,0
419,Thus more efforts on this aspect are required in future CPDP studies.,0,0,0,0,1,0
420,(2) Transfer learning is of ultimate importance in CPDP.,0,0,0,0,1,0
421,"Given a tight computational budget, it is more cost-effective to focus on optimizing the parameter configuration of transfer learning algorithms (3) The research on CPDP is far from mature where it is 'not difficult' to find a better alternative by making a combination of existing transfer learning and classification techniques.",0,0,0,0,1,0
422,This finding provides important insights about the future design of CPDP techniques.,0,0,0,0,0,1
423,Existing work on software patches often use features specific to a single task.,1,0,0,0,0,0
424,"These works often rely on manually identified features, and human effort is required to identify these features for each task.",1,0,0,0,0,0
425,"In this work, we propose CC2Vec, a neural network model that learns a representation of code changes guided by their accompanying log messages, which represent the semantic intent of the code changes.",0,1,1,0,0,0
426,CC2Vec models the hierarchical structure of a code change with the help of the attention mechanism and uses multiple comparison functions to identify the differences between the removed and added code.,0,0,1,0,0,0
427,"To evaluate if CC2Vec can produce a distributed representation of code changes that is general and useful for multiple tasks on software patches, we use the vectors produced by CC2Vec for three tasks: log message generation, bug fixing patch identification, and just-in-time defect prediction.",0,0,0,1,0,0
428,"In all tasks, the models using CC2Vec outperform the state-of-the-art techniques.",0,0,0,0,1,0
429,"Over the last few years, there has been substantial research on automated analysis, testing, and debugging of Ethereum smart contracts.",1,0,0,0,0,0
430,"However, it is not trivial to compare and reproduce that research.",1,0,0,0,0,0
431,"To address this, we present an empirical evaluation of 9 state-of-the-art automated analysis tools using two new datasets: i) a dataset of 69 annotated vulnerable smart contracts that can be used to evaluate the precision of analysis tools; and ii) a dataset with all the smart contracts in the Ethereum Blockchain that have Solidity source code available on Etherscan (a total of 47,518 contracts).",0,1,1,1,0,0
432,"The datasets are part of SmartBugs, a new extendable execution framework that we created to facilitate the integration and comparison between multiple analysis tools and the analysis of Ethereum smart contracts.",0,0,0,1,0,0
433,We used SmartBugs to execute the 9 automated analysis tools on the two datasets.,0,0,0,1,0,0
434,"In total, we ran 428,337 analyses that took approximately 564 days and 3 hours, being the largest experimental setup to date both in the number of tools and in execution time.",0,0,0,1,1,0
435,"We found that only 42% of the vulnerabilities from our annotated dataset are detected by all the tools, with the tool Mythril having the higher accuracy (27%).",0,0,0,0,1,0
436,"When considering the largest dataset, we observed that 97% of contracts are tagged as vulnerable, thus suggesting a considerable number of false positives.",0,0,0,0,1,0
437,"Indeed, only a small number of vulnerabilities (and of only two categories) were detected simultaneously by four or more tools.",0,0,0,0,1,0
438,"Over the past decade, deep learning (DL) has been successfully applied to many industrial domain-specific tasks.",1,0,0,0,0,0
439,"However, the current state-of-the-art DL software still suffers from quality issues, which raises great concern especially in the context of safety- and security-critical scenarios.",1,0,0,0,0,0
440,"Adversarial examples (AEs) represent a typical and important type of defects needed to be urgently addressed, on which a DL software makes incorrect decisions.",1,0,0,0,0,0
441,"Such defects occur through either intentional attack or physical-world noise perceived by input sensors, potentially hindering further industry deployment.",1,0,0,0,0,0
442,The intrinsic uncertainty nature of deep learning decisions can be a fundamental reason for its incorrect behavior.,1,0,0,0,0,0
443,"Although some testing, adversarial attack and defense techniques have been recently proposed, it still lacks a systematic study to uncover the relationship between AEs and DL uncertainty.",1,0,0,0,0,0
444,"In this paper, we conduct a large-scale study towards bridging this gap.",0,1,1,0,0,0
445,"We first investigate the capability of multiple uncertainty metrics in differentiating benign examples (BEs) and AEs, which enables to characterize the uncertainty patterns of input data.",0,0,1,0,0,0
446,"Then, we identify and categorize the uncertainty patterns of BEs and AEs, and find that while BEs and AEs generated by existing methods do follow common uncertainty patterns, some other uncertainty patterns are largely missed.",0,0,1,0,0,0
447,"Based on this, we propose an automated testing technique to generate multiple types of uncommon AEs and BEs that are largely missed by existing techniques.",0,0,1,0,0,0
448,Our further evaluation reveals that the uncommon data generated by our method is hard to be defended by the existing defense techniques with the average defense success rate reduced by 35%.,0,0,0,1,1,0
449,Our results call for attention and necessity to generate more diverse data for evaluating quality assurance solutions of DL software.,0,0,0,0,0,1
450,"In Continuous Integration (CI), regression testing is constrained by the time between commits.",1,0,0,0,0,0
451,This demands for careful selection and/or prioritization of test cases within test suites too large to be run entirely.,1,0,0,0,0,0
452,"To this aim, some Machine Learning (ML) techniques have been proposed, as an alternative to deterministic approaches.",1,0,0,0,0,0
453,"Two broad strategies for ML-based prioritization are learning-to-rank and what we call ranking-to-learn (i.e., reinforcement learning).",1,0,0,0,0,0
454,Various ML algorithms can be applied in each strategy.,1,0,0,0,0,0
455,"In this paper we introduce ten of such algorithms for adoption in CI practices, and perform a comprehensive study comparing them against each other using subjects from the Apache Commons project.",0,1,1,1,0,0
456,We analyze the influence of several features of the code under test and of the test process.,0,1,1,0,0,0
457,The results allow to draw criteria to support testers in selecting and tuning the technique that best fits their context.,0,0,0,0,1,0
458,Black-box testing has been extensively applied to test models of Cyber-Physical systems (CPS) since these models are not often amenable to static and symbolic testing and verification.,1,0,0,0,0,0
459,"Black-box testing, however, requires to execute the model under test for a large number of candidate test inputs.",1,0,0,0,0,0
460,"This poses a challenge for a large and practically-important category of CPS models, known as compute-intensive CPS (CI-CPS) models, where a single simulation may take hours to complete.",1,0,0,0,0,0
461,"We propose a novel approach, namely ARIsTEO, to enable effective and efficient testing of CI-CPS models.",0,1,1,0,0,0
462,Our approach embeds black-box testing into an iterative approximation-refinement loop.,0,0,1,0,0,0
463,"At the start, some sampled inputs and outputs of the CI-CPS model under test are used to generate a surrogate model that is faster to execute and can be subjected to black-box testing.",0,0,1,0,0,0
464,Any failure-revealing test identified for the surrogate model is checked on the original model.,0,0,1,0,0,0
465,"If spurious, the test results are used to refine the surrogate model to be tested again.",0,0,1,0,0,0
466,"Otherwise, the test reveals a valid failure.",0,0,1,0,0,0
467,"We evaluated ARIsTEO by comparing it with S-Taliro, an open-source and industry-strength tool for testing CPS models.",0,0,0,1,0,0
468,"Our results, obtained based on five publicly-available CPS models, show that, on average, ARIsTEO is able to find 24% more requirements violations than S-Taliro and is 31% faster than S-Taliro in finding those violations.",0,0,0,0,1,0
469,We further assessed the effectiveness and efficiency of ARIsTEO on a large industrial case study from the satellite domain.,0,0,0,1,0,0
470,"In contrast to S-Taliro, ARIsTEO successfully tested two different versions of this model and could identify three requirements violations, requiring four hours, on average, for each violation.",0,0,0,0,1,0
471,"Although the need for gender-inclusivity in software is gaining attention among SE researchers and SE practitioners, and at least one method (GenderMag) has been published to help, little has been reported on how to make such methods work in real-world settings.",1,0,0,0,0,0
472,Real-world teams are ever-mindful of the practicalities of adding new methods on top of their existing processes.,1,0,0,0,0,0
473,"For example, how can they keep the time costs viable?",1,0,0,0,0,0
474,How can they maximize impacts of using it?,1,0,0,0,0,0
475,What about controversies that can arise in talking about gender?,1,0,0,0,0,0
476,"To find out how software teams ""in the trenches"" handle these and similar questions, we collected the GenderMag-based processes of 10 real-world software teams---more than 50 people---for periods ranging from 5 months to 3.5 years.",0,0,0,1,0,0
477,"We present these teams' insights and experiences in the form of 9 practices, 2 potential pitfalls, and 2 open issues, so as to provide their insights to other real-world software teams trying to engineer gender-inclusivity into their software products.",0,0,0,0,1,0
478,Formal methods and tools have a long history of successful applications in the design of safety-critical railway products.,1,0,0,0,0,0
479,"However, most of the experiences focused on the application of a single method at once, and little work has been performed to compare the applicability of the different available frameworks to the railway context.",1,0,0,0,0,0
480,"As a result, companies willing to introduce formal methods in their development process have little guidance on the selection of tools that could fit their needs.",1,0,0,0,0,0
481,"To address this goal, this paper presents a comparison between 9 different formal tools, namely Atelier B, CADP, FDR4, NuSMV, ProB, Simulink, SPIN, UMC, and UPPAAL SMC.",0,1,1,0,0,0
482,"We performed a judgment study, involving 17 experts with experience in formal methods applied to railways.",0,0,0,1,0,0
483,"In the study, part of the experts were required to model a railway signaling problem (a moving-block train distancing system) with the different tools, and to provide feedback on their experience.",0,0,0,1,0,0
484,"The information produced was then synthesized, and the results were validated by the remaining experts.",0,0,0,1,0,0
485,"Based on the outcome of this process, we provide a synthesis that describes when to use a certain tool, and what are the problems that may be faced by modelers.",0,0,0,0,1,0
486,"Our experience shows that the different tools serve different purposes, and multiple formal methods are required to fully cover the needs of the railway system design process.",0,0,0,0,1,1
487,"Developers experience a wide range of emotions during programming tasks, which may have an impact on job performance.",1,0,0,0,0,0
488,"In this paper, we present an empirical study aimed at (i) investigating the link between emotion and progress, (ii) understanding the triggers for developers' emotions and the strategies to deal with negative ones, (iii) identifying the minimal set of non-invasive biometric sensors for emotion recognition during programming tasks.",0,1,1,1,0,0
489,Results confirm previous findings about the relation between emotions and perceived productivity.,0,0,0,0,1,0
490,"Furthermore, we show that developers' emotions can be reliably recognized using only a wristband capturing the electrodermal activity and heart-related metrics.",0,0,0,0,1,0
491,Understanding the root cause of a defect is critical to isolating and repairing buggy behavior.,1,0,0,0,0,0
492,"We present Causal Testing, a new method of root-cause analysis that relies on the theory of counterfactual causality to identify a set of executions that likely hold key causal information necessary to understand and repair buggy behavior.",0,1,1,0,0,0
493,"Using the Defects4J benchmark, we find that Causal Testing could be applied to 71% of real-world defects, and for 77% of those, it can help developers identify the root cause of the defect.",0,0,0,1,1,0
494,A controlled experiment with 37 developers shows that Causal Testing improves participants' ability to identify the cause of the defect from 80% of the time with standard testing tools to 86% of the time with Causal Testing.,0,0,0,1,1,0
495,The participants report that Causal Testing provides useful information they cannot get using tools such as JUnit.,0,0,0,0,1,0
496,"Holmes, our prototype, open-source Eclipse plugin implementation of Causal Testing, is available at http://holmes.cs.umass.edu/.",0,0,0,0,0,1
497,Deep learning (DL) applications are becoming increasingly popular.,1,0,0,0,0,0
498,Their reliabilities largely depend on the performance of DL models integrated in these applications as a central classifying module.,1,0,0,0,0,0
499,Traditional techniques need to retrain the models or rebuild and redeploy the applications for coping with unexpected conditions beyond the models' handling capabilities.,1,0,0,0,0,0
500,"In this paper, we take a fault tolerance approach, Dissector, to distinguishing those inputs that represent unexpected conditions (beyond-inputs) from normal inputs that are still within the models' handling capabilities (within-inputs), thus keeping the applications still function with expected reliabilities.",0,1,1,1,0,0
501,"The key insight of Dissector is that a DL model should interpret a within-input with increasing confidence, while a beyond-input would probably cause confused guesses in the prediction process.",0,0,1,0,0,0
502,"Dissector works in an application-specific way, adaptive to DL models used in applications, and extremely efficiently, scalable to large-size datasets from complex scenarios.",0,0,1,0,0,0
503,The experimental evaluation shows that Dissector outperformed state-of-the-art techniques in the effectiveness (AUC: avg. 0.8935 and up to 0.9894) and efficiency (runtime overhead: only 3.3--5.8 milliseconds).,0,0,0,1,1,0
504,"Besides, it also exhibited encouraging usefulness in defensing against adversarial inputs (AUC: avg. 0.9983) and improving a DL model's actual accuracy in use (up to 16% for CIFAR-100 and 20% for ImageNet).",0,0,0,0,1,0
505,"Finding bugs in commercial cyber-physical system development tools (or ""model-based design"" tools) such as MathWorks's Simulink is important in practice, as these tools are widely used to generate embedded code that gets deployed in safety-critical applications such as cars and planes.",1,0,0,0,0,0
506,Equivalence Modulo Input (EMI) based mutation is a new twist on differential testing that promises lower use of computational resources and has already been successful at finding bugs in compilers for procedural languages.,1,0,0,0,0,0
507,"To provide EMI-based mutation for differential testing of cyber-physical system (CPS) development tools, this paper develops several novel mutation techniques.",0,1,1,0,0,0
508,"These techniques deal with CPS language features that are not found in procedural languages, such as an explicit notion of execution time and zombie code, which combines properties of live and dead procedural code.",0,0,1,0,0,0
509,In our experiments the most closely related work (SLforge) found two bugs in the Simulink tool.,0,0,0,1,1,0
510,"In comparison, SLEMI found a super-set of issues, including 9 confirmed as bugs by MathWorks Support.",0,0,0,0,1,0
511,"Android apps demand high-quality test inputs, whose generation remains an open challenge.",1,0,0,0,0,0
512,"Existing techniques fall short on exploring complex app functionalities reachable only by a long, meaningful, and effective test input.",1,0,0,0,0,0
513,"Observing that such test inputs can usually be decomposed into relatively independent short use cases, this paper presents ComboDroid, a fundamentally different Android app testing framework.",0,1,1,0,0,0
514,"ComboDroid obtains use cases for manifesting a specific app functionality (either manually provided or automatically extracted), and systematically enumerates the combinations of use cases, yielding high-quality test inputs.",0,0,1,0,0,0
515,The evaluation results of ComboDroid on real-world apps are encouraging.,0,0,0,0,1,0
516,"Our fully automatic variant outperformed the best existing technique APE by covering 4.6% more code (APE only outperformed Monkey by 2.1%), and revealed four previously unknown bugs in extensively tested subjects.",0,0,0,0,1,0
517,"Our semi-automatic variant boosts the manual use cases obtained with little manual labor, achieving a comparable coverage (only 3.2% less) with a white-box human testing expert.",0,0,0,0,1,0
518,Puppet is a popular computer system configuration management tool.,1,0,0,0,0,0
519,"By providing abstractions that model system resources it allows administrators to set up computer systems in a reliable, predictable, and documented fashion.",1,0,0,0,0,0
520,Its use suffers from two potential pitfalls.,1,0,0,0,0,0
521,"First, if ordering constraints are not correctly specified whenever a Puppet resource depends on another, the non-deterministic application of resources can lead to race conditions and consequent failures.",1,0,0,0,0,0
522,"Second, if a service is not tied to its resources (through the notification construct), the system may operate in a stale state whenever a resource gets modified.",1,0,0,0,0,0
523,Such faults can degrade a computing infrastructure's availability and functionality.,1,0,0,0,0,0
524,We have developed an approach that identifies these issues through the analysis of a Puppet program and its system call trace.,0,1,1,0,0,0
525,"Specifically, a formal model for traces allows us to capture the interactions of Puppet resources with the file system.",0,1,1,0,0,0
526,"By analyzing these interactions we identify (1) resources that are related to each other (e.g., operate on the same file), and (2) resources that should act as notifiers so that changes are correctly propagated.",0,0,1,0,0,0
527,We then check the relationships from the trace's analysis against the program's dependency graph: a representation containing all the ordering constraints and notifications declared in the program.,0,0,1,0,0,0
528,"If a mismatch is detected, our system reports a potential fault.",0,0,1,0,0,0
529,"We have evaluated our method on a large set of popular Puppet modules, and discovered 92 previously unknown issues in 33 modules.",0,0,0,1,0,0
530,Performance benchmarking shows that our approach can analyze in seconds real-world configurations with a magnitude measured in thousands of lines and millions of system calls.,0,0,0,0,1,0
531,A wide range of tools exist to assist developers in creating secure software.,1,0,0,0,0,0
532,"Many of these tools, such as static analysis engines or security checkers included in compilers, use warnings to communicate security issues to developers.",1,0,0,0,0,0
533,"The effectiveness of these tools relies on developers heeding these warnings, and there are many ways in which these warnings could be displayed.",1,0,0,0,0,0
534,Johnson et al. [46] conducted qualitative research and found that warning presentation and integration are main issues.,1,0,0,0,0,0
535,"We built on Johnson et al.'s work and examined what developers want from security warnings, including what form they should take and how they should integrate into their workflow and work context.",0,1,1,0,0,0
536,"To this end, we conducted a Grounded Theory study with 14 professional software developers and 12 computer science students as well as a focus group with 7 academic researchers to gather qualitative insights.",0,0,0,1,0,0
537,"To back up the theory developed from the qualitative research, we ran a quantitative survey with 50 professional software developers.",0,0,0,1,0,0
538,Our results show that there is significant heterogeneity amongst developers and that no one warning type is preferred over all others.,0,0,0,0,1,0
539,"The context in which the warnings are shown is also highly relevant, indicating that it is likely to be beneficial if IDEs and other development tools become more flexible in their warning interactions with developers.",0,0,0,0,1,0
540,"Based on our findings, we provide concrete recommendations for both future research as well as how IDEs and other security tools can improve their interaction with developers.",0,0,0,0,0,1
541,Software defect prediction aims to automatically locate defective code modules to better focus testing resources and human effort.,1,0,0,0,0,0
542,"Typically, software defect prediction pipelines are comprised of two parts: the first extracts program features, like abstract syntax trees, by using external tools, and the second applies machine learning-based classification models to those features in order to predict defective modules.",1,0,0,0,0,0
543,"Since such approaches depend on specific feature extraction tools, machine learning classifiers have to be custom-tailored to effectively build most accurate models.",1,0,0,0,0,0
544,"To bridge the gap between deep learning and defect prediction, we propose an end-to-end framework which can directly get prediction results for programs without utilizing feature-extraction tools.",0,1,1,0,0,0
545,"To that end, we first visualize programs as images, apply the self-attention mechanism to extract image features, use transfer learning to reduce the difference in sample distributions between projects, and finally feed the image files into a pre-trained, deep learning model for defect prediction.",0,0,1,0,0,0
546,Experiments with 10 open source projects from the PROMISE dataset show that our method can improve cross-project and within-project defect prediction.,0,0,0,1,0,0
547,Our code and data pointers are available at https://zenodo.org/record/3373409#.XV0Oy5Mza35.,0,0,0,0,0,1
548,Modern JavaScript applications extensively depend on third-party libraries.,1,0,0,0,0,0
549,"Especially for the Node.js platform, vulnerabilities can have severe consequences to the security of applications, resulting in, e.g., cross-site scripting and command injection attacks.",1,0,0,0,0,0
550,"Existing static analysis tools that have been developed to automatically detect such issues are either too coarse-grained, looking only at package dependency structure while ignoring dataflow, or rely on manually written taint specifications for the most popular libraries to ensure analysis scalability.",1,0,0,0,0,0
551,"In this work, we propose a technique for automatically extracting taint specifications for JavaScript libraries, based on a dynamic analysis that leverages the existing test suites of the libraries and their available clients in the npm repository.",0,1,1,0,0,0
552,"Due to the dynamic nature of JavaScript, mapping observations from dynamic analysis to taint specifications that fit into a static analysis is non-trivial.",1,0,0,0,0,0
553,"Our main insight is that this challenge can be addressed by a combination of an access path mechanism that identifies entry and exit points, and the use of membranes around the libraries of interest.",0,0,1,0,0,0
554,We show that our approach is effective at inferring useful taint specifications at scale.,0,0,1,0,0,0
555,Our prototype tool automatically extracts 146 additional taint sinks and 7840 propagation summaries spanning 1 393 npm modules.,0,0,0,1,1,0
556,"By integrating the extracted specifications into a commercial, state-of-the-art static analysis, 136 new alerts are produced, many of which correspond to likely security vulnerabilities.",0,0,0,0,1,0
557,"Moreover, many important specifications that were originally manually written are among the ones that our tool can now extract automatically.",0,0,0,0,1,0
558,Deep Learning (DL) systems are key enablers for engineering intelligent applications due to their ability to solve complex tasks such as image recognition and machine translation.,1,0,0,0,0,0
559,"Nevertheless, using DL systems in safety- and security-critical applications requires to provide testing evidence for their dependable operation.",1,0,0,0,0,0
560,Recent research in this direction focuses on adapting testing criteria from traditional software engineering as a means of increasing confidence for their correct behaviour.,1,0,0,0,0,0
561,"However, they are inadequate in capturing the intrinsic properties exhibited by these systems.",1,0,0,0,0,0
562,"We bridge this gap by introducing DeepImportance, a systematic testing methodology accompanied by an Importance-Driven (IDC) test adequacy criterion for DL systems.",0,1,1,0,0,0
563,Applying IDC enables to establish a layer-wise functional understanding of the importance of DL system components and use this information to assess the semantic diversity of a test set.,0,0,1,0,0,0
564,"Our empirical evaluation on several DL systems, across multiple DL datasets and with state-of-the-art adversarial generation techniques demonstrates the usefulness and effectiveness of DeepImportance and its ability to support the engineering of more robust DL systems.",0,0,0,1,1,0
565,"Failure to account for human values in software (e.g., equality and fairness) can result in user dissatisfaction and negative socio-economic impact.",1,0,0,0,0,0
566,"Engineering these values in software, however, requires technical and methodological support throughout the development life cycle.",1,0,0,0,0,0
567,This paper investigates to what extent top Software Engineering (SE) conferences and journals have included research on human values in SE.,0,1,1,0,0,0
568,We investigate the prevalence of human values in recent (2015 -- 2018) publications in these top venues.,0,0,1,0,0,0
569,"We classify these publications, based on their relevance to different values, against a widely used value structure adopted from the social sciences.",0,0,0,1,0,0
570,"Our results show that: (a) only a small proportion of the publications directly consider values, classified as directly relevant publications; (b) for the majority of the values, very few or no directly relevant publications were found; and (c) the prevalence of directly relevant publications was higher in SE conferences compared to SE journals.",0,0,0,0,1,0
571,This paper shares these and other insights that may motivate future research on human values in software engineering.,0,0,0,0,0,1
572,"Research has established the wide variety of security failures in mobile apps, their consequences, and how app developers introduce or exacerbate them.",1,0,0,0,0,0
573,What is not well known is why developers do so---what is the rationale underpinning the decisions they make which eventually strengthen or weaken app security?,1,0,0,0,0,0
574,"This is all the more complicated in modern app development's increasingly diverse demographic: growing numbers of independent, solo, or small team developers who do not have the organizational structures and support that larger software development houses enjoy.",1,0,0,0,0,0
575,"Through two studies, we open the box on developer rationale, by performing a holistic analysis of the rationale underpinning various activities in which app developers engage when developing an app.",0,1,1,0,0,0
576,"The first study does so through a task-based study with app developers (N=44) incorporating six distinct tasks for which this developer demographic must take responsibility: setting up a development environment, reviewing code, seeking help, seeking testers, selecting an advertisement SDK, and software licensing.",0,0,0,1,0,0
577,"We found that, while on first glance in several activities participants seemed to prioritize security, only in the code task such prioritization was underpinned by a security rationale-indicating that development behavior perceived to be secure may only be an illusion until the box is opened on their rationale.",0,0,0,0,1,0
578,The second study confirms these findings through a wider survey of app developers (N=274) investigating to what extent they find the activities of the task-based study to affect their app's security.,0,0,0,1,0,0
579,"In line with the task-based study, we found that developers perceived actively writing code and actively using external SDKs as the only security-relevant, while similarly disregarding other activities having an impact on app security.",0,0,0,0,1,0
580,Our results suggest the need for a stronger focus on the tasks and activities surrounding the coding task - all of which need to be underpinned by a security rationale.,0,0,0,0,1,0
581,"Without such a holistic focus, developers may write ""secure code"" but not produce ""secure apps"".",0,0,0,0,0,1
582,Uncontrolled memory consumption is a kind of critical software security weaknesses.,1,0,0,0,0,0
583,It can also become a security-critical vulnerability when attackers can take control of the input to consume a large amount of memory and launch a Denial-of-Service attack.,1,0,0,0,0,0
584,"However, detecting such vulnerability is challenging, as the state-of-the-art fuzzing techniques focus on the code coverage but not memory consumption.",1,0,0,0,0,0
585,"To this end, we propose a memory usage guided fuzzing technique, named MemLock, to generate the excessive memory consumption inputs and trigger uncontrolled memory consumption bugs.",0,1,1,0,0,0
586,The fuzzing process is guided with memory consumption information so that our approach is general and does not require any domain knowledge.,0,0,1,0,0,0
587,We perform a thorough evaluation for MemLock on 14 widely-used real-world programs.,0,0,0,1,0,0
588,"Our experiment results show that MemLock substantially outperforms the state-of-the-art fuzzing techniques, including AFL, AFLfast, PerfFuzz, FairFuzz, Angora and QSYM, in discovering memory consumption bugs.",0,0,0,0,1,0
589,"During the experiments, we discovered many previously unknown memory consumption bugs and received 15 new CVEs.",0,0,0,0,1,0
590,"Self-driving cars, or Autonomous Vehicles (AVs), are increasingly becoming an integral part of our daily life.",1,0,0,0,0,0
591,"About 50 corporations are actively working on AVs, including large companies such as Google, Ford, and Intel.",1,0,0,0,0,0
592,"Some AVs are already operating on public roads, with at least one unfortunate fatality recently on record.",1,0,0,0,0,0
593,"As a result, understanding bugs in AVs is critical for ensuring their security, safety, robustness, and correctness.",1,0,0,0,0,0
594,"While previous studies have focused on a variety of domains (e.g., numerical software; machine learning; and error-handling, concurrency, and performance bugs) to investigate bug characteristics, AVs have not been studied in a similar manner.",1,0,0,0,0,0
595,"Recently, two software systems for AVs, Baidu Apollo and Autoware, have emerged as frontrunners in the open-source community and have been used by large companies and governments (e.g., Lincoln, Volvo, Ford, Intel, Hitachi, LG, and the US Department of Transportation).",1,0,0,0,0,0
596,"From these two leading AV software systems, this paper describes our investigation of 16,851 commits and 499 AV bugs and introduces our classification of those bugs into 13 root causes, 20 bug symptoms, and 18 categories of software components those bugs often affect.",0,1,1,0,0,0
597,"We identify 16 major findings from our study and draw broader lessons from them to guide the research community towards future directions in software bug detection, localization, and repair.",0,0,0,0,1,1
598,Android testing tools generate sequences of input events to exercise the state space of the app-under-test.,1,0,0,0,0,0
599,Existing search-based techniques systematically evolve a population of event sequences so as to achieve certain objectives such as maximal code coverage.,1,0,0,0,0,0
600,The hope is that the mutation of fit event sequences leads to the generation of even fitter sequences.,1,0,0,0,0,0
601,"However, the evolution of event sequences may be ineffective.",1,0,0,0,0,0
602,Our key insight is that pertinent app states which contributed to the original sequence's fitness may not be reached by a mutated event sequence.,1,0,0,0,0,0
603,The original path through the state space is truncated at the point of mutation.,1,0,0,0,0,0
604,"In this paper, we propose instead to evolve a population of states which can be captured upon discovery and resumed when needed.",0,1,1,0,0,0
605,The hope is that generating events on a fit program state leads to the transition to even fitter states.,1,0,0,0,0,0
606,"For instance, we can quickly deprioritize testing the main screen state which is visited by most event sequences, and instead focus our limited resources on testing more interesting states that are otherwise difficult to reach.",0,0,1,0,0,0
607,We call our approach time-travel testing because of this ability to travel back to any state that has been observed in the past.,0,0,1,0,0,0
608,"We implemented time-travel testing into TimeMachine, a time-travel enabled version of the successful, automated Android testing tool Monkey.",0,0,1,0,0,0
609,"In our experiments on a large number of open- and closed source Android apps, TimeMachine outperforms the state-of-the-art search-based/model-based Android testing tools Sapienz and Stoat, both in terms of coverage achieved and crashes found.",0,0,0,0,1,0
610,Just-In-Time Software Defect Prediction (JIT-SDP) is concerned with predicting whether software changes are defect-inducing or clean based on machine learning classifiers.,1,0,0,0,0,0
611,Building such classifiers requires a sufficient amount of training data that is not available at the beginning of a software project.,1,0,0,0,0,0
612,"Cross-Project (CP) JIT-SDP can overcome this issue by using data from other projects to build the classifier, achieving similar (not better) predictive performance to classifiers trained on Within-Project (WP) data.",1,0,0,0,0,0
613,"However, such approaches have never been investigated in realistic online learning scenarios, where WP software changes arrive continuously over time and can be used to update the classifiers.",1,0,0,0,0,0
614,It is unknown to what extent CP data can be helpful in such situation.,1,0,0,0,0,0
615,"In particular, it is unknown whether CP data are only useful during the very initial phase of the project when there is little WP data, or whether they could be helpful for extended periods of time.",1,0,0,0,0,0
616,This work thus provides the first investigation of when and to what extent CP data are useful for JIT-SDP in a realistic online learning scenario.,0,1,1,0,0,0
617,"For that, we develop three different CP JIT-SDP approaches that can operate in online mode and be updated with both incoming CP and WP training examples over time.",0,0,1,0,0,0
618,"We also collect 2048 commits from three software repositories being developed by a software company over the course of 9 to 10 months, and use 19,8468 commits from 10 active open source GitHub projects being developed over the course of 6 to 14 years.",0,0,0,1,0,0
619,The study shows that training classifiers with incoming CP+WP data can lead to improvements in G-mean of up to 53.90% compared to classifiers using only WP data at the initial stage of the projects.,0,0,0,0,1,0
620,"For the open source projects, which have been running for longer periods of time, using CP data to supplement WP data also helped the classifiers to reduce or prevent large drops in predictive performance that may occur over time, leading to up to around 40% better G-Mean during such periods.",0,0,0,0,1,0
621,"Such use of CP data was shown to be beneficial even after a large number of WP data were received, leading to overall G-means up to 18.5% better than those of WP classifiers.",0,0,0,0,1,0
622,"In theory, (good) documentation is an invaluable asset to any software project, as it helps stakeholders to use, understand, maintain, and evolve a system.",1,0,0,0,0,0
623,"In practice, however, documentation is generally affected by numerous shortcomings and issues, such as insufficient and inadequate content and obsolete, ambiguous information.",1,0,0,0,0,0
624,"To counter this, researchers are investigating the development of advanced recommender systems that automatically suggest high-quality documentation, useful for a given task.",1,0,0,0,0,0
625,A crucial first step is to understand what quality means for practitioners and what information is actually needed for specific tasks.,1,0,0,0,0,0
626,We present two surveys performed with 146 practitioners to investigate (i) the documentation issues they perceive as more relevant together with solutions they apply when these issues arise; and (ii) the types of documentation considered as important in different tasks.,0,1,1,1,0,0
627,Our findings can help researchers in designing the next generation of documentation recommender systems.,0,0,0,0,0,1
628,"With the growing use of DevOps tools and frameworks, there is an increased need for tools and techniques that support more than code.",1,0,0,0,0,0
629,The current state-of-the-art in static developer assistance for tools like Docker is limited to shallow syntactic validation.,1,0,0,0,0,0
630,"We identify three core challenges in the realm of learning from, understanding, and supporting developers writing DevOps artifacts: (i) nested languages in DevOps artifacts, (ii) rule mining, and (iii) the lack of semantic rule-based analysis.",0,1,0,0,0,0
631,"To address these challenges we introduce a toolset, binnacle, that enabled us to ingest 900,000 GitHub repositories.",0,1,0,0,0,0
632,"Focusing on Docker, we extracted approximately 178,000 unique Dockerfiles, and also identified a Gold Set of Dockerfiles written by Docker experts.",0,1,0,0,0,0
633,We addressed challenge (i) by reducing the number of effectively uninterpretable nodes in our ASTs by over 80% via a technique we call phased parsing.,0,0,1,0,0,0
634,"To address challenge (ii), we introduced a novel rule-mining technique capable of recovering two-thirds of the rules in a benchmark we curated.",0,0,1,0,0,0
635,"Through this automated mining, we were able to recover 16 new rules that were not found during manual rule collection.",0,0,0,0,1,0
636,"To address challenge (iii), we manually collected a set of rules for Dockerfiles from commits to the files in the Gold Set.",0,1,0,0,0,0
637,"These rules encapsulate best practices, avoid docker build failures, and improve image size and build latency.",0,1,0,0,0,0
638,"We created an analyzer that used these rules, and found that, on average, Dockerfiles on GitHub violated the rules five times more frequently than the Dockerfiles in our Gold Set.",0,0,0,0,1,0
639,We also found that industrial Dockerfiles fared no better than those sourced from GitHub.,0,0,0,0,1,0
640,"The learned rules and analyzer in binnacle can be used to aid developers in the IDE when creating Dockerfiles, and in a post-hoc fashion to identify issues in, and to improve, existing Dockerfiles.",0,0,0,0,0,1
641,"Successful cross-language clone detection could enable researchers and developers to create robust language migration tools, facilitate learning additional programming languages once one is mastered, and promote reuse of code snippets over a broader codebase.",1,0,0,0,0,0
642,"However, identifying cross-language clones presents special challenges to the clone detection problem.",1,0,0,0,0,0
643,"A lack of common underlying representation between arbitrary languages means detecting clones requires one of the following solutions: 1) a static analysis framework replicated across each targeted language with annotations matching language features across all languages, or 2) a dynamic analysis framework that detects clones based on runtime behavior.",1,0,0,0,0,0
644,"In this work, we demonstrate the feasibility of the latter solution, a dynamic analysis approach called SLACC for cross-language clone detection.",0,1,1,0,0,0
645,"Like prior clone detection techniques, we use input/output behavior to match clones, though we overcome limitations of prior work by amplifying the number of inputs and covering more data types; and as a result, achieve better clusters than prior attempts.",0,0,1,0,0,0
646,"Since clusters are generated based on input/output behavior, SLACC supports cross-language clone detection.",0,0,1,0,0,0
647,"As an added challenge, we target a static typed language, Java, and a dynamic typed language, Python.",0,0,1,0,0,0
648,"Compared to HitoshiIO, a recent clone detection tool for Java, SLACC retrieves 6 times as many clusters and has higher precision (86.7% vs. 30.7%).",0,0,0,0,1,0
649,This is the first work to perform clone detection for dynamic typed languages (precision = 87.3%) and the first to perform clone detection across languages that lack a common underlying representation (precision = 94.1%).,0,0,0,0,1,0
650,It provides a first step towards the larger goal of scalable language migration tools.,0,0,0,0,0,1
651,Software logging is widely used in practice.,1,0,0,0,0,0
652,"Logs have been used for a variety of purposes like debugging, monitoring, security compliance, and business analytics.",1,0,0,0,0,0
653,"Instead of directly invoking the standard output functions, developers usually prefer to use logging utilities (LUs) (e.g., SLF4J), which provide additional functionalities like thread-safety and verbosity level support, to instrument their source code.",1,0,0,0,0,0
654,Many of the previous research works on software logging are focused on the log printing code.,1,0,0,0,0,0
655,"There are very few works studying the use of LUs, although new LUs are constantly being introduced by companies and researchers.",1,0,0,0,0,0
656,"In this paper, we conducted a large-scale empirical study on the use of Java LUs in the wild.",0,1,1,1,0,0
657,"We analyzed the use of 3, 856 LUs from 11,194 projects in GitHub and found that many projects have complex usage patterns for LUs.",0,0,0,1,1,0
658,"For example, 75.8% of the large-sized projects have implemented their own LUs in their projects.",0,0,0,0,1,0
659,More than 50% of these projects use at least three LUs.,0,0,0,0,1,0
660,We conducted further qualitative studies to better understand and characterize the complex use of LUs.,0,0,0,1,0,0
661,"Our findings show that different LUs are used for a variety of reasons (e.g., internationalization of the log messages).",0,0,0,0,1,0
662,"Some projects develop their own LUs to satisfy project-specific logging needs (e.g., defining the logging format).",0,0,0,0,1,0
663,Multiple uses of LUs in one project are pretty common for large and very largesized projects mainly for context like enabling and configuring the logging behavior for the imported packages.,0,0,0,0,1,0
664,Interviewing with 13 industrial developers showed that our findings are also generally true for industrial projects and are considered as very helpful for them to better configure and manage the logging behavior for their projects.,0,0,0,1,1,0
665,The findings and the implications presented in this paper will be useful for developers and researchers who are interested in developing and maintaining LUs.,0,0,0,0,0,1
666,"Defects in infrastructure as code (IaC) scripts can have serious consequences, for example, creating large-scale system outages.",1,0,0,0,0,0
667,"A taxonomy of IaC defects can be useful for understanding the nature of defects, and identifying activities needed to fix and prevent defects in IaC scripts.",1,0,0,0,0,0
668,The goal of this paper is to help practitioners improve the quality of infrastructure as code (IaC) scripts by developing a defect taxonomy for IaC scripts through qualitative analysis.,0,1,1,0,0,0
669,"We develop a taxonomy of IaC defects by applying qualitative analysis on 1,448 defect-related commits collected from open source software (OSS) repositories of the Openstack organization.",0,0,1,0,0,0
670,We conduct a survey with 66 practitioners to assess if they agree with the identified defect categories included in our taxonomy.,0,0,0,1,0,0
671,"We quantify the frequency of identified defect categories by analyzing 80,425 commits collected from 291 OSS repositories spanning across 2005 to 2019.",0,0,0,1,0,0
672,"Our defect taxonomy for IaC consists of eight categories, including a category specific to IaC called idempotency (i.e., defects that lead to incorrect system provisioning when the same IaC script is executed multiple times).",0,0,0,1,0,0
673,We observe the surveyed 66 practitioners to agree most with idempotency.,0,0,0,1,0,0
674,"The most frequent defect category is configuration data i.e., providing erroneous configuration data in IaC scripts.",0,0,0,0,1,0
675,Our taxonomy and the quantified frequency of the defect categories may help in advancing the science of IaC script quality.,0,0,0,0,0,1
676,"The notion of forking has changed with the rise of distributed version control systems and social coding environments, like GitHub.",1,0,0,0,0,0
677,"Traditionally forking refers to splitting off an independent development branch (which we call hard forks); research on hard forks, conducted mostly in pre-GitHub days showed that hard forks were often seen critical as they may fragment a community Today, in social coding environments, open-source developers are encouraged to fork a project in order to contribute to the community (which we call social forks), which may have also influenced perceptions and practices around hard forks.",1,0,0,0,0,0
678,"To revisit hard forks, we identify, study, and classify 15,306 hard forks on GitHub and interview 18 owners of hard forks or forked repositories.",0,1,1,1,0,0
679,"We find that, among others, hard forks often evolve out of social forks rather than being planned deliberately and that perception about hard forks have indeed changed dramatically, seeing them often as a positive noncompetitive alternative to the original project.",0,0,0,0,1,0
680,"Rust, an emerging programming language with explosive growth, provides a robust type system that enables programmers to write memory-safe and data-race free code.",1,0,0,0,0,0
681,"To allow access to a machine's hardware and to support low-level performance optimizations, a second language, Unsafe Rust, is embedded in Rust.",1,0,0,0,0,0
682,"It contains support for operations that are difficult to statically check, such as C-style pointers for access to arbitrary memory locations and mutable global variables.",1,0,0,0,0,0
683,"When a program uses these features, the compiler is unable to statically guarantee the safety properties Rust promotes.",1,0,0,0,0,0
684,"In this work, we perform a large-scale empirical study to explore how software developers are using Unsafe Rust in real-world Rust libraries and applications.",0,1,1,1,0,0
685,"Our results indicate that software engineers use the keyword unsafe in less than 30% of Rust libraries, but more than half cannot be entirely statically checked by the Rust compiler because of Unsafe Rust hidden somewhere in a library's call chain.",0,0,0,0,1,0
686,"We conclude that although the use of the keyword unsafe is limited, the propagation of unsafeness offers a challenge to the claim of Rust as a memory-safe language.",0,0,0,0,0,1
687,"Furthermore, we recommend changes to the Rust compiler and to the central Rust repository's interface to help Rust software developers be aware of when their Rust code is unsafe.",0,0,0,0,0,1
688,"During code review, developers critically examine each others' code to improve its quality, share knowledge, and ensure conformance to coding standards.",1,0,0,0,0,0
689,"In the process, developers may have negative interpersonal interactions with their peers, which can lead to frustration and stress; these negative interactions may ultimately result in developers abandoning projects.",1,0,0,0,0,0
690,"In this mixed-methods study at one company, we surveyed 1,317 developers to characterize the negative experiences and cross-referenced the results with objective data from code review logs to predict these experiences.",0,0,1,1,0,0
691,"Our results suggest that such negative experiences, which we call ""pushback"", are relatively rare in practice, but have negative repercussions when they occur.",0,0,0,0,1,0
692,"Our metrics can predict feelings of pushback with high recall but low precision, making them potentially appropriate for highlighting interactions that may benefit from a self-intervention.",0,0,0,0,1,0
693,"Automated web testing techniques infer models from a given web app, which are used for test generation.",1,0,0,0,0,0
694,"From a testing viewpoint, such an inferred model should contain the minimal set of states that are distinct, yet, adequately cover the app's main functionalities.",1,0,0,0,0,0
695,"In practice, models inferred automatically are affected by near-duplicates, i.e., replicas of the same functional webpage differing only by small insignificant changes.",1,0,0,0,0,0
696,We present the first study of near-duplicate detection algorithms used in within app model inference.,0,1,1,0,0,0
697,"We first characterize functional near-duplicates by classifying a random sample of state-pairs, from 493k pairs of webpages obtained from over 6,000 websites, into three categories, namely clone, near-duplicate, and distinct.",0,0,1,0,0,0
698,We systematically compute thresholds that define the boundaries of these categories for each detection technique.,0,0,0,1,0,0
699,"We then use these thresholds to evaluate 10 near-duplicate detection techniques from three different domains, namely, information retrieval, web testing, and computer vision on nine open-source web apps.",0,0,0,1,0,0
700,Our study highlights the challenges posed in automatically inferring a model for any given web app.,0,0,0,0,0,1
701,"Our findings show that even with the best thresholds, no algorithm is able to accurately detect all functional near-duplicates within apps, without sacrificing coverage.",0,0,0,0,1,0
702,Deep Neural Networks (DNNs) have been widely applied in autonomous systems such as self-driving vehicles.,1,0,0,0,0,0
703,"Recently, DNN testing has been intensively studied to automatically generate adversarial examples, which inject small-magnitude perturbations into inputs to test DNNs under extreme situations.",1,0,0,0,0,0
704,"While existing testing techniques prove to be effective, particularly for autonomous driving, they mostly focus on generating digital adversarial perturbations, e.g., changing image pixels, which may never happen in the physical world.",1,0,0,0,0,0
705,"Thus, there is a critical missing piece in the literature on autonomous driving testing: understanding and exploiting both digital and physical adversarial perturbation generation for impacting steering decisions.",1,0,0,0,0,0
706,"In this paper, we propose a systematic physical-world testing approach, namely DeepBillboard, targeting at a quite common and practical driving scenario: drive-by billboards.",0,1,1,0,0,0
707,"DeepBillboard is capable of generating a robust and resilient printable adversarial billboard test, which works under dynamic changing driving conditions including viewing angle, distance, and lighting.",0,0,1,0,0,0
708,"The objective is to maximize the possibility, degree, and duration of the steering-angle errors of an autonomous vehicle driving by our generated adversarial billboard.",0,1,0,0,0,0
709,We have extensively evaluated the efficacy and robustness of DeepBillboard by conducting both experiments with digital perturbations and physical-world case studies.,0,0,0,1,0,0
710,The digital experimental results show that DeepBillboard is effective for various steering models and scenes.,0,0,0,1,1,0
711,"Furthermore, the physical case studies demonstrate that DeepBillboard is sufficiently robust and resilient for generating physical-world adversarial billboard tests for real-world driving under various weather conditions, being able to mislead the average steering angle error up to 26.44 degrees.",0,0,0,1,1,0
712,"To the best of our knowledge, this is the first study demonstrating the possibility of generating realistic and continuous physical-world tests for practical autonomous driving systems; moreover, DeepBillboard can be directly generalized to a variety of other physical entities/surfaces along the curbside, e.g., a graffiti painted on a wall.",0,0,0,0,1,1
713,"Ethereum, one of the most popular blockchain platforms, provides financial transactions like payments and auctions through smart contracts.",1,0,0,0,0,0
714,"Due to the immense interest in smart contracts in academia, the research community of smart contract security has made a significant improvement recently.",1,0,0,0,0,0
715,"Researchers have reported various security vulnerabilities in smart contracts, and developed static analysis tools and verification frameworks to detect them.",1,0,0,0,0,0
716,"However, it is unclear whether such great efforts from academia has indeed enhanced the security of smart contracts in reality.",1,0,0,0,0,0
717,"To understand the security level of smart contracts in the wild, we empirically studied 55,046 real-world Ethereum smart contracts written in Solidity, the most popular programming language used by Ethereum smart contract developers.",0,1,1,1,0,0
718,"We first examined how many well-known vulnerabilities the Solidity compiler has patched, and how frequently the Solidity team publishes compiler releases.",0,0,1,0,0,0
719,"Unfortunately, we observed that many known vulnerabilities are not yet patched, and some patches are not even sufficient to avoid their target vulnerabilities.",0,0,0,0,1,0
720,"Subsequently, we investigated whether smart contract developers use the most recent compiler with vulnerabilities patched.",0,0,1,0,0,0
721,"We reported that developers of more than 98% of real-world Solidity contracts still use older compilers without vulnerability patches, and more than 25% of the contracts are potentially vulnerable due to the missing security patches.",0,0,0,0,1,0
722,"To understand actual impacts of the missing patches, we manually investigated potentially vulnerable contracts that are detected by our static analyzer and identified common mistakes by Solidity developers, which may cause serious security issues such as financial loss.",0,0,0,1,0,0
723,We detected hundreds of vulnerable contracts and about one fourth of the vulnerable contracts are used by thousands of people.,0,0,0,0,1,0
724,"We recommend the Solidity team to make patches that resolve known vulnerabilities correctly, and developers to use the latest Solidity compiler to avoid missing security patches.",0,0,0,0,1,0
725,The PyPI ecosystem has indexed millions of Python libraries to allow developers to automatically download and install dependencies of their projects based on the specified version constraints.,1,0,0,0,0,0
726,"Despite the convenience brought by automation, version constraints in Python projects can easily conflict, resulting in build failures.",1,0,0,0,0,0
727,We refer to such conflicts as Dependency Confict (DC) issues.,1,0,0,0,0,0
728,"Although DC issues are common in Python projects, developers lack tool support to gain a comprehensive knowledge for diagnosing the root causes of these issues.",1,0,0,0,0,0
729,"In this paper, we conducted an empirical study on 235 real-world DC issues.",0,1,1,1,0,0
730,We studied the manifestation patterns and fixing strategies of these issues and found several key factors that can lead to DC issues and their regressions.,0,0,1,0,0,0
731,"Based on our findings, we designed and implemented Watchman, a technique to continuously monitor dependency conflicts for the PyPI ecosystem.",0,0,0,1,0,0
732,"In our evaluation, Watchman analyzed PyPI snapshots between 11 Jul 2019 and 16 Aug 2019, and found 117 potential DC issues.",0,0,0,1,1,0
733,We reported these issues to the developers of the corresponding projects.,0,0,0,0,0,1
734,"So far, 63 issues have been confirmed, 38 of which have been quickly fixed by applying our suggested patches.",0,0,0,0,1,1
735,"Existing intrusive test automation techniques for touch screen applications (e.g., Appium and Sikuli) are difficult to work on many closed or uncommon systems, such as a GoPro.",1,0,0,0,0,0
736,Being non-intrusive can largely extend the application scope of the test automation techniques.,1,0,0,0,0,0
737,"To this end, this paper presents RoScript, a truly non-intrusive test-script-driven robotic testing system for test automation of touch screen applications.",0,1,1,0,0,0
738,RoScript leverages visual test scripts to express GUI actions on a touch screen application and uses a physical robot to drive automated test execution.,0,0,1,0,0,0
739,"To reduce the test script creation cost, a non-intrusive computer vision based technique is also introduced in RoScript to automatically record touch screen actions into test scripts from videos of human actions on the device under test.",0,0,1,0,0,0
740,"RoScript is applicable to touch screen applications running on almost arbitrary platforms, whatever the underlying operating systems or GUI frameworks are.",0,0,1,0,0,0
741,We conducted experiments applying it to automate the testing of 21 touch screen applications on 6 different devices.,0,0,0,1,0,0
742,The results show that RoScript is highly usable.,0,0,0,0,1,0
743,"In the experiments, it successfully automated 104 test scenarios containing over 650 different GUI actions on the subject applications.",0,0,0,0,1,0
744,RoScript accurately performed GUI actions on over 90% of the test script executions and accurately recorded about 85% of human screen click actions into test code.,0,0,0,0,1,0
745,"Modern machine learning programs are often written in Python, with the main computations specified through calls to some highly optimized libraries (e.g., TensorFlow, PyTorch).",1,0,0,0,0,0
746,"How to maximize the computing efficiency of such programs is essential for many application domains, which has drawn lots of recent attention.",1,0,0,0,0,0
747,"This work points out a common limitation in existing efforts: they focus their views only on the static computation graphs specified by library APIs, but leave the influence from the hosting Python code largely unconsidered.",0,1,0,0,0,0
748,The limitation often causes them to miss the big picture and hence many important optimization opportunities.,0,1,0,0,0,0
749,This work proposes a new approach named HARP to address the problem.,0,0,1,0,0,0
750,HARP enables holistic analysis that spans across computation graphs and their hosting Python code.,0,0,1,0,0,0
751,"HARP achieves it through a set of novel techniques: analytics-conscious speculative analysis to circumvent Python complexities, a unified representation augmented computation graphs to capture all dimensions of knowledge related with the holistic analysis, and conditioned feedback mechanism to allow risk-controlled aggressive analysis.",0,0,1,0,0,0
752,Refactoring based on HARP gives 1.3--3X and 2.07X average speedups on a set of TensorFlow and PyTorch programs.,0,0,0,0,1,0
753,"In modern software development, software libraries play a crucial role in reducing software development effort and improving software quality.",1,0,0,0,0,0
754,"However, at the same time, the asynchronous upgrades of software libraries and client software projects often result in incompatibilities between different versions of libraries and client projects.",1,0,0,0,0,0
755,"When libraries evolve, it is often very challenging for library developers to maintain the so-called backward compatibility and keep all their external behavior untouched, and behavioral backward incompatibilities (BBIs) may occur.",1,0,0,0,0,0
756,"In practice, the regression test suites of library projects often fail to detect all BBIs.",1,0,0,0,0,0
757,"Therefore, in this paper, we propose DeBBI to detect BBIs via cross-project testing and analysis, i.e., using the test suites of various client projects to detect library BBIs.",0,1,1,0,0,0
758,"Since executing all the possible client projects can be extremely time consuming, DeBBI transforms the problem of cross-project BBI detection into a traditional information retrieval (IR) problem to execute the client projects with higher probability to detect BBIs earlier.",0,0,1,0,0,0
759,"Furthermore, DeBBI considers project diversity and test relevance information for even faster BBI detection.",0,0,1,0,0,0
760,The experimental results show that DeBBI can reduce the end-to-end testing time for detecting the first and average unique BBIs by 99.1% and 70.8% for JDK compared to naive cross-project BBI detection.,0,0,0,1,1,0
761,"Also, DeBBI has been applied to other popular 3rd-party libraries.",0,0,0,1,0,0
762,"To date, DeBBI has detected 97 BBI bugs with 19 already confirmed as previously unknown bugs.",0,0,0,0,1,0
763,Continuous integration (CI) is a widely used practice in modern software engineering.,1,0,0,0,0,0
764,"Unfortunately, it is also an expensive practice --- Google and Mozilla estimate their CI systems in millions of dollars.",1,0,0,0,0,0
765,"In this paper, we propose a novel approach for reducing the cost of CI.",0,1,1,0,0,0
766,The cost of CI lies in the computing power to run builds and its value mostly lies on letting developers find bugs early --- when their size is still small.,0,0,1,0,0,0
767,"Thus, we target reducing the number of builds that CI executes by still executing as many failing builds as early as possible.",0,0,1,0,0,0
768,"To achieve this goal, we propose SmartBuildSkip, a technique which predicts the first builds in a sequence of build failures and the remaining build failures separately.",0,0,1,0,0,0
769,"SmartBuildSkip is customizable, allowing developers to select different preferred trade-offs of saving many builds vs. observing build failures early.",0,0,1,0,0,0
770,"We evaluate the motivating hypothesis of SmartBuildSkip, its prediction power, and its cost savings in a realistic scenario.",0,0,0,1,0,0
771,"In its most conservative configuration, SmartBuildSkip saved a median 30% of builds by only incurring a median delay of 1 build in a median of 15% failing builds.",0,0,0,0,1,0
772,"Return-oriented programming (ROP) is an effective code-reuse attack in which short code sequences (i.e., gadgets) ending in a ret instruction are found within existing binaries and then executed by taking control of the call stack.",1,0,0,0,0,0
773,"The shadow stack, control flow integrity (CFI) and code (re)randomization are three popular techniques for protecting programs against return address overwrites.",1,0,0,0,0,0
774,"However, existing runtime rerandomization techniques operate on concrete return addresses, requiring expensive pointer tracking.",1,0,0,0,0,0
775,"By adding one level of indirection, we introduce BarRA, the first shadow stack mechanism that applies continuous runtime rerandomization to abstract return addresses for protecting their corresponding concrete return addresses (protected also by CFI), thus avoiding expensive pointer tracking.",0,1,1,0,0,0
776,"As a nice side-effect, BarRA naturally combines the shadow stack, CFI and runtime rerandomization in the same framework.",0,0,1,0,0,0
777,"The key novelty of BarRA, however, is that once some abstract return addresses are leaked, BarRA will enforce the burn-after-reading property by rerandomizing the mapping from the abstract to the concrete return address space in the order of microseconds instead of seconds required for rerandomizing a concrete return address space.",0,0,1,0,0,0
778,"As a result, BarRA can be used as a superior replacement for the shadow stack, as demonstrated by comparing both using the 19 C/C++ benchmarks in SPEC CPU2006 (totalling 2,047,447 LOC) and analyzing a proof-of-concept attack, provided that we can tolerate some slight binary code size increases (by an average of 29.44%) and are willing to use 8MB of dedicated memory for holding up to 220 return addresses (on a 64-bit platform).",0,0,0,1,1,0
779,"Under an information leakage attack (for some return addresses), the shadow stack is always vulnerable but BarRA is significantly more resilient (by reducing an attacker's success rate to 1/220 on average).",0,0,0,0,1,0
780,"In terms of the average performance overhead introduced, both are comparable: 6.09% (BarRA) vs. 5.38% (the shadow stack).",0,0,0,0,1,0
781,"Software projects are increasingly forming social-technical ecosystems within which individual projects rely on the infrastructures or functional components provided by other projects, leading to complex inter-dependencies.",1,0,0,0,0,0
782,"Through inter-project dependencies, a bug in an upstream project may have profound impact on a large number of downstream projects, resulting in cross-project bugs.",1,0,0,0,0,0
783,This emerging type of bugs has brought new challenges in bug fixing due to their unclear influence on downstream projects.,1,0,0,0,0,0
784,"In this paper, we present an approach to estimating the impact of a cross-project bug within its ecosystem by identifying the affected downstream modules (classes/methods).",0,1,1,0,0,0
785,Note that a downstream project that uses a buggy upstream function may not be affected as the usage does not satisfy the failure inducing preconditions.,1,0,0,0,0,0
786,"For a reported bug with the known root cause function and failure inducing preconditions, we first collect the candidate downstream modules that call the upstream function through an ecosystem-wide dependence analysis.",0,0,1,0,0,0
787,"Then, the paths to the call sites of the buggy upstream function are encoded as symbolic constraints.",0,0,1,0,0,0
788,"Solving the constraints, together with the failure inducing preconditions, identifies the affected downstream modules.",0,0,1,0,0,0
789,"Our evaluation of 31 existing upstream bugs on the scientific Python ecosystem containing 121 versions of 22 popular projects (with a total of 16 millions LOC) shows that the approach is highly effective: from the 25490 candidate downstream modules that invoke the buggy upstream functions, it identifies 1132 modules where the upstream bugs can be triggered, pruning 95.6% of the candidates.",0,0,0,1,1,0
790,The technique has no false negatives and an average false positive rate of 7.9%.,0,0,0,0,1,0
791,Only 49 downstream modules (out of the 1132 we found) were reported before to be affected.,0,0,0,0,1,0
792,A user's review of an app often describes the user's interactions with the app.,1,0,0,0,0,0
793,"These interactions, which we interpret as mini stories, are prominent in reviews with negative ratings.",1,0,0,0,0,0
794,"In general, a story in an app review would contain at least two types of events: user actions and associated app behaviors.",1,0,0,0,0,0
795,Being able to identify such stories would enable an app's developer in better maintaining and improving the app's functionality and enhancing user experience.,1,0,0,0,0,0
796,"We present Caspar, a method for extracting and synthesizing user-reported mini stories regarding app problems from reviews.",0,1,1,0,0,0
797,"By extending and applying natural language processing techniques, Caspar extracts ordered events from app reviews, classifies them as user actions or app problems, and synthesizes action-problem pairs.",0,0,1,0,0,0
798,Our evaluation shows that Caspar is effective in finding action-problem pairs from reviews.,0,0,0,0,1,0
799,"First, Caspar classifies the events with an accuracy of 82.0% on manually labeled data.",0,0,0,0,1,0
800,"Second, relative to human evaluators, Caspar extracts event pairs with 92.9% precision and 34.2% recall.",0,0,0,0,1,0
801,"In addition, we train an inference model on the extracted action-problem pairs that automatically predicts possible app problems for different use cases.",0,0,0,1,0,0
802,Preliminary evaluation shows that our method yields promising results.,0,0,0,0,1,0
803,Caspar illustrates the potential for a deeper understanding of app reviews and possibly other natural language artifacts arising in software engineering.,0,0,0,0,0,1
804,"Background: Despite a lot of research on the effectiveness of Pair Programming (PP), the question when it is useful or less useful remains unsettled.",1,0,0,0,0,0
805,Method: We analyze recordings of many industrial PP sessions with Grounded Theory Methodology and build on prior work that identified various phenomena related to within-session knowledge build-up and transfer.,0,0,1,1,0,0
806,We validate our findings with practitioners.,0,0,0,1,0,0
807,Result: We identify two fundamentally different types of required knowledge and explain how different constellations of knowledge gaps in these two respects lead to different session dynamics.,0,0,0,0,1,0
808,Gaps in project-specific systems knowledge are more hampering than gaps in general programming knowledge and are dealt with first and foremost in a PP session.,0,0,0,0,1,0
809,Conclusion: Partner constellations with complementary knowledge make PP a particularly effective practice.,0,0,0,0,0,1
810,"In PP sessions, differences in system understanding are more important than differences in general software development knowledge.",0,0,0,0,0,1
811,The engineering of high-quality software requirements generally relies on properties and assumptions about the environment in which the software-to-be has to operate.,1,0,0,0,0,0
812,"Such properties and assumptions, referred to as environment conditions in this paper, are highly subject to change over time or from one software variant to another.",1,0,0,0,0,0
813,"As a consequence, the requirements engineered for a specific set of environment conditions may no longer be adequate, complete and consistent for another set.",1,0,0,0,0,0
814,The paper addresses this problem through a tool-supported requirements adaptation technique.,0,1,1,0,0,0
815,A goal-oriented requirements modelling framework is considered to make requirements' refinements and dependencies on environment conditions explicit.,0,0,1,0,0,0
816,"When environment conditions change, an adapted goal model is computed that is correct with respect to the new environment conditions.",0,0,1,0,0,0
817,The space of possible adaptations is not fixed a priori; the required changes are expected to meet one or more environment-independent goal(s) to be satisfied in any version of the system.,0,0,1,0,0,0
818,"The adapted goal model is generated using a new counterexample-guided learning procedure that ensures the correctness of the updated goal model, and prefers more local adaptations and more similar goal models.",0,0,1,0,0,0
819,"We present a quasi-experiment to investigate whether, and to what extent, sleep deprivation impacts the performance of novice software developers using the agile practice of test-first development (TFD).",0,1,1,1,0,0
820,"We recruited 45 undergraduates, and asked them to tackle a programming task.",0,0,0,1,0,0
821,"Among the participants, 23 agreed to stay awake the night before carrying out the task, while 22 slept normally.",0,0,0,1,0,0
822,"We analyzed the quality (i.e., the functional correctness) of the implementations delivered by the participants in both groups, their engagement in writing source code (i.e., the amount of activities performed in the IDE while tackling the programming task) and ability to apply TFD (i.e., the extent to which a participant is able to apply this practice).",0,0,0,1,0,0
823,"By comparing the two groups of participants, we found that a single night of sleep deprivation leads to a reduction of 50 percent in the quality of the implementations.",0,0,0,0,1,0
824,There is notable evidence that the developers' engagement and their prowess to apply TFD are negatively impacted.,0,0,0,0,1,0
825,Our results also show that sleep-deprived developers make more fixes to syntactic mistakes in the source code.,0,0,0,0,1,0
826,We conclude that sleep deprivation has possibly disruptive effects on software development activities.,0,0,0,0,0,1
827,The results open opportunities for improving developers' performance by integrating the study of sleep with other psycho-physiological factors in which the software engineering research community has recently taken an interest in.,0,0,0,0,0,1
828,Informal language and the absence of a standard taxonomy for software technologies make it difficult to reliably analyze technology trends on discussion forums and other on-line venues.,1,0,0,0,0,0
829,We propose an automated approach called Witt for the categorization of software technologies (an expanded version of the hypernym discovery problem).,0,1,1,0,0,0
830,"Witt takes as input a phrase describing a software technology or concept and returns a general category that describes it (e.g., integrated development environment), along with attributes that further qualify it (commercial, php, etc.).",0,0,1,0,0,0
831,"By extension, the approach enables the dynamic creation of lists of all technologies of a given type (e.g., web application frameworks).",0,0,1,0,0,0
832,"Our approach relies on Stack Overflow and Wikipedia, and involves numerous original domain adaptations and a new solution to the problem of normalizing automatically-detected hypernyms.",0,0,1,0,0,0
833,"We compared Witt with six independent taxonomy tools and found that, when applied to software terms, Witt demonstrated better coverage than all evaluated alternative solutions, without a corresponding degradation in false positive rate.",0,0,0,1,1,0
834,Continuous Integration (CI) is a popular practice where software systems are automatically compiled and tested as changes appear in the version control system of a project.,1,0,0,0,0,0
835,"Like other software artifacts, CI specifications require maintenance effort.",1,0,0,0,0,0
836,"Although there are several service providers like TRAVIS CI offering various CI features, it is unclear which features are being (mis)used.",1,0,0,0,0,0
837,"In this paper, we present a study of feature use and misuse in 9,312 open source systems that use TRAVIS CI.",0,1,1,0,0,0
838,Analysis of the features that are adopted by projects reveals that explicit deployment code is rare-48.16 percent of the studied TRAVIS CI specification code is instead associated with configuring job processing nodes.,0,0,0,0,1,0
839,"To analyze feature misuse, we propose HANSEL-an anti-pattern detection tool for TRAVIS CI specifications.",0,0,1,0,0,0
840,"We define four anti-patterns and HANSEL detects anti-patterns in the TRAVIS CI specifications of 894 projects in the corpus (9.60 percent), and achieves a recall of 82.76 percent in a sample of 100 projects.",0,0,0,1,1,0
841,"Furthermore, we propose GRETEL-an anti-pattern removal tool for TRAVIS CI specifications, which can remove 69.60 percent of the most frequently occurring antipattern automatically.",0,0,0,0,1,0
842,"Using GRETEL, we have produced 36 accepted pull requests that remove TRAVIS CI anti-patterns automatically.",0,0,0,0,1,0
843,An important question in a software economy is how to incentivize deep rather than shallow fixes.,1,0,0,0,0,0
844,A deep fix corrects the root cause of a bug instead of suppressing the symptoms.,1,0,0,0,0,0
845,This paper initiates the study of the problem of incentive design for open workflows in fixing code.,0,1,1,0,0,0
846,We model the dynamics of the software ecosystem and introduce subsumption mechanisms.,0,0,1,0,0,0
847,These mechanisms only make use of externally observable information in determining payments and promote competition between workers.,0,0,1,0,0,0
848,"We use a mean field equilibrium methodology to evaluate the performance of these mechanisms, demonstrating in simulation that subsumption mechanisms perform robustly across various environment configurations and satisfy important criteria for market design.",0,0,0,1,0,0
849,Context: The proper management of people can help software organisations to achieve higher levels of success.,1,0,0,0,0,0
850,"However, the limited attention paid to the appropriate use of theories to underpin the research in this area leaves it unclear how to deal with human aspects of software engineers, such as motivation and satisfaction.",1,0,0,0,0,0
851,Objectives: This article aims to expose what drives the motivation and satisfaction of software engineers at work.,0,1,1,0,0,0
852,Methods: A multiple case study was conducted at four software organisations in Brazil.,0,0,0,1,0,0
853,"For 11 months, data was collected using semi-structured interviews, diary studies, and document analyses.",0,0,0,1,0,0
854,"Results: The Theory of Motivation and Satisfaction of Software Engineers (TMS-SE), presented in this article, combines elements from well established theories with new findings, and translates them into the software engineering context.",0,0,0,0,1,0
855,Conclusion: The TMS-SE advances the understanding of people management in the software engineering field and presents a strong conceptual framework for future investigations in this area.,0,0,0,0,0,1
856,Dead code is a bad smell and it appears to be widespread in open-source and commercial software systems.,1,0,0,0,0,0
857,"Surprisingly, dead code has received very little empirical attention from the software engineering research community.",1,0,0,0,0,0
858,"In this paper, we present a multi-study investigation with an overarching goal to study, from the perspective of researchers and developers, when and why developers introduce dead code, howthey perceive and cope with it, and whether dead code is harmful.",0,1,1,1,0,0
859,"To this end, we conducted semi-structured interviews with software professionals and four experiments at the University of Basilicata and the College of William & Mary.",0,0,0,1,0,0
860,"The results suggest that it is worth studying dead code not only in the maintenance and evolution phases, where our results suggest that dead code is harmful, but also in the design and implementation phases.",0,0,0,0,1,0
861,Our results motivate future work to develop techniques for detecting and removing dead code and suggest that developers should avoid this smell.,0,0,0,0,0,1
862,Combinatorial testing (CT) has been proven effective in revealing the failures caused by the interaction of factors that affect the behavior of a system.,1,0,0,0,0,0
863,The theory of Minimal Failure-Causing Schema (MFS) has been proposed to isolate the cause of a failure after CT.,1,0,0,0,0,0
864,Most algorithms that aim to identify MFS focus on handling a single fault in the System Under Test (SUT).,1,0,0,0,0,0
865,"However, we argue that multiple faults are more common in practice, under which masking effects may be triggered so that some failures cannot be observed.",1,0,0,0,0,0
866,"The traditional MFS theory lacks a mechanism to handle such effects; hence, they may incorrectly isolate the MFS.",1,0,0,0,0,0
867,"To address this problem, we propose a new MFS model that takes into account multiple faults.",0,1,1,0,0,0
868,"We first formally analyze the impact of the multiple faults on existing MFS identifying algorithms, especially in situations where masking effects are triggered by multiple faults.",0,0,1,0,0,0
869,We then develop an approach that can assist traditional algorithms to better handle multiple faults.,0,0,1,0,0,0
870,"Empirical studies were conducted using several kinds of open-source software, which showed that multiple faults with masking effects do negatively affect traditional MFS identifying approaches and that our approach can help to alleviate these effects.",0,0,0,1,1,0
871,Malicious users can attack Web applications by exploiting injection vulnerabilities in the source code.,1,0,0,0,0,0
872,This work addresses the challenge of detecting injection vulnerabilities in the server-side code of Java Web applications in a scalable and effective way.,0,1,1,0,0,0
873,We propose an integrated approach that seamlessly combines security slicing with hybrid constraint solving; the latter orchestrates automata-based solving with meta-heuristic search.,0,0,1,0,0,0
874,We use static analysis to extract minimal program slices relevant to security from Web programs and to generate attack conditions.,0,0,1,0,0,0
875,We then apply hybrid constraint solving to determine the satisfiability of attack conditions and thus detect vulnerabilities.,0,0,1,0,0,0
876,"The experimental results, using a benchmark comprising a set of diverse and representative Web applications/services as well as security benchmark applications, show that our approach (implemented in the JOACO tool) is significantly more effective at detecting injection vulnerabilities than state-of-the-art approaches, achieving 98 percent recall, without producing any false alarm.",0,0,0,1,1,0
877,"We also compared the constraint solving module of our approach with state-of-the-art constraint solvers, using six different benchmark suites; our approach correctly solved the highest number of constraints (665 out of 672), without producing any incorrect result, and was the one with the least number of time-out/failing cases.",0,0,0,0,1,0
878,"In both scenarios, the execution time was practically acceptable, given the offline nature of vulnerability detection.",0,0,0,0,1,0
879,It is common practice for developers of user-facing software to transform a mock-up of a graphical user interface (GUI) into code.,1,0,0,0,0,0
880,This process takes place both at an application's inception and in an evolutionary context as GUI changes keep pace with evolving features.,1,0,0,0,0,0
881,"Unfortunately, this practice is challenging and time-consuming.",1,0,0,0,0,0
882,"In this paper, we present an approach that automates this process by enabling accurate prototyping of GUIs via three tasks: detection, classification, and assembly.",0,1,1,0,0,0
883,"First, logical components of a GUI are detected from a mock-up artifact using either computer vision techniques or mock-up metadata.",0,0,1,0,0,0
884,"Then, software repository mining, automated dynamic analysis, and deep convolutional neural networks are utilized to accurately classify GUI-components into domain-specific types (e.g., toggle-button).",0,0,1,0,0,0
885,"Finally, a data-driven, K-nearest-neighbors algorithm generates a suitable hierarchical GUI structure from which a prototype application can be automatically assembled.",0,0,1,0,0,0
886,We implemented this approach for Android in a system called ReDraw.,0,0,0,1,0,0
887,Our evaluation illustrates that ReDraw achieves an average GUI-component classification accuracy of 91 percent and assembles prototype applications that closely mirror target mock-ups in terms of visual affinity while exhibiting reasonable code structure.,0,0,0,0,1,0
888,Interviews with industrial practitioners illustrate ReDraw's potential to improve real development workflows.,0,0,0,1,1,0
889,"Conventional wisdom on model transformations in Model-Driven Engineering (MDE) suggests that they are crucial components in modeling environments to achieve superior automation, whether it be refactoring, simulation, or code generation.",1,0,0,0,0,0
890,"While their relevance is well-accepted, model transformations are challenging to design, implement, and verify because of the inherent complexity that they must encode.",1,0,0,0,0,0
891,"Thus, defining transformations by chaining existing ones is key to success for enhancing their reusability.",1,0,0,0,0,0
892,"This paper proposes an approach, based on well-established algorithms, to support modellers when multiple transformation chains are available to bridge a source metamodel with a target one.",0,1,1,0,0,0
893,The all-important goal of selecting the optimal chain has been based on the quality criteria of coverage and information loss.,0,0,1,0,0,0
894,The feasibility of the approach has been demonstrated by means of experiments operated on chains obtained from transformations borrowed from a publicly available repository.,0,0,0,1,0,0
895,Context: Software is an important part in safety-critical system (SCS) development since it is becoming a major source of hazards.,1,0,0,0,0,0
896,Requirements-related hazards have been associated with many accidents and safety incidents.,1,0,0,0,0,0
897,"Requirements issues tend to be mitigated in companies with high processes maturity levels since they do their business in a systematic, consistent and proactive approach.",1,0,0,0,0,0
898,"However, requirements engineers need systematic guidance to consider safety concerns early in the development process.",1,0,0,0,0,0
899,Goal: the paper investigates which safety practices are suitable to be used in the Requirements Engineering (RE) process for SCS and how to design a safety maturity model for this area.,0,1,1,0,0,0
900,"Method: we followed the design science methodology to propose Uni-REPM SCS, a safety module for Unified Requirements Engineering Process Maturity Model (Uni-REPM).",0,0,0,1,0,0
901,"We also conducted a static validation with two practitioners and nine academic experts to evaluate its coverage, correctness, usefulness, and applicability.",0,0,0,1,0,0
902,"Results: The module has seven main processes, fourteen sub-processes and 148 practices that form the basis of safety processes maturity.",0,0,0,0,1,0
903,"Moreover, we describe its usage through a tool.",0,0,0,0,1,0
904,Conclusions: The validation indicates a good coverage of practices and well receptivity by the experts.,0,0,0,0,0,1
905,"Finally, the module can help companies in evaluating their current practices.",0,0,0,0,0,1
906,"Critical systems that integrate software components (e.g., from third-parties) need to address the risk of residual software defects in these components.",1,0,0,0,0,0
907,Software fault injection is an experimental solution to gauge such risk.,1,0,0,0,0,0
908,"Many error models have been proposed for emulating faulty components, such as by injecting error codes and exceptions, or by corrupting data with bit-flips, boundary values, and random values.",1,0,0,0,0,0
909,"Even if these error models have been able to find breaches in fragile systems, it is unclear whether these errors are in fact representative of software faults.",1,0,0,0,0,0
910,"To pursue this open question, we propose a methodology to analyze how software faults in C/C++ software components turn into errors at components' interfaces (interface error propagation), and present an experimental analysis on what, where, and when to inject interface errors.",0,1,1,1,0,0
911,"The results point out that the traditional error models, as used so far, do not accurately emulate software faults, but that richer interface errors need to be injected, by: injecting both fail-stop behaviors and data corruptions; targeting larger amounts of corrupted data structures; emulating silent data corruptions not signaled by the component; combining bit-flips, boundary values, and data perturbations.",0,0,0,0,1,0
912,"We present an empirical comparison of three test generation techniques, namely, Combinatorial Testing (CT), Random Testing (RT) and Adaptive Random Testing (ART), under different test scenarios.",0,1,1,1,0,0
913,"This is the first study in the literature to account for the (more realistic) testing setting in which the tester may not have complete information about the parameters and constraints that pertain to the system, and to account for the challenge posed by faults (in terms of failure rate).",0,0,1,0,0,0
914,Our study was conducted on nine real-world programs under a total of 1683 test scenarios (combinations of available parameter and constraint information and failure rate).,0,0,0,1,0,0
915,The results show significant differences in the techniques' fault detection ability when faults are hard to detect (failure rates are relatively low).,0,0,0,0,1,0
916,CT performs best overall; no worse than any other in 98 percent of scenarios studied.,0,0,0,0,1,0
917,"ART enhances RT, and is comparable to CT in 96 percent of scenarios, but its computational cost can be up to 3.5 times higher than CT when the program is highly constrained.",0,0,0,0,1,0
918,"Additionally, when constraint information is unavailable for a highly-constrained program, a large random test suite is as effective as CT or ART, yet its computational cost of test generation is significantly lower than that of other techniques.",0,0,0,0,1,0
919,"This paper presents our approach to the quantitative modeling and analysis of highly (re)configurable systems, such as software product lines.",0,1,1,0,0,0
920,Different combinations of the optional features of such a system give rise to combinatorially many individual system variants.,0,0,1,0,0,0
921,"We use a formal modeling language that allows us to model systems with probabilistic behavior, possibly subject to quantitative feature constraints, and able to dynamically install, remove or replace features.",0,0,1,0,0,0
922,"More precisely, our models are defined in the probabilistic feature-oriented language QFLan, a rich domain specific language (DSL) for systems with variability defined in terms of features.",0,0,1,0,0,0
923,"QFLan specifications are automatically encoded in terms of a process algebra whose operational behavior interacts with a store of constraints, and hence allows to separate system configuration from system behavior.",0,0,1,0,0,0
924,"The resulting probabilistic configurations and behavior converge seamlessly in a semantics based on discrete-time Markov chains, thus enabling quantitative analysis.",0,0,1,0,0,0
925,"Our analysis is based on statistical model checking techniques, which allow us to scale to larger models with respect to precise probabilistic analysis techniques.",0,0,1,0,0,0
926,"The analyses we can conduct range from the likelihood of specific behavior to the expected average cost, in terms of feature attributes, of specific system variants.",0,0,1,0,0,0
927,Our approach is supported by a novel Eclipse-based tool which includes state-of-the-art DSL utilities for QFLan based on the Xtext framework as well as analysis plug-ins to seamlessly run statistical model checking analyses.,0,0,1,0,0,0
928,We provide a number of case studies that have driven and validated the development of our framework.,0,0,0,1,1,0
929,We have conducted in-depth interviews with experienced practitioners in the Safety-Critical Systems (SCS) domain in order to investigate several aspects related to requirements specification and safety analysis for SCS.,0,1,1,1,0,0
930,"We interviewed 19 practitioners from eleven SCS companies in different domains with the intention of verifying which approaches they use day-to-day, and what their perceptions are in relation to the approaches used to elicit, analyze, specify and validate safety requirements.",0,1,1,1,0,0
931,The aim of this study is to obtain an in-depth understanding of how requirements engineering is carried out in companies that develop SCS.,0,1,1,0,0,0
932,Temporal properties are important in a wide variety of domains for different purposes.,1,0,0,0,0,0
933,"For example, they can be used to avoid architectural drift in software engineering orto support the regulatory compliance of business processes.",1,0,0,0,0,0
934,"In this work, we study the understandability of three majortemporal property representations: (1) LinearTemporal Logic (LTL) is a formal and well-established logic that offers temporal operators to describe temporal properties; (2) Property Specification Patterns (PSP) are a collection of recurring temporal properties that abstract underlying formal and technical representations; (3) Event Processing Language (EPL) can be used for runtime monitoring of event streams using Complex Event Processing.",0,1,1,0,0,0
935,We conducted two controlled experiments with 216 participants in total to study the understandability of those approaches using a completely randomized design with one alternative per experimental unit.,0,0,0,1,0,0
936,"We hypothesized that PSP, as a highly abstracting pattern language, is easier to understand than LTL and EPL, and that EPL, due to separation of concerns (as one or more queries can be used to explicitly define the truth value change that an observed event pattern causes), is easier to understand than LTL.",0,0,0,0,1,0
937,We found evidence supporting our hypotheses which was statistically significant and reproducible.,0,0,0,0,1,0
938,"In Domain-Specific Modelling (DSM) the general goal is to provide Domain-Specific Modelling Languages (DSMLs) for domain users to model systems using concepts and notations they are familiar with, in their problem domain.",1,0,0,0,0,0
939,"Verifying whether a model satisfies a set of requirements is considered to be an important challenge in DSM, but is nevertheless mostly neglected.",1,0,0,0,0,0
940,"We present a solution in the form of ProMoBox, a framework that integrates the definition and verification of temporal properties in discrete-time behavioural DSMLs, whose semantics can be described as a schedule of graph rewrite rules.",0,1,1,0,0,0
941,"Thanks to the expressiveness of graph rewriting, this covers a very large class of problems.",0,0,1,0,0,0
942,"With ProMoBox, the domain user models not only the system with a DSML, but also its properties, input model, run-time state and output trace.",0,0,1,0,0,0
943,"A DSML is thus comprised of five sublanguages, which share domain-specific syntax, and are generated from a single metamodel.",0,0,1,0,0,0
944,Generic transformations to and from a verification backbone ensure that both the language engineer and the domain user are shielded from underlying notations and techniques.,0,0,1,0,0,0
945,We explicitly model the ProMoBox framework's process in the paper.,0,0,1,0,0,0
946,"Furthermore, we evaluate ProMoBox to assert that it supports the specification and verification of properties in a highly flexible and automated way.",0,0,0,1,0,0
947,"As software evolves, test suite augmentation techniques may be used to identify which part of the program needs to be tested due to code changes and how to generate these new test cases for regression testing.",1,0,0,0,0,0
948,"However, existing techniques focus exclusively on sequential software, without considering concurrent software in which multiple threads may interleave with each other during the execution and thus lead to a combinatorial explosion.",1,0,0,0,0,0
949,"To fill the gap, we propose ConTesa, the first test suite augmentation tool for concurrent software.",0,1,1,0,0,0
950,The goal is to generate new test cases capable of exercising both code changes and the thread interleavings affected by these code changes.,0,1,0,0,0,0
951,At the center of ConTesa is a two-pronged approach.,0,0,1,0,0,0
952,"First, it judiciously reuses the current test inputs while amplifying their interleaving coverage using random thread schedules.",0,0,1,0,0,0
953,"Then, it leverages an incremental symbolic execution technique to generate more test inputs and interleavings, to cover the new concurrency-related program behaviors.",0,0,1,0,0,0
954,We have implemented ConTesa and evaluated it on a set of real-world multithreaded Linux applications.,0,0,0,1,0,0
955,Our results show that it can achieve a significantly high interleaving coverage and reveal more bugs than state-of-the-art testing techniques.,0,0,0,0,1,0
956,"Dependency information (data- and/or control-dependencies) among program variables and program statements is playing crucial roles in a wide range of software-engineering activities, e.g., program slicing, information flow security analysis, debugging, code-optimization, code-reuse, code-understanding.",1,0,0,0,0,0
957,Most existing dependency analyzers focus on mainstream languages and they do not support database applications embedding queries and data-manipulation commands.,1,0,0,0,0,0
958,"The first extension to the languages for relational database management systems, proposed by Willmor et al. in 2004, suffers from the lack of precision in the analysis primarily due to its syntax-based computation and flow insensitivity.",1,0,0,0,0,0
959,Since then no significant contribution is found in this research direction.,1,0,0,0,0,0
960,"This paper extends the Abstract Interpretation framework for static dependency analysis of database applications, providing a semantics-based computation tunable with respect to precision.",0,1,1,0,0,0
961,"More specifically, we instantiate dependency computation by using various relational and non-relational abstract domains, yielding to a detailed comparative analysis with respect to precision and efficiency.",0,0,1,0,0,0
962,"Finally, we present a prototype semDDA, a semantics-based Database Dependency Analyzer integrated with various abstract domains, and we present experimental evaluation results to establish the effectiveness of our approach.",0,0,0,1,0,0
963,"We show an improvement of the precision on an average of 6 percent in the interval, 11 percent in the octagon, 21 percent in the polyhedra and 7 percent in the powerset of intervals abstract domains, as compared to their syntax-based counterpart, for the chosen set of Java Server Page (JSP)-based open-source database-driven web applications as part of the GotoCode project.",0,0,0,0,1,0
964,"As new requirements are introduced and implemented in a software system, developers must identify the set of source code classes which need to be changed.",1,0,0,0,0,0
965,"Therefore, past effort has focused on predicting the set of classes impacted by a requirement.",1,0,0,0,0,0
966,"In this paper, we introduce and evaluate a new type of information based on the intuition that the set of requirements which are associated with historical changes to a specific class are likely to exhibit semantic similarity to new requirements which impact that class.",0,1,1,0,0,0
967,This new Requirements to Requirements Set (R2RS) family of metrics captures the semantic similarity between a new requirement and the set of existing requirements previously associated with a class.,0,0,1,0,0,0
968,The aim of this paper is to present and evaluate the usefulness of R2RS metrics in predicting the set of classes impacted by a requirement.,0,1,1,0,0,0
969,"We consider 18 different R2RS metrics by combining six natural language processing techniques to measure the semantic similarity among texts (e.g., VSM) and three distribution scores to compute overall similarity (e.g., average among similarity scores).",0,0,1,0,0,0
970,"We evaluate if R2RS is useful for predicting impacted classes in combination and against four other families of metrics that are based upon temporal locality of changes, direct similarity to code, complexity metrics, and code smells.",0,0,0,1,0,0
971,"Our evaluation features five classifiers and 78 releases belonging to four large open-source projects, which result in over 700,000 candidate impacted classes.",0,0,0,1,0,0
972,Experimental results show that leveraging R2RS information increases the accuracy of predicting impacted classes practically by an average of more than 60 percent across the various classifiers and projects.,0,0,0,0,1,0
973,"Program comprehension is an important, but hard to measure cognitive process.",1,0,0,0,0,0
974,"This makes it difficult to provide suitable programming languages, tools, or coding conventions to support developers in their everyday work.",1,0,0,0,0,0
975,"Here, we explore whether functional magnetic resonance imaging (fMRI) is feasible for soundly measuring program comprehension.",0,1,1,0,0,0
976,"To this end, we observed 17 participants inside an fMRI scanner while they were comprehending source code.",0,0,0,1,0,0
977,"The results show a clear, distinct activation of five brain regions, which are related to working memory, attention, and language processing, which all fit well to our understanding of program comprehension.",0,0,0,0,1,0
978,"Furthermore, we found reduced activity in the default mode network, indicating the cognitive effort necessary for program comprehension.",0,0,0,0,1,0
979,We also observed that familiarity with Java as underlying programming language reduced cognitive effort during program comprehension.,0,0,0,0,1,0
980,"To gain confidence in the results and the method, we replicated the study with 11 new participants and largely confirmed our findings.",0,0,0,1,0,0
981,"Our results encourage us and, hopefully, others to use fMRI to observe programmers and, in the long run, answer questions, such as: How should we train programmers?",0,0,0,0,0,1
982,Can we train someone to become an excellent programmer?,0,0,0,0,0,1
983,How effective are new languages and tools for program comprehension?,0,0,0,0,0,1
984,Bounded model checking is among the most efficient techniques for the automated verification of concurrent programs.,1,0,0,0,0,0
985,"However, due to the nondeterministic thread interleavings, a large and complex formula is usually required to give an exact encoding of all possible behaviors, which significantly limits the scalability.",1,0,0,0,0,0
986,"Observing that the large formula is usually dominated by the exact encoding of the scheduling constraint, this paper proposes a novel scheduling constraint based abstraction refinement method for multi-threaded C program verification.",0,1,1,0,0,0
987,"Our method is both efficient in practice and complete in theory, which is challenging for existing techniques.",0,0,1,0,0,0
988,"To achieve this, we first proposed an effective and powerful technique which works well for nearly all benchmarks we evaluated.",0,0,1,0,0,0
989,"We have proposed the notion of Event Order Graph (EOG), and have devised two graph-based algorithms over EOG for counterexample validation and refinement generation, which can often obtain a small yet effective refinement constraint.",0,0,1,0,0,0
990,"Then, to ensure completeness, our method was enhanced with two constraint-based algorithms for counterexample validation and refinement generation.",0,0,0,1,0,0
991,Experimental results on SV-COMP 2017 benchmarks and two real-world server systems indicate that our method is promising and significantly outperforms the state-of-the-art tools.,0,0,0,1,1,0
992,We present a new method for the accurate analysis of the quality-of-service (QoS) properties of component-based systems.,0,1,1,0,0,0
993,"Our method takes as input a QoS property of interest and a high-level continuous-time Markov chain (CTMC) model of the analysed system, and refines this CTMC based on observations of the execution times of the system components.",0,0,1,0,0,0
994,The refined CTMC can then be analysed with existing probabilistic model checkers to accurately predict the value of the QoS property.,0,0,0,1,0,0
995,"The paper describes the theoretical foundation underlying this model refinement, the tool we developed to automate it, and two case studies that apply our QoS analysis method to a service-based system implemented using public web services and to an IT support system at a large university, respectively.",0,1,1,1,0,0
996,Our experiments show that traditional CTMC-based QoS analysis can produce highly inaccurate results and may lead to invalid engineering and business decisions.,0,0,0,1,1,0
997,"In contrast, our new method reduced QoS analysis errors by 84.4-89.6 percent for the service-based system and by 94.7-97 percent for the IT support system, significantly lowering the risk of such invalid decisions.",0,0,0,0,1,0
998,Developers use bug reports to triage and fix bugs.,1,0,0,0,0,0
999,"When triaging a bug report, developers must decide whether the bug report is valid (i.e., a real bug).",1,0,0,0,0,0
1000,"A large amount of bug reports are submitted every day, with many of them end up being invalid reports.",1,0,0,0,0,0
1001,Manually determining valid bug report is a difficult and tedious task.,1,0,0,0,0,0
1002,"Thus, an approach that can automatically analyze the validity of a bug report and determine whether a report is valid can help developers prioritize their triaging tasks and avoid wasting time and effort on invalid bug reports.",1,0,0,0,0,0
1003,"In this study, motivated by the above needs, we propose an approach which can determine whether a newly submitted bug report is valid.",0,1,1,0,0,0
1004,Our approach first extracts 33 features from bug reports.,0,0,1,0,0,0
1005,"The extracted features are grouped along 5 dimensions, i.e., reporter experience, collaboration network, completeness, readability and text.",0,0,1,0,0,0
1006,"Based on these features, we use a random forest classifier to identify valid bug reports.",0,0,1,0,0,0
1007,"To evaluate the effectiveness of our approach, we experiment on large-scale datasets containing a total of 560,697 bug reports from five open source projects (i.e., Eclipse, Netbeans, Mozilla, Firefox and Thunderbird).",0,0,0,1,0,0
1008,"On average, across the five datasets, our approach achieves an F1-score for valid bug reports and F1-score for invalid ones of 0.74 and 0.67, respectively.",0,0,0,0,1,0
1009,"Moreover, our approach achieves an average AUC of 0.81.",0,0,0,0,1,0
1010,"In terms of AUC and F1-scores for valid and invalid bug reports, our approach statistically significantly outperforms two baselines using features that are proposed by Zanetti et al. [104] .",0,0,0,0,1,0
1011,We also study the most important features that distinguish valid bug reports from invalid ones.,0,0,0,0,1,0
1012,We find that the textual features of a bug report and reporter's experience are the most important factors to distinguish valid bug reports from invalid ones.,0,0,0,0,1,0
1013,"Context: Families of experiments (i.e., groups of experiments with the same goal) are on the rise in Software Engineering (SE).",1,0,0,0,0,0
1014,Selecting unsuitable aggregation techniques to analyze families may undermine their potential to provide in-depth insights from experiments' results.,1,0,0,0,0,0
1015,Objectives: Identifying the techniques used to aggregate experiments' results within families in SE.,0,1,1,0,0,0
1016,Raising awareness of the importance of applying suitable aggregation techniques to reach reliable conclusions within families.,0,1,0,0,0,0
1017,Method: We conduct a systematic mapping study (SMS) to identify the aggregation techniques used to analyze families of experiments in SE.,0,0,1,1,0,0
1018,We outline the advantages and disadvantages of each aggregation technique according to mature experimental disciplines such as medicine and pharmacology.,0,1,1,0,0,0
1019,We provide preliminary recommendations to analyze and report families of experiments in view of families' common limitations with regard to joint data analysis.,0,1,1,0,0,0
1020,"Results: Several aggregation techniques have been used to analyze SE families of experiments, including Narrative synthesis, Aggregated Data (AD), Individual Participant Data (IPD) mega-trial or stratified, and Aggregation of p-values.",0,0,0,1,1,0
1021,The rationale used to select aggregation techniques is rarely discussed within families.,0,0,0,0,1,0
1022,Families of experiments are commonly analyzed with unsuitable aggregation techniques according to the literature of mature experimental disciplines.,0,0,0,0,1,0
1023,Conclusion: Data analysis' reporting practices should be improved to increase the reliability and transparency of joint results.,0,0,0,0,0,1
1024,AD and IPD stratified appear to be suitable to analyze SE families of experiments.,0,0,0,0,0,1
1025,Combinatorial testing (CT) seeks to detect potential faults caused by various interactions of factors that can influence the software systems.,1,0,0,0,0,0
1026,"When applying CT, it is a common practice to first generate a set of test cases to cover each possible interaction and then to identify the failure-inducing interaction after a failure is detected.",1,0,0,0,0,0
1027,"Although this conventional procedure is simple and forthright, we conjecture that it is not the ideal choice in practice.",1,0,0,0,0,0
1028,This is because 1) testers desire to identify the root cause of failures before all the needed test cases are generated and executed 2) the early identified failure-inducing interactions can guide the remaining test case generation so that many unnecessary and invalid test cases can be avoided.,1,0,0,0,0,0
1029,"For these reasons, we propose a novel CT framework that allows both generation and identification process to interact with each other.",0,1,1,0,0,0
1030,"As a result, both generation and identification stages will be done more effectively and efficiently.",0,0,1,0,0,0
1031,"We conducted a series of empirical studies on several open-source software, the results of which show that our framework can identify the failure-inducing interactions more quickly than traditional approaches while requiring fewer test cases.",0,0,0,1,1,0
1032,Combinatorial testing has been shown to be a very effective strategy for software testing.,1,0,0,0,0,0
1033,"After a failure is detected, the next task is to identify one or more faulty statements in the source code that have caused the failure.",1,0,0,0,0,0
1034,"In this paper, we present a fault localization approach, called BEN, which produces a ranking of statements in terms of their likelihood of being faulty by leveraging the result of combinatorial testing.",0,1,1,0,0,0
1035,BEN consists of two major phases.,0,0,1,0,0,0
1036,"In the first phase, BEN identifies a combination that is very likely to be failure-inducing.",0,0,1,0,0,0
1037,A combination is failure-inducing if it causes any test in which it appears to fail.,0,0,1,0,0,0
1038,"In the second phase, BEN takes as input a failure-inducing combination identified in the first phase and produces a ranking of statements in terms of their likelihood to be faulty.",0,0,1,0,0,0
1039,"We conducted an experiment in which our approach was applied to the Siemens suite and four real-world programs, flex, grep, gzip and sed, from Software Infrastructure Repository (SIR).",0,0,0,1,0,0
1040,The experimental results show that our approach can effectively and efficiently localize the faulty statements in these programs.,0,0,0,0,1,0
1041,"Modern software applications are adapted to different situations (e.g., memory limits, enabling/disabling features, database credentials) by changing the values of configuration options, without any source code modifications.",1,0,0,0,0,0
1042,"According to several studies, this flexibility is expensive as configuration failures represent one of the most common types of software failures.",1,0,0,0,0,0
1043,"They are also hard to debug and resolve as they require a lot of effort to detect which options are misconfigured among a large number of configuration options and values, while comprehension of the code also is hampered by sprinkling conditional checks of the values of configuration options.",1,0,0,0,0,0
1044,"Although researchers have proposed various approaches to help debug or prevent configuration failures, especially from the end users' perspective, this paper takes a step back to understand the process required by practitioners to engineer the run-time configuration options in their source code, the challenges they experience as well as best practices that they have or could adopt.",0,1,1,0,0,0
1045,"By interviewing 14 software engineering experts, followed by a large survey on 229 Java software engineers, we identified 9 major activities related to configuration engineering, 22 challenges faced by developers, and 24 expert recommendations to improve software configuration quality.",0,0,0,1,1,0
1046,"We complemented this study by a systematic literature review to enrich the experts' recommendations, and to identify possible solutions discussed and evaluated by the research community for the developers' problems and challenges.",0,0,0,1,0,0
1047,"We find that developers face a variety of challenges for all nine configuration engineering activities, starting from the creation of options, which generally is not planned beforehand and increases the complexity of a software system, to the non-trivial comprehension and debugging of configurations, and ending with the risky maintenance of configuration options, since developers avoid touching and changing configuration options in a mature system.",0,0,0,0,1,0
1048,"We also find that researchers thus far focus primarily on testing and debugging configuration failures, leaving a large range of opportunities for future work.",0,0,0,0,1,0
1049,Regression testing is performed during maintenance activities to assess whether the unchanged parts of a software behave as intended.,1,0,0,0,0,0
1050,"To reduce its cost, test case prioritization techniques can be used to schedule the execution of the available test cases to increase their ability to reveal regression faults earlier.",1,0,0,0,0,0
1051,"Optimal test ordering can be determined using various techniques, such as greedy algorithms and meta-heuristics, and optimizing multiple fitness functions, such as the average percentage of statement and branch coverage.",1,0,0,0,0,0
1052,These fitness functions condense the cumulative coverage scores achieved when incrementally running test cases in a given ordering using Area Under Curve (AUC) metrics.,1,0,0,0,0,0
1053,"In this paper, we notice that AUC metrics represent a bi-dimensional (simplified) version of the hypervolume metric, which is widely used in many-objective optimization.",0,1,0,0,0,0
1054,"Thus, we propose a Hypervolume-based Genetic Algorithm, namely HGA, to solve the Test Case Prioritization problem when using multiple test coverage criteria.",0,0,1,0,0,0
1055,"An empirical study conducted with respect to five state-of-the-art techniques shows that (i) HGA is more cost-effective, (ii) HGA improves the efficiency of Test Case Prioritization, (iii) HGA has a stronger selective pressure when dealing with more than three criteria.",0,0,0,1,1,0
1056,We introduce two complementary approaches to monitor decentralized systems.,0,1,1,0,0,0
1057,"The first approach relies on systems with a centralized specification, i.e., when the specification is written for the behavior of the entire system.",0,0,1,0,0,0
1058,"To do so, our approach introduces a data structure that (i) keeps track of the execution of an automaton (ii) has predictable parameters and size, and (iii) guarantees strong eventual consistency.",0,0,1,0,0,0
1059,The second approach defines decentralized specifications wherein multiple specifications are provided for separate parts of the system.,0,0,1,0,0,0
1060,We study two properties of decentralized specifications pertaining to monitorability and compatibility between specification and architecture.,0,1,1,0,0,0
1061,We also present a general algorithm for monitoring decentralized specifications.,0,1,1,0,0,0
1062,We map three existing algorithms to our approaches and provide a framework for analyzing their behavior.,0,1,1,0,0,0
1063,"Furthermore, we present THEMIS, a framework for designing such decentralized algorithms and simulating their behavior.",0,1,1,0,0,0
1064,We demonstrate the usage of THEMIS to compare multiple algorithms and validate the trends predicted by the analysis in two scenarios: a synthetic benchmark and the Chiron user interface.,0,1,1,1,0,0
1065,Generic programming is a key paradigm for developing reusable software components.,1,0,0,0,0,0
1066,The inherent support for generic constructs is therefore important in programming languages.,1,0,0,0,0,0
1067,"As for C++, the generic construct, templates, has been supported since the language was first released.",1,0,0,0,0,0
1068,"However, little is currently known about how C++ templates are actually used in developing real software.",1,0,0,0,0,0
1069,"In this study, we conduct an experiment to investigate the use of templates in practice.",0,1,1,1,0,0
1070,"We analyze 1,267 historical revisions of 50 open source systems, consisting of 566 million lines of C++ code, to collect the data of the practical use of templates.",0,0,0,1,0,0
1071,We perform statistical analyses on the collected data and produce many interesting results.,0,0,0,1,1,0
1072,"We uncover the following important findings: (1) templates are practically used to prevent code duplication, but this benefit is largely confined to a few highly used templates; (2) function templates do not effectively replace C-style generics, and developers with a C background do not show significant preference between the two language constructs; (3) developers seldom convert dynamic polymorphism to static polymorphism by using CRTP (Curiously Recursive Template Pattern); (4) the use of templates follows a power-law distribution in most cases, and C++ developers who prefer using templates are those without other language background; (5) C developer background seems to override C++ project guidelines.",0,0,0,0,1,0
1073,These findings are helpful not only for researchers to understand the tendency of template use but also for tool builders to implement better tools to support generic programming.,0,0,0,0,0,1
1074,"In model-driven design of embedded systems, how to generate code from high-level control models seamlessly and correctly is challenging.",1,0,0,0,0,0
1075,"This is because hybrid systems are involved with continuous evolution, discrete jumps, and the complicated entanglement between them, while code only contains discrete actions.",1,0,0,0,0,0
1076,"In this article, we investigate the code generation from Hybrid Communicating Sequential Processes (HCSP), a formal hybrid control model, to SystemC.",0,1,1,0,0,0
1077,"We first introduce the notion of approximate bisimulation as a criterion to check the consistency between two different systems, especially between the original control model and the final generated code.",0,1,1,0,0,0
1078,"We prove that it is decidable whether two HCSPs are approximately bisimilar in bounded time and unbounded time with some conditions, respectively.",0,1,1,0,0,0
1079,"For both the cases, we present two sets of rules correspondingly for discretizing HCSPs and prove that the original HCSP model and the corresponding discretization are approximately bisimilar.",0,1,1,0,0,0
1080,"Furthermore, based on the discretization, we define a transformation function to map a discretized HCSP model to SystemC code such that they are also approximately bisimilar.",0,1,1,0,0,0
1081,We finally implement a tool to automatically realize the translation from HCSP to SystemC code and illustrate our approach through some case studies.,0,1,1,1,0,0
1082,"Bug repair is a major component of software maintenance, which requires a huge amount of manpower.",1,0,0,0,0,0
1083,"Evolutionary computation, particularly genetic programming (GP), is a class of promising techniques for automating this time-consuming and expensive process.",1,0,0,0,0,0
1084,"Although recent research in evolutionary program repair has made significant progress, major challenges still remain.",1,0,0,0,0,0
1085,"In this article, we propose ARJA-e, a new evolutionary repair system for Java code that aims to address challenges for the search space, search algorithm, and patch overfitting.",0,1,1,0,0,0
1086,"To determine a search space that is more likely to contain correct patches, ARJA-e combines two sources of fix ingredients (i.e., the statement-level redundancy assumption and repair templates) with contextual analysis-based search space reduction, thereby leveraging their complementary strengths.",0,0,1,0,0,0
1087,"To encode patches in GP more properly, ARJA-e unifies the edits at different granularities into statement-level edits and then uses a lower-granularity patch representation that is characterized by the decoupling of statements for replacement and statements for insertion.",0,0,1,0,0,0
1088,"ARJA-e also uses a finer-grained fitness function that can make full use of semantic information contained in the test suite, which is expected to better guide the search of GP.",0,0,1,0,0,0
1089,"To alleviate patch overfitting, ARJA-e further includes a postprocessing tool that can serve the purposes of overfit detection and patch ranking.",0,0,1,0,0,0
1090,We evaluate ARJA-e on 224 real Java bugs from Defects4J and compare it with the state-of-the-art repair techniques.,0,0,0,1,0,0
1091,"The evaluation results show that ARJA-e can correctly fix 39 bugs in terms of the patches ranked first, achieving substantial performance improvements over the state of the art.",0,0,0,0,1,0
1092,"In addition, we analyze the effect of the components of ARJA-e qualitatively and quantitatively to demonstrate their effectiveness and advantages.",0,0,0,0,0,1
1093,"A Software Product Line (SPL) is a set of products built from a number of features, the set of valid products being defined by a feature model.",1,0,0,0,0,0
1094,"Typically, it does not make sense to test all products defined by an SPL and one instead chooses a set of products to test (test selection) and, ideally, derives a good order in which to test them (test prioritisation).",1,0,0,0,0,0
1095,"Since one cannot know in advance which products will reveal faults, test selection and prioritisation are normally based on objective functions that are known to relate to likely effectiveness or cost.",1,0,0,0,0,0
1096,"This article introduces a new technique, the grid-based evolution strategy (GrES), which considers several objective functions that assess a selection or prioritisation and aims to optimise on all of these.",0,1,1,0,0,0
1097,The problem is thus a many-objective optimisation problem.,0,0,1,0,0,0
1098,"We use a new approach, in which all of the objective functions are considered but one (pairwise coverage) is seen as the most important.",0,0,1,0,0,0
1099,We also derive a novel evolution strategy based on domain knowledge.,0,1,1,0,0,0
1100,"The results of the evaluation, on randomly generated and realistic feature models, were promising, with GrES outperforming previously proposed techniques and a range of many-objective optimisation algorithms.",0,0,0,1,1,0
1101,We address the problem of engineering a sociotechnical system (STS) with respect to its stakeholders’ requirements.,0,1,1,0,0,0
1102,"We motivate a two-tier STS conception composed of a technical tier that provides control mechanisms and describes what actions are allowed by the software components, and a social tier that characterizes the stakeholders’ expectations of each other in terms of norms.",0,1,1,0,0,0
1103,"We adopt agents as computational entities, each representing a different stakeholder.",0,1,1,0,0,0
1104,"Unlike previous approaches, our framework, DESEN, incorporates the social dimension into the formal verification process.",0,0,1,0,0,0
1105,"Thus, DESEN supports agents potentially violating applicable norms—a consequence of their autonomy.",0,0,1,0,0,0
1106,"In addition to requirements verification, DESEN supports refinement of STS specifications via design patterns to meet stated requirements.",0,0,1,0,0,0
1107,We evaluate DESEN at three levels.,0,0,0,1,0,0
1108,We illustrate how DESEN carries out refinement via the application of patterns on a hospital emergency scenario.,0,0,0,1,0,0
1109,We show via a human-subject study that a design process based on our patterns is helpful for participants who are inexperienced in conceptual modeling and norms.,0,0,0,1,1,0
1110,"We provide an agent-based environment to simulate the hospital emergency scenario to compare STS specifications (including participant solutions from the human-subject study) with metrics indicating social welfare and norm compliance, and other domain dependent metrics.",0,0,0,1,0,0
1111,Grown software systems often contain code that is not necessary anymore.,1,0,0,0,0,0
1112,"Such unnecessary code wastes resources during development and maintenance, for example, when preparing code for migration or certification.",1,0,0,0,0,0
1113,"Running a profiler may reveal code that is not used in production, but it is often time-consuming to obtain representative data in this way.",1,0,0,0,0,0
1114,"We investigate to what extent a static analysis approach, which is based on code stability and code centrality, is able to identify unnecessary code and whether its recommendations are relevant in practice.",0,1,1,0,0,0
1115,"To study the feasibility and usefulness of our approach, we conducted a study involving 14 open-source and closed-source software systems.",0,0,0,1,0,0
1116,"As there is no perfect oracle for unnecessary code, we compared recommendations for unnecessary code with historical cleanups, runtime usage data, and feedback from 25 developers of five software projects.",0,0,0,1,0,0
1117,Our study shows that recommendations generated from stability and centrality information point to unnecessary code that cannot be identified by dead code detectors.,0,0,0,0,1,0
1118,Developers confirmed that 34% of recommendations were indeed unnecessary and deleted 20% of the recommendations shortly after our interviews.,0,0,0,0,1,0
1119,"Overall, our results suggest that static analysis can provide quick feedback on unnecessary code and is useful in practice.",0,0,0,0,0,1
1120,Machine learning–based classification dominates current malware detection approaches for Android.,1,0,0,0,0,0
1121,"However, due to the evolution of both the Android platform and its user apps, existing such techniques are widely limited by their reliance on new malware samples, which may not be timely available, and constant retraining, which is often very costly.",1,0,0,0,0,0
1122,"As a result, new and emerging malware slips through, as seen from the continued surging of malware in the wild.",1,0,0,0,0,0
1123,"Thus, a more practical detector needs not only to be accurate on particular datasets but, more critically, to be able to sustain its capabilities over time without frequent retraining.",1,0,0,0,0,0
1124,"In this article, we propose and study the sustainability problem for learning-based app classifiers.",0,1,1,0,0,0
1125,We define sustainability metrics and compare them among five state-of-the-art malware detectors for Android.,0,1,1,0,0,0
1126,"We further developed DroidSpan, a novel classification system based on a new behavioral profile for Android apps that captures sensitive access distribution from lightweight profiling.",0,0,1,0,0,0
1127,"We evaluated the sustainability of DroidSpan versus the five detectors as baselines on longitudinal datasets across the past eight years, which include 13,627 benign apps and 12,755 malware.",0,0,0,1,0,0
1128,"Through our extensive experiments, we showed that DroidSpan significantly outperformed all the baselines in substainability at reasonable costs, by 6%–32% for same-period detection and 21%–37% for over-time detection.",0,0,0,1,0,0
1129,"The main takeaway, which also explains the superiority of DroidSpan, is that the use of features consistently differentiating malware from benign apps over time is essential for sustainable learning-based malware detection, and that these features can be learned from studies on app evolution.",0,0,0,0,1,0
1130,Distributed systems pose unique challenges for software developers.,1,0,0,0,0,0
1131,Understanding the system’s communication topology and reasoning about concurrent activities of system hosts can be difficult.,1,0,0,0,0,0
1132,"The standard approach, analyzing system logs, can be a tedious and complex process that involves reconstructing a system log from multiple hosts’ logs, reconciling timestamps among hosts with non-synchronized clocks, and understanding what took place during the execution encoded by the log.",1,0,0,0,0,0
1133,"This article presents a novel approach for tackling three tasks frequently performed during analysis of distributed system executions: (1) understanding the relative ordering of events, (2) searching for specific patterns of interaction between hosts, and (3) identifying structural similarities and differences between pairs of executions.",0,1,1,0,0,0
1134,"Our approach consists of XVector, which instruments distributed systems to capture partial ordering information that encodes the happens-before relation between events, and ShiViz, which processes the resulting logs and presents distributed system executions as interactive time-space diagrams.",0,0,1,0,0,0
1135,"Two user studies with a total of 109 students and a case study with 2 developers showed that our method was effective, helping participants answer statistically significantly more system-comprehension questions correctly, with a very large effect size.",0,0,0,1,1,0
1136,Search-Based Software Engineering (SBSE) researchers who apply multi-objective search algorithms (MOSAs) often assess the quality of solutions produced by MOSAs with one or more quality indicators (QIs).,1,0,0,0,0,0
1137,"However, SBSE lacks evidence providing insights on commonly used QIs, especially about agreements among them and their relations with SBSE problems and applied MOSAs.",1,0,0,0,0,0
1138,"Such evidence about QIs agreements is essential to understand relationships among QIs, identify redundant QIs, and consequently devise guidelines for SBSE researchers to select appropriate QIs for their specific contexts.",1,0,0,0,0,0
1139,"To this end, we conducted an extensive empirical evaluation to provide insights on commonly used QIs in the context of SBSE, by studying agreements among QIs with and without considering differences of SBSE problems and MOSAs.",0,1,1,1,0,0
1140,"In addition, by defining a systematic process based on three common ways of comparing MOSAs in SBSE, we present additional observations that were automatically produced based on the results of our empirical evaluation.",0,1,0,1,0,0
1141,"These observations can be used by SBSE researchers to gain a better understanding of the commonly used QIs in SBSE, in particular, regarding their agreements.",0,0,0,0,1,0
1142,"Finally, based on the results, we also provide a set of guidelines for SBSE researchers to select appropriate QIs for their particular context.",0,0,0,0,0,1
1143,The ability to generate test data is often a necessary prerequisite for automated software testing.,1,0,0,0,0,0
1144,"For the generated data to be fit for their intended purpose, the data usually have to satisfy various logical constraints.",1,0,0,0,0,0
1145,"When testing is performed at a system level, these constraints tend to be complex and are typically captured in expressive formalisms based on first-order logic.",1,0,0,0,0,0
1146,"Motivated by improving the feasibility and scalability of data generation for system testing, we present a novel approach, whereby we employ a combination of metaheuristic search and Satisfiability Modulo Theories (SMT) for constraint solving.",0,1,1,0,0,0
1147,Our approach delegates constraint solving tasks to metaheuristic search and SMT in such a way as to take advantage of the complementary strengths of the two techniques.,0,0,1,0,0,0
1148,"We ground our work on test data models specified in UML, with OCL used as the constraint language.",0,0,1,0,0,0
1149,We present tool support and an evaluation of our approach over three industrial case studies.,0,0,0,1,0,0
1150,"The results indicate that, for complex system test data generation problems, our approach presents substantial benefits over the state-of-the-art in terms of applicability and scalability.",0,0,0,0,1,0
1151,"An important issue faced during software development is to identify defects and the properties of those defects, if found, in a given source file.",1,0,0,0,0,0
1152,Determining defectiveness of source code assumes significance due to its implications on software development and maintenance cost.,1,0,0,0,0,0
1153,"We present a novel system to estimate the presence of defects in source code and detect attributes of the possible defects, such as the severity of defects.",0,1,1,0,0,0
1154,"The salient elements of our system are: (i) a dataset of newly introduced source code metrics, called PROgramming CONstruct (PROCON) metrics, and (ii) a novel Machine-Learning (ML)-based system, called Defect Estimator for Source Code (DESCo), that makes use of PROCON dataset for predicting defectiveness in a given scenario.",0,0,1,0,0,0
1155,"The dataset was created by processing 30,400+ source files written in four popular programming languages, viz., C, C++, Java, and Python.",0,0,1,0,0,0
1156,The results of our experiments show that DESCo system outperforms one of the state-of-the-art methods with an improvement of 44.9%.,0,0,0,1,1,0
1157,"To verify the correctness of our system, we compared the performance of 12 different ML algorithms with 50+ different combinations of their key parameters.",0,0,0,1,0,0
1158,Our system achieves the best results with SVM technique with a mean accuracy measure of 80.8%.,0,0,0,0,1,0
1159,"Many software services today are hosted on cloud computing platforms, such as Amazon EC2, due to many benefits like reduced operational costs.",1,0,0,0,0,0
1160,"However, node failures in these platforms can impact the availability of their hosted services and potentially lead to large financial losses.",1,0,0,0,0,0
1161,"Predicting node failures before they actually occur is crucial, as it enables DevOps engineers to minimize their impact by performing preventative actions.",1,0,0,0,0,0
1162,"However, such predictions are hard due to many challenges like the enormous size of the monitoring data and the complexity of the failure symptoms.",1,0,0,0,0,0
1163,"AIOps (Artificial Intelligence for IT Operations), a recently introduced approach in DevOps, leverages data analytics and machine learning to improve the quality of computing platforms in a cost-effective manner.",1,0,0,0,0,0
1164,"However, the successful adoption of such AIOps solutions requires much more than a top-performing machine learning model.",1,0,0,0,0,0
1165,"Instead, AIOps solutions must be trustable, interpretable, maintainable, scalable, and evaluated in context.",1,0,0,0,0,0
1166,"To cope with these challenges, in this article we report our process of building an AIOps solution for predicting node failures for an ultra-large-scale cloud computing platform at Alibaba.",0,1,1,0,0,0
1167,"We expect our experiences to be of value to researchers and practitioners, who are interested in building and maintaining AIOps solutions for large-scale cloud computing platforms.",0,0,0,0,0,1
1168,Spectre-style attacks disclosed in early 2018 expose data leakage scenarios via cache side channels.,1,0,0,0,0,0
1169,"Specifically, speculatively executed paths due to branch mis-prediction may bring secret data into the cache, which are then exposed via cache side channels even after the speculative execution is squashed.",1,0,0,0,0,0
1170,Symbolic execution is a well-known test generation method to cover program paths at the level of the application software.,1,0,0,0,0,0
1171,"In this article, we extend symbolic execution with modeling of cache and speculative execution.",0,1,1,0,0,0
1172,"Our tool KLEESPECTRE, built on top of the KLEE symbolic execution engine, can thus provide a testing engine to check for data leakage through the cache side channel as shown via Spectre attacks.",0,0,1,0,0,0
1173,Our symbolic cache model can verify whether the sensitive data leakage due to speculative execution can be observed by an attacker at a given program point.,0,0,1,0,0,0
1174,Our experiments show that KLEESPECTRE can effectively detect data leakage along speculatively executed paths and our cache model can make the leakage detection more precise.,0,0,0,1,1,0
1175,"The alignment of observed and modeled behavior is an essential element for organizations, since it opens the door for conformance checking and enhancement of processes.",1,0,0,0,0,0
1176,"The state-of-the-art technique for computing alignments has exponential time and space complexity, hindering its applicability for medium and large instances.",1,0,0,0,0,0
1177,"In this article, a novel approach is presented to tackle the challenge of computing an alignment for large-problem instances that correspond to well-formed process models.",0,1,1,0,0,0
1178,"Given an observed trace, first it uses a novel replay technique to find an initial candidate trace in the model.",0,0,1,0,0,0
1179,Then a local search framework is applied to try to improve the alignment until no further improvement is possible.,0,0,1,0,0,0
1180,The implementation of the presented technique reveals a magnificent reduction both in computation time and in memory usage.,0,0,0,0,1,0
1181,"Moreover, although the proposed technique does not guarantee the derivation of an alignment with minimal cost, the experiments show that in practice the quality of the obtained solutions is close to optimal.",0,0,0,1,1,0
1182,"Vacuity is a well-known quality issue in formal specifications, studied mostly in the context of model checking.",1,0,0,0,0,0
1183,"Inherent vacuity is a type of vacuity that applies to specifications, without the context of a model.",1,0,0,0,0,0
1184,"GR(1) is an expressive assume-guarantee fragment of LTL, which enables efficient symbolic synthesis.",1,0,0,0,0,0
1185,In this work we investigate inherent vacuity for GR(1) specifications.,0,1,1,0,0,0
1186,"We define several general types of inherent vacuity for GR(1), including specification element vacuity and domain value vacuity.",0,1,1,0,0,0
1187,"We detect vacuities using a reduction to LTL satisfiability, specialized for the context of GR(1).",0,1,1,0,0,0
1188,"We further extend vacuity detection to handle GR(1) specifications that are enriched with past LTL, monitors, and patterns.",0,1,1,0,0,0
1189,"Finally, we define a novel notion of vacuity core, which provides means to localize the cause of vacuity.",0,1,1,0,0,0
1190,We implemented our work and evaluated it on benchmarks from the literature.,0,0,0,1,0,0
1191,"The evaluation shows that vacuities are indeed common in GR(1) specifications, and that we are able to efficiently detect them and effectively localize their causes.",0,0,0,0,1,0
1192,"Moreover, our evaluation shows that removal of vacuous specification elements may significantly reduce synthesis time.",0,0,0,0,1,0
1193,The landscape of web APIs is evolving to meet new client requirements and to facilitate how providers fulfill them.,1,0,0,0,0,0
1194,"A recent web API model is GraphQL, which is both a query language and a runtime.",1,0,0,0,0,0
1195,"Using GraphQL, client queries express the data they want to retrieve or mutate, and servers respond with exactly those data or changes.",1,0,0,0,0,0
1196,"GraphQL’s expressiveness is risky for service providers because clients can succinctly request stupendous amounts of data, and responding to overly complex queries can be costly or disrupt service availability.",1,0,0,0,0,0
1197,Recent empirical work has shown that many service providers are at risk.,1,0,0,0,0,0
1198,"Using traditional API management methods is not sufficient, and practitioners lack principled means of estimating and measuring the cost of the GraphQL queries they receive.",1,0,0,0,0,0
1199,"In this work, we present a linear-time GraphQL query analysis that can measure the cost of a query without executing it.",0,1,1,0,0,0
1200,Our approach can be applied in a separate API management layer and used with arbitrary GraphQL backends.,0,0,1,0,0,0
1201,"In contrast to existing static approaches, our analysis supports common GraphQL conventions that affect query cost, and our analysis is provably correct based on our formal specification of GraphQL semantics.",0,0,1,0,0,0
1202,We demonstrate the potential of our approach using a novel GraphQL query-response corpus for two commercial GraphQL APIs.,0,0,0,1,0,0
1203,"Our query analysis consistently obtains upper cost bounds, tight enough relative to the true response sizes to be actionable for service providers.",0,0,0,0,1,0
1204,"In contrast, existing static GraphQL query analyses exhibit over-estimates and under-estimates because they fail to support GraphQL conventions.",0,0,0,0,1,0
1205,Incidents in online service systems could dramatically degrade system availability and destroy user experience.,1,0,0,0,0,0
1206,"To guarantee service quality and reduce economic loss, it is essential to predict the occurrence of incidents in advance so that engineers can take some proactive actions to prevent them.",1,0,0,0,0,0
1207,"In this work, we propose an effective and interpretable incident prediction approach, called eWarn, which utilizes historical data to forecast whether an incident will happen in the near future based on alert data in real time.",0,1,1,0,0,0
1208,"More specifically, eWarn first extracts a set of effective features (including textual features and statistical features) to represent omen alert patterns via careful feature engineering.",0,0,1,0,0,0
1209,"To reduce the influence of noisy alerts (that are not relevant to the occurrence of incidents), eWarn then incorporates the multi-instance learning formulation.",0,0,1,0,0,0
1210,"Finally, eWarn builds a classification model via machine learning and generates an interpretable report about the prediction result via a state-of-the-art explanation technique (i.e., LIME).",0,0,1,0,0,0
1211,"In this way, an early warning signal along with its interpretable report can be sent to engineers to facilitate their understanding and handling for the incoming incident.",0,0,1,0,0,0
1212,"An extensive study on 11 real-world online service systems from a large commercial bank demonstrates the effectiveness of eWarn, outperforming state-of-the-art alert-based incident prediction approaches and the practice of incident prediction with alerts.",0,0,0,1,1,0
1213,"In particular, we have applied eWarn to two large commercial banks in practice and shared some success stories and lessons learned from real deployment.",0,0,0,0,1,0
1214,Natural Language (NL) programming automatically synthesizes code based on inputs expressed in natural language.,1,0,0,0,0,0
1215,It has recently received lots of growing interest.,1,0,0,0,0,0
1216,Recent solutions however all require many labeled training examples for their data-driven nature.,1,0,0,0,0,0
1217,"This paper proposes an NLU-driven approach, a new approach inspired by how humans learn programming.",0,1,1,0,0,0
1218,"It centers around Natural Language Understanding and draws on a novel graph-based mapping algorithm, foregoing the need of large numbers of labeled examples.",0,0,1,0,0,0
1219,"The resulting NL programming framework, HISyn, using no training examples, gives synthesis accuracy comparable to those by data-driven methods trained on hundreds of training numbers.",0,0,0,0,1,0
1220,"HISyn meanwhile demonstrates advantages in interpretability, error diagnosis support, and cross-domain extensibility.",0,0,0,0,0,1
1221,"With the rise of containerization, cloud development, and continuous integration and delivery, configuration has become an essential aspect not only to tailor software to user requirements, but also to configure a software system’s environment and infrastructure.",1,0,0,0,0,0
1222,"This heterogeneity of activities, domains, and processes blurs the term configuration, as it is not clear anymore what tasks, artifacts, or stakeholders are involved and intertwined.",1,0,0,0,0,0
1223,"However, each re- search study and each paper involving configuration places their contributions and findings in a certain context without making the context explicit.",1,0,0,0,0,0
1224,"This makes it difficult to compare findings, translate them to practice, and to generalize the results.",1,0,0,0,0,0
1225,"Thus, we set out to evaluate whether these different views on configuration are really distinct or can be summarized under a common umbrella.",0,0,1,0,0,0
1226,"By interviewing practitioners from different domains and in different roles about the aspects of configuration and by analyzing two qualitative studies in similar areas, we derive a model of configuration that provides terminology and context for research studies, identifies new research opportunities, and allows practitioners to spot possible challenges in their current tasks.",0,0,1,1,0,0
1227,"Although our interviewees have a clear view about configuration, it substantially differs due to their personal experience and role.",0,0,0,0,1,0
1228,This indicates that the term configuration might be overloaded.,0,0,0,0,1,0
1229,"However, when taking a closer look, we see the interconnections and dependencies among all views, arriving at the conclusion that we need to start considering the entire spectrum of dimensions of configuration.",0,0,0,0,1,0
1230,One of the key properties of a program is its input specification.,1,0,0,0,0,0
1231,"Having a formal input specification can be critical in fields such as vulnerability analysis, reverse engineering, software testing, clone detection, or refactoring.",1,0,0,0,0,0
1232,"Unfortunately, accurate input specifications for typical programs are often unavailable or out of date.",1,0,0,0,0,0
1233,"In this paper, we present a general algorithm that takes a program and a small set of sample inputs and automatically infers a readable context-free grammar capturing the input language of the program.",0,1,1,0,0,0
1234,We infer the syntactic input structure only by observing access of input characters at different locations of the input parser.,0,0,1,0,0,0
1235,"This works on all stack based recursive descent input parsers, including parser combinators, and works entirely without program specific heuristics.",0,0,1,0,0,0
1236,"Our Mimid prototype produced accurate and readable grammars for a variety of evaluation subjects, including complex languages such as JSON, TinyC, and JavaScript.",0,0,0,0,1,0
1237,Software engineering bots – automated tools that handle tedious tasks – are increasingly used by industrial and open source projects to improve developer productivity.,1,0,0,0,0,0
1238,"Current research in this area is held back by a lack of consensus of what software engineering bots (DevBots) actually are, what characteristics distinguish them from other tools, and what benefits and challenges are associated with DevBot usage.",1,0,0,0,0,0
1239,In this paper we report on a mixed-method empirical study of DevBot usage in industrial practice.,0,1,1,1,0,0
1240,We report on findings from interviewing 21 and surveying a total of 111 developers.,0,0,0,1,0,0
1241,"We identify three different personas among DevBot users (focusing on autonomy, chat interfaces, and “smartness”), each with different definitions of what a DevBot is, why developers use them, and what they struggle with.We conclude that future DevBot research should situate their work within our framework, to clearly identify what type of bot the work targets, and what advantages practitioners can expect.",0,0,0,0,1,0
1242,"Further, we find that there currently is a lack of general purpose “smart” bots that go beyond simple automation tools or chat interfaces.",0,0,0,0,1,0
1243,"This is problematic, as we have seen that such bots, if available, can have a transformative effect on the projects that use them.",0,0,0,0,1,0
1244,"Code review is a critical step in modern software quality assurance, yet it is vulnerable to human biases.",1,0,0,0,0,0
1245,"Previous studies have clarified the extent of the problem, particularly regarding biases against the authors of code,but no consensus understanding has emerged.",1,0,0,0,0,0
1246,"Advances in medical imaging are increasingly applied to software engineering, supporting grounded neurobiological explorations of computing activities, including the review, reading, and writing of source code.",1,0,0,0,0,0
1247,"In this paper, we present the results of a controlled experiment using both medical imaging and also eye tracking to investigate the neurological correlates of biases and differences between genders of humans and machines (e.g., automated program repair tools) in code review.",0,1,1,1,0,0
1248,"We find that men and women conduct code reviews differently, in ways that are measurable and supported by behavioral, eye-tracking and medical imaging data.",0,0,0,0,1,0
1249,"We also find biases in how humans review code as a function of its apparent author, when controlling for code quality.",0,0,0,0,1,0
1250,"In addition to advancing our fundamental understanding of how cognitive biases relate to the code review process, the results may inform subsequent training and tool design to reduce bias.",0,0,0,0,0,1
1251,Software reuse lowers development costs and improves the quality of software systems.,1,0,0,0,0,0
1252,Two strategies are common: clone & own (copying and adapting a system) and platform-oriented reuse (building a configurable platform).,1,0,0,0,0,0
1253,"The former is readily available, flexible, and initially cheap, but does not scale with the frequency of reuse, imposing high maintenance costs.",1,0,0,0,0,0
1254,"The latter scales, but imposes high upfront investments for building the platform, and reduces flexibility.",1,0,0,0,0,0
1255,"As such, each strategy has distinctive advantages and disadvantages, imposing different development activities and software architectures.",1,0,0,0,0,0
1256,Deciding for one strategy is a core decision with long-term impact on an organization’s software development.,1,0,0,0,0,0
1257,"Unfortunately, the strategies’ costs are not well-understood - not surprisingly, given the lack of systematically elicited empirical data, which is difficult to collect.",1,0,0,0,0,0
1258,"We present an empirical study of the development activities, costs, cost factors, and benefits associated with either reuse strategy.",0,1,1,1,0,0
1259,"For this purpose, we combine quantitative and qualitative data that we triangulated from 26 interviews at a large organization and a systematic literature review covering 57 publications.",0,0,0,1,0,0
1260,Our study both confirms and refutes common hypotheses on software reuse.,0,0,0,0,1,0
1261,"For instance, we confirm that developing for platform-oriented reuse is more expensive, but simultaneously reduces reuse costs; and that platform-orientation results in higher code quality compared to clone & own.",0,0,0,0,1,0
1262,"Surprisingly, refuting common hypotheses, we find that change propagation can be more expensive in a platform, that platforms can facilitate the advancement into innovative markets, and that there is no strict distinction of clone & own and platform-oriented reuse in practice.",0,0,0,0,1,0
1263,"Use-before-Initialization (UBI) bugs in the Linux kernel have serious security impacts, such as information leakage and privilege escalation.",1,0,0,0,0,0
1264,"Developers are adopting forced initialization to cope with UBI bugs, but this approach can still lead to undefined behaviors (e.g., NULL pointer dereference).",1,0,0,0,0,0
1265,"As it is hard to infer correct initialization values, we believe that the best way to mitigate UBI bugs is detection and manual patching.",1,0,0,0,0,0
1266,Precise detection of UBI bugs requires path-sensitive analysis.,1,0,0,0,0,0
1267,The detector needs to track an associated variable’s initialization status along all the possible program execution paths to its uses.,1,0,0,0,0,0
1268,"However, such exhaustive analysis prevents the detection from scaling to the whole Linux kernel.",1,0,0,0,0,0
1269,"This paper presents UBITect, a UBI bug finding tool which combines flow-sensitive type qualifier analysis and symbolic execution to perform precise and scalable UBI bug detection.",0,1,1,0,0,0
1270,The scalable qualifier analysis guides symbolic execution to analyze variables that are likely to cause UBI bugs.,0,0,1,0,0,0
1271,"UBITect also does not require manual effort for annotations and hence, it can be directly applied to the kernel without any source code or intermediate representation (IR) change.",0,0,1,0,0,0
1272,"On the Linux kernel version 4.14, UBITect reported 190 bugs, among which 78 bugs were deemed by us as true positives and 52 were confirmed by Linux maintainers.",0,0,0,0,1,0
1273,"Intelligent services provide the power of AI to developers via simple RESTful API endpoints, abstracting away many complexities of machine learning.",1,0,0,0,0,0
1274,"However, most of these intelligent services---such as computer vision---continually learn with time.",1,0,0,0,0,0
1275,"When the internals within the abstracted 'black box' become hidden and evolve, pitfalls emerge in the robustness of applications that depend on these evolving services.",1,0,0,0,0,0
1276,"Without adapting the way developers plan and construct projects reliant on intelligent services, significant gaps and risks result in both project planning and development.",1,0,0,0,0,0
1277,"Therefore, how can software engineers best mitigate software evolution risk moving forward, thereby ensuring that their own applications maintain quality?",1,0,0,0,0,0
1278,Our proposal is an architectural tactic designed to improve intelligent service-dependent software robustness.,0,1,1,0,0,0
1279,"The tactic involves creating an application-specific benchmark dataset baselined against an intelligent service, enabling evolutionary behaviour changes to be mitigated.",0,0,1,0,0,0
1280,"A technical evaluation of our implementation of this architecture demonstrates how the tactic can identify 1,054 cases of substantial confidence evolution and 2,461 cases of substantial changes to response label sets using a dataset consisting of 331 images that evolve when sent to a service.",0,0,0,1,1,0
1281,"As a mixed result of intensive dependency on third-party libraries, flexible mechanisms to declare dependencies and increased number of modules in a project, different modules of a project directly depend on multiple versions of the same third-party library.",1,0,0,0,0,0
1282,"Such library version inconsistencies could increase dependency maintenance cost, or even lead to dependency conflicts when modules are inter-dependent.",1,0,0,0,0,0
1283,"Although automated build tools (e.g., Maven's enforcer plugin) provide partial support to detect library version inconsistencies, they do not provide any support to harmonize inconsistent library versions.",1,0,0,0,0,0
1284,"We first conduct a survey with 131 Java developers from GitHub to retrieve first-hand information about the root causes, detection methods, reasons for fixing or not fixing, fixing strategies, fixing efforts, and tool expectations on library version inconsistencies.",0,0,1,1,0,0
1285,"Then, based on the insights from our survey, we propose LibHarmo, an interactive, effort-aware library version harmonization technique, to detect library version inconsistencies, interactively suggest a harmonized version with the least harmonization efforts based on library API usage analysis, and refactor build configuration files.",0,0,1,0,0,0
1286,LibHarmo is currently developed for Java Maven projects.,0,0,1,0,0,0
1287,"Our experimental study on 443 highly-starred Java Maven projects from GitHub shows that i) LibHarmo detected 621 library version inconsistencies in 152 (34.3%) projects with a false positive rate of 16.8%, while Maven's enforcer plugin only detected 219 of them; and ii) LibHarmo saved 87.5% of the harmonization efforts.",0,0,0,1,1,0
1288,"Further, 31 library version inconsistencies have been confirmed, and 17 of them have been already harmonized by developers.",0,0,0,0,1,0
1289,"Mining software repositories (MSR) has been shown effective for extracting data used to improve various software engineering tasks, including code completion, code repair, code search, and code summarization.",1,0,0,0,0,0
1290,"Despite a large body of work on MSR, researchers have focused almost exclusively on repositories that contain code written in imperative programming languages, such as Java and C/C++.",1,0,0,0,0,0
1291,"Unlike prior work, in this paper, we focus on mining publicly available hardware descriptions (HDs) written in hardware description languages (HDLs), such as VHDL.",0,1,0,0,0,0
1292,"HDLs have unique syntax and semantics compared to popular imperative languages, and learning-based tools available to hardware designers are well behind those used in other application domains.",0,0,1,0,0,0
1293,We assembled large HD corpora consisting of source code written in several HDLs and report on their characteristics.,0,0,0,1,0,0
1294,Our language model evaluation reveals that HDs possess a high level of naturalness similar to software written in imperative languages.,0,0,0,0,1,0
1295,"Further, by utilizing our corpora, we built several deep learning models for automated code completion in VHDL; our models take into account unique characteristics of HDLs, including similarities of nearby concurrent signal assignment statements, in-built concurrency, and the frequently used signal types.",0,0,0,1,0,0
1296,"These characteristics led to more effective neural models, achieving a BLEU score of 37.3, an 8-14-point improvement over rule-based and neural baselines.",0,0,0,0,1,0
1297,"Today, most developers bundle changes into commits that they submit to a shared code repository.",1,0,0,0,0,0
1298,"Tangled commits intermix distinct concerns, such as a bug fix and a new feature.",1,0,0,0,0,0
1299,"They cause issues for developers, reviewers, and researchers alike: they restrict the usability of tools such as git bisect, make patch comprehension more difficult, and force researchers who mine software repositories to contend with noise.",1,0,0,0,0,0
1300,"We present a novel data structure, the 𝛿-NFG, a multiversion Program Dependency Graph augmented with name flows.",0,1,1,0,0,0
1301,"A 𝛿-NFG directly and simultaneously encodes different program versions, thereby capturing commits, and annotates data flow edges with the names/lexemes that flow across them.",0,0,1,0,0,0
1302,"Our technique, Flexeme, builds a 𝛿-NFG from commits, then applies Agglomerative Clustering using Graph Similarity to that 𝛿-NFG to untangle its commits.",0,0,1,0,0,0
1303,"At the untangling task on a C# corpus, our implementation, Heddle, improves the state-of-the-art on accuracy by 0.14, achieving 0.81, in a fraction of the time: Heddle is 32 times faster than the previous state-of-the-art.",0,0,0,0,1,0
1304,Software refactoring aims at improving code quality while preserving the system's external behavior.,1,0,0,0,0,0
1305,"Although in principle refactoring is a behavior-preserving activity, a study presented by Bavota etal in 2012 reported the proneness of some refactoring actions (eg pull up method) to induce faults.",1,0,0,0,0,0
1306,The study was performed by mining refactoring activities and bugs from three systems.,1,0,0,0,0,0
1307,"Taking profit of the advances made in the mining software repositories field (eg better tools to detect refactoring actions at commit-level granularity), we present a differentiated replication of the work by Bavota etal in which we (i) overcome some of the weaknesses that affect their experimental design, (ii) answer the same research questions of the original study on a much larger dataset (3 vs 103 systems), and (iii) complement the quantitative analysis of the relationship between refactoring and bugs with a qualitative, manual inspection of commits aimed at verifying the extent to which refactoring actions trigger bug-fixing activities.",0,1,1,0,0,0
1308,"The results of our quantitative analysis confirm the findings of the replicated study, while the qualitative analysis partially demystifies the role played by refactoring actions in the bug introduction.",0,0,0,1,1,0
1309,"We propose a novel fine-grained integration of pointer analysis with dynamic analysis, including dynamic symbolic execution.",0,1,1,0,0,0
1310,"This is achieved via past-sensitive pointer analysis, an on-demand pointer analysis instantiated with an abstraction of the dynamic state on which it is invoked.",0,0,1,0,0,0
1311,"We evaluate our technique in three application scenarios: chopped symbolic execution, symbolic pointer resolution, and write integrity testing.",0,0,0,1,0,0
1312,"Our preliminary results show that the approach can have a significant impact in these scenarios, by effectively improving the precision of standard pointer analysis with only a modest performance overhead.",0,0,0,0,1,0
1313,"Polyglot programming, the use of multiple programming languages during the development process, is common practice in modern software development.",1,0,0,0,0,0
1314,This study investigates this practice through a randomized controlled trial conducted under the context of database programming.,0,1,1,0,0,0
1315,Participants in the study were given coding tasks written in Java and one of three SQL-like embedded languages.,0,0,0,1,0,0
1316,"One was plain SQL in strings, one was in Java only, and the third was a hybrid embedded language that was closer to the host language.",0,0,0,1,0,0
1317,We recorded 109 valid data points.,0,0,0,1,0,0
1318,Results showed significant differences in how developers of different experience levels code using polyglot techniques.,0,0,0,0,1,0
1319,"Notably, less experienced programmers wrote correct programs faster in the hybrid condition (frequent, but less severe, switches), while more experienced developers that already knew both languages performed better in traditional SQL (less frequent but more complete switches).",0,0,0,0,1,0
1320,The results indicate that the productivity impact of polyglot programming is complex and experience level dependent.,0,0,0,0,1,0
1321,"Automation tools like continuous integration services, code coverage reporters, style checkers, dependency managers, etc. are all known to provide significant improvements in developer productivity and software quality.",1,0,0,0,0,0
1322,"Some of these tools are widespread, others are not.",1,0,0,0,0,0
1323,"How do these automation ""best practices"" spread?",1,0,0,0,0,0
1324,And how might we facilitate the diffusion process for those that have seen slower adoption?,1,0,0,0,0,0
1325,"In this paper, we rely on a recent innovation in transparency on code hosting platforms like GitHub---the use of repository badges---to track how automation tools spread in open-source ecosystems through different social and technical mechanisms over time.",0,1,1,0,0,0
1326,"Using a large longitudinal data set, multivariate network science techniques, and survival analysis, we study which socio-technical factors can best explain the observed diffusion process of a number of popular automation tools.",0,0,1,1,0,0
1327,"Our results show that factors such as social exposure, competition, and observability affect the adoption of tools significantly, and they provide a roadmap for software engineers and researchers seeking to propagate best practices and tools.",0,0,0,0,1,0
1328,"The typical software tutorial includes step-by-step instructions for installing developer tools, editing files and code, and running commands.",1,0,0,0,0,0
1329,"When these software tutorials are not executable, either due to missing instructions, ambiguous steps, or simply broken commands, their value is diminished.",1,0,0,0,0,0
1330,"Non-executable tutorials impact developers in several ways, including frustrating learning experiences, and limiting usability of developer tools.",1,0,0,0,0,0
1331,"To understand to what extent software tutorials are executable---and why they may fail---we conduct an empirical study on over 600 tutorials, including nearly 15,000 code blocks.",0,1,1,1,0,0
1332,We find a naive execution strategy achieves an overall executability rate of only 26%.,0,0,0,0,1,0
1333,Even a human-annotation-based execution strategy---while doubling executability---still yields no tutorial that can successfully execute all steps.,0,0,0,0,1,0
1334,"We identify several common executability barriers, ranging from potentially innocuous causes, such as interactive prompts requiring human responses, to insidious errors, such as missing steps and inaccessible resources.",0,0,0,0,1,0
1335,"We validate our findings with major stakeholders in technical documentation and discuss possible strategies for improving software tutorials, such as providing accessible alternatives for tutorial takers, and investing in automated tutorial testing to ensure continuous quality of software tutorials.",0,0,0,1,0,0
1336,"Open design discussion is a primary mechanism through which open source projects debate, make and document design decisions.",1,0,0,0,0,0
1337,"However, there are open questions regarding how design discussions are conducted and what effect they have on the design quality of projects.",1,0,0,0,0,0
1338,"Recent work has begun to investigate design discussions, but has thus far focused on a single communication channel, whereas many projects use multiple channels.",1,0,0,0,0,0
1339,"In this study, we examine 37 Apache projects and their design discussions, the project’s design quality evolution, and the relationship between design discussion and design quality.",0,1,1,0,0,0
1340,"A mixed method empirical analysis (data mining and a survey of 130 developers) shows that: I) 89.51% of all design discussions occur in project mailing list, II) both core and non-core developers participate in design discussions, but core developers implement more design related changes (67.06%), and III) the correlation between design discussions and design quality is small.",0,0,0,1,1,0
1341,We conclude the paper with several observations that form the foundation for future research and development.,0,0,0,0,0,1
1342,An effective and efficient application of Continuous Integration (CI) and Delivery (CD) requires software projects to follow certain principles and good practices.,1,0,0,0,0,0
1343,Configuring such a CI/CD pipeline is challenging and error-prone.,1,0,0,0,0,0
1344,"Therefore, automated linters have been proposed to detect errors in the pipeline.",1,0,0,0,0,0
1345,"While existing linters identify syntactic errors, detect security vulnerabilities or misuse of the features provided by build servers, they do not support developers that want to prevent common misconfigurations of a CD pipeline that potentially violate CD principles (“CD smells”).",1,0,0,0,0,0
1346,"To this end, we propose CD-Linter, a semantic linter that can automatically identify four different smells in pipeline configuration files.",0,1,1,0,0,0
1347,"We have evaluated our approach through a large-scale and long-term study that consists of (i) monitoring 145 issues (opened in as many open-source projects) over a period of 6 months, (ii) manually validating the detection precision and recall on a representative sample of issues, and (iii) assessing the magnitude of the observed smells on 5,312 open-source projects on GitLab.",0,0,0,1,0,0
1348,Our results show that CD smells are accepted and fixed by most of the developers and our linter achieves a precision of 87% and a recall of 94%.,0,0,0,0,1,0
1349,"Those smells can be frequently observed in the wild, as 31% of projects with long configurations are affected by at least one smell.",0,0,0,0,1,0
1350,The selection of third-party libraries is an essential element of virtually any software development project.,1,0,0,0,0,0
1351,"However, deciding which libraries to choose is a challenging practical problem.",1,0,0,0,0,0
1352,"Selecting the wrong library can severely impact a software project in terms of cost, time, and development effort, with the severity of the impact depending on the role of the library in the software architecture, among others.",1,0,0,0,0,0
1353,"Despite the importance of following a careful library selection process, in practice, the selection of third-party libraries is still conducted in an ad-hoc manner, where dozens of factors play an influential role in the decision.",1,0,0,0,0,0
1354,"In this paper, we study the factors that influence the selection process of libraries, as perceived by industry developers.",0,1,1,0,0,0
1355,"To that aim, we perform a cross-sectional interview study with 16 developers from 11 different businesses and survey 115 developers that are involved in the selection of libraries.",0,0,0,1,0,0
1356,"We systematically devised a comprehensive set of 26 technical, human, and economic factors that developers take into consideration when selecting a software library.",0,0,0,0,1,0
1357,Eight of these factors are new to the literature.,0,0,0,0,1,0
1358,We explain each of these factors and how they play a role in the decision.,0,0,0,0,1,0
1359,"Finally, we discuss the implications of our work to library maintainers, potential library users, package manager developers, and empirical software engineering researchers.",0,0,0,0,1,0
1360,Software engineering candidates commonly participate in whiteboard technical interviews as part of a hiring assessment.,1,0,0,0,0,0
1361,"During these sessions, candidates write code while thinking aloud as they work towards a solution, under the watchful eye of an interviewer.",1,0,0,0,0,0
1362,"While technical interviews should allow for an unbiased and inclusive assessment of problem-solving ability, surprisingly, technical interviews may be instead a procedure for identifying candidates who best handle and migrate stress solely caused by being examined by an interviewer (performance anxiety).",1,0,0,0,0,0
1363,"To understand if coding interviews—as administered today—can induce stress that significantly hinders performance, we conducted a randomized controlled trial with 48 Computer Science students, comparing them in private and public whiteboard settings.",0,1,1,1,0,0
1364,"We found that performance is reduced by more than half, by simply being watched by an interviewer.",0,0,0,0,1,0
1365,We also observed that stress and cognitive load were significantly higher in a traditional technical interview when compared with our private interview.,0,0,0,0,1,0
1366,"Consequently, interviewers may be filtering out qualified candidates by confounding assessment of problem-solving ability with unnecessary stress.",0,0,0,0,1,0
1367,"We propose interview modifications to make problem-solving assessment more equitable and inclusive, such as through private focus sessions and retrospective think-aloud, allowing companies to hire from a larger and diverse pool of talent.",0,0,0,0,0,1
1368,"Maintaining large code bases written in dynamically typed languages, such as JavaScript or Python, can be challenging due to the absence of type annotations: simple data compatibility errors proliferate, IDE support is limited, and APIs are hard to comprehend.",1,0,0,0,0,0
1369,Recent work attempts to address those issues through either static type inference or probabilistic type prediction.,1,0,0,0,0,0
1370,"Unfortunately, static type inference for dynamic languages is inherently limited, while probabilistic approaches suffer from imprecision.",1,0,0,0,0,0
1371,"This paper presents TypeWriter, the first combination of probabilistic type prediction with search-based refinement of predicted types.",0,1,1,0,0,0
1372,TypeWriter’s predictor learns to infer the return and argument types for functions from partially annotated code bases by combining the natural language properties of code with programming language-level information.,0,0,1,0,0,0
1373,"To validate predicted types, TypeWriter invokes a gradual type checker with different combinations of the predicted types, while navigating the space of possible type combinations in a feedback-directed manner.",0,0,1,0,0,0
1374,"We implement the TypeWriter approach for Python and evaluate it on two code corpora: a multi-million line code base at Facebook and a collection of 1,137 popular open-source projects.",0,0,0,1,0,0
1375,"We show that TypeWriter’s type predictor achieves an F1 score of 0.64 (0.79) in the top-1 (top-5) predictions for return types, and 0.57 (0.80) for argument types, which clearly outperforms prior type prediction models.",0,0,0,0,1,0
1376,"By combining predictions with search-based validation, TypeWriter can fully annotate between 14% to 44% of the files in a randomly selected corpus, while ensuring type correctness.",0,0,0,0,1,0
1377,A comparison with a static type inference tool shows that TypeWriter adds many more non-trivial types.,0,0,0,0,1,0
1378,TypeWriter currently suggests types to developers at Facebook and several thousands of types have already been accepted with minimal changes.,0,0,0,0,0,1
1379,"Formal program specifications are essential for various software engineering tasks, such as program verification, program synthesis, code debugging and software testing.",1,0,0,0,0,0
1380,"However, manually inferring formal program specifications is not only time-consuming but also error-prone.",1,0,0,0,0,0
1381,"In addition, it requires substantial expertise.",1,0,0,0,0,0
1382,"Natural language comments contain rich semantics about behaviors of code, making it feasible to infer program specifications from comments.",1,0,0,0,0,0
1383,"Inspired by this, we develop a tool, named C2S, to automate the specification synthesis task by translating natural language comments into formal program specifications.",0,1,1,0,0,0
1384,Our approach firstly constructs alignments between natural language word and specification tokens from existing comments and their corresponding specifications.,0,0,1,0,0,0
1385,"Then for a given method comment, our approach assembles tokens that are associated with words in the comment from the alignments into specifications guided by specification syntax and the context of the target method.",0,0,1,0,0,0
1386,"Our tool successfully synthesizes 1,145 specifications for 511 methods of 64 classes in 5 different projects, substantially outperforming the state-of-the-art.",0,0,0,0,1,0
1387,"The generated specifications are also used to improve a number of software engineering tasks like static taint analysis, which demonstrates the high quality of the specifications.",0,0,0,0,0,1
1388,"In 2014, a Microsoft study investigated the sort of questions that data science applied to software engineering should answer.",1,0,0,0,0,0
1389,"This resulted in 145 questions that developers considered relevant for data scientists to answer, thus providing a research agenda to the community.",1,0,0,0,0,0
1390,"Fast forward to five years, no further studies investigated whether the questions from the software engineers at Microsoft hold for other software companies, including software-intensive companies with different primary focus (to which we refer as software-defined enterprises).",1,0,0,0,0,0
1391,"Furthermore, it is not evident that the problems identified five years ago are still applicable, given the technological advances in software engineering.",1,0,0,0,0,0
1392,"This paper presents a study at ING, a software-defined enterprise in banking in which over 15,000 IT staff provides in-house software solutions.",0,1,1,0,0,0
1393,This paper presents a comprehensive guide of questions for data scientists selected from the previous study at Microsoft along with our current work at ING.,0,1,1,0,0,0
1394,"We replicated the original Microsoft study at ING, looking for questions that impact both software companies and software-defined enterprises and continue to impact software engineering.",0,0,1,0,0,0
1395,We also add new questions that emerged from differences in the context of the two companies and the five years gap in between.,0,0,1,0,0,0
1396,"Our results show that software engineering questions for data scientists in the software-defined enterprise are largely similar to the software company, albeit with exceptions.",0,0,0,0,1,0
1397,We hope that the software engineering research community builds on the new list of questions to create a useful body of knowledge.,0,0,0,0,0,1
1398,"Whenever a new software-verification technique is developed, additional effort is necessary to extend the new program analysis to an interprocedural one, such that it supports recursive procedures.",1,0,0,0,0,0
1399,We would like to reduce that additional effort.,0,1,0,0,0,0
1400,"Our contribution is an approach to extend an existing analysis in a modular and domain-independent way to an interprocedural analysis without large changes: We present interprocedural block-abstraction memoization (BAM), which is a technique for procedure summarization to analyze (recursive) procedures.",0,1,1,0,0,0
1401,"For recursive programs, a fix-point algorithm terminates the recursion if every procedure is sufficiently unrolled and summarized to cover the abstract state space.",0,0,1,0,0,0
1402,"BAM Interprocedural works for data-flow analysis and for model checking, and is independent from the underlying abstract domain.",0,0,1,0,0,0
1403,"To witness that our interprocedural analysis is generic and configurable, we defined and evaluated the approach for three completely different abstract domains: predicate abstraction, explicit values, and intervals.",0,0,0,1,0,0
1404,The interprocedural BAM-based analysis is implemented in the open-source verification framework CPAchecker.,0,0,1,0,0,0
1405,The evaluation shows that the overhead for modularity and domain-independence is not prohibitively large and the analysis is still competitive with other state-of-the-art software-verification tools.,0,0,0,0,1,0
1406,Approximation is a technique that optimizes the balance between application outcome quality and its resource usage.,1,0,0,0,0,0
1407,"Trading quality for performance has been investigated for single application scenarios, but not for environments where multiple approximate applications may run concurrently on the same machine, interfering with each other by sharing machine resources.",1,0,0,0,0,0
1408,"Applying existing, single application techniques to this multi-programming environment may lead to configuration space size explosion, or result in poor overall application quality outcomes.",1,0,0,0,0,0
1409,Our new RAPID-M system is the first cross-application con-figuration management framework.,0,0,1,0,0,0
1410,"It reduces the problem size by clustering configurations of individual applications into local""similarity buckets"".",0,0,1,0,0,0
1411,The global cross-applications configuration selection is based on these local bucket spaces.,0,0,1,0,0,0
1412,"RAPID-M dynamically assigns buckets to applications such that overall quality is maximized while respecting individual application cost budgets.Once assigned a bucket, reconfigurations within buckets may be performed locally with minimal impact on global selections.",0,0,1,0,0,0
1413,"Experimental results using six configurable applications show that even large configuration spaces of complex applications can be clustered into a small number of buckets, resulting in search space size reductions of up to 9 orders of magnitude for our six applications.",0,0,0,1,1,0
1414,RAPID-M constructs performance cost models with an average prediction error of ≤3%.,0,0,0,0,1,0
1415,"For our application execution traces, RAPID-M dynamically selects configurations that lower the budget violation rate by 33.9% with an average budget exceeding rate of 6.6% as compared to other possible approaches.",0,0,0,0,1,0
1416,RAPID-M successfully finishes 22.75% more executions which translates to a 1.52X global output quality increase under high system loads.,0,0,0,0,1,0
1417,Theo verhead ofRAPID-Mis within≤1% of application execution times.,0,0,0,0,1,0
1418,"Summer of code programs connect students to open source software (OSS) projects, typically during the summer break from school.",1,0,0,0,0,0
1419,"Analyzing consolidated summer of code programs can reveal how college students, who these programs usually target, can be motivated to participate in OSS, and what onboarding strategies OSS communities adopt to receive these students.",1,0,0,0,0,0
1420,"In this paper, we study the well-established Google Summer of Code (GSoC) and devise an integrated engagement theory grounded in multiple data sources to explain motivation and onboarding in this context.",0,1,1,0,0,0
1421,"Our analysis shows that OSS communities employ several strategies for planning and executing student participation, socially integrating the students, and rewarding student’s contributions and achievements.",0,0,0,0,1,0
1422,"Students are motivated by a blend of rewards, which are moderated by external factors.",0,0,0,0,1,0
1423,We presented these rewards and the motivation theory to students who had never participated in a summer of code program and collected their shift in motivation after learning about the theory.,0,0,0,0,1,0
1424,"New students can benefit from the former students' experiences detailed in our results, and OSS stakeholders can leverage both the insight into students’ motivations for joining such programs as well as the onboarding strategies we identify to devise actions to attract and retain newcomers.",0,0,0,0,0,1
1425,"A large percentage of real-world software configuration issues, such as misconfigurations, involve multiple interdependent configuration parameters.",1,0,0,0,0,0
1426,"However, existing techniques and tools either do not consider dependencies among configuration parameters— termed configuration dependencies—or rely on one or two dependency types and code patterns as input.",1,0,0,0,0,0
1427,"Without rigorous understanding of configuration dependencies, it is hard to deal with many resulting configuration issues.",1,0,0,0,0,0
1428,"This paper presents our study of software configuration dependencies in 16 widely-used cloud and datacenter systems, including dependencies within and across software components.",0,1,1,0,0,0
1429,"To understand types of configuration dependencies, we conduct an exhaustive search of descriptions in structured configuration metadata and unstructured user manuals.",0,0,1,0,0,0
1430,We find and manually analyze 521 configuration dependencies.,0,0,1,0,0,0
1431,We define five types of configuration dependencies and identify their common code patterns.,0,0,1,0,0,0
1432,We report on consequences of not satisfying these dependencies and current software engineering practices for handling the consequences.,0,0,1,0,0,0
1433,"We mechanize the knowledge gained from our study in a tool, cDep, which detects configuration dependencies.",0,0,0,1,0,0
1434,cDep automatically discovers five types of configuration dependencies from bytecode using static program analysis.,0,0,0,1,0,0
1435,We apply cDep to the eight Java and Scala software systems in our study.,0,0,0,1,0,0
1436,cDep finds 87.9% (275/313) of the related subset of dependencies from our study.,0,0,0,0,1,0
1437,"cDep also finds 448 previously undocumented dependencies, with a 6.0% average false positive rate.",0,0,0,0,1,0
1438,"Overall, our results show that configuration dependencies are more prevalent and diverse than previously reported and should henceforth be considered a first-class issue in software configuration engineering.",0,0,0,0,0,1
1439,Data stored in cloud services is highly sensitive and so access to it is controlled via policies written in domain-specific languages (DSLs).,1,0,0,0,0,0
1440,"The expressiveness of these DSLs provides users flexibility to cover a wide variety of uses cases, however, unintended misconfigurations can lead to potential security issues.",1,0,0,0,0,0
1441,"We introduce Block Public Access, a tool that formally verifies policies to ensure that they only allow access to trusted principals, i.e. that they prohibit access to the general public.",0,1,1,0,0,0
1442,"To this end, we formalize the notion of Trust Safety that formally characterizes whether or not a policy allows unconstrained (public) access.",0,0,1,0,0,0
1443,"Next, we present a method to compile the policy down to a logical formula whose unsatisfiability can be (1) checked by SMT and (2) ensures Trust Safety.",0,0,1,0,0,0
1444,"The constructs of the policy DSLs render unsatisfiability checking PSPACE-complete, which precludes verifying the millions of requests per second seen at cloud scale.",0,0,1,0,0,0
1445,"Hence, we present an approach that leverages the structure of the policy DSL to compute a much smaller residual policy that corresponds only to untrusted accesses.",0,0,1,0,0,0
1446,"Our approach allows Block Public Access to, in the common case, syntactically verify Trust Safety without having to query the SMT solver.",0,0,1,0,0,0
1447,"We have implemented Block Public Access and present an evaluation showing how the above optimization yields a low-latency policy verifier that the S3 team at AWS has integrated into their authorization system, where it is currently in production, analyzing millions of policies everyday to ensure that client buckets do not grant unintended public access.",0,0,0,0,0,1
1448,"We present a new framework and associated synthesis algorithms for program synthesis over noisy data, i.e., data that may contain incorrect/corrupted input-output examples.",0,1,1,0,0,0
1449,This framework is based on an extension of finite tree automata called state-weighted finite tree automata.,0,0,1,0,0,0
1450,We show how to apply this framework to formulate and solve a variety of program synthesis problems over noisy data.,0,1,0,0,0,0
1451,"Results from our implemented system running on problems from the SyGuS 2018 benchmark suite highlight its ability to successfully synthesize programs in the face of noisy data sets, including the ability to synthesize a correct program even when every input-output example in the data set is corrupted.",0,0,0,1,1,0
1452,Merging execution paths is a powerful technique for reducing path explosion in symbolic execution.,1,0,0,0,0,0
1453,"One approach, introduced and dubbed “veritesting” by Avgerinos et al., works by translating abounded control flow region into a single constraint.",1,0,0,0,0,0
1454,This approach is a convenient way to achieve path merging as a modification to a pre-existing single-path symbolic execution engine.,1,0,0,0,0,0
1455,"Previous work evaluated this approach for symbolic execution of binary code, but different design considerations apply when building tools for other languages.",1,0,0,0,0,0
1456,"In this paper, we extend the previous approach for symbolic execution of Java.",0,1,0,0,0,0
1457,"Because Java code typically contains many small dynamically dispatched methods, it is important to include them in multi-path regions; we introduce dynamic inlining of method-regions to do so modularly.",0,0,1,0,0,0
1458,"Java’s typed memory structure is very different from the binary representation, but we show how the idea of static single assignment (SSA) form can be applied to object references to statically account for aliasing.",0,0,1,0,0,0
1459,"We have implemented our algorithms in Java Ranger, an extension to the widely used Symbolic Pathfinder tool.",0,0,1,0,0,0
1460,"In a set of nine benchmarks, Java Ranger reduces the running time and number of execution paths by a total of 38% and 71% respectively as compared to SPF.",0,0,0,0,1,0
1461,"Our results are a significant improvement over the performance of JBMC, a recently released verification tool for Java bytecode.",0,0,0,0,1,0
1462,We also participated in a static verification competition at a top theory conference where other participants included state-of-the-art Java verifiers.,0,0,0,0,0,1
1463,JR won first place in the competition’s Java verification track.,0,0,0,0,0,1
1464,"In this paper, we present the first exploratory study of deprecated Python library APIs to understand the status quo of API deprecation in the realm of Python libraries.",0,1,1,1,0,0
1465,"Specifically, we aim to comprehend how deprecated library APIs are declared and documented in practice by their maintainers, and how library users react to them.",0,1,1,0,0,0
1466,"By thoroughly looking into six reputed Python libraries and 1,200 GitHub projects, we experimentally observe that API deprecation is poorly handled by library contributors, which subsequently introduce difficulties for Python developers to resolve the usage of deprecated library APIs.",0,0,0,1,1,0
1467,This empirical evidence suggests that our community should take immediate actions to appropriately handle the deprecation of Python library APIs.,0,0,0,0,0,1
1468,Software verification approaches aim to check a software component under analysis for all possible environments.,1,0,0,0,0,0
1469,"In reality, however, components are expected to operate within a larger system and are required to satisfy their requirements only when their inputs are constrained by environment assumptions.",1,0,0,0,0,0
1470,"In this paper, we propose EPIcuRus, an approach to automatically synthesize environment assumptions for a component under analysis (i.e., conditions on the component inputs under which the component is guaranteed to satisfy its requirements).",0,1,1,0,0,0
1471,"EPIcuRus combines search-based testing, machine learning and model checking.",0,0,1,0,0,0
1472,The core of EPIcuRus is a decision tree algorithm that infers environment assumptions from a set of test results including test cases and their verdicts.,0,0,1,0,0,0
1473,"The test cases are generated using search-based testing, and the assumptions inferred by decision trees are validated through model checking.",0,0,1,0,0,0
1474,"In order to improve the efficiency and effectiveness of the assumption generation process, we propose a novel test case generation technique, namely Important Features Boundary Test (IFBT), that guides the test generation based on the feedback produced by machine learning.",0,0,1,0,0,0
1475,We evaluated EPIcuRus by assessing its effectiveness in computing assumptions on a set of study subjects that include 18 requirements of four industrial models.,0,0,0,1,0,0
1476,"We show that, for each of the 18 requirements, EPIcuRus was able to compute an assumption to ensure the satisfaction of that requirement, and further, ≈78% of these assumptions were computed in one hour.",0,0,0,0,1,0
1477,Modern software is bloated.,1,0,0,0,0,0
1478,"Demand for new functionality has led developers to include more and more features, many of which become unneeded or unused as software evolves.",1,0,0,0,0,0
1479,"This phenomenon, known as software bloat, results in software consuming more resources than it otherwise needs to.",1,0,0,0,0,0
1480,How to effectively and automatically debloat software is a long-standing problem in software engineering.,1,0,0,0,0,0
1481,Various debloating techniques have been proposed since the late 1990s.,1,0,0,0,0,0
1482,"However, many of these techniques are built upon pure static analysis and have yet to be extended and evaluated in the context of modern Java applications where dynamic language features are prevalent.",1,0,0,0,0,0
1483,"To this end, we develop an end-to-end bytecode debloating framework called JShrink.",0,1,1,0,0,0
1484,It augments traditional static reachability analysis with dynamic profiling and type dependency analysis and renovates existing bytecode transformations to account for new language features in modern Java.,0,0,1,0,0,0
1485,We highlight several nuanced technical challenges that must be handled properly and examine behavior preservation of debloated software via regression testing.,0,0,1,0,0,0
1486,"We find that (1) JShrink is able to debloat our real-world Java benchmark suite by up to 47% (14% on average); (2) accounting for dynamic language features is indeed crucial to ensure behavior preservation---reducing 98% of test failures incurred by a purely static equivalent, Jax, and 84% for ProGuard; and (3) compared with purely dynamic approaches, integrating static analysis with dynamic profiling makes the debloated software more robust to unseen test executions---in 22 out of 26 projects, the debloated software ran successfully under new tests.",0,0,0,0,1,0
1487,"In large-scale cloud systems, unplanned service interruptions and outages may cause severe degradation of service availability.",1,0,0,0,0,0
1488,"Such incidents can occur in a bursty manner, which will deteriorate user satisfaction.",1,0,0,0,0,0
1489,Identifying incidents rapidly and accurately is critical to the operation and maintenance of a cloud system.,1,0,0,0,0,0
1490,"In industrial practice, incidents are typically detected through analyzing the issue reports, which are generated over time by monitoring cloud services.",1,0,0,0,0,0
1491,Identifying incidents in a large number of issue reports is quite challenging.,1,0,0,0,0,0
1492,An issue report is typically multi-dimensional: it has many categorical attributes.,1,0,0,0,0,0
1493,It is difficult to identify a specific attribute combination that indicates an incident.,1,0,0,0,0,0
1494,"Existing methods generally rely on pruning-based search, which is time-consuming given high-dimensional data, thus not practical to incident detection in large-scale cloud systems.",1,0,0,0,0,0
1495,"In this paper, we propose MID (Multi-dimensional Incident Detection), a novel framework for identifying incidents from large-amount, multi-dimensional issue reports effectively and efficiently.",0,1,1,0,0,0
1496,Key to the MID design is encoding the problem into a combinatorial optimization problem.,0,0,1,0,0,0
1497,"Then a specific-tailored meta-heuristic search method is designed, which can rapidly identify attribute combinations that indicate incidents.",0,0,1,0,0,0
1498,We evaluate MID with extensive experiments using both synthetic data and real-world data collected from a large-scale production cloud system.,0,0,0,1,0,0
1499,The experimental results show that MID significantly outperforms the current state-of-the-art methods in terms of effectiveness and efficiency.,0,0,0,0,1,0
1500,"Additionally, MID has been successfully applied to Microsoft's cloud systems and helped greatly reduce manual maintenance effort.",0,0,0,0,1,0
1501,"Robots that support humans by performing useful tasks (a.k.a., service robots) are booming worldwide.",1,0,0,0,0,0
1502,"In contrast to industrial robots, the development of service robots comes with severe software engineering challenges, since they require high levels of robustness and autonomy to operate in highly heterogeneous environments.",1,0,0,0,0,0
1503,"As a domain with critical safety implications, service robotics faces a need for sound software development practices.",1,0,0,0,0,0
1504,"In this paper, we present the first large-scale empirical study to assess the state of the art and practice of robotics software engineering.",0,1,1,1,0,0
1505,We conducted 18 semi-structured interviews with industrial practitioners working in 15 companies from 9 different countries and a survey with 156 respondents from 26 countries from the robotics domain.,0,0,0,1,0,0
1506,"Our results provide a comprehensive picture of (i) the practices applied by robotics industrial and academic practitioners, including processes, paradigms, languages, tools, frameworks, and reuse practices, (ii) the distinguishing characteristics of robotics software engineering, and (iii) recurrent challenges usually faced, together with adopted solutions.",0,0,0,0,1,0
1507,"The paper concludes by discussing observations, derived hypotheses, and proposed actions for researchers and practitioners.",0,0,0,0,0,1
1508,"Keeping a good influx of newcomers is critical for open source software projects' survival, while newcomers face many barriers to contributing to a project for the first time.",1,0,0,0,0,0
1509,"To support newcomers onboarding, GitHub encourages projects to apply labels such as good first issue (GFI) to tag issues suitable for newcomers.",1,0,0,0,0,0
1510,"However, many newcomers still fail to contribute even after many attempts, which not only reduces the enthusiasm of newcomers to contribute but makes the efforts of project members in vain.",1,0,0,0,0,0
1511,"To better support the onboarding of newcomers, this paper reports a preliminary study on this mechanism from its application status, effect, problems, and best practices.",0,1,1,1,0,0
1512,"By analyzing 9,368 GFIs from 816 popular GitHub projects and conducting email surveys with newcomers and project members, we obtain the following results.",0,0,0,1,0,0
1513,"We find that more and more projects are applying this mechanism in the past decade, especially the popular projects.",0,0,0,0,1,0
1514,"Compared to common issues, GFIs usually need more days to be solved.",0,0,0,0,1,0
1515,"While some newcomers really join the projects through GFIs, almost half of GFIs are not solved by newcomers.",0,0,0,0,1,0
1516,"We also discover a series of problems covering mechanism (e.g., inappropriate GFIs), project (e.g., insufficient GFIs) and newcomer (e.g., uneven skills) that makes this mechanism ineffective.",0,0,0,0,1,0
1517,"We discover the practices that may address the problems, including identifying GFIs that have informative description and available support, and require limited scope and skill, etc.",0,0,0,0,1,0
1518,"Newcomer onboarding is an important but challenging question in open source projects and our work enables a better understanding of GFI mechanism and its problems, as well as highlights ways in improving them.",0,0,0,0,0,1
1519,"JavaScript is widely used for implementing client-side web applications, and it is common to include JavaScript code from many different hosts.",1,0,0,0,0,0
1520,"However, in a web browser, all the scripts loaded in the same frame share a single global namespace.",1,0,0,0,0,0
1521,"As a result, a script may read or even overwrite the global objects or functions in other scripts, causing unexpected behaviors.",1,0,0,0,0,0
1522,"For example, a script can redefine a function in a different script as an object, so that any call of that function would cause an exception at run time.",1,0,0,0,0,0
1523,We systematically investigate the client-side JavaScript code integrity problem caused by JavaScript global identifier conflicts in this paper.,0,1,0,0,0,0
1524,"We developed a browser-based analysis framework, JSObserver, to collect and analyze the write operations to global memory locations by JavaScript code.",0,0,1,0,0,0
1525,"We identified three categories of conflicts using JSObserver on the Alexa top 100K websites, and detected 145,918 conflicts on 31,615 websites.",0,0,0,0,1,0
1526,We reveal that JavaScript global identifier conflicts are prevalent and could cause behavior deviation at run time.,0,0,0,0,1,0
1527,"In particular, we discovered that 1,611 redefined functions were called after being overwritten, and many scripts modified the value of cookies or redefined cookie-related functions.",0,0,0,0,1,0
1528,Our research demonstrated that JavaScript global identifier conflict is an emerging threat to both the web users and the integrity of web applications.,0,0,0,0,0,1
1529,Good documentation offers the promise of enabling developers to easily understand design decisions.,1,0,0,0,0,0
1530,"Unfortunately, in practice, design documents are often rarely updated, becoming inaccurate, incomplete, and untrustworthy.",1,0,0,0,0,0
1531,A better solution is to enable developers to write down design rules which are checked against code for consistency.,1,0,0,0,0,0
1532,"But existing rule checkers require learning specialized query languages or program analysis frameworks, creating a barrier to writing project-specific rules.",1,0,0,0,0,0
1533,We introduce two new techniques for authoring design rules: snippet-based authoring and semi-natural-language authoring.,0,1,1,0,0,0
1534,"In snippet-based authoring, developers specify characteristics of elements to match by writing partial code snippets.",0,0,1,0,0,0
1535,"In semi-natural language authoring, a textual representation offers a representation for understanding design rules and resolving ambiguities.",0,0,1,0,0,0
1536,We implemented these approaches in RulePad.,0,0,1,0,0,0
1537,"To evaluate RulePad, we conducted a between-subjects study with 14 participants comparing RulePad to the PMD Designer, a utility for writing rules in a popular rule checker.",0,0,0,1,0,0
1538,We found that those with RulePad were able to successfully author 13 times more query elements in significantly less time and reported being significantly more willing to use RulePad in their everyday work.,0,0,0,0,1,0
1539,Loop invariant generation has long been a challenging problem.,1,0,0,0,0,0
1540,Black-box learning has recently emerged as a promising method for inferring loop invariants.,1,0,0,0,0,0
1541,"However, the performance depends heavily on the quality of collected examples.",1,0,0,0,0,0
1542,"In many cases, only after tens or even hundreds of constraint queries, can a feasible invariant be successfully inferred.",1,0,0,0,0,0
1543,"To reduce the gigantic number of constraint queries and improve the performance of black-box learning, we introduce interval counterexamples into the learning framework.",0,1,1,0,0,0
1544,Each interval counterexample represents a set of counterexamples from constraint solvers.,0,0,1,0,0,0
1545,We propose three different generalization techniques to compute interval counterexamples.,0,0,1,0,0,0
1546,The existing decision tree algorithm is also improved to adapt interval counterexamples.,0,0,1,0,0,0
1547,We evaluate our techniques and report over 40% improvement on learning rounds and verification time over the state-of-the-art approach.,0,0,0,1,1,0
1548,Software systems are designed and implemented with assumptions about the environment.,1,0,0,0,0,0
1549,"However, once the system is deployed, the actual environment may deviate from its expected behavior, possibly undermining desired properties of the system.",1,0,0,0,0,0
1550,"To enable systematic design of systems that are robust against potential environmental deviations, we propose a rigorous notion of robustness for software systems.",0,1,1,0,0,0
1551,"In particular, the robustness of a system is defined as the largest set of deviating environmental behaviors under which the system is capable of guaranteeing a desired property.",0,0,1,0,0,0
1552,"We describe a new set of design analysis problems based on our notion of robustness, and a technique for automatically computing robustness of a system given its behavior description.",0,0,1,0,0,0
1553,We demonstrate potential applications of our robustness notion on two case studies involving network protocols and safety-critical interfaces.,0,0,0,1,0,0
1554,"We present HOMI, a new technique to enhance symbolic execution by maintaining only a small number of promising states.",0,1,1,0,0,0
1555,"In practice, symbolic execution typically maintains as many states as possible in a fear of losing important states.",1,0,0,0,0,0
1556,"In this paper, however, we show that only a tiny subset of the states plays a significant role in increasing code coverage or reaching bug points.",0,1,0,0,0,0
1557,"Based on this observation, HOMI aims to minimize the total number of states while keeping “promising” states during symbolic execution.",0,0,1,0,0,0
1558,We identify promising states by a learning algorithm that continuously updates the probabilistic pruning strategy based on data accumulated during the testing process.,0,0,1,0,0,0
1559,Experimental results show that HOMI greatly increases code coverage and the ability to find bugs of KLEE on open-source C programs.,0,0,0,1,1,0
1560,Equivalence checking techniques help establish whether two versions of a program exhibit the same behavior.,1,0,0,0,0,0
1561,The majority of popular techniques for formally proving/refuting equivalence relies on symbolic execution – a static analysis approach that reasons about program behaviors in terms of symbolic input variables.,1,0,0,0,0,0
1562,"Yet, symbolic execution is difficult to scale in practice due to complex programming constructs, such as loops and non-linear arithmetic.",1,0,0,0,0,0
1563,"This paper proposes an approach, named ARDiff, for improving the scalability of symbolic-execution-based equivalence checking techniques when comparing syntactically-similar versions of a program, e.g., for verifying the correctness of code upgrades and refactoring.",0,1,1,0,0,0
1564,"Our approach relies on a set of novel heuristics to determine which parts of the versions’ common code can be effectively pruned during the analysis, reducing the analysis complexity without sacrificing its effectiveness.",0,0,1,0,0,0
1565,"Furthermore, we devise a new equivalence checking benchmark, extending existing benchmarks with a set of real-life methods containing complex math functions and loops.",0,0,1,0,0,0
1566,"We evaluate the effectiveness and efficiency of ARDiff on this benchmark and show that it outperforms existing method-level equivalence checking techniques by solving 86% of all equivalent and 55% of non-equivalent cases, compared with 47% to 69% for equivalent and 38% to 52% for non-equivalent cases in related work.",0,0,0,1,1,0
1567,"The software development profession suffers from severe gender biases, which could be explicit and implicit.",1,0,0,0,0,0
1568,"However, SE literature has not systematically explored and evaluated the methods for reducing gender biases, especially for implicit gender biases.",1,0,0,0,0,0
1569,This paper reports on a field experiment to examine whether the intergroup contact theory could reduce implicit gender biases in software development.,0,1,1,1,0,0
1570,"In the field experiment, 280 undergraduate students taking a project-centric introductory software engineering course were assigned to 70 teams with different contact configurations.",0,0,0,1,0,0
1571,We measured and compared their explicit and implicit gender biases before and after contacts in their teams.,0,0,0,1,0,0
1572,The study yields a rich set of findings.,0,0,0,0,1,0
1573,"First, we confirmed the positive effects of intergroup contact theory in reducing gender biases, particularly the implicit gender biases in both general and SE-specific contexts.",0,0,0,0,1,0
1574,We further revealed that such effects were subjected to different contact configurations.,0,0,0,0,1,0
1575,The intergroup contact theory's effects were maximized in teams where the number of females is greater than or equal to the number of males.,0,0,0,0,1,0
1576,"When the female is the minority group in a team, contacts among members contribute to reducing male members' implicit gender biases but fail to result in the same scale of effects on female members' implicit gender biases.",0,0,0,0,1,0
1577,The findings provide insights into using intergroup contact theory in reducing implicit gender biases in software development contexts.,0,0,0,0,0,1
1578,"Current approaches combining multiple static analyses deriving different, independent properties focus either on modularity or performance.",1,0,0,0,0,0
1579,"Whereas declarative approaches facilitate modularity and automated, analysis-independent optimizations, imperative approaches foster manual, analysis-specific optimizations.",1,0,0,0,0,0
1580,"In this paper, we present a novel approach to static analyses that leverages the modularity of blackboard systems and combines declarative and imperative techniques.",0,1,1,0,0,0
1581,"Our approach allows exchangeability, and pluggable extension of analyses in order to improve sound(i)ness, precision, and scalability and explicitly enables the combination of otherwise incompatible analyses.",0,0,1,0,0,0
1582,"With our approach integrated in the OPAL framework, we were able to implement various dissimilar analyses, including a points-to analysis that outperforms an equivalent analysis from Doop, the state-of-the-art points-to analysis framework.",0,0,0,0,0,1
1583,"When software products and services are developed and maintained over longer time, software engineering practices tend to drift away from both structured and agile methods.",1,0,0,0,0,0
1584,"Nonetheless, in many cases the evolving practices are far from ad hoc or chaotic.",1,0,0,0,0,0
1585,How are the teams involved able to coordinate their joint development?This article reports on an ethnographic study of a small team at a successful provider of software as a service.,0,1,1,1,0,0
1586,What struck us was the very explicit way in which the team adopted and adapted their practices to fit the needs of the evolving development.,0,0,1,0,0,0
1587,"The discussion relates the findings to the concepts of social practices and methods in software engineering, and explores the differences between degraded behavior and the coordinated evolution of development practices.",0,0,1,0,0,0
1588,"The analysis helps to better understand how software engineering practices evolve, and thus provides a starting point for rethinking software engineering methods and their relation to software engineering practice.",0,0,0,0,0,1
1589,Background.,1,0,0,0,0,0
1590,Artifact evaluation has been introduced into the software engineering and programming languages research community with a pilot at ESEC/FSE 2011 and has since then enjoyed a healthy adoption throughout the conference landscape.,1,0,0,0,0,0
1591,Objective.,0,1,0,0,0,0
1592,"In this qualitative study, we examine the expectations of the community toward research artifacts and their evaluation processes.",0,1,1,0,0,0
1593,Method.,0,0,0,1,0,0
1594,We conducted a survey including all members of artifact evaluation committees of major conferences in the software engineering and programming language field since the first pilot and compared the answers to expectations set by calls for artifacts and reviewing guidelines.,0,0,0,1,0,0
1595,Results.,0,0,0,0,1,0
1596,"While we find that some expectations exceed the ones expressed in calls and reviewing guidelines, there is no consensus on quality thresholds for artifacts in general.",0,0,0,0,1,0
1597,"We observe very specific quality expectations for specific artifact types for review and later usage, but also a lack of their communication in calls.",0,0,0,0,1,0
1598,We also find problematic inconsistencies in the terminology used to express artifact evaluation’s most important purpose – replicability.,0,0,0,0,1,0
1599,Conclusion.,0,0,0,0,0,1
1600,We derive several actionable suggestions which can help to mature artifact evaluation in the inspected community and also to aid its introduction into other communities in computer science.,0,0,0,0,0,1
1601,"In large-scale online service systems, incidents occur frequently due to a variety of causes, from updates of software and hardware to changes in operation environment.",1,0,0,0,0,0
1602,These incidents could significantly degrade system’s availability and customers’ satisfaction.,1,0,0,0,0,0
1603,Some incidents are linked because they are duplicate or inter-related.,1,0,0,0,0,0
1604,The linked incidents can greatly help on-call engineers find mitigation solutions and identify the root causes.,1,0,0,0,0,0
1605,"In this work, we investigate the incidents and their links in a representative real-world incident management (IcM) system.",0,1,1,0,0,0
1606,"Based on the identified indicators of linked incidents, we further propose LiDAR (Linked Incident identification with DAta-driven Representation), a deep learning based approach to incident linking.",0,0,1,0,0,0
1607,"More specifically, we incorporate the textual description of incidents and structural information extracted from historical linked incidents to identify possible links among a large number of incidents.",0,0,1,0,0,0
1608,"To show the effectiveness of our method, we apply our method to a real-world IcM system and find that our method outperforms other state-of-the-art methods.",0,0,0,1,1,0

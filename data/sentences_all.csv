,sentence,background_motivation,aim_contribution,research_object,research_method,results_findings,summary
0,Developers have access to tools like Google Lighthouse to assess the performance of web apps and to guide the adoption of development best practices.,1,0,0,0,0,0
1,"However, when it comes to energy consumption of mobile web apps, these tools seem to be lacking.",1,0,0,0,0,0
2,This study investigates on the correlation between the performance scores produced by Lighthouse and the energy consumption of mobile web apps.,0,1,0,0,0,0
3,We design and conduct an empirical experiment where 21 real mobile web apps are (i) analyzed via the Lighthouse performance analysis tool and (ii) measured on an Android device running a software-based energy profiler.,0,0,0,1,0,0
4,"Then, we statistically assess how energy consumption correlates with the obtained performance scores and carry out an effect size estimation.",0,0,0,1,0,0
5,"We discover a statistically significant negative correlation between performance scores and the energy consumption of mobile web apps (with medium to large effect sizes), implying that an increase of the performance score tend to lead to a decrease of energy consumption.",0,0,0,0,1,0
6,"We recommend developers to strive to improve the performance level of their mobile web apps, as this can also have a positive impact on their energy consumption on Android devices.",0,0,0,0,0,1
7,Factors such as app stores or platform choices heavily affect functional and non-functional mobile app requirements.,1,0,0,0,0,0
8,We surveyed 45 companies and interviewed ten experts to explore how factors that impact mobile app requirements are understood by requirements engineers in the mobile app industry.,0,0,0,1,0,0
9,We observed the lack of knowledge in several areas.,0,0,0,0,1,0
10,"For instance, we observed that all practitioners were aware of data privacy concerns, however, they did not know that certain third-party libraries, usage aggregators, or advertising libraries also occasionally leak sensitive user data.",0,0,0,0,1,0
11,"Similarly, certain functional requirements may not be implementable in the absence of a third-party library that is either banned from an app store for policy violations or lacks features, for instance, missing desired features in ARKit library for iOS made practitioners turn to Android.",0,0,0,0,1,0
12,"We conclude that requirements engineers should have adequate technical experience with mobile app development as well as sufficient knowledge in areas such as privacy, security and law, in order to make informed decisions during requirements elicitation.",0,0,0,0,0,1
13,The software engineering industry is increasingly aware of the role and value of neurodiverse engineers within the workforce.,1,0,0,0,0,0
14,One motivation is the alignment between skills needed for software development and the processing strengths of individuals with autistic spectrum conditions.,1,0,0,0,0,0
15,"One aspect of neurodiversity is dyslexia, typically presenting in individuals through a range of reading deficiencies.",1,0,0,0,0,0
16,In this paper we build on recent work which has sought to investigate if programmers with dyslexia read program code in a way which is different from programmers without dyslexia.,0,1,0,0,0,0
17,The particular focus of this analysis is the nature of saccadic movement and patterns of linearity when reading code.,0,0,1,0,0,0
18,A study is presented in which the eye gaze of 28 programmers (14 with dyslexia and 14 without) was recorded using an eye tracking device while reading and understanding three on-screen Java programs.,0,0,0,1,0,0
19,"Using insights from the wider dyslexia literature, hypotheses are formulated to reflect the expected saccadic gaze behaviour of programmers with dyslexia.",0,0,0,1,0,0
20,A range of existing metrics for linearity of program reading are adapted and used for statistical analysis of the data.,0,0,0,1,0,0
21,Results are consistent with recent work elsewhere and indicate that programmers with dyslexia do not exhibit patterns of linearity significantly different from the control group.,0,0,0,0,1,0
22,Non-linear gaze is shown to be approximately 40% of all saccadic movement.,0,0,0,0,1,0
23,"Some preliminary insights are offered based on the data available, suggesting that the extent of non-linear reading when comprehending program code might complement the processing and problem solving style of the programmer with dyslexia.",0,0,0,0,0,1
24,"In Software Product Lines (SPL), feature extraction from software requirements specifications has been subject to intense research in order to assist domain analysis in a time-saving way.",1,0,0,0,0,0
25,"Although various approaches are proposed to extract features, there still exists a gap to achieve the complete view of features, that is, how to figure out the intention of a feature.",1,0,0,0,0,0
26,Feature terms as the smallest units in a feature can be regarded as vital indicators for describing a feature.,1,0,0,0,0,0
27,"Automated feature term extraction can provide key information regarding the intention of a feature, which improves the efficiency of domain analysis.",1,0,0,0,0,0
28,"In this paper, we propose an approach to train prediction models by using machine learning techniques to identify feature terms.",0,1,0,0,0,0
29,"To this end, we extract candidate terms from requirement specifications in one domain and take six attributes of each term into account to create a labeled dataset.",0,0,0,1,0,0
30,"Subsequently, we apply seven commonly used machine algorithms to train prediction models on the labeled dataset.",0,0,0,1,0,0
31,We then use these prediction models to predict feature terms from the requirements belonging to the other two different domains.,0,0,0,1,0,0
32,"Our results show that (1) feature terms can be predicted with high accuracy of ≈ 90% within a domain (2) prediction across domains leads to a decreased but still good accuracy (≈ 80%), and (3) machine learning algorithms perform differently.",0,0,0,0,1,0
33,GitHub has become a precious service for storing and managing software source code.,1,0,0,0,0,0
34,"Over the last year, 10M new developers have joined the GitHub community, contributing to more than 44M repositories.",1,0,0,0,0,0
35,"In order to help developers increase the reachability of their repositories, in 2017 GitHub introduced the possibility to classify them by means of topics.",1,0,0,0,0,0
36,"However, assigning wrong topics to a given repository can compromise the possibility of helping other developers approach it, and thus preventing them from contributing to its development.",1,0,0,0,0,0
37,In this paper we investigate the application of Multinomial Naïve Bayesian (MNB) networks to automatically classify GitHub repositories.,0,1,0,0,0,0
38,"By analyzing the README file(s) of the repository to be classified and the source code implementing it, the conceived approach is able to recommend GitHub topics.",0,0,0,1,0,0
39,"To the best of our knowledge, this is the first supervised approach addressing the considered problem.",0,0,0,0,0,1
40,"Consequently, since there exists no suitable baseline for the comparison, we validated the approach by considering different metrics, aiming to study various quality aspects.",0,0,0,0,1,0
41,Background: Publication bias is the failure to publish the results of a study based on the direction or strength of the study findings.,1,0,0,0,0,0
42,The existence of publication bias is firmly established in areas like medical research.,1,0,0,0,0,0
43,Recent research suggests the existence of publication bias in Software Engineering.,1,0,0,0,0,0
44,Aims: Finding out whether experiments published in the International Workshop on Empirical Software Engineering and Measurement (ESEM) are affected by publication bias.,0,1,0,0,0,0
45,Method: We review experiments published in ESEM.,0,0,0,1,0,0
46,We also survey with experimental researchers to triangulate our findings.,0,0,0,1,0,0
47,Results: ESEM experiments do not define hypotheses and frequently perform multiple testing.,0,0,0,0,1,0
48,One-tailed tests have a slightly higher rate of achieving statistically significant results.,0,0,0,0,1,0
49,We could not find other practices associated with publication bias.,0,0,0,0,1,0
50,"Conclusions: Our results provide a more encouraging perspective of SE research than previous research: (1) ESEM publications do not seem to be strongly affected by biases and (2) we identify some practices that could be associated with p-hacking, but it is more likely that they are related to the conduction of exploratory research.",0,0,0,0,0,1
51,Context: There is considerable diversity in the range and design of computational experiments to assess classifiers for software defect prediction.,1,0,0,0,0,0
52,"This is particularly so, regarding the choice of classifier performance metrics.",1,0,0,0,0,0
53,"Unfortunately some widely used metrics are known to be biased, in particular F1.",1,0,0,0,0,0
54,Objective: We want to understand the extent to which the widespread use of the F1 renders empirical results in software defect prediction unreliable.,0,1,0,0,0,0
55,Method: We searched for defect prediction studies that report both F1 and the Matthews correlation coefficient (MCC).,0,0,0,1,0,0
56,This enabled us to determine the proportion of results that are consistent between both metrics and the proportion that change.,0,0,0,1,0,0
57,Results: Our systematic review identifies 8 studies comprising 4017 pairwise results.,0,0,0,0,1,0
58,"Of these results, the direction of the comparison changes in 23% of the cases when the unbiased MCC metric is employed.",0,0,0,0,1,0
59,"Conclusion: We find compelling reasons why the choice of classification performance metric matters, specifically the biased and misleading F1 metric should be deprecated.",0,0,0,0,0,1
60,"Context: Design pattern detection is a very important research on software reuse, which can greatly help software maintenance and reconstruction.",1,0,0,0,0,0
61,"At present, many researchers have invested in this work and proposed a variety of methods for detection.",1,0,0,0,0,0
62,Method: This paper extends the graph matching technology based on the past and proposes a new method that combines network analysis and structural matching for detection.,0,0,0,1,0,0
63,"First, we use network level analysis to obtain important nodes, then use the neighborhood path matching algorithm to match the pattern instance.",0,0,0,1,0,0
64,"Result: We describe the detection of five patterns on four open source systems, then analyze and compare with the other three methods, for achieving high precision and recall, which demonstrates that our method is effective.",0,0,0,0,1,0
65,"Conclusion: Using combining network analysis with structural matching can well detect these pattern instances, and these instances are also especially important for future software refactoring.",0,0,0,0,0,1
66,Spectrum-Based Fault Localization (SBFL) follows the basic intuitions that the faulty parts are more likely to be covered by failure-revealing test cases and less likely to be covered by passed test cases.,1,0,0,0,0,0
67,"However, due to the diversity of programs and faults, many other characteristics (related to program structure, test suites, and type of faulty components) will influence the practical application of SBFL.",1,0,0,0,0,0
68,"For example, a statement can be covered by numerous failure-revealing test cases, and also covered by numerous passed test cases.",1,0,0,0,0,0
69,"To get more indicators about the faulty components towards a better application of SBFL, we extend the scope of spectrum-based knowledge from the basic intuitions to the Characteristics of Spectra Distribution (CSDs for short).",0,1,0,0,0,0
70,"That is, we explore the relationships between different types of statements and their spectra.",0,1,0,0,0,0
71,"Firstly, we introduce the concepts of Failure-Independent, Failure-Related, and Failure-Exclusionary to describe the relationships between different types of statements and their executions.",0,0,0,0,1,0
72,"Then, we propose two probabilistic models, with and without the noise of fault interference, respectively, to identify various CSDs for each type of statements.",0,0,0,0,1,0
73,"As the analysis results, we introduce a visualization technique to generalize the identified CSDs and provide an overall picture of spectra distribution and its dynamics.",0,0,0,0,1,0
74,"Finally, based on our analysis and also the observation of the program spectra of current benchmarks, we design a technique to filter the potential non-faulty statements to improve the accuracy of SBFL.",0,0,0,0,1,0
75,"Context: With the growing popularity of rapid software delivery and deployment, the methods, practices and technologies of Continuous Software Engineering (CSE) are evolving steadily.",1,0,0,0,0,0
76,"This creates the need for understanding the recent trends of the technologies, practitioners' challenges and views in this domain.",1,0,0,0,0,0
77,"Objective: In this paper, we present an empirical study aimed at exploring CSE from the practitioners' perspective by mining discussions from Q&A websites.",0,1,0,0,0,0
78,"Method: We have analyzed 12,989 questions and answers posted on Stack Overflow.",0,0,0,1,0,0
79,Topic modelling is conducted to derive the dominant topics in this domain.,0,0,0,1,0,0
80,"Further, a qualitative analysis was conducted to identify the key challenges discussed.",0,0,0,1,0,0
81,"Findings: Whilst the trend of posted questions is sharply increasing, the questions are becoming more specific to technologies and more difficult to attract answers.",0,0,0,0,0,1
82,"We identified 32 topics of discussions, among which ""Error messages in Continuous Integration/Deployment"" and ""Continuous Integration concepts"" are the most dominant.",0,0,0,0,1,0
83,We also present the most challenging areas in this domain from the practitioners' perspectives.,0,0,0,0,1,0
84,Decisions run through the whole software development and maintenance processes.,1,0,0,0,0,0
85,"Explicitly documenting these decisions helps to organize development knowledge and to reduce its vaporization, thereby controlling the development process and maintenance costs.",1,0,0,0,0,0
86,It can also support the knowledge acquisition process for stakeholders of the project.,1,0,0,0,0,0
87,"Meanwhile, developers (e.g., architects) and managers will be able to rely on the decisions made in the past to solve the problems encountered in their current projects.",1,0,0,0,0,0
88,"However, identifying decisions from massive textual artifacts, which involves considerable human effort, time, and cost, is usually unaffordable due to limited resources.",1,0,0,0,0,0
89,"To address this problem, we conducted an experiment to automatically identify decisions from textual artifacts using machine learning techniques.",0,1,0,0,0,0
90,"We created a dataset of 1,300 sentences labelled from the Hibernate developer mailing list, containing 650 decision sentences and non-decision sentences respectively, and trained machine learning models using 160 configurations regarding text preprocessing, feature extraction, and classification algorithms.",0,0,0,1,0,0
91,"The results show that (1) the text preprocessing method with Including Stop Words, No Stemming and Lemmatization, and No Filtering Out Sentences performs best when preprocessing posts to identify decisions; (2) the simple Bag-of-Words (BoW) model works best when extracting features to identify decisions; (3) the Support Vector Machine (SVM) algorithm gets the best result when training classifiers to identify decisions; and (4) the SVM algorithm with Including Stop Words (ISW), No Stemming and Lemmatization (NSaL), Filtering Out Sentences by Length (FOSbL), and BoW achieves the best performance (with a precision of 0.640, a recall of 0.932, and an F1-score of 0.759), compared with other configurations when identifying decisions from the mailing list.",0,0,0,0,1,0
92,Context: The vast majority of software engineering research is reported independently of the application domain: techniques and tools usage is reported without any domain context.,1,0,0,0,0,0
93,"As reported in previous research, this has not always been so: early in the computing era, the research focus was frequently application domain specific (for example, scientific and data processing).",1,0,0,0,0,0
94,Objective: We believe determining the research context is often important.,0,1,0,0,0,0
95,"Therefore we propose a code-based approach to identify the application domain of a software system, via its lexicon.",0,1,0,0,0,0
96,We compare its use against the plain textual description attached to the same system.,0,1,0,0,0,0
97,"Method: Using a sample of 50 Java projects, we obtained i) the description of each project (e.g., its ReadMe file), ii) the lexicon extracted from its source code, and iii) a list of its main topics extracted with the Latent Dirichlet Allocation (LDA) modelling technique.",0,0,0,1,0,0
98,"We assigned a random subset of these data items to different researchers (i.e., 'experts'), and asked them to assign each item to one (or more) application domain.",0,0,0,1,0,0
99,We then evaluated the precision and accuracy of the three techniques.,0,0,0,1,0,0
100,"Results: Using the agreement levels between experts, We observed that the 'baseline' dataset (i.e., the ReadMe files) obtained the highest average in terms of agreement between experts, but we also observed that the three techniques had the same mode and median agreement levels.",0,0,0,0,1,0
101,"Additionally, in the cases where no agreement was reached for the baseline dataset, the two other techniques provided sufficient additional support.",0,0,0,0,1,0
102,"Conclusions: We conclude that the source code is sufficient for determining the application domain, so that classification is possible without special documentation requirements.",0,0,0,0,0,1
103,Many companies have turned towards globally distributed software development in their quest for access to more development capacity.,1,0,0,0,0,0
104,"This paper investigates how a company onboarded distributed teams in a global project, and report experience on how to study such distributed projects.",0,1,0,0,0,0
105,Onboarding is the process of helping new team members adapt to the existing team and ways of working.,1,0,0,0,0,0
106,The goal of the studied onboarding program was to integrate Portuguese developers into two existing Norwegian teams.,0,0,0,1,0,0
107,"Further, due to the growing trend in utilizing globally distributed projects, and the challenge of conducting studies in distributed organizations, it is crucial to find good practices for researching such projects.",1,0,0,0,0,0
108,"We collected qualitative data from interviews, observations, Slack conversations and documents, and quantitative data on Slack activity.",0,0,0,0,1,0
109,"We report experiences on different onboarding practices and techniques, and we suggest guidelines to help other researchers conduct qualitative studies in globally distributed projects.",0,0,0,0,0,1
110,Expanding abbreviations in source code to their full meanings is very useful for software maintainers to comprehend the source code.,1,0,0,0,0,0
111,"The existing approaches, however, focus on expanding an abbreviation to a single word, i.e., unigram.",1,0,0,0,0,0
112,They do not perform well when dealing with abbreviations of phrases that consist of multiple unigrams.,1,0,0,0,0,0
113,This paper proposes a bigram-based approach for retrieving abbreviated phrases automatically.,0,1,0,0,0,0
114,Key to this approach is a bigram-based inference model for choosing the best phrase from all candidates.,0,0,0,1,0,0
115,It utilizes the statistical properties of unigrams and bigrams as prior knowledge and a bigram language model for estimating the likelihood of each candidate phrase of a given abbreviation.,0,0,0,1,0,0
116,"We have applied the bigram-based approach to 100 phrase abbreviations, randomly selected from eight open source projects.",0,0,0,1,0,0
117,The experiment results show that it has correctly retrieved 78% of the abbreviations by using the unigram and bigram properties of a source code repository.,0,0,0,0,1,0
118,This is 9% more accurate than the unigram-based approach and much better than other existing approaches.,0,0,0,0,1,0
119,The bigram-based approach is also less biased towards specific phrase sizes than the unigram-based approach.,0,0,0,0,1,0
120,"There is a rapidly increasing amount of Artificial Intelligence (AI) systems developed in recent years, with much expectation on its capacity of innovation and business value generation.",1,0,0,0,0,0
121,"However, the promised value of AI systems in specific business contexts might not be understood, and further integrated into the development processes.",1,0,0,0,0,0
122,"We wanted to understand how software engineering processes and practices can be applied to develop AI systems in a fast-faced, business-driven manner.",0,1,0,0,0,0
123,"As the first step, we explored contextual factors of AI development and the connections between AI developments to business opportunities.",0,0,0,1,0,0
124,"We conducted 12 semi-structured interviews in seven companies in Brazil, Norway and Southeast Asia.",0,0,0,1,0,0
125,Our investigation revealed different types of AI systems and different AI development approaches.,0,0,0,0,1,0
126,"However, it is common that business opportunities involving with AI systems are not validated and there is lack of business-driven metrics that guide the development of AI systems.",0,0,0,0,1,0
127,The findings have implications for future research on business-driven AI development and supporting tools and practices.,0,0,0,0,0,1
128,Conclusions that are drawn from experiments are subject to varying degrees of uncertainty.,1,0,0,0,0,0
129,"For example, they might rely on small data sets, employ statistical techniques that make assumptions that are hard to verify, or there may be unknown confounding factors.",1,0,0,0,0,0
130,"In this paper we propose an alternative but complementary mechanism to explicitly incorporate these various sources of uncertainty into reasoning about empirical findings, by applying Subjective Logic.",0,1,0,0,0,0
131,"To do this we show how typical traditional results can be encoded as ""subjective opinions"" -- the building blocks of Subjective Logic.",0,0,0,1,0,0
132,We demonstrate the value of the approach by using Subjective Logic to aggregate empirical results from two large published studies that explore the relationship between programming languages and defects or failures.,0,0,0,0,1,0
133,Background: Machine Learning (ML) has been widely used as a powerful tool to support Software Engineering (SE).,1,0,0,0,0,0
134,The fundamental assumptions of data characteristics required for specific ML methods have to be carefully considered prior to their applications in SE.,1,0,0,0,0,0
135,"Within the context of Continuous Integration (CI) and Continuous Deployment (CD) practices, there are two vital characteristics of data prone to be violated in SE research.",1,0,0,0,0,0
136,"First, the logs generated during CI/CD for training are imbalanced data, which is contrary to the principles of common balanced classifiers; second, these logs are also time-series data, which violates the assumption of cross-validation.",1,0,0,0,0,0
137,Objective: We aim to systematically study the two data characteristics and further provide a comprehensive evaluation for predictive CI/CD with the data from real projects.,0,1,0,0,0,0
138,Method: We conduct an experimental study that evaluates 67 CI/CD predictive models using both cross-validation and time-series-validation.,0,0,0,1,0,0
139,"Results: Our evaluation shows that cross-validation makes the evaluation of the models optimistic in most cases, there are a few counter-examples as well.",0,0,0,0,1,0
140,"The performance of the top 10 imbalanced models are better than the balanced models in the predictions of failed builds, even for balanced data.",0,0,0,0,1,0
141,The degree of data imbalance has a negative impact on prediction performance.,0,0,0,0,1,0
142,"Conclusion: In research and practice, the assumptions of the various ML methods should be seriously considered for the validity of research.",0,0,0,0,0,1
143,"Even if it is used to compare the relative performance of models, cross-validation may not be applicable to the problems with time-series features.",0,0,0,0,0,1
144,The research community need to revisit the evaluation results reported in some existing research.,0,0,0,0,0,1
145,Context: Software testing plays an important role in assuring the reliability of systems.,1,0,0,0,0,0
146,Assessing the efficacy of testing remains challenging with few established test effectiveness metrics.,1,0,0,0,0,0
147,Those metrics that have been used (e.g. coverage and mutation analysis) have been criticised for insufficiently differentiating between the faults detected by tests.,1,0,0,0,0,0
148,Objective: We investigate how effective tests are at detecting different types of faults and whether some types of fault evade tests more than others.,0,1,0,0,0,0
149,Our aim is to suggest to developers specific ways in which their tests need to be improved to increase fault detection.,0,1,0,0,0,0
150,Method: We investigate seven fault types and analyse how often each goes undetected in 10 open source systems.,0,0,0,1,0,0
151,We statistically look for any relationship between the test set and faults.,0,0,0,1,0,0
152,"Results: Our results suggest that the fault detection rates of unit tests are relatively low, typically finding only about a half of all faults.",0,0,0,0,1,0
153,"In addition, conditional boundary and method call removals are less well detected by tests than other fault types.",0,0,0,0,1,0
154,Conclusions: We conclude that the testing of these open source systems needs to be improved across the board.,0,0,0,0,0,1
155,"In addition, despite boundary cases being long known to attract faults, tests covering boundaries need particular improvement.",0,0,0,0,0,1
156,"Overall, we recommend that developers do not rely only on code coverage and mutation score to measure the effectiveness of their tests.",0,0,0,0,0,1
157,Software testing is a crucial activity to check the internal quality of a software.,1,0,0,0,0,0
158,"During testing, developers often create tests for the normal behavior of a particular functionality (e.g., was this file properly uploaded to the cloud?).",1,0,0,0,0,0
159,"However, little is known whether developers also create tests for the exceptional behavior (e.g., what happens if the network fails during the file upload?).",1,0,0,0,0,0
160,"To minimize this knowledge gap, in this paper we design and perform a mixed-method study to understand how 417 open source Java projects are testing the exceptional behavior using the JUnit and TestNG frameworks, and the AssertJ library.",0,1,0,0,0,0
161,We found that 254 (60.91%) projects have at least one test method dedicated to test the exceptional behavior.,0,0,0,0,1,0
162,We also found that the number of test methods for exceptional behavior with respect to the total number of test methods lies between 0% and 10% in 317 (76.02%) projects.,0,0,0,0,1,0
163,"Also, 239 (57.31%) projects test only up to 10% of the used exceptions in the System Under Test (SUT).",0,0,0,0,1,0
164,"When it comes to mobile apps, we found that, in general, developers pay less attention to exceptional behavior tests when compared to desktop/server and multi-platform developers.",0,0,0,0,1,0
165,"In general, we found more test methods covering custom exceptions (the ones created in the own project) when compared to standard exceptions available in the Java Development Kit (JDK) or in third-party libraries.",0,0,0,0,1,0
166,"To triangulate the results, we conduct a survey with 66 developers from the projects we study.",0,0,0,1,0,0
167,"In general, the survey results confirm our findings.",0,0,0,0,0,1
168,"In particular, the majority of the respondents agrees that developers often neglect exceptional behavior tests.",0,0,0,0,0,1
169,"As implications, our numbers might be important to alert developers that more effort should be placed on creating tests for the exceptional behavior.",0,0,0,0,0,1
170,"Driven by the need for faster time-to-market and reduced development lead-time, large-scale systems engineering companies are adopting agile methods in their organizations.",1,0,0,0,0,0
171,This agile transformation is challenging and it is common that adoption starts bottom-up with agile software teams within the context of traditional company structures.,1,0,0,0,0,0
172,This creates the challenge of agile teams working within a document-centric and plan-driven (or waterfall) environment.,1,0,0,0,0,0
173,"While it may be desirable to take the best of both worlds, it is not clear how that can be achieved especially with respect to managing requirements in large-scale systems.",1,0,0,0,0,0
174,This paper presents an exploratory case study focusing on two departments of a large-scale systems engineering company (automotive) that is in the process of company-wide agile adoption.,0,0,0,1,0,0
175,We present challenges that agile teams face while working within a larger plan-driven context and propose potential strategies to mitigate the challenges.,0,0,0,0,1,0
176,"Challenges relate to, e.g., development teams not being aware of the high-level requirements, difficulties to manage change of these requirements as well as their relationship to backlog items such as user stories.",0,0,0,0,1,0
177,"While we found strategies for solving most of the challenges, they remain abstract and empirical research on their effectiveness is currently lacking.",0,0,0,0,0,1
178,"Background: Practitioners would like to take action based on software metrics, as long as they find them reliable.",1,0,0,0,0,0
179,"Existing literature explores how metrics can be made reliable, but remains unclear if there are other conditions necessary for a metric to be actionable.",1,0,0,0,0,0
180,"Context & Method: In the context of a European H2020 Project, we conducted a multiple case study to study metrics' use in four companies, and identified instances where these metrics influenced actions.",0,0,0,1,0,0
181,We used an online questionnaire to enquire about the project participants' views on actionable metrics.,0,0,0,1,0,0
182,"Next, we invited one participant from each company to elaborate on the identified metrics' use for taking actions and the questionnaire responses (N=17).",0,0,0,1,0,0
183,"Result: We learned that a metric that is practical, contextual, and exhibits high data quality characteristics is actionable.",0,0,0,0,1,0
184,"Even a non-actionable metric can be useful, but an actionable metric mostly requires interpretation.",0,0,0,0,1,0
185,"However, the more these metrics are simple and reflect the software development context accurately, the less interpretation required to infer actionable information from the metric.",0,0,0,0,1,0
186,Company size and project characteristics can also influence the type of metric that can be actionable.,0,0,0,0,1,0
187,Conclusion: This exploration of industry's views on actionable metrics help characterize actionable metrics in practical terms.,0,0,0,0,0,1
188,This awareness of what characteristics constitute an actionable metric can facilitate their definition and development right from the start of a software metrics program.,0,0,0,0,0,1
189,Context: Quality requirements (QRs) have a significant role in the success of software projects.,1,0,0,0,0,0
190,"In agile software development (ASD), where working software is valued over comprehensive documentation, QRs are often under-specified or not documented.",1,0,0,0,0,0
191,"Consequently, they may be handled improperly and result in degraded software quality and increased maintenance costs.",1,0,0,0,0,0
192,"Investigating the documentation of QRs in ASD, would provide evidence on existing practices, tools and aspects considered in ASD that other practitioners might utilize to improve documentation and management of QRs in ASD.",1,0,0,0,0,0
193,"Although there are some studies examining documentation in ASD, those that specifically investigate the documentation of QRs in depth are lacking.",1,0,0,0,0,0
194,"Method: we conducted a multiple case study by interviewing 15 practitioners of four ASD cases, to provide empirical evidence on documentation of QRs in ASD.",0,0,0,1,0,0
195,"We also run workshops with two of the cases, to identify important aspects that ASD practitioners consider when documenting QRs in requirements management repositories.",0,0,0,1,0,0
196,Result and conclusions: ASD companies approach documentation of QRs to fit the needs of their context.,0,0,0,0,1,0
197,"They used tools, backlogs, iterative prototypes, and artifacts such as epic, and stories to document QRs, or utilized face-face communication without documenting QRs.",0,0,0,0,1,0
198,"We observed that documentation of QRs in ASD is affected by factors such as context (e.g. product domain, and size) and the experience of practitioners.",0,0,0,0,1,0
199,"Some tools used to document QRs also enhanced customer collaboration, enabling customers report and document QRs.",0,0,0,0,1,0
200,"Aspects such as levels of abstraction, the traceability of QRs, optimal details of information of QRs and verification and validation are deemed important when documenting QRs in ASD requirements management repositories.",0,0,0,0,1,0
201,"Modelling is a fundamental activity in software engineering, which is often performed in collaboration.",1,0,0,0,0,0
202,"For this purpose, on-line tools running on the cloud are frequently used.",1,0,0,0,0,0
203,"However, recent advances in Natural Language Processing have fostered the emergence of chatbots, which are increasingly used for all sorts of software engineering tasks, including modelling.",1,0,0,0,0,0
204,"To evaluate to what extent chatbots are suitable for collaborative modelling, we conducted an experimental study with 54 participants, to evaluate the usability of a modelling chatbot called SOCIO, comparing it with the on-line tool Creately.",0,1,0,0,0,0
205,We employed a within-subjects cross-over design of 2 sequences and 2 periods.,0,0,0,1,0,0
206,"Usability was determined by attributes of efficiency, effectiveness, satisfaction and quality of the results.",0,0,0,1,0,0
207,We found that SOCIO saved time and reduced communication effort over Creately.,0,0,0,0,1,0
208,"SOCIO satisfied users to a greater extent than Creately, while in effectiveness results were similar.",0,0,0,0,1,0
209,"With respect to diagram quality, SOCIO outperformed Creately in terms of precision, while solutions with Creately had better recall and perceived success.",0,0,0,0,1,0
210,"However, in terms of accuracy and error scores, both tools were similar.",0,0,0,0,1,0
211,Pull requests are a method to facilitate review and management of contribution in distributed software development.,1,0,0,0,0,0
212,"Software developers author commits, and present them in a pull request to be inspected by maintainers and reviewers.",1,0,0,0,0,0
213,"The success and sustainability of communities depends on ongoing contributions, but rejections decrease motivation of contributors.",1,0,0,0,0,0
214,We carried out a a qualitative study to understand the mechanisms of evaluating PRs in open source software (FOSS) communities from developers and maintainers perspective.,0,1,0,0,0,0
215,We interviewed 30 participants from five different FOSS communities.,0,0,0,1,0,0
216,"The data shows that acceptance of contributions depends not only on technical criteria, but also significantly on social and strategic aspects.",0,0,0,0,1,0
217,"This paper identifies three PR governance styles found in the studied communities: (1) protective, (2) equitable and (3) lenient.",0,0,0,0,1,0
218,Each one of these styles has its particularities.,0,0,0,0,1,0
219,"While the protective style values trustworthiness and reliability of the contributor, the lenient style believes in creating a positive and welcoming environment where contributors are mentored to evolve contributions until they meet the community standards.",0,0,0,0,1,0
220,"Despite the differences, these governance styles have a commonality, they all safeguard the quality of the software.",0,0,0,0,0,1
221,Background: Using design metrics to predict fault-prone elements of a software design can help to focus attention on classes that need redesign and more extensive testing.,1,0,0,0,0,0
222,"However, some design metrics have been pointed out to be theoretically invalid, and the usefulness of some metrics is questioned.",1,0,0,0,0,0
223,"Aim: To identify a set of object-oriented metrics that are theoretically valid, and useful for identifying fault-prone classes in a design.",0,1,0,0,0,0
224,"Method: Drawing on four well-known sets of design metrics (CK, LK, MOOD and QMOOD), we propose a consolidated set of metrics that covers many aspects of object-oriented software design.",0,0,0,1,0,0
225,"We conduct two experiments, first using a single large system and then considering successive releases of that system, to compare the usefulness of the consolidated set with the other four sets for within-project prediction of fault-prone classes.",0,0,0,1,0,0
226,"Results: Both experiments suggest the consolidated set is effective at identifying fault-prone classes, outperforming the other metric sets (though at a cost of more false alarms).",0,0,0,0,1,0
227,"Conclusion: This paper adds to knowledge about the usefulness of existing sets of design metrics for within-project defect prediction, and identifies a consolidated set of metrics that is more effective than the existing sets at identifying fault-prone classes.",0,0,0,0,0,1
228,Background: Little is known about the practices used for technical debt (TD) payment.,1,0,0,0,0,0
229,"The study of payment practices, as well as the reasons for not applying them, can help practitioners to control and manage TD items.",1,0,0,0,0,0
230,"Aims: To investigate, from the point of view of software practitioners, if TD items have been paid off in software projects, the practices that have been used to pay off TD and the reasons that hamper the implementation of these practices.",0,1,0,0,0,0
231,"Method: We analyzed - both quantitatively and qualitatively - a corpus of responses from a survey of 432 practitioners, from four countries, about the possibility of TD payment.",0,0,0,1,0,0
232,"Results: We found that, for most of the cases, TD items have not been eliminated from software projects.",0,0,0,0,1,0
233,"The main reasons for not paying off TD are lack of organizational interest, low priority on the debt, focus on short-term goals, cost, and lack of time.",0,0,0,0,1,0
234,"On the other hand, we identified that code refactoring, design refactoring, and update system documentation are the most used practices for TD payment.",0,0,0,0,1,0
235,"Practitioners also cited practices related to the prevention, prioritization, and creation of a favorable setting as part of TD payment initiatives.",0,0,0,0,1,0
236,Conclusion: This paper summarizes the identified practices and reasons for not paying off debt items in a map.,0,0,0,0,0,1
237,Our map reveals that the majority of payment practices are of a technical nature while the majority of reasons for not paying off debts are associated with non-technical issues.,0,0,0,0,0,1
238,Open source software (OSS) communities are often able to produce high quality software comparable to proprietary software.,1,0,0,0,0,0
239,"The success of an open source software development (OSSD) community is often attributed to the underlying governance model, and a key component of these models is the decision-making (DM) process.",1,0,0,0,0,0
240,"While there have been studies on the decision-making processes publicized by OSS communities (e.g., through published process diagrams), little has been done to study decision-making processes that can be extracted using a bottom-up, data-driven approach, which can then be used to assess whether the publicized processes conform to the extracted processes.",1,0,0,0,0,0
241,"To bridge this gap, we undertook a large-scale data-driven study to understand how decisions are made in an OSSD community, using the case study of Python Enhancement Proposals (PEPs), which embody decisions made during the evolution of the Python language.",0,0,0,1,0,0
242,"Our main contributions are:

(a) the design and development of a framework using information retrieval and natural language processing techniques to analyze the Python email archives (comprising 1.48 million emails), and

(b) the extraction of decision-making processes that reveal activities that are neither explicitly mentioned in documentation published by the Python community nor identified in prior research work.",0,1,0,0,0,0
243,Our results provide insights into the actual decision-making process employed by the Python community.,0,0,0,0,0,1
244,"There is a rapidly increasing amount of Artificial Intelligence (AI) systems developed in recent years, with much expectation on its capacity of innovation and business value generation.",1,0,0,0,0,0
245,"However, the promised value of AI systems in specific business contexts might not be understood, and further integrated into the development processes.",1,0,0,0,0,0
246,"We wanted to understand how software engineering processes and practices can be applied to develop AI systems in a fast-faced, business-driven manner.",0,1,1,0,0,0
247,"As the first step, we explored contextual factors of AI development and the connections between AI developments to business opportunities.",0,0,1,0,0,0
248,"We conducted 12 semi-structured interviews in seven companies in Brazil, Norway and Southeast Asia.",0,0,0,1,0,0
249,Our investigation revealed different types of AI systems and different AI development approaches.,0,0,1,0,0,0
250,"However, it is common that business opportunities involving with AI systems are not validated and there is lack of business-driven metrics that guide the development of AI systems.",1,0,0,0,0,0
251,The findings have implications for future research on business-driven AI development and supporting tools and practices.,0,0,0,0,1,0
252,Expanding abbreviations in source code to their full meanings is very useful for software maintainers to comprehend the source code.,1,0,0,0,0,0
253,"The existing approaches, however, focus on expanding an abbreviation to a single word, i.e., unigram.",1,0,0,0,0,0
254,They do not perform well when dealing with abbreviations of phrases that consist of multiple unigrams.,1,0,0,0,0,0
255,This paper proposes a bigram-based approach for retrieving abbreviated phrases automatically.,0,1,0,0,0,0
256,Key to this approach is a bigram-based inference model for choosing the best phrase from all candidates.,0,0,1,0,0,0
257,It utilizes the statistical properties of unigrams and bigrams as prior knowledge and a bigram language model for estimating the likelihood of each candidate phrase of a given abbreviation.,0,0,1,0,0,0
258,"We have applied the bigram-based approach to 100 phrase abbreviations, randomly selected from eight open source projects.",0,0,0,1,0,0
259,The experiment results show that it has correctly retrieved 78% of the abbreviations by using the unigram and bigram properties of a source code repository.,0,0,0,0,1,0
260,This is 9% more accurate than the unigram-based approach and much better than other existing approaches.,0,0,0,0,1,0
261,The bigram-based approach is also less biased towards specific phrase sizes than the unigram-based approach.,0,0,0,0,1,0
262,Background: Machine Learning (ML) has been widely used as a powerful tool to support Software Engineering (SE).,1,0,0,0,0,0
263,The fundamental assumptions of data characteristics required for specific ML methods have to be carefully considered prior to their applications in SE.,1,0,0,0,0,0
264,"Within the context of Continuous Integration (CI) and Continuous Deployment (CD) practices, there are two vital characteristics of data prone to be violated in SE research.",0,0,1,0,0,0
265,"First, the logs generated during CI/CD for training are imbalanced data, which is contrary to the principles of common balanced classifiers; second, these logs are also time-series data, which violates the assumption of cross-validation.",0,0,1,0,0,0
266,Objective: We aim to systematically study the two data characteristics and further provide a comprehensive evaluation for predictive CI/CD with the data from real projects.,0,1,0,1,0,0
267,Method: We conduct an experimental study that evaluates 67 CI/CD predictive models using both cross-validation and time-series-validation.,0,0,0,1,0,0
268,"Results: Our evaluation shows that cross-validation makes the evaluation of the models optimistic in most cases, there are a few counter-examples as well.",0,0,0,0,1,0
269,"The performance of the top 10 imbalanced models are better than the balanced models in the predictions of failed builds, even for balanced data.",0,0,0,0,1,0
270,The degree of data imbalance has a negative impact on prediction performance.,0,0,0,0,1,0
271,"Conclusion: In research and practice, the assumptions of the various ML methods should be seriously considered for the validity of research.",0,0,0,0,0,1
272,"Even if it is used to compare the relative performance of models, cross-validation may not be applicable to the problems with time-series features.",0,0,0,0,0,1
273,The research community need to revisit the evaluation results reported in some existing research.,0,0,0,0,0,1
274,"Driven by the need for faster time-to-market and reduced development lead-time, large-scale systems engineering companies are adopting agile methods in their organizations.",1,0,0,0,0,0
275,This agile transformation is challenging and it is common that adoption starts bottom-up with agile software teams within the context of traditional company structures.,1,0,0,0,0,0
276,This creates the challenge of agile teams working within a document-centric and plan-driven (or waterfall) environment.,1,0,0,0,0,0
277,"While it may be desirable to take the best of both worlds, it is not clear how that can be achieved especially with respect to managing requirements in large-scale systems.",0,1,0,0,0,0
278,This paper presents an exploratory case study focusing on two departments of a large-scale systems engineering company (automotive) that is in the process of company-wide agile adoption.,0,0,0,1,0,0
279,We present challenges that agile teams face while working within a larger plan-driven context and propose potential strategies to mitigate the challenges.,0,0,0,0,1,0
280,"Challenges relate to, e.g., development teams not being aware of the high-level requirements, difficulties to manage change of these requirements as well as their relationship to backlog items such as user stories.",0,0,0,0,1,0
281,"While we found strategies for solving most of the challenges, they remain abstract and empirical research on their effectiveness is currently lacking.",0,0,0,0,0,1
282,"Context: With the growing popularity of rapid software delivery and deployment, the methods, practices and technologies of Continuous Software Engineering (CSE) are evolving steadily.",1,0,0,0,0,0
283,"This creates the need for understanding the recent trends of the technologies, practitioners' challenges and views in this domain.",1,0,0,0,0,0
284,"Objective: In this paper, we present an empirical study aimed at exploring CSE from the practitioners' perspective by mining discussions from Q&A websites.",0,1,1,1,0,0
285,"Method: We have analyzed 12,989 questions and answers posted on Stack Overflow.",0,0,0,1,0,0
286,Topic modelling is conducted to derive the dominant topics in this domain.,0,0,0,1,0,0
287,"Further, a qualitative analysis was conducted to identify the key challenges discussed.",0,0,0,1,0,0
288,"Findings: Whilst the trend of posted questions is sharply increasing, the questions are becoming more specific to technologies and more difficult to attract answers.",0,0,0,0,1,0
289,"We identified 32 topics of discussions, among which ""Error messages in Continuous Integration/Deployment"" and ""Continuous Integration concepts"" are the most dominant.",0,0,0,0,1,0
290,We also present the most challenging areas in this domain from the practitioners' perspectives.,0,0,0,0,1,0
291,Decisions run through the whole software development and maintenance processes.,1,0,0,0,0,0
292,"Explicitly documenting these decisions helps to organize development knowledge and to reduce its vaporization, thereby controlling the development process and maintenance costs.",1,0,0,0,0,0
293,It can also support the knowledge acquisition process for stakeholders of the project.,1,0,0,0,0,0
294,"Meanwhile, developers (e.g., architects) and managers will be able to rely on the decisions made in the past to solve the problems encountered in their current projects.",1,0,0,0,0,0
295,"However, identifying decisions from massive textual artifacts, which involves considerable human effort, time, and cost, is usually unaffordable due to limited resources.",1,0,0,0,0,0
296,"To address this problem, we conducted an experiment to automatically identify decisions from textual artifacts using machine learning techniques.",0,1,1,1,0,0
297,"We created a dataset of 1,300 sentences labelled from the Hibernate developer mailing list, containing 650 decision sentences and non-decision sentences respectively, and trained machine learning models using 160 configurations regarding text preprocessing, feature extraction, and classification algorithms.",0,0,0,1,0,0
298,"The results show that (1) the text preprocessing method with Including Stop Words, No Stemming and Lemmatization, and No Filtering Out Sentences performs best when preprocessing posts to identify decisions; (2) the simple Bag-of-Words (BoW) model works best when extracting features to identify decisions; (3) the Support Vector Machine (SVM) algorithm gets the best result when training classifiers to identify decisions; and (4) the SVM algorithm with Including Stop Words (ISW), No Stemming and Lemmatization (NSaL), Filtering Out Sentences by Length (FOSbL), and BoW achieves the best performance (with a precision of 0.640, a recall of 0.932, and an F1-score of 0.759), compared with other configurations when identifying decisions from the mailing list.",0,0,0,0,1,0
299,"Context: Design pattern detection is a very important research on software reuse, which can greatly help software maintenance and reconstruction.",1,0,0,0,0,0
300,"At present, many researchers have invested in this work and proposed a variety of methods for detection.",1,0,0,0,0,0
301,Method: This paper extends the graph matching technology based on the past and proposes a new method that combines network analysis and structural matching for detection.,0,1,1,0,0,0
302,"First, we use network level analysis to obtain important nodes, then use the neighborhood path matching algorithm to match the pattern instance.",0,0,1,1,0,0
303,"Result: We describe the detection of five patterns on four open source systems, then analyze and compare with the other three methods, for achieving high precision and recall, which demonstrates that our method is effective.",0,0,0,0,1,0
304,"Conclusion: Using combining network analysis with structural matching can well detect these pattern instances, and these instances are also especially important for future software refactoring.",0,0,0,0,0,1
305,GitHub has become a precious service for storing and managing software source code.,1,0,0,0,0,0
306,"Over the last year, 10M new developers have joined the GitHub community, contributing to more than 44M repositories.",1,0,0,0,0,0
307,"In order to help developers increase the reachability of their repositories, in 2017 GitHub introduced the possibility to classify them by means of topics.",1,0,0,0,0,0
308,"However, assigning wrong topics to a given repository can compromise the possibility of helping other developers approach it, and thus preventing them from contributing to its development.",1,0,0,0,0,0
309,In this paper we investigate the application of Multinomial Naïve Bayesian (MNB) networks to automatically classify GitHub repositories.,0,0,1,0,0,0
310,"By analyzing the README file(s) of the repository to be classified and the source code implementing it, the conceived approach is able to recommend GitHub topics.",0,0,1,0,0,0
311,"To the best of our knowledge, this is the first supervised approach addressing the considered problem.",0,0,0,0,0,1
312,"Consequently, since there exists no suitable baseline for the comparison, we validated the approach by considering different metrics, aiming to study various quality aspects.",0,0,0,1,0,1
313,The software engineering industry is increasingly aware of the role and value of neurodiverse engineers within the workforce.,1,0,0,0,0,0
314,One motivation is the alignment between skills needed for software development and the processing strengths of individuals with autistic spectrum conditions.,1,0,0,0,0,0
315,"One aspect of neurodiversity is dyslexia, typically presenting in individuals through a range of reading deficiencies.",1,0,0,0,0,0
316,In this paper we build on recent work which has sought to investigate if programmers with dyslexia read program code in a way which is different from programmers without dyslexia.,0,1,0,0,0,0
317,The particular focus of this analysis is the nature of saccadic movement and patterns of linearity when reading code.,0,0,1,0,0,0
318,A study is presented in which the eye gaze of 28 programmers (14 with dyslexia and 14 without) was recorded using an eye tracking device while reading and understanding three on-screen Java programs.,0,0,0,1,0,0
319,"Using insights from the wider dyslexia literature, hypotheses are formulated to reflect the expected saccadic gaze behaviour of programmers with dyslexia.",0,0,0,1,0,0
320,A range of existing metrics for linearity of program reading are adapted and used for statistical analysis of the data.,0,0,0,1,0,0
321,Results are consistent with recent work elsewhere and indicate that programmers with dyslexia do not exhibit patterns of linearity significantly different from the control group.,0,0,0,0,1,0
322,Non-linear gaze is shown to be approximately 40% of all saccadic movement.,0,0,0,0,1,0
323,"Some preliminary insights are offered based on the data available, suggesting that the extent of non-linear reading when comprehending program code might complement the processing and problem solving style of the programmer with dyslexia.",0,0,0,0,0,1
324,"In Software Product Lines (SPL), feature extraction from software requirements specifications has been subject to intense research in order to assist domain analysis in a time-saving way.",1,0,0,0,0,0
325,"Although various approaches are proposed to extract features, there still exists a gap to achieve the complete view of features, that is, how to figure out the intention of a feature.",1,0,0,0,0,0
326,Feature terms as the smallest units in a feature can be regarded as vital indicators for describing a feature.,1,0,0,0,0,0
327,"Automated feature term extraction can provide key information regarding the intention of a feature, which improves the efficiency of domain analysis.",1,0,0,0,0,0
328,"In this paper, we propose an approach to train prediction models by using machine learning techniques to identify feature terms.",0,1,1,0,0,0
329,"To this end, we extract candidate terms from requirement specifications in one domain and take six attributes of each term into account to create a labeled dataset.",0,0,0,1,0,0
330,"Subsequently, we apply seven commonly used machine algorithms to train prediction models on the labeled dataset.",0,0,0,1,0,0
331,We then use these prediction models to predict feature terms from the requirements belonging to the other two different domains.,0,0,0,1,0,0
332,"Our results show that (1) feature terms can be predicted with high accuracy of ≈ 90% within a domain (2) prediction across domains leads to a decreased but still good accuracy (≈ 80%), and (3) machine learning algorithms perform differently.",0,0,0,0,1,0
333,Spectrum-Based Fault Localization (SBFL) follows the basic intuitions that the faulty parts are more likely to be covered by failure-revealing test cases and less likely to be covered by passed test cases.,1,0,0,0,0,0
334,"However, due to the diversity of programs and faults, many other characteristics (related to program structure, test suites, and type of faulty components) will influence the practical application of SBFL.",1,0,0,0,0,0
335,"For example, a statement can be covered by numerous failure-revealing test cases, and also covered by numerous passed test cases.",1,0,0,0,0,0
336,"To get more indicators about the faulty components towards a better application of SBFL, we extend the scope of spectrum-based knowledge from the basic intuitions to the Characteristics of Spectra Distribution (CSDs for short).",0,1,0,0,0,0
337,"That is, we explore the relationships between different types of statements and their spectra.",0,0,1,0,0,0
338,"Firstly, we introduce the concepts of Failure-Independent, Failure-Related, and Failure-Exclusionary to describe the relationships between different types of statements and their executions.",0,1,1,0,0,0
339,"Then, we propose two probabilistic models, with and without the noise of fault interference, respectively, to identify various CSDs for each type of statements.",0,0,1,1,0,0
340,"As the analysis results, we introduce a visualization technique to generalize the identified CSDs and provide an overall picture of spectra distribution and its dynamics.",0,0,1,1,0,0
341,"Finally, based on our analysis and also the observation of the program spectra of current benchmarks, we design a technique to filter the potential non-faulty statements to improve the accuracy of SBFL.",0,0,0,0,1,0
342,Context: The vast majority of software engineering research is reported independently of the application domain: techniques and tools usage is reported without any domain context.,1,0,0,0,0,0
343,"As reported in previous research, this has not always been so: early in the computing era, the research focus was frequently application domain specific (for example, scientific and data processing).",1,0,0,0,0,0
344,Objective: We believe determining the research context is often important.,0,1,0,0,0,0
345,"Therefore we propose a code-based approach to identify the application domain of a software system, via its lexicon.",0,1,1,0,0,0
346,We compare its use against the plain textual description attached to the same system.,0,0,1,0,0,0
347,"Method: Using a sample of 50 Java projects, we obtained i) the description of each project (e.g., its ReadMe file), ii) the lexicon extracted from its source code, and iii) a list of its main topics extracted with the Latent Dirichlet Allocation (LDA) modelling technique.",0,0,0,1,0,0
348,"We assigned a random subset of these data items to different researchers (i.e., 'experts'), and asked them to assign each item to one (or more) application domain.",0,0,0,1,0,0
349,We then evaluated the precision and accuracy of the three techniques.,0,0,0,1,0,0
350,"Results: Using the agreement levels between experts, We observed that the 'baseline' dataset (i.e., the ReadMe files) obtained the highest average in terms of agreement between experts, but we also observed that the three techniques had the same mode and median agreement levels.",0,0,0,0,1,0
351,"Additionally, in the cases where no agreement was reached for the baseline dataset, the two other techniques provided sufficient additional support.",0,0,0,0,1,0
352,"Conclusions: We conclude that the source code is sufficient for determining the application domain, so that classification is possible without special documentation requirements.",0,0,0,0,0,1
353,Context: There is considerable diversity in the range and design of computational experiments to assess classifiers for software defect prediction.,1,0,0,0,0,0
354,"This is particularly so, regarding the choice of classifier performance metrics.",1,0,0,0,0,0
355,"Unfortunately some widely used metrics are known to be biased, in particular F1.",1,0,0,0,0,0
356,Objective: We want to understand the extent to which the widespread use of the F1 renders empirical results in software defect prediction unreliable.,0,1,0,0,0,0
357,Method: We searched for defect prediction studies that report both F1 and the Matthews correlation coefficient (MCC).,0,0,0,1,0,0
358,This enabled us to determine the proportion of results that are consistent between both metrics and the proportion that change.,0,0,0,1,0,0
359,Results: Our systematic review identifies 8 studies comprising 4017 pairwise results.,0,0,0,0,1,0
360,"Of these results, the direction of the comparison changes in 23% of the cases when the unbiased MCC metric is employed.",0,0,0,0,1,0
361,"Conclusion: We find compelling reasons why the choice of classification performance metric matters, specifically the biased and misleading F1 metric should be deprecated.",0,0,0,0,0,1
362,Background: Publication bias is the failure to publish the results of a study based on the direction or strength of the study findings.,1,0,0,0,0,0
363,The existence of publication bias is firmly established in areas like medical research.,1,0,0,0,0,0
364,Recent research suggests the existence of publication bias in Software Engineering.,1,0,0,0,0,0
365,Aims: Finding out whether experiments published in the International Workshop on Empirical Software Engineering and Measurement (ESEM) are affected by publication bias.,0,1,0,0,0,0
366,Method: We review experiments published in ESEM.,0,0,1,1,0,0
367,We also survey with experimental researchers to triangulate our findings.,0,0,0,1,0,0
368,Results: ESEM experiments do not define hypotheses and frequently perform multiple testing.,0,0,0,0,1,0
369,One-tailed tests have a slightly higher rate of achieving statistically significant results.,0,0,0,0,1,0
370,We could not find other practices associated with publication bias.,0,0,0,0,0,1
371,"Conclusions: Our results provide a more encouraging perspective of SE research than previous research: (1) ESEM publications do not seem to be strongly affected by biases and (2) we identify some practices that could be associated with p-hacking, but it is more likely that they are related to the conduction of exploratory research.",0,0,0,0,0,1
372,Conclusions that are drawn from experiments are subject to varying degrees of uncertainty.,1,0,0,0,0,0
373,"For example, they might rely on small data sets, employ statistical techniques that make assumptions that are hard to verify, or there may be unknown confounding factors.",1,0,0,0,0,0
374,"In this paper we propose an alternative but complementary mechanism to explicitly incorporate these various sources of uncertainty into reasoning about empirical findings, by applying Subjective Logic.",0,1,1,0,0,0
375,"To do this we show how typical traditional results can be encoded as ""subjective opinions"" -- the building blocks of Subjective Logic.",0,1,0,0,0,0
376,We demonstrate the value of the approach by using Subjective Logic to aggregate empirical results from two large published studies that explore the relationship between programming languages and defects or failures.,0,1,0,1,0,0
377,Many companies have turned towards globally distributed software development in their quest for access to more development capacity.,1,0,0,0,0,0
378,"This paper investigates how a company onboarded distributed teams in a global project, and report experience on how to study such distributed projects.",0,1,1,0,0,0
379,Onboarding is the process of helping new team members adapt to the existing team and ways of working.,0,0,1,0,0,0
380,The goal of the studied onboarding program was to integrate Portuguese developers into two existing Norwegian teams.,0,0,1,0,0,0
381,"Further, due to the growing trend in utilizing globally distributed projects, and the challenge of conducting studies in distributed organizations, it is crucial to find good practices for researching such projects.",0,0,1,0,0,0
382,"We collected qualitative data from interviews, observations, Slack conversations and documents, and quantitative data on Slack activity.",0,0,0,1,0,0
383,"We report experiences on different onboarding practices and techniques, and we suggest guidelines to help other researchers conduct qualitative studies in globally distributed projects.",0,0,0,0,1,0
384,Context: Software testing plays an important role in assuring the reliability of systems.,1,0,0,0,0,0
385,Assessing the efficacy of testing remains challenging with few established test effectiveness metrics.,1,0,0,0,0,0
386,Those metrics that have been used (e.g. coverage and mutation analysis) have been criticised for insufficiently differentiating between the faults detected by tests.,1,0,0,0,0,0
387,Objective: We investigate how effective tests are at detecting different types of faults and whether some types of fault evade tests more than others.,0,1,1,0,0,0
388,Our aim is to suggest to developers specific ways in which their tests need to be improved to increase fault detection.,0,1,0,0,0,0
389,Method: We investigate seven fault types and analyse how often each goes undetected in 10 open source systems.,0,0,1,1,0,0
390,We statistically look for any relationship between the test set and faults.,0,0,0,1,0,0
391,"Results: Our results suggest that the fault detection rates of unit tests are relatively low, typically finding only about a half of all faults.",0,0,0,0,1,0
392,"In addition, conditional boundary and method call removals are less well detected by tests than other fault types.",0,0,0,0,1,0
393,Conclusions: We conclude that the testing of these open source systems needs to be improved across the board.,0,0,0,0,0,1
394,"In addition, despite boundary cases being long known to attract faults, tests covering boundaries need particular improvement.",0,0,0,0,0,1
395,"Overall, we recommend that developers do not rely only on code coverage and mutation score to measure the effectiveness of their tests.",0,0,0,0,0,1
396,Software testing is a crucial activity to check the internal quality of a software.,1,0,0,0,0,0
397,"During testing, developers often create tests for the normal behavior of a particular functionality (e.g., was this file properly uploaded to the cloud?).",1,0,0,0,0,0
398,"However, little is known whether developers also create tests for the exceptional behavior (e.g., what happens if the network fails during the file upload?).",1,0,0,0,0,0
399,"To minimize this knowledge gap, in this paper we design and perform a mixed-method study to understand how 417 open source Java projects are testing the exceptional behavior using the JUnit and TestNG frameworks, and the AssertJ library.",0,0,0,1,0,0
400,We found that 254 (60.91%) projects have at least one test method dedicated to test the exceptional behavior.,0,0,0,0,1,0
401,We also found that the number of test methods for exceptional behavior with respect to the total number of test methods lies between 0% and 10% in 317 (76.02%) projects.,0,0,0,0,1,0
402,"Also, 239 (57.31%) projects test only up to 10% of the used exceptions in the System Under Test (SUT).",0,0,0,0,1,0
403,"When it comes to mobile apps, we found that, in general, developers pay less attention to exceptional behavior tests when compared to desktop/server and multi-platform developers.",0,0,0,0,1,0
404,"In general, we found more test methods covering custom exceptions (the ones created in the own project) when compared to standard exceptions available in the Java Development Kit (JDK) or in third-party libraries.",0,0,0,0,1,0
405,"To triangulate the results, we conduct a survey with 66 developers from the projects we study.",0,0,0,1,0,0
406,"In general, the survey results confirm our findings.",0,0,0,0,1,0
407,"In particular, the majority of the respondents agrees that developers often neglect exceptional behavior tests.",0,0,0,0,1,0
408,"As implications, our numbers might be important to alert developers that more effort should be placed on creating tests for the exceptional behavior.",0,0,0,0,0,1
409,Factors such as app stores or platform choices heavily affect functional and non-functional mobile app requirements.,1,0,0,0,0,0
410,We surveyed 45 companies and interviewed ten experts to explore how factors that impact mobile app requirements are understood by requirements engineers in the mobile app industry.,0,1,1,1,0,0
411,We observed the lack of knowledge in several areas.,0,0,0,0,1,0
412,"For instance, we observed that all practitioners were aware of data privacy concerns, however, they did not know that certain third-party libraries, usage aggregators, or advertising libraries also occasionally leak sensitive user data.",0,0,0,0,1,0
413,"Similarly, certain functional requirements may not be implementable in the absence of a third-party library that is either banned from an app store for policy violations or lacks features, for instance, missing desired features in ARKit library for iOS made practitioners turn to Android.",0,0,0,0,1,0
414,"We conclude that requirements engineers should have adequate technical experience with mobile app development as well as sufficient knowledge in areas such as privacy, security and law, in order to make informed decisions during requirements elicitation.",0,0,0,0,0,1
415,Context.,1,0,0,0,0,0
416,Developers have access to tools like Google Lighthouse to assess the performance of web apps and to guide the adoption of development best practices.,1,0,0,0,0,0
417,"However, when it comes to energy consumption of mobile web apps, these tools seem to be lacking.",1,0,0,0,0,0
418,This study investigates on the correlation between the performance scores produced by Lighthouse and the energy consumption of mobile web apps.,0,1,1,0,0,0
419,Method.,0,0,0,1,0,0
420,We design and conduct an empirical experiment where 21 real mobile web apps are (i) analyzed via the Lighthouse performance analysis tool and (ii) measured on an Android device running a software-based energy profiler.,0,0,0,1,0,0
421,"Then, we statistically assess how energy consumption correlates with the obtained performance scores and carry out an effect size estimation.",0,0,0,1,0,0
422,Results.,0,0,0,0,1,0
423,"We discover a statistically significant negative correlation between performance scores and the energy consumption of mobile web apps (with medium to large effect sizes), implying that an increase of the performance score tend to lead to a decrease of energy consumption.",0,0,0,0,1,0
424,Conclusions.,0,0,0,0,0,1
425,"We recommend developers to strive to improve the performance level of their mobile web apps, as this can also have a positive impact on their energy consumption on Android devices.",0,0,0,0,0,1
426,Open source software (OSS) communities are often able to produce high quality software comparable to proprietary software.,1,0,0,0,0,0
427,"The success of an open source software development (OSSD) community is often attributed to the underlying governance model, and a key component of these models is the decision-making (DM) process.",1,0,0,0,0,0
428,"While there have been studies on the decision-making processes publicized by OSS communities (e.g., through published process diagrams), little has been done to study decision-making processes that can be extracted using a bottom-up, data-driven approach, which can then be used to assess whether the publicized processes conform to the extracted processes.",1,0,0,0,0,0
429,"To bridge this gap, we undertook a large-scale data-driven study to understand how decisions are made in an OSSD community, using the case study of Python Enhancement Proposals (PEPs), which embody decisions made during the evolution of the Python language.",0,1,1,1,0,0
430,"Our main contributions are: (a) the design and development of a framework using information retrieval and natural language processing techniques to analyze the Python email archives (comprising 1.48 million emails), and (b) the extraction of decision-making processes that reveal activities that are neither explicitly mentioned in documentation published by the Python community nor identified in prior research work.",0,1,1,1,0,0
431,Our results provide insights into the actual decision-making process employed by the Python community.,0,0,0,0,1,0
432,Background: Little is known about the practices used for technical debt (TD) payment.,1,0,0,0,0,0
433,"The study of payment practices, as well as the reasons for not applying them, can help practitioners to control and manage TD items.",1,0,0,0,0,0
434,"Aims: To investigate, from the point of view of software practitioners, if TD items have been paid off in software projects, the practices that have been used to pay off TD and the reasons that hamper the implementation of these practices.",0,1,1,0,0,0
435,"Method: We analyzed - both quantitatively and qualitatively - a corpus of responses from a survey of 432 practitioners, from four countries, about the possibility of TD payment.",0,0,0,1,0,0
436,"Results: We found that, for most of the cases, TD items have not been eliminated from software projects.",0,0,0,0,1,0
437,"The main reasons for not paying off TD are lack of organizational interest, low priority on the debt, focus on short-term goals, cost, and lack of time.",0,0,0,0,1,0
438,"On the other hand, we identified that code refactoring, design refactoring, and update system documentation are the most used practices for TD payment.",0,0,0,0,1,0
439,"Practitioners also cited practices related to the prevention, prioritization, and creation of a favorable setting as part of TD payment initiatives.",0,0,0,0,1,0
440,Conclusion: This paper summarizes the identified practices and reasons for not paying off debt items in a map.,0,0,0,0,0,1
441,Our map reveals that the majority of payment practices are of a technical nature while the majority of reasons for not paying off debts are associated with non-technical issues.,0,0,0,0,0,1
442,Pull requests are a method to facilitate review and management of contribution in distributed software development.,1,0,0,0,0,0
443,"Software developers author commits, and present them in a pull request to be inspected by maintainers and reviewers.",1,0,0,0,0,0
444,"The success and sustainability of communities depends on ongoing contributions, but rejections decrease motivation of contributors.",1,0,0,0,0,0
445,We carried out a a qualitative study to understand the mechanisms of evaluating PRs in open source software (FOSS) communities from developers and maintainers perspective.,0,1,0,1,0,0
446,We interviewed 30 participants from five different FOSS communities.,0,0,0,1,0,0
447,"The data shows that acceptance of contributions depends not only on technical criteria, but also significantly on social and strategic aspects.",0,0,0,0,1,0
448,"This paper identifies three PR governance styles found in the studied communities: (1) protective, (2) equitable and (3) lenient.",0,0,0,0,1,0
449,Each one of these styles has its particularities.,0,0,0,0,1,0
450,"While the protective style values trustworthiness and reliability of the contributor, the lenient style believes in creating a positive and welcoming environment where contributors are mentored to evolve contributions until they meet the community standards.",0,0,0,0,1,0
451,"Despite the differences, these governance styles have a commonality, they all safeguard the quality of the software.",0,0,0,0,0,1
452,Background: Using design metrics to predict fault-prone elements of a software design can help to focus attention on classes that need redesign and more extensive testing.,1,0,0,0,0,0
453,"However, some design metrics have been pointed out to be theoretically invalid, and the usefulness of some metrics is questioned.",1,0,0,0,0,0
454,"Aim: To identify a set of object-oriented metrics that are theoretically valid, and useful for identifying fault-prone classes in a design.",0,1,1,0,0,0
455,"Method: Drawing on four well-known sets of design metrics (CK, LK, MOOD and QMOOD), we propose a consolidated set of metrics that covers many aspects of object-oriented software design.",0,0,1,0,0,0
456,"We conduct two experiments, first using a single large system and then considering successive releases of that system, to compare the usefulness of the consolidated set with the other four sets for within-project prediction of fault-prone classes.",0,0,0,1,0,0
457,"Results: Both experiments suggest the consolidated set is effective at identifying fault-prone classes, outperforming the other metric sets (though at a cost of more false alarms).",0,0,0,0,1,0
458,"Conclusion: This paper adds to knowledge about the usefulness of existing sets of design metrics for within-project defect prediction, and identifies a consolidated set of metrics that is more effective than the existing sets at identifying fault-prone classes.",0,0,0,0,0,1
459,"Background: Practitioners would like to take action based on software metrics, as long as they find them reliable.",1,0,0,0,0,0
460,"Existing literature explores how metrics can be made reliable, but remains unclear if there are other conditions necessary for a metric to be actionable.",1,0,0,0,0,0
461,"Context & Method: In the context of a European H2020 Project, we conducted a multiple case study to study metrics' use in four companies, and identified instances where these metrics influenced actions.",0,0,0,1,0,0
462,We used an online questionnaire to enquire about the project participants' views on actionable metrics.,0,0,0,1,0,0
463,"Next, we invited one participant from each company to elaborate on the identified metrics' use for taking actions and the questionnaire responses (N=17).",0,0,0,1,0,0
464,"Result: We learned that a metric that is practical, contextual, and exhibits high data quality characteristics is actionable.",0,0,0,0,1,0
465,"Even a non-actionable metric can be useful, but an actionable metric mostly requires interpretation.",0,0,0,0,1,0
466,"However, the more these metrics are simple and reflect the software development context accurately, the less interpretation required to infer actionable information from the metric.",0,0,0,0,1,0
467,Company size and project characteristics can also influence the type of metric that can be actionable.,0,0,0,0,1,0
468,Conclusion: This exploration of industry's views on actionable metrics help characterize actionable metrics in practical terms.,0,0,0,0,0,1
469,This awareness of what characteristics constitute an actionable metric can facilitate their definition and development right from the start of a software metrics program.,0,0,0,0,0,1
470,Context: Quality requirements (QRs) have a significant role in the success of software projects.,1,0,0,0,0,0
471,"In agile software development (ASD), where working software is valued over comprehensive documentation, QRs are often under-specified or not documented.",1,0,0,0,0,0
472,"Consequently, they may be handled improperly and result in degraded software quality and increased maintenance costs.",1,0,0,0,0,0
473,"Investigating the documentation of QRs in ASD, would provide evidence on existing practices, tools and aspects considered in ASD that other practitioners might utilize to improve documentation and management of QRs in ASD.",1,0,0,0,0,0
474,"Although there are some studies examining documentation in ASD, those that specifically investigate the documentation of QRs in depth are lacking.",1,0,0,0,0,0
475,"Method: we conducted a multiple case study by interviewing 15 practitioners of four ASD cases, to provide empirical evidence on documentation of QRs in ASD.",0,0,0,1,0,0
476,"We also run workshops with two of the cases, to identify important aspects that ASD practitioners consider when documenting QRs in requirements management repositories.",0,0,0,1,0,0
477,Result and conclusions: ASD companies approach documentation of QRs to fit the needs of their context.,0,0,0,0,1,0
478,"They used tools, backlogs, iterative prototypes, and artifacts such as epic, and stories to document QRs, or utilized face-face communication without documenting QRs.",0,0,0,0,1,0
479,"We observed that documentation of QRs in ASD is affected by factors such as context (e.g. product domain, and size) and the experience of practitioners.",0,0,0,0,1,0
480,"Some tools used to document QRs also enhanced customer collaboration, enabling customers report and document QRs.",0,0,0,0,1,0
481,"Aspects such as levels of abstraction, the traceability of QRs, optimal details of information of QRs and verification and validation are deemed important when documenting QRs in ASD requirements management repositories.",0,0,0,0,1,0
482,"Modelling is a fundamental activity in software engineering, which is often performed in collaboration.",1,0,0,0,0,0
483,"For this purpose, on-line tools running on the cloud are frequently used.",1,0,0,0,0,0
484,"However, recent advances in Natural Language Processing have fostered the emergence of chatbots, which are increasingly used for all sorts of software engineering tasks, including modelling.",1,0,0,0,0,0
485,"To evaluate to what extent chatbots are suitable for collaborative modelling, we conducted an experimental study with 54 participants, to evaluate the usability of a modelling chatbot called SOCIO, comparing it with the on-line tool Creately.",0,1,1,1,0,0
486,We employed a within-subjects cross-over design of 2 sequences and 2 periods.,0,0,0,1,0,0
487,"Usability was determined by attributes of efficiency, effectiveness, satisfaction and quality of the results.",0,0,0,1,0,0
488,We found that SOCIO saved time and reduced communication effort over Creately.,0,0,0,0,1,0
489,"SOCIO satisfied users to a greater extent than Creately, while in effectiveness results were similar.",0,0,0,0,1,0
490,"With respect to diagram quality, SOCIO outperformed Creately in terms of precision, while solutions with Creately had better recall and perceived success.",0,0,0,0,1,0
491,"However, in terms of accuracy and error scores, both tools were similar.",0,0,0,0,0,1
492,"
Traceability plays an essential role in assuring that software and systems are safe to use.",1,0,0,0,0,0
493,Automated requirements traceability faces the low precision challenge due to a large number of false positives being returned and mingled with the true links.,1,0,0,0,0,0
494,"To overcome this challenge, we present a mutation-driven method built on the novel idea of proactively creating many seemingly correct tracing targets (i.e., mutants of a state machine diagram), and then exploiting model checking within process mining to automatically verify whether the safety requirement's properties hold in the mutants.",0,1,0,0,0,0
495,"A mutant is killed if its model checking fails; otherwise, it is survived.",0,1,0,0,0,0
496,"We leverage the underlying killed-survived distinction, and develop a correlation analysis procedure to identify the traceability links.",0,1,0,0,0,0
497,Experimental evaluation results on two automotive systems with 27 safety requirements show considerable precision improvements compared with the state-of-the-art.,0,0,0,0,1,1
498,"
Software developers use a mix of source code and natural language text to communicate with each other: Stack Overflow and Developer mailing lists abound with this mixed text.",1,0,0,0,0,0
499,"Tagging this mixed text is essential for making progress on two seminal software engineering problems --- traceability, and reuse via precise extraction of code snippets from mixed text.",1,0,0,0,0,0
500,"In this paper, we borrow code-switching techniques from Natural Language Processing and adapt them to apply to mixed text to solve two problems: language identification and token tagging.",0,1,0,0,0,0
501,"Our technique, POSIT, simultaneously provides abstract syntax tree tags for source code tokens, part-of-speech tags for natural language words, and predicts the source language of a token in mixed text.",0,1,0,0,0,0
502,"To realize POSIT, we trained a biLSTM network with a Conditional Random Field output layer using abstract syntax tree tags from the CLANG compiler and part-of-speech tags from the Standard Stanford part-of-speech tagger.",0,0,0,1,0,0
503,POSIT improves the state-of-the-art on language identification by 10.6% and PoS/AST tagging by 23.7% in accuracy.,0,0,0,0,1,0
504,"
Static analyses have problems modelling dynamic language features soundly while retaining acceptable precision.",1,0,0,0,0,0
505,"The problem is well-understood in theory, but there is little evidence on how this impacts the analysis of real-world programs.",1,0,0,0,0,0
506,"We have studied this issue for call graph construction on a set of 31 real-world Java programs using an oracle of actual program behaviour recorded from executions of built-in and synthesised test cases with high coverage, have measured the recall that is being achieved by various static analysis algorithms and configurations, and investigated which language features lead to static analysis false negatives.",0,0,1,0,0,0
507,"We report that (1) the median recall is 0.884 suggesting that standard static analyses have significant gaps with respect to the proportion of the program modelled (2) built-in tests are significantly better to expose dynamic program behaviour than synthesised tests (3) adding precision to the static analysis has little impact on recall indicating that those are separate concerns (4) state-of-the-art support for dynamic language features can significantly improve recall (the median observed is 0.935), but it comes with a hefty performance penalty, and (5) the main sources of unsoundness are not reflective method invocations, but objects allocated or accessed via native methods, and invocations initiated by the JVM, without matching call sites in the program under analysis.",0,0,0,0,1,0
508,These results provide some novel insights into the interaction between static and dynamic program analyses that can be used to assess the utility of static analysis results and to guide the development of future static and hybrid analyses.,0,0,0,0,0,1
509,"
Although deep neural networks (DNNs) have demonstrated astonishing performance in many applications, there are still concerns on their dependability.",1,0,0,0,0,0
510,"One desirable property of DNN for applications with societal impact is fairness (i.e., non-discrimination).",1,0,0,0,0,0
511,"In this work, we propose a scalable approach for searching individual discriminatory instances of DNN.",0,1,0,0,0,0
512,"Compared with state-of-the-art methods, our approach only employs lightweight procedures like gradient computation and clustering, which makes it significantly more scalable than existing methods.",0,1,0,0,0,0
513,Experimental results show that our approach explores the search space more effectively (9 times) and generates much more individual discriminatory instances (25 times) using much less time (half to 1/7).,0,0,0,0,1,0
514,"
During regression testing, developers rely on the pass or fail outcomes of tests to check whether changes broke existing functionality.",1,0,0,0,0,0
515,"Thus, flaky tests, which nondeterministically pass or fail on the same code, are problematic because they provide misleading signals during regression testing.",1,0,0,0,0,0
516,"Although flaky tests are the focus of several existing studies, none of them study (1) the reoccurrence, runtimes, and time-before-fix of flaky tests, and (2) flaky tests in-depth on proprietary projects.",1,0,0,0,0,0
517,This paper fills this knowledge gap about flaky tests and investigates whether prior categorization work on flaky tests also apply to proprietary projects.,0,0,1,0,0,0
518,"Specifically, we study the lifecycle of flaky tests in six large-scale proprietary projects at Microsoft.",0,0,1,0,0,0
519,"We find, as in prior work, that asynchronous calls are the leading cause of flaky tests in these Microsoft projects.",0,0,0,0,1,0
520,"Therefore, we propose the first automated solution, called Flakiness and Time Balancer (FaTB), to reduce the frequency of flaky-test failures caused by asynchronous calls.",0,1,0,0,0,0
521,Our evaluation of five such flaky tests shows that FaTB can reduce the running times of these tests by up to 78% without empirically affecting the frequency of their flaky-test failures.,0,0,0,1,0,0
522,"Lastly, our study finds several cases where developers claim they ""fixed"" a flaky test but our empirical experiments show that their changes do not fix or reduce these tests' frequency of flaky-test failures.",0,0,0,1,0,0
523,"Future studies should be more cautious when basing their results on changes that developers claim to be ""fixes"".",0,0,0,0,0,1
524,"
Metamodels play a significant role to describe and analyze the relations between domain concepts.",1,0,0,0,0,0
525,They are also cornerstone to build a software language (SL) for a domain and its associated tooling.,1,0,0,0,0,0
526,Metamodel definition generally drives code generation of a core API.,1,0,0,0,0,0
527,"The latter is further enriched by developers with additional code implementing advanced functionalities, e.g., checkers, recommenders, etc.",1,0,0,0,0,0
528,"When a SL is evolved to the next version, the metamodels are evolved as well before to re-generate the core API code.",1,0,0,0,0,0
529,"As a result, the developers added code both in the core API and the SL toolings may be impacted and thus may need to be co-evolved accordingly.",1,0,0,0,0,0
530,Many approaches support the co-evolution of various artifacts when metamodels evolve.,1,0,0,0,0,0
531,"However, not the co-evolution of code.",1,0,0,0,0,0
532,This paper fills this gap.,0,0,1,0,0,0
533,We propose a semi-automatic co-evolution approach based on change propagation.,0,1,0,0,0,0
534,The premise is that knowledge of the metamodel evolution changes can be propagated by means of resolutions to drive the code co-evolution.,0,1,0,0,0,0
535,Our approach leverages on the abstraction level of metamodels where a given metamodel element has often different usages in the code.,0,1,0,0,0,0
536,It supports alternative co-evaluations to meet different developers needs.,0,1,0,0,0,0
537,"Our work is evaluated on three Eclipse SL implementations, namely OCL, Modisco, and Papyrus over several evolved versions of metamodels and code.",0,0,0,1,0,0
538,"In response to five different evolved metamodels, we co-evolved 976 impacts over 18 projects.A comparison of our co-evolved code with the versioned ones shows the usefulness of our approach.",0,0,0,0,1,0
539,Our approach was able to reach a weighted average of 87.4% and 88.9% respectively of precision and recall while supporting useful alternative co-evolution that developers have manually performed.,0,0,0,0,1,0
540,"
Developer turnover is inevitable on software projects and leads to knowledge loss, a reduction in productivity, and an increase in defects.",1,0,0,0,0,0
541,Mitigation strategies to deal with turnover tend to disrupt and increase workloads for developers.,1,0,0,0,0,0
542,"In this work, we suggest that through code review recommendation we can distribute knowledge and mitigate turnover with minimal impacton the development process.",0,1,0,0,0,0
543,"We evaluate review recommenders in the context of ensuring expertise during review, Expertise, reducing the review workload of the core team, CoreWorkload, and reducing the Files at Risk to turnover, FaR.",0,0,0,1,0,0
544,We find that prior work that assigns reviewers based on file ownership concentrates knowledge on a small group of core developers increasing risk of knowledge loss from turnover by up to 65%.,0,0,0,0,1,0
545,We propose learning and retention aware review recommenders that when combined are effective at reducing the risk of turnover by -29% but they unacceptably reduce the overall expertise during reviews by -26%.,0,0,0,0,1,0
546,"We develop the Sofia recommender that suggests experts when none of the files under review are hoarded by developers, but distributes knowledge when files are at risk.",0,1,0,0,0,0
547,"In this way, we are able to simultaneously increase expertise during review with a ΔExpertise of 6%, with a negligible impact on workload of ΔCoreWorkload of 0.09%, and reduce the files at risk by ΔFaR -28%.",0,0,0,0,1,0
548,"Sofia is integrated into GitHub pull requests allowing developers to select an appropriate expert or ""learner"" based on the context of the review.",0,0,0,0,1,0
549,We release the Sofia bot as well as the code and data for replication purposes.,0,0,0,0,0,1
550,"
Context: Following on other scientific disciplines, such as health sciences, the use of Grey Literature (GL) has become widespread in Software Engineering (SE) research.",1,0,0,0,0,0
551,"Whilst the number of papers incorporating GL in SE is increasing, there is little empirically known about different aspects of the use of GL in SE research.",1,0,0,0,0,0
552,Method: We used a mixed-methods approach for this research.,0,0,0,1,0,0
553,"We carried out a Systematic Literature Review (SLR) of the use of GL in SE, and surveyed the authors of the selected papers included in the SLR (as GL users) and the invited experts in SE community on the use of GL in SE research.",0,0,0,1,0,0
554,"Results: We systematically selected and reviewed 102 SE secondary studies that incorporate GL in SE research, from which we identified two groups based on their reporting: 1) 76 reviews only claim their use of GL; 2) 26 reviews report the results by including GL.",0,0,0,0,1,0
555,We also obtained 20 replies from the GL users and 24 replies from the invited SE experts.,0,0,0,0,1,0
556,Conclusion: There is no common understanding of the meaning of GL in SE.,0,0,0,0,0,1
557,Researchers define the scopes and the definitions of GL in a variety of ways.,0,0,0,0,0,1
558,We found five main reasons of using GL in SE research.,0,0,0,0,0,1
559,The findings have enabled us to propose a conceptual model for how GL works in SE research lifecycle.,0,0,0,0,0,1
560,There is an apparent need for research to develop guidelines for using GL in SE and for assessing quality of GL.,0,0,0,0,0,1
561,"The current work can provide a panorama of the state-of-the-art of using GL in SE for the follow-up research, as to determine the important position of GL in SE research.",0,0,0,0,0,1
562,"
Performance is one of the important aspects of software quality.",1,0,0,0,0,0
563,"Performance issues exist widely in software systems, and the process of fixing the performance issues is an essential step in the release cycle of software systems.",1,0,0,0,0,0
564,"Although performance testing is widely adopted in practice, it is still expensive and time-consuming.",1,0,0,0,0,0
565,"In particular, the performance testing is usually conducted after the system is built in a dedicated testing environment.",1,0,0,0,0,0
566,The challenges of performance testing make it difficult to fit into the common DevOps process in software development.,1,0,0,0,0,0
567,"On the other hand, there exist a large number of tests readily available, that are executed regularly within the release pipeline during software development.",1,0,0,0,0,0
568,"In this paper, we perform an exploratory study to determine whether such readily available tests are capable of serving as performance tests.",0,0,1,0,0,0
569,"In particular, we would like to see whether the performance of these tests can demonstrate performance improvements obtained from fixing real-life performance issues.",0,0,1,0,0,0
570,"We collect 127 performance issues from Hadoop and Cassandra, and evaluate the performance of the readily available tests from the commits before and after the performance issue fixes.",0,0,0,1,0,0
571,We find that most of the improvements from the fixes to performance issues can be demonstrated using the readily available tests in the release pipeline.,0,0,0,0,1,0
572,"However, only a very small portion of the tests can be used for demonstrating the improvements.",0,0,0,0,1,0
573,"By manually examining the tests, we identify eight reasons that a test cannot demonstrate performance improvements even though it covers the changed source code of the issue fix.",0,0,0,0,1,0
574,"Finally, we build random forest classifiers determining the important metrics influencing the readily available tests (not) being able to demonstrate performance improvements from issue fixes.",0,0,0,0,1,0
575,"We find that the test code itself and the source code covered by the test are important factors, while the factors related to the code changes in the performance issues fixes have a low importance.",0,0,0,0,1,0
576,"Practitioners may focus on designing and improving the tests, instead of fine-tuning tests for different performance issues fixes.",0,0,0,0,0,1
577,Our findings can be used as a guideline for practitioners to reduce the amount of effort spent on leveraging and designing tests that run in the release pipeline for performance assurance activities.,0,0,0,0,0,1
578,"
Recurrent Neural Networks (RNN) can deal with (textual) input with various length and hence have a lot of applications in software systems and software engineering applications.",1,0,0,0,0,0
579,RNNs depend on word embeddings that are usually pre-trained by third parties to encode textual inputs to numerical values.,1,0,0,0,0,0
580,It is well known that problematic word embeddings can lead to low model accuracy.,1,0,0,0,0,0
581,"In this paper, we propose a new technique to automatically diagnose how problematic embeddings impact model performance, by comparing model execution traces from correctly and incorrectly executed samples.",0,1,0,0,0,0
582,We then leverage the diagnosis results as guidance to harden/repair the embeddings.,0,1,0,0,0,0
583,"Our experiments show that TRADER can consistently and effectively improve accuracy for real world models and datasets by 5.37% on average, which represents substantial improvement in the literature of RNN models.",0,0,0,0,1,0
584,"
Mobile apps are an integral component of our daily life.",1,0,0,0,0,0
585,"Ability to use mobile apps is important for everyone, but arguably even more so for approximately 15% of the world population with disabilities.",1,0,0,0,0,0
586,This paper presents the results of a large-scale empirical study aimed at understanding accessibility of Android apps from three complementary perspectives.,0,0,1,0,0,0
587,"First, we analyze the prevalence of accessibility issues in over 1, 000 Android apps.",0,0,0,1,0,0
588,"We find that almost all apps are riddled with accessibility issues, hindering their use by disabled people.",0,0,0,0,1,0
589,We then investigate the developer sentiments through a survey aimed at understanding the root causes of so many accessibility issues.,0,0,0,1,0,0
590,"We find that in large part developers are unaware of accessibility design principles and analysis tools, and the organizations in which they are employed do not place a premium on accessibility.",0,0,0,0,1,0
591,We finally investigate user ratings and comments on app stores.,0,0,0,1,0,0
592,"We find that due to the disproportionately small number of users with disabilities, user ratings and app popularity are not indicative of the extent of accessibility issues in apps.",0,0,0,0,1,0
593,We conclude the paper with several observations that form the foundation for future research and development.,0,0,0,0,0,1
594,"
Existing coverage-based fuzzers usually use the individual control flow graph (CFG) edge coverage to guide the fuzzing process, which has shown great potential in finding vulnerabilities.",1,0,0,0,0,0
595,"However, CFG edge coverage is not effective in discovering vulnerabilities such as use-after-free (UaF).",1,0,0,0,0,0
596,"This is because, to trigger UaF vulnerabilities, one needs not only to cover individual edges, but also to traverse some (long) sequence of edges in a particular order, which is challenging for existing fuzzers.",1,0,0,0,0,0
597,"To this end, we propose to model UaF vulnerabilities as typestate properties, and develop a typestate-guided fuzzer, named UAFL, for discovering vulnerabilities violating typestate properties.",0,1,0,0,0,0
598,"Given a typestate property, we first perform a static typestate analysis to find operation sequences potentially violating the property.",0,0,0,1,0,0
599,Our fuzzing process is then guided by the operation sequences in order to progressively generate test cases triggering property violations.,0,0,0,1,0,0
600,"In addition, we also employ an information flow analysis to improve the efficiency of the fuzzing process.",0,0,0,1,0,0
601,We have performed a thorough evaluation of UAFL on 14 widely-used real-world programs.,0,0,0,1,0,0
602,"The experiment results show that UAFL substantially outperforms the state-of-the-art fuzzers, including AFL, AFLFast, FairFuzz, MOpt, Angora and QSYM, in terms of the time taken to discover vulnerabilities.",0,0,0,0,1,0
603,"We have discovered 10 previously unknown vulnerabilities, and received 5 new CVEs.",0,0,0,0,1,0
604,"
Merge conflicts are inevitable in collaborative software development and are disruptive.",1,0,0,0,0,0
605,"When they occur, developers have to stop their current work, understand the conflict and the surrounding code, and plan an appropriate resolution.",1,0,0,0,0,0
606,"However, not all conflicts are equally problematic---some can be easily fixed, while others might be complicated enough to need multiple people.",1,0,0,0,0,0
607,"Currently, there is not much support to help developers plan their conflict resolution.",1,0,0,0,0,0
608,"In this work, we aim to predict the difficulty of a merge conflict so as to help developers plan their conflict resolution.",0,1,0,0,0,0
609,The ability to predict the difficulty of a merge conflict and to identify the underlying factors for its difficulty can help tool builders improve their conflict detection tools to prioritize and warn developers of difficult conflicts.,1,0,0,0,0,0
610,"In this work, we investigate the characteristics of difficult merge conflicts, and automatically classify them.",0,1,1,0,0,0
611,"We analyzed 6,380 conflicts across 128 java projects and found that merge conflict difficulty can be accurately predicted (AUC of 0.76) through machine learning algorithms, such as bagging.",0,0,0,1,1,0
612,"
Generating high-quality system call sequences is not only important to testing file system implementations, but also challenging due to the astronomically large input space.",1,0,0,0,0,0
613,This paper introduces a new approach to the workload generation problem by building layered models and abstract workloads refinement.,0,1,0,0,0,0
614,This approach is instantiated as a three-layer file system model for file system workload generation.,0,1,0,0,0,0
615,"In a short-period experiment run, sequential workloads (system call sequences) manifested over a thousand crashes in mainline Linux Kernel file systems, with 12 previously unknown bugs being reported.",0,0,0,1,0,0
616,We also provide evidence that such workloads benefit other domain-specific testing techniques including crash consistency testing and concurrency testing.,0,0,0,0,1,0
617,"
Significant interest in applying Deep Neural Network (DNN) has fueled the need to support engineering of software that uses DNNs.",1,0,0,0,0,0
618,"Repairing software that uses DNNs is one such unmistakable SE need where automated tools could be beneficial; however, we do not fully understand challenges to repairing and patterns that are utilized when manually repairing DNNs.",1,0,0,0,0,0
619,What challenges should automated repair tools address?,1,0,0,0,0,0
620,What are the repair patterns whose automation could help developers?,1,0,0,0,0,0
621,Which repair patterns should be assigned a higher priority for building automated bug repair tools?,1,0,0,0,0,0
622,This work presents a comprehensive study of bug fix patterns to address these questions.,0,0,1,0,0,0
623,"We have studied 415 repairs from Stack Overflow and 555 repairs from GitHub for five popular deep learning libraries Caffe, Keras, Tensorflow, Theano, and Torch to understand challenges in repairs and bug repair patterns.",0,0,0,1,0,0
624,"Our key findings reveal that DNN bug fix patterns are distinctive compared to traditional bug fix patterns; the most common bug fix patterns are fixing data dimension and neural network connectivity; DNN bug fixes have the potential to introduce adversarial vulnerabilities; DNN bug fixes frequently introduce new bugs; and DNN bug localization, reuse of trained model, and coping with frequent releases are major challenges faced by developers when fixing bugs.",0,0,0,0,1,0
625,"We also contribute a benchmark of 667 DNN (bug, repair) instances.",0,0,0,0,1,0
626,"
Modern static analyzers often need to simultaneously check a few dozen or even hundreds of value-flow properties, causing serious scalability issues when high precision is required.",1,0,0,0,0,0
627,"A major factor to this deficiency, as we observe, is that the core static analysis engine is oblivious of the mutual synergy among the properties being checked, thus inevitably losing many optimization opportunities.",1,0,0,0,0,0
628,Our work is to leverage the inter-property awareness and to capture redundancies and inconsistencies when many properties are considered at the same time.,0,1,0,0,0,0
629,We have evaluated our approach by checking twenty value-flow properties in standard benchmark programs and ten real-world software systems.,0,0,0,1,0,0
630,The results demonstrate that our approach is more than 8× faster than existing ones but consumes only 1/7 of the memory.,0,0,0,0,1,0
631,"Such substantial improvement in analysis efficiency is not achieved by sacrificing the effectiveness: at the time of writing, thirty-nine bugs found by our approach have been fixed by developers and four of them have been assigned CVE IDs due to their security impact.",0,0,0,0,0,1
632,"
This paper presents TransRepair, a fully automatic approach for testing and repairing the consistency of machine translation systems.",0,1,0,0,0,0
633,TransRepair combines mutation with metamorphic testing to detect inconsistency bugs (without access to human oracles).,0,1,0,0,0,0
634,"It then adopts probability-reference or cross-reference to post-process the translations, in a grey-box or black-box manner, to repair the inconsistencies.",0,1,0,0,0,0
635,"Our evaluation on two state-of-the-art translators, Google Translate and Transformer, indicates that TransRepair has a high precision (99%) on generating input pairs with consistent translations.",0,0,0,1,1,0
636,"With these tests, using automatic consistency metrics and manual assessment, we find that Google Translate and Transformer have approximately 36% and 40% inconsistency bugs.",0,0,0,1,1,0
637,Black-box repair fixes 28% and 19% bugs on average for Google Translate and Transformer.,0,0,0,0,1,0
638,Grey-box repair fixes 30% bugs on average for Transformer.,0,0,0,0,1,0
639,"Manual inspection indicates that the translations repaired by our approach improve consistency in 87% of cases (degrading it in 2%), and that our repairs have better translation acceptability in 27% of the cases (worse in 8%).",0,0,0,0,1,1
640,"
In contemporary code review, the comments put by reviewers on a specific code change are immediately visible to the other reviewers involved.",1,0,0,0,0,0
641,"Could this visibility prime new reviewers' attention (due to the human's proneness to availability bias), thus biasing the code review outcome?",1,0,0,0,0,0
642,"In this study, we investigate this topic by conducting a controlled experiment with 85 developers who perform a code review and a psychological experiment.",0,0,1,1,0,0
643,"With the psychological experiment, we find that ≈70% of participants are prone to availability bias.",0,0,0,1,1,0
644,"However, when it comes to the code review, our experiment results show that participants are primed only when the existing code review comment is about a type of bug that is not normally considered; when this comment is visible, participants are more likely to find another occurrence of this type of bug.",0,0,0,0,1,0
645,"Moreover, this priming effect does not influence reviewers' likelihood of detecting other types of bugs.",0,0,0,0,1,0
646,"Our findings suggest that the current code review practice is effective because existing review comments about bugs in code changes are not negative primers, rather positive reminders for bugs that would otherwise be overlooked during code review.",0,0,0,0,1,0
647,"
Many data-driven software engineering tasks such as discovering programming patterns, mining API specifications, etc., perform source code analysis over control flow graphs (CFGs) at scale.",1,0,0,0,0,0
648,Analyzing millions of CFGs can be expensive and performance of the analysis heavily depends on the underlying CFG traversal strategy.,1,0,0,0,0,0
649,State-of-the-art analysis frameworks use a fixed traversal strategy.,1,0,0,0,0,0
650,We argue that a single traversal strategy does not fit all kinds of analyses and CFGs and propose bespoke control flow analysis (BCFA).,0,0,1,0,0,0
651,"Given a control flow analysis (CFA) and a large number of CFGs, BCFA selects the most efficient traversal strategy for each CFG.",1,0,0,0,0,0
652,"BCFA extracts a set of properties of the CFA by analyzing the code of the CFA and combines it with properties of the CFG, such as branching factor and cyclicity, for selecting the optimal traversal strategy.",0,0,0,0,1,0
653,"We have implemented BCFA in Boa, and evaluated BCFA using a set of representative static analyses that mainly involve traversing CFGs and two large datasets containing 287 thousand and 162 million CFGs.",0,0,0,1,0,0
654,Our results show that BCFA can speedup the large scale analyses by 1%-28%.,0,0,0,0,1,0
655,"Further, BCFA has low overheads; less than 0.2%, and low misprediction rate; less than 0.01%.",0,0,0,0,1,0
656,"
Grey-box fuzzing is an evolutionary process, which maintains and evolves a population of test cases with the help of a fitness function.",1,0,0,0,0,0
657,Fitness functions used by current grey-box fuzzers are not informative in that they cannot distinguish different program executions as long as those executions achieve the same coverage.,1,0,0,0,0,0
658,"The problem is that current fitness functions only consider a union of data, but not their combination.",1,0,0,0,0,0
659,"As such, fuzzers often get stuck in a local optimum during their search.",1,0,0,0,0,0
660,"In this paper, we introduce Ankou, the first grey-box fuzzer that recognizes different combinations of execution information, and present several scalability challenges encountered while designing and implementing Ankou.",0,1,0,0,0,0
661,"Our experimental results show that Ankou is 1.94× and 8.0× more effective in finding bugs than AFL and Angora, respectively.",0,0,0,0,1,0
662,"
Bottom-up program analysis has been traditionally easy to parallelize because functions without caller-callee relations can be analyzed independently.",1,0,0,0,0,0
663,"However, such function-level parallelism is significantly limited by the calling dependence - functions with caller-callee relations have to be analyzed sequentially because the analysis of a function depends on the analysis results, a.k.a., function summaries, of its callees.",1,0,0,0,0,0
664,"We observe that the calling dependence can be relaxed in many cases and, as a result, the parallelism can be improved.",1,0,0,0,0,0
665,"In this paper, we present Coyote, a framework of bottom-up data flow analysis, in which the analysis task of each function is elaborately partitioned into multiple sub-tasks to generate pipelineable function summaries.",0,1,0,0,0,0
666,"These sub-tasks are pipelined and run in parallel, even though the calling dependence exists.",0,1,0,0,0,0
667,We formalize our idea under the IFDS/IDE framework and have implemented an application to checking null-dereference bugs and taint issues in C/C++ programs.,0,1,0,0,0,0
668,"We evaluate Coyote on a series of standard benchmark programs and open-source software systems, which demonstrates significant speedup over a conventional parallel design.",0,0,0,1,1,1
669,"
Static analysis is a proven technique for catching bugs during software development.",1,0,0,0,0,0
670,"However, analysis tooling must approximate, both theoretically and in the interest of practicality.",1,0,0,0,0,0
671,False positives are a pervading manifestation of such approximations---tool configuration and customization is therefore crucial for usability and directing analysis behavior.,1,0,0,0,0,0
672,"To suppress false positives, developers readily disable bug checks or insert comments that suppress spurious bug reports.",1,0,0,0,0,0
673,Existing work shows that these mechanisms fall short of developer needs and present a significant pain point for using or adopting analyses.,1,0,0,0,0,0
674,We draw on the insight that an analysis user always has one notable ability to influence analysis behavior regardless of analyzer options and implementation: modifying their program.,1,0,0,0,0,0
675,"We present a new technique for automated, generic, and temporary code changes that tailor to suppress spurious analysis errors.",0,1,0,0,0,0
676,"We adopt a rule-based approach where simple, declarative templates describe general syntactic changes for code patterns that are known to be problematic for the analyzer.",0,0,0,1,0,0
677,Our technique promotes program transformation as a general primitive for improving the fidelity of analysis reports (we treat any given analyzer as a black box).,0,0,0,1,0,0
678,"We evaluate using five different static analyzers supporting three different languages (C, Java, and PHP) on large, real world programs (up to 800KLOC).",0,0,0,1,0,0
679,We show that our approach is effective in sidestepping long-standing and complex issues in analysis implementations.,0,0,0,0,0,1
680,"
As Android platform evolves in a fast pace, API-related compatibility issues become a significant challenge for developers.",1,0,0,0,0,0
681,"To handle an incompatible API invocation, developers mainly have two choices: merely performing sufficient checks to avoid invoking incompatible APIs on platforms that do not support them, or gracefully providing replacement implementations on those incompatible platforms.",1,0,0,0,0,0
682,"As providing more consistent app behaviors, the latter one is more recommended and more challenging to adopt.",1,0,0,0,0,0
683,"However, it is still unknown how these issues are handled in the real world, do developers meet difficulties and what can we do to help them.",1,0,0,0,0,0
684,"In light of this, this paper performs the first large-scale study on the current practice of handling evolution-induced API compatibility issues in about 300,000 Android market apps, and more importantly, their solutions (if exist).",0,0,1,1,0,0
685,"Actually, it is in general very challenging to determine if developers have put in counter-measure for a compatibility issue, as different APIs have diverse behaviors, rendering various repair.",1,0,0,0,0,0
686,"To facilitate a large-scale study, this paper proposes RAPID, an automated tool to determine whether a compatibility issue has been addressed or not, by incorporating both static analysis and machine learning techniques.",0,1,0,0,0,0
687,Results show that our trained classifier is quite effective by achieving a F1-score of 95.21% and 91.96% in the training stage and the validation stage respectively.,0,0,0,0,1,0
688,"With the help of RAPID, our study yields many interesting findings, e.g. developers are not willing to provide alternative implementations when handling incompatible API invocations (only 38.4%); for those incompatible APIs that Google gives replacement recommendations, the ratio of providing alternative implementations is significantly higher than those without recommendations; developers find more ways to repair compatibility issues than Google's recommendations and the knowledge acquired from these experienced developers would be extremely useful to novice developers and may significantly improve the current status of compatibility issue handling.",0,0,0,0,1,0
689,"
Message passing is the standard paradigm of programming in high-performance computing.",1,0,0,0,0,0
690,"However, verifying Message Passing Interface (MPI) programs is challenging, due to the complex program features (such as non-determinism and non-blocking operations).",1,0,0,0,0,0
691,"In this work, we present MPI symbolic verifier (MPI-SV), the first symbolic execution based tool for automatically verifying MPI programs with non-blocking operations.",0,1,0,0,0,0
692,MPI-SV combines symbolic execution and model checking in a synergistic way to tackle the challenges in MPI program verification.,0,1,0,0,0,0
693,The synergy improves the scalability and enlarges the scope of verifiable properties.,0,0,0,0,1,0
694,We have implemented MPI-SV1 and evaluated it with 111 real-world MPI verification tasks.,0,0,0,1,0,0
695,"The pure symbolic execution-based technique successfully verifies 61 out of the 111 tasks (55%) within one hour, while in comparison, MPI-SV verifies 100 tasks (90%).",0,0,0,0,1,0
696,"On average, compared with pure symbolic execution, MPI-SV achieves 19x speedups on verifying the satisfaction of the critical property and 5x speedups on finding violations.",0,0,0,0,1,1
697,"
Identifying and optimizing open participation is essential to the success of open software development.",1,0,0,0,0,0
698,Existing studies highlighted the importance of worker recommendation for crowdtesting tasks in order to detect more bugs with fewer workers.,1,0,0,0,0,0
699,"However, these studies mainly focus on one-time recommendations with respect to the initial context at the beginning of a new task.",1,0,0,0,0,0
700,This paper argues the need for in-process crowdtesting worker recommendation.,0,0,1,0,0,0
701,"We motivate this study through a pilot study, revealing the prevalence of long-sized non-yielding windows, i.e., no new bugs are revealed in consecutive test reports during the process of a crowdtesting task.",0,0,0,1,0,0
702,"This indicates the potential opportunity for accelerating crowdtesting by recommending appropriate workers in a dynamic manner, so that the non-yielding windows could be shortened.",0,0,0,0,1,0
703,"To that end, this paper proposes a context-aware in-process crowdworker recommendation approach, iRec, to detect more bugs earlier and potentially shorten the non-yielding windows.",0,0,0,0,1,0
704,"It consists of three main components: 1) the modeling of dynamic testing context, 2) the learning-based ranking component, and 3) the diversity-based re-ranking component.",0,0,0,0,1,0
705,"The evaluation is conducted on 636 crowdtesting tasks from one of the largest crowdtesting platforms, and results show the potential of iRec in improving the cost-effectiveness of crowdtesting by saving the cost and shortening the testing process.",0,0,0,1,1,1
706,"
The growing application of deep neural networks in safety-critical domains makes the analysis of faults that occur in such systems of enormous importance.",1,0,0,0,0,0
707,In this paper we introduce a large taxonomy of faults in deep learning (DL) systems.,0,1,0,0,0,0
708,"We have manually analysed 1059 artefacts gathered from GitHub commits and issues of projects that use the most popular DL frameworks (TensorFlow, Keras and PyTorch) and from related Stack Overflow posts.",0,0,0,1,0,0
709,Structured interviews with 20 researchers and practitioners describing the problems they have encountered in their experience have enriched our taxonomy with a variety of additional faults that did not emerge from the other two sources.,0,0,0,1,0,0
710,"Our final taxonomy was validated with a survey involving an additional set of 21 developers, confirming that almost all fault categories (13/15) were experienced by at least 50% of the survey participants.",0,0,0,1,1,0
711,"
Traceability is a fundamental component of the modern software development process that helps to ensure properly functioning, secure programs.",1,0,0,0,0,0
712,"Due to the high cost of manually establishing trace links, researchers have developed automated approaches that draw relationships between pairs of textual software artifacts using similarity measures.",1,0,0,0,0,0
713,"However, the effectiveness of such techniques are often limited as they only utilize a single measure of artifact similarity and cannot simultaneously model (implicit and explicit) relationships across groups of diverse development artifacts.",1,0,0,0,0,0
714,"In this paper, we illustrate how these limitations can be overcome through the use of a tailored probabilistic model.",0,0,1,0,0,0
715,"To this end, we design and implement a HierarchiCal PrObabilistic Model for SoftwarE Traceability (Comet) that is able to infer candidate trace links.",0,1,0,0,0,0
716,Comet is capable of modeling relationships between artifacts by combining the complementary observational prowess of multiple measures of textual similarity.,0,1,0,0,0,0
717,"Additionally, our model can holistically incorporate information from a diverse set of sources, including developer feedback and transitive (often implicit) relationships among groups of software artifacts, to improve inference accuracy.",0,1,0,0,0,0
718,We conduct a comprehensive empirical evaluation of Comet that illustrates an improvement over a set of optimally configured baselines of ≈14% in the best case and ≈5% across all subjects in terms of average precision.,0,0,0,1,0,0
719,"The comparative effectiveness of Comet in practice, where optimal configuration is typically not possible, is likely to be higher.",0,0,0,0,1,0
720,"Finally, we illustrate Comet's potential for practical applicability in a survey with developers from Cisco Systems who used a prototype Comet Jenkins plugin.",0,0,0,0,0,1
721,"
API usage directives in official API documentation describe the contracts, constraints and guidelines for using APIs in natural language.",1,0,0,0,0,0
722,"Through the investigation of API misuse scenarios on Stack Overflow, we identify three barriers that hinder the understanding of the API usage directives, i.e., lack of specific usage context, indirect relationships to cooperative APIs, and confusing APIs with subtle differences.",1,0,0,0,0,0
723,"To overcome these barriers, we develop a text mining approach to discover the crowdsourced API misuse scenarios on Stack Overflow and extract from these scenarios erroneous code examples and patches, as well as related API and confusing APIs to construct demystification reports to help developers understand the official API usage directives described in natural language.",0,1,0,0,0,0
724,We apply our approach to API usage directives in official Android API documentation and android-tagged discussion threads on Stack Overflow.,0,0,0,1,0,0
725,"We extract 159,116 API misuse scenarios for 23,969 API usage directives of 3138 classes and 7471 methods, from which we generate the demystification reports.",0,0,0,1,0,0
726,Our manual examination confirms that the extracted information in the generated demystification reports are of high accuracy.,0,0,0,0,1,0
727,"By a user study of 14 developers on 8 API-misuse related error scenarios, we show that our demystification reports help developer understand and debug API-misuse related program errors faster and more accurately, compared with reading only plain API usage-directive sentences.",0,0,0,0,1,0
728,"
Statistical language modeling techniques have successfully been applied to large source code corpora, yielding a variety of new software development tools, such as tools for code suggestion, improving readability, and API migration.",1,0,0,0,0,0
729,"A major issue with these techniques is that code introduces new vocabulary at a far higher rate than natural language, as new identifier names proliferate.",1,0,0,0,0,0
730,"Both large vocabularies and out-of-vocabulary issues severely affect Neural Language Models (NLMs) of source code, degrading their performance and rendering them unable to scale.",1,0,0,0,0,0
731,"In this paper, we address this issue by: 1) studying how various modelling choices impact the resulting vocabulary on a large-scale corpus of 13,362 projects; 2) presenting an open vocabulary source code NLM that can scale to such a corpus, 100 times larger than in previous work; and 3) showing that such models outperform the state of the art on three distinct code corpora (Java, C, Python).",0,1,0,0,0,0
732,"To our knowledge, these are the largest NLMs for code that have been reported.",1,0,0,0,0,0
733,"All datasets, code, and trained models used in this work are publicly available.",0,0,0,0,1,0
734,"
Timing side channels arise in software when a program's execution time can be correlated with security-sensitive program input.",1,0,0,0,0,0
735,Recent results on software side-channel detection focus on analysis of program's source code.,1,0,0,0,0,0
736,"However, runtime behavior, in particular optimizations introduced during just-in-time (JIT) compilation, can impact or even introduce timing side channels in programs.",1,0,0,0,0,0
737,"In this paper, we present a technique for automatically detecting such JIT-induced timing side channels in Java programs.",0,1,0,0,0,0
738,We first introduce patterns to detect partitions of secret input potentially separable by side channels.,0,1,0,0,0,0
739,Then we present an automated approach for exploring behaviors of the Java Virtual Machine (JVM) to identify states where timing channels separating these partitions arise.,0,1,0,0,0,0
740,We evaluate our technique on three datasets used in recent work on side-channel detection.,0,0,0,1,0,0
741,"We find that many code variants labeled ""safe"" with respect to side-channel vulnerabilities are in fact vulnerable to JIT-induced timing side channels.",0,0,0,0,1,0
742,Our results directly contradict the conclusions of four separate state-of-the-art program analysis tools for side-channel detection and demonstrate that JIT-induced side channels are prevalent and can be detected automatically.,0,0,0,0,1,1
743,"
To battle the ever-increasing Android malware, malware family classification, which classifies malware with common features into a malware family, has been proposed as an effective malware analysis method.",1,0,0,0,0,0
744,Several machine-learning based approaches have been proposed for the task of malware family classification.,1,0,0,0,0,0
745,"Our study shows that malware families suffer from several data imbalance, with many families with only a small number of malware applications (referred to as few shot malware families in this work).",0,0,1,0,0,0
746,"Unfortunately, this issue has been overlooked in existing approaches.",1,0,0,0,0,0
747,"Although existing approaches achieve high classification performance at the overall level and for large malware families, our experiments show that they suffer from poor performance and generalizability for few shot malware families, and traditionally downsampling method cannot solve the problem.",0,0,0,0,1,0
748,"To address the challenge in few shot malware family classification, we propose a novel siamese-network based learning method, which allows us to train an effective MultiLayer Perceptron (MLP) network for embedding malware applications into a real-valued, continuous vector space by contrasting the malware applications from the same or different families.",0,1,0,0,0,0
749,"In the embedding space, the performance of malware family classification can be significantly improved for all scales of malware families, especially for few shot malware families, which also leads to the significant performance improvement at the overall level.",0,0,0,0,0,1
750,"
Source code summarization aims to automatically generate concise summaries of source code in natural language texts, in order to help developers better understand and maintain source code.",1,0,0,0,0,0
751,"Traditional work generates a source code summary by utilizing information retrieval techniques, which select terms from original source code or adapt summaries of similar code snippets.",1,0,0,0,0,0
752,Recent studies adopt Neural Machine Translation techniques and generate summaries from code snippets using encoder-decoder neural networks.,1,0,0,0,0,0
753,The neural-based approaches prefer the high-frequency words in the corpus and have trouble with the low-frequency ones.,1,0,0,0,0,0
754,"In this paper, we propose a retrieval-based neural source code summarization approach where we enhance the neural model with the most similar code snippets retrieved from the training set.",0,1,0,0,0,0
755,Our approach can take advantages of both neural and retrieval-based techniques.,0,1,0,0,0,0
756,"Specifically, we first train an attentional encoder-decoder model based on the code snippets and the summaries in the training set; Second, given one input code snippet for testing, we retrieve its two most similar code snippets in the training set from the aspects of syntax and semantics, respectively; Third, we encode the input and two retrieved code snippets, and predict the summary by fusing them during decoding.",0,0,0,1,0,0
757,We conduct extensive experiments to evaluate our approach and the experimental results show that our proposed approach can improve the state-of-the-art methods.,0,0,0,1,0,1
758,"
In object-oriented languages, constructors often have a combination of required and optional formal parameters.",1,0,0,0,0,0
759,It is tedious and inconvenient for programmers to write a constructor by hand for each combination.,1,0,0,0,0,0
760,"The multitude of constructors is error-prone for clients, and client code is difficult to read due to the large number of constructor arguments.",1,0,0,0,0,0
761,"Therefore, programmers often use design patterns that enable more flexible object construction---the builder pattern, dependency injection, or factory methods.",1,0,0,0,0,0
762,"However, these design patterns can be too flexible: not all combinations of logical parameters lead to the construction of well-formed objects.",1,0,0,0,0,0
763,"When a client uses the builder pattern to construct an object, the compiler does not check that a valid set of values was provided.",1,0,0,0,0,0
764,"Incorrect use of builders can lead to security vulnerabilities, run-time crashes, and other problems.",1,0,0,0,0,0
765,"This work shows how to statically verify uses of object construction, such as the builder pattern.",0,0,1,0,0,0
766,"Using a simple specification language, programmers specify which combinations of logical arguments are permitted.",0,0,0,0,1,0
767,Our compile-time analysis detects client code that may construct objects unsafely.,0,0,0,0,1,0
768,"Our analysis is based on a novel special case of typestate checking, accumulation analysis, that modularly reasons about accumulations of method calls.",0,0,0,1,0,0
769,"Because accumulation analysis does not require precise aliasing information for soundness, our analysis scales to industrial programs.",0,0,0,1,0,0
770,"We evaluated it on over 9 million lines of code, discovering defects which included previously-unknown security vulnerabilities and potential null-pointer violations in heavily-used open-source codebases.",0,0,0,1,0,0
771,Our analysis has a low false positive rate and low annotation burden.,0,0,0,0,1,0
772,Our implementation and experimental data are publicly available.,0,0,0,0,1,0
773,"
Code comments provide abundant information that have been leveraged to help perform various software engineering tasks, such as bug detection, specification inference, and code synthesis.",1,0,0,0,0,0
774,"However, developers are less motivated to write and update comments, making it infeasible and error-prone to leverage comments to facilitate software engineering tasks.",1,0,0,0,0,0
775,"In this paper, we propose to leverage program analysis to systematically derive, refine, and propagate comments.",0,1,0,0,0,0
776,"For example, by propagation via program analysis, comments can be passed on to code entities that are not commented such that code bugs can be detected leveraging the propagated comments.",0,1,0,0,0,0
777,"Developers usually comment on different aspects of code elements like methods, and use comments to describe various contents, such as functionalities and properties.",1,0,0,0,0,0
778,"To more effectively utilize comments, a fine-grained and elaborated taxonomy of comments and a reliable classifier to automatically categorize a comment are needed.",1,0,0,0,0,0
779,"In this paper, we build a comprehensive taxonomy and propose using program analysis to propagate comments.",0,1,0,0,0,0
780,"We develop a prototype CPC, and evaluate it on 5 projects.",0,0,0,1,0,0
781,The evaluation results demonstrate 41573 new comments can be derived by propagation from other code locations with 88% accuracy.,0,0,0,0,1,0
782,"Among them, we can derive precise functional comments for 87 native methods that have neither existing comments nor source code.",0,0,0,0,1,0
783,"Leveraging the propagated comments, we detect 37 new bugs in open source large projects, 30 of which have been confirmed and fixed by developers, and 304 defects in existing comments (by looking at inconsistencies between existing and propagated comments), including 12 incomplete comments and 292 wrong comments.",0,0,0,0,1,0
784,This demonstrates the effectiveness of our approach.,0,0,0,0,0,1
785,Our user study confirms propagated comments align well with existing comments in terms of quality.,0,0,0,1,0,1
786,"
Application programming interfaces (APIs) have become ubiquitous in software development.",1,0,0,0,0,0
787,"However, external APIs are not guaranteed to contain every desirable feature, nor are they immune to software defects.",1,0,0,0,0,0
788,"Therefore, API users will sometimes be faced with situations where a current API does not satisfy all of their requirements, but migrating to another API is costly.",1,0,0,0,0,0
789,"In these cases, due to the lack of communication channels between API developers and users, API users may intentionally bypass an existing API after inquiring into workarounds for their API problems with online communities.",1,0,0,0,0,0
790,"This mechanism takes the API developer out of the conversation, potentially leaving API defects unreported and desirable API features undiscovered.",1,0,0,0,0,0
791,In this paper we explore API workaround inquiries from API users on Stack Overflow.,0,0,1,0,0,0
792,"We uncover general reasons why API users inquire about API workarounds, and general solutions to API workaround requests.",0,0,1,0,0,0
793,"Furthermore, using workaround implementations in Stack Overflow answers, we develop three API workaround implementation patterns.",0,1,0,0,1,0
794,We identify instances of these patterns in real-life open source projects and determine their value for API developers from their responses to feature requests based on the identified API workarounds.,0,0,0,0,1,0
795,"
While CUDA has become a mainstream parallel computing platform and programming model for general-purpose GPU computing, how to effectively and efficiently detect CUDA synchronization bugs remains a challenging open problem.",1,0,0,0,0,0
796,"In this paper, we propose the first lightweight CUDA synchronization bug detection framework, namely Simulee, to model CUDA program execution by interpreting the corresponding LLVM bytecode and collecting the memory-access information for automatically detecting general CUDA synchronization bugs.",0,1,0,0,0,0
797,"To evaluate the effectiveness and efficiency of Simulee, we construct a benchmark with 7 popular CUDA-related projects from GitHub, upon which we conduct an extensive set of experiments.",0,0,0,1,0,0
798,"The experimental results suggest that Simulee can detect 21 out of the 24 manually identified bugs in our preliminary study and also 24 previously unknown bugs among all projects, 10 of which have already been confirmed by the developers.",0,0,0,0,1,0
799,"Furthermore, Simulee significantly outperforms state-of-the-art approaches for CUDA synchronization bug detection.",0,0,0,0,0,1
800,"
Self-adaptive systems often employ dynamic programming or similar techniques to select optimal adaptations at run-time.",1,0,0,0,0,0
801,"These techniques suffer from the ""curse of dimensionality"", increasing the cost of run-time adaptation decisions.",1,0,0,0,0,0
802,We propose a novel approach that improves upon the state-of-the-art proactive self-adaptation techniques to reduce the number of possible adaptations that need be considered for each run-time adaptation decision.,0,1,0,0,0,0
803,"The approach, realized in a tool called Thallium, employs a combination of automated formal modeling techniques to (i) analyze a structural model of the system showing which configurations are reachable from other configurations and (ii) compute the utility that can be generated by the optimal adaptation over a bounded horizon in both the best- and worst-case scenarios.",0,1,0,0,0,0
804,"It then constructs triangular possibility values using those optimized bounds to automatically compare adjacent adaptations for each configuration, keeping only the alternatives with the best range of potential results.",0,1,0,0,0,0
805,"The experimental results corroborate Thallium's ability to significantly reduce the number of states that need to be considered with each adaptation decision, freeing up vital resources at run-time.",0,0,0,0,1,0
806,"
Mobile banking apps, belonging to the most security-critical app category, render massive and dynamic transactions susceptible to security risks.",1,0,0,0,0,0
807,"Given huge potential financial loss caused by vulnerabilities, existing research lacks a comprehensive empirical study on the security risks of global banking apps to provide useful insights and improve the security of banking apps.",1,0,0,0,0,0
808,"Since data-related weaknesses in banking apps are critical and may directly cause serious financial loss, this paper first revisits the state-of-the-art available tools and finds that they have limited capability in identifying data-related security weaknesses of banking apps.",0,0,1,0,0,0
809,"To complement the capability of existing tools in data-related weakness detection, we propose a three-phase automated security risk assessment system, named Ausera, which leverages static program analysis techniques and sensitive keyword identification.",0,1,0,0,0,0
810,"By leveraging Ausera, we collect 2,157 weaknesses in 693 real-world banking apps across 83 countries, which we use as a basis to conduct a comprehensive empirical study from different aspects, such as global distribution and weakness evolution during version updates.",0,0,0,1,0,0
811,We find that apps owned by subsidiary banks are always less secure than or equivalent to those owned by parent banks.,0,0,0,0,1,0
812,"In addition, we also track the patching of weaknesses and receive much positive feedback from banking entities so as to improve the security of banking apps in practice.",0,0,0,1,0,0
813,We further find that weaknesses derived from outdated versions of banking apps or third-party libraries are highly prone to being exploited by attackers.,0,0,0,0,1,0
814,"To date, we highlight that 21 banks have confirmed the weaknesses we reported (including 126 weaknesses in total).",0,0,0,0,1,0
815,"We also exchange insights with 7 banks, such as HSBC in UK and OCBC in Singapore, via in-person or online meetings to help them improve their apps.",0,0,0,1,0,0
816,"We hope that the insights developed in this paper will inform the communities about the gaps among multiple stakeholders, including banks, academic researchers, and third-party security companies.",0,0,0,0,0,1
817,"
Floating point is widely used in software to emulate arithmetic over reals.",1,0,0,0,0,0
818,"Unfortunately, floating point leads to rounding errors that propagate and accumulate during execution.",1,0,0,0,0,0
819,Generating inputs to maximize the numerical error is critical when evaluating the accuracy of floating-point code.,1,0,0,0,0,0
820,"In this paper, we formulate the problem of generating high error-inducing floating-point inputs as a code coverage maximization problem solved using symbolic execution.",0,0,1,0,0,0
821,"Specifically, we define inaccuracy checks to detect large precision loss and cancellation.",0,0,1,0,0,0
822,"We inject these checks at strategic program locations to construct specialized branches that, when covered by a given input, are likely to lead to large errors in the result.",0,0,0,1,0,0
823,"We apply symbolic execution to generate inputs that exercise these specialized branches, and describe optimizations that make our approach practical.",0,0,0,1,0,0
824,We implement a tool named FPGen and present an evaluation on 21 numerical programs including matrix computation and statistics libraries.,0,0,0,1,0,0
825,"We show that FPGen exposes errors for 20 of these programs and triggers errors that are, on average, over 2 orders of magnitude larger than the state of the art.",0,0,0,0,1,0
826,"
Software testing is an essential part of the software lifecycle and requires a substantial amount of time and effort.",1,0,0,0,0,0
827,It has been estimated that software developers spend close to 50% of their time on testing the code they write.,1,0,0,0,0,0
828,"For these reasons, a long standing goal within the research community is to (partially) automate software testing.",1,0,0,0,0,0
829,"While several techniques and tools have been proposed to automatically generate test methods, recent work has criticized the quality and usefulness of the assert statements they generate.",1,0,0,0,0,0
830,"Therefore, we employ a Neural Machine Translation (NMT) based approach called Atlas (AuTomatic Learning of Assert Statements) to automatically generate meaningful assert statements for test methods.",0,1,1,0,0,0
831,"Given a test method and a focal method (i.e., the main method under test), Atlas can predict a meaningful assert statement to assess the correctness of the focal method.",0,1,0,0,0,0
832,We applied Atlas to thousands of test methods from GitHub projects and it was able to predict the exact assert statement manually written by developers in 31% of the cases when only considering the top-1 predicted assert.,0,0,0,1,0,0
833,"When considering the top-5 predicted assert statements, Atlas is able to predict exact matches in 50% of the cases.",0,0,0,0,1,0
834,"These promising results hint to the potential usefulness of our approach as (i) a complement to automatic test case generation techniques, and (ii) a code completion support for developers, who can benefit from the recommended assert statements while writing test code.",0,0,0,0,0,1
835,"
Multithreaded programs can have deadlocks, even after deployment, so users may want to run deadlock tools on deployed programs.",1,0,0,0,0,0
836,"However, current deadlock predictors such as MagicLock and UnDead have large overheads that make them impractical for end-user deployment and confine their use to development time.",1,0,0,0,0,0
837,Such overhead stems from running an exponential-time algorithm on a large execution trace.,1,0,0,0,0,0
838,"In this paper, we present the first low-overhead deadlock predictor, called AirLock, that is fit for both in-house testing and deployed programs.",0,1,0,0,0,0
839,"AirLock maintains a small predictive lock reachability graph, searches the graph for cycles, and runs an exponential-time algorithm only for each cycle.",0,1,0,0,0,0
840,This approach lets AirLock find the same deadlocks as MagicLock and UnDead but with much less overhead because the number of cycles is small in practice.,0,1,0,0,0,0
841,"Our experiments with real-world benchmarks show that the average time overhead of AirLock is 3.5%, which is three orders of magnitude less than that of MagicLock and UnDead.",0,0,0,1,1,0
842,AirLock's low overhead makes it suitable for use with fuzz testers like AFL and on-the-fly after deployment.,0,0,0,0,0,1
843,"
Mobile application (app) developers commonly utilize analytic services to analyze their app users' behavior to support debugging, improve service quality, and facilitate advertising.",1,0,0,0,0,0
844,"Anonymization and aggregation can reduce the sensitivity of such behavioral data, therefore analytic services often encourage the use of such protections.",1,0,0,0,0,0
845,"However, these protections are not directly enforced so it is possible for developers to misconfigure the analytic services and expose personal information, which may cause greater privacy risks.",1,0,0,0,0,0
846,"Since people use apps in many aspects of their daily lives, such misconfigurations may lead to the leaking of sensitive personal information such as a users' real-time location, health data, or dating preferences.",1,0,0,0,0,0
847,"To study this issue and identify potential privacy risks due to such misconfigurations, we developed a semi-automated approach, Privacy-Aware Analytics Misconfiguration Detector (PAMDroid), which enables our empirical study on mis-configurations of analytic services.",0,0,1,0,0,0
848,"This paper describes a study of 1,000 popular apps using top analytic services in which we found misconfigurations in 120 apps.",0,0,0,1,0,0
849,"In 52 of the 120 apps, misconfigurations lead to a violation of either the analytic service providers' terms of service or the app's own privacy policy.",0,0,0,0,1,0
850,"
Deep neural networks (DNN) have been shown to be notoriously brittle to small perturbations in their input data.",1,0,0,0,0,0
851,"This problem is analogous to the over-fitting problem in test-based program synthesis and automatic program repair, which is a consequence of the incomplete specification, i.e., the limited tests or training examples, that the program synthesis or repair algorithm has to learn from.",1,0,0,0,0,0
852,"Recently, test generation techniques have been successfully employed to augment existing specifications of intended program behavior, to improve the generalizability of program synthesis and repair.",1,0,0,0,0,0
853,"Inspired by these approaches, in this paper, we propose a technique that re-purposes software testing methods, specifically mutation-based fuzzing, to augment the training data of DNNs, with the objective of enhancing their robustness.",0,1,0,0,0,0
854,Our technique casts the DNN data augmentation problem as an optimization problem.,0,1,0,0,0,0
855,"It uses genetic search to generate the most suitable variant of an input data to use for training the DNN, while simultaneously identifying opportunities to accelerate training by skipping augmentation in many instances.",0,1,0,0,0,0
856,"We instantiate this technique in two tools, Sensei and Sensei-SA, and evaluate them on 15 DNN models spanning 5 popular image data-sets.",0,0,0,1,0,0
857,"Our evaluation shows that Sensei can improve the robust accuracy of the DNN, compared to the state of the art, on each of the 15 models, by upto 11.9% and 5.5% on average.",0,0,0,0,1,0
858,"Further, Sensei-SA can reduce the average DNN training time by 25%, while still improving robust accuracy.",0,0,0,0,1,0
859,"
SMT solvers are at the basis of many applications, such as program verification, program synthesis, and test case generation.",1,0,0,0,0,0
860,"For all these applications to provide reliable results, SMT solvers must answer queries correctly.",1,0,0,0,0,0
861,"However, since they are complex, highly-optimized software systems, ensuring their correctness is challenging.",1,0,0,0,0,0
862,"In particular, state-of-the-art testing techniques do not reliably detect when an SMT solver is unsound.",1,0,0,0,0,0
863,"In this paper, we present an automatic approach for generating test cases that reveal soundness errors in the implementations of string solvers, as well as potential completeness and performance issues.",0,1,0,0,0,0
864,We synthesize input formulas that are satisfiable or unsatisfiable by construction and use this ground truth as test oracle.,0,1,0,0,0,0
865,"We automatically apply satisfiability-preserving transformations to generate increasingly-complex formulas, which allows us to detect many errors with simple inputs and, thus, facilitates debugging.",0,1,0,0,0,0
866,"The experimental evaluation shows that our technique effectively reveals bugs in the implementation of widely-used SMT solvers and applies also to other types of solvers, such as automata-based solvers.",0,0,0,1,1,0
867,"We focus on strings here, but our approach carries over to other theories and their combinations.",0,0,0,0,0,1
868,"
Property-based testing is a popular approach for validating the logic of a program.",1,0,0,0,0,0
869,An effective property-based test quickly generates many diverse valid test inputs and runs them through a parameterized test driver.,1,0,0,0,0,0
870,"However, when the test driver requires strict validity constraints on the inputs, completely random input generation fails to generate enough valid inputs.",1,0,0,0,0,0
871,Existing approaches to solving this problem rely on whitebox or greybox information collected by instrumenting the input generator and/or test driver.,1,0,0,0,0,0
872,"However, collecting such information reduces the speed at which tests can be executed.",1,0,0,0,0,0
873,"In this paper, we propose and study a black-box approach for generating valid test inputs.",0,0,1,0,0,0
874,We first formalize the problem of guiding random input generators towards producing a diverse set of valid inputs.,0,0,1,0,0,0
875,This formalization highlights the role of a guide which governs the space of choices within a random input generator.,0,0,1,0,0,0
876,"We then propose a solution based on reinforcement learning (RL), using a tabular, on-policy RL approach to guide the generator.",0,0,1,0,0,0
877,"We evaluate this approach, RLCheck, against pure random input generation as well as a state-of-the-art greybox evolutionary algorithm, on four real-world benchmarks.",0,0,0,1,0,0
878,"We find that in the same time budget, RLCheck generates an order of magnitude more diverse valid inputs than the baselines.",0,0,0,0,0,1
879,"
Highly-configurable software systems can have thousands of interdependent configuration options across different subsystems.",1,0,0,0,0,0
880,"In the resulting configuration space, discovering a valid product configuration for some selected options can be complex and error prone.",1,0,0,0,0,0
881,"The configuration space can be organized using a feature model, fragmented into smaller interdependent feature models reflecting the configuration options of each subsystem.",1,0,0,0,0,0
882,We propose a method for lazy product discovery in large fragmented feature models with interdependent features.,0,1,0,0,0,0
883,We formalize the method and prove its soundness and completeness.,0,1,0,0,0,0
884,The evaluation explores an industrial-size configuration space.,0,1,0,0,0,0
885,"The results show that lazy product discovery has significant performance benefits compared to standard product discovery, which in contrast to our method requires all fragments to be composed to analyze the feature model.",0,0,0,0,0,1
886,"Furthermore, the method succeeds when more efficient, heuristics-based engines fail to find a valid configuration.",0,0,0,0,0,1
887,"
Data scientists frequently analyze data by writing scripts.",1,0,0,0,0,0
888,"We conducted a contextual inquiry with interdisciplinary researchers, which revealed that parameter tuning is a highly iterative process and that debugging is time-consuming.",0,0,0,1,0,0
889,"As analysis scripts evolve and become more complex, analysts have difficulty conceptualizing their workflow.",1,0,0,0,0,0
890,"In particular, after editing a script, it becomes difficult to determine precisely which code blocks depend on the edit.",1,0,0,0,0,0
891,"Consequently, scientists frequently re-run entire scripts instead of re-running only the necessary parts.",1,0,0,0,0,0
892,"We present ProvBuild, a tool that leverages language-level provenance to streamline the debugging process by reducing programmer cognitive load and decreasing subsequent runtimes, leading to an overall reduction in elapsed debugging time.",0,1,0,0,0,0
893,ProvBuild uses provenance to track dependencies in a script.,0,1,0,0,0,0
894,"When an analyst debugs a script, ProvBuild generates a simplifed script that contains only the information necessary to debug a particular problem.",0,1,0,0,0,0
895,We demonstrate that debugging the simplified script lowers a programmer's cognitive load and permits faster re-execution when testing changes.,0,0,0,0,1,0
896,The combination of reduced cognitive load and shorter runtime reduces the time necessary to debug a script.,0,0,0,0,0,1
897,"We quantitatively and qualitatively show that even though ProvBuild introduces overhead during a script's first execution, it is a more efficient way for users to debug and tune complex workflows.",0,0,0,0,1,0
898,"ProvBuild demonstrates a novel use of language-level provenance, in which it is used to proactively improve programmer productively rather than merely providing a way to retroactively gain insight into a body of code.",0,0,0,0,1,0
899,"
Image classifiers are an important component of today's software, from consumer and business applications to safety-critical domains.",1,0,0,0,0,0
900,The advent of Deep Neural Networks (DNNs) is the key catalyst behind such wide-spread success.,1,0,0,0,0,0
901,"However, wide adoption comes with serious concerns about the robustness of software systems dependent on DNNs for image classification, as several severe erroneous behaviors have been reported under sensitive and critical circumstances.",1,0,0,0,0,0
902,We argue that developers need to rigorously test their software's image classifiers and delay deployment until acceptable.,0,1,0,0,0,0
903,We present an approach to testing image classifier robustness based on class property violations.,0,1,0,0,0,0
904,We found that many of the reported erroneous cases in popular DNN image classifiers occur because the trained models confuse one class with another or show biases towards some classes over others.,0,0,0,0,1,0
905,These bugs usually violate some class properties of one or more of those classes.,0,0,0,0,1,0
906,"Most DNN testing techniques focus on perimage violations, so fail to detect class-level confusions or biases.",1,0,0,0,0,0
907,We developed a testing technique to automatically detect class-based confusion and bias errors in DNN-driven image classification software.,0,0,0,0,1,0
908,"We evaluated our implementation, DeepInspect, on several popular image classifiers with precision up to 100% (avg.",0,0,0,0,1,0
909,"72.6%) for confusion errors, and up to 84.3% (avg.",0,0,0,0,1,0
910,66.8%) for bias errors.,0,0,0,0,1,0
911,"DeepInspect found hundreds of classification mistakes in widely-used models, many exposing errors indicating confusion or bias.",0,0,0,0,0,1
912,"
CPU cache is a limited but crucial storage component in modern processors, whereas the cache timing side-channel may inadvertently leak information through the physically measurable timing variance.",1,0,0,0,0,0
913,"Speculative execution, an essential processor optimization, and a source of such variances, can cause severe detriment on deliberate branch mispredictions.",1,0,0,0,0,0
914,"Despite static analysis could qualitatively verify the timing-leakage-free property under speculative execution, it is incapable of producing endorsements including inputs and speculated flows to diagnose leaks in depth.",1,0,0,0,0,0
915,"This work proposes a new symbolic execution based method, SpecuSym, for precisely detecting cache timing leaks introduced by speculative execution.",0,1,0,0,0,0
916,"Given a program (leakage-free in non-speculative execution), SpecuSym systematically explores the program state space, models speculative behavior at conditional branches, and accumulates the cache side effects along with subsequent path explorations.",0,1,0,0,0,0
917,"During the dynamic execution, SpecuSym constructs leak predicates for memory visits according to the specified cache model and conducts a constraint-solving based cache behavior analysis to inspect the new cache behaviors.",0,1,0,0,0,0
918,We have implemented SpecuSym atop KLEE and evaluated it against 15 open-source benchmarks.,0,0,0,1,0,0
919,Experimental results show that SpecuSym successfully detected from 2 to 61 leaks in 6 programs under 3 different cache settings and identified false positives in 2 programs reported by recent work.,0,0,0,0,1,0
920,"
Intelligent services are becoming increasingly more pervasive; application developers want to leverage the latest advances in areas such as computer vision to provide new services and products to users, and large technology firms enable this via RESTful APIs.",1,0,0,0,0,0
921,"While such APIs promise an easy-to-integrate on-demand machine intelligence, their current design, documentation and developer interface hides much of the underlying machine learning techniques that power them.",1,0,0,0,0,0
922,"Such APIs look and feel like conventional APIs but abstract away data-driven probabilistic behaviour---the implications of a developer treating these APIs in the same way as other, traditional cloud services, such as cloud storage, is of concern.",1,0,0,0,0,0
923,"The objective of this study is to determine the various pain-points developers face when implementing systems that rely on the most mature of these intelligent services, specifically those that provide computer vision.",0,0,1,0,0,0
924,"We use Stack Overflow to mine indications of the frustrations that developers appear to face when using computer vision services, classifying their questions against two recent classification taxonomies (documentation-related and general questions).",0,0,0,1,0,0
925,"We find that, unlike mature fields like mobile development, there is a contrast in the types of questions asked by developers.",0,0,0,0,1,0
926,These indicate a shallow understanding of the underlying technology that empower such systems.,0,0,0,0,1,0
927,We discuss several implications of these findings via the lens of learning taxonomies to suggest how the software engineering community can improve these services and comment on the nature by which developers use them.,0,0,0,0,0,1
928,"
Deep learning has made significant achievements in many application areas.",1,0,0,0,0,0
929,"To train and test models more efficiently, enterprise developers submit and run their deep learning programs on a shared, multi-tenant platform.",1,0,0,0,0,0
930,"However, some of the programs fail after a long execution time due to code/script defects, which reduces the development productivity and wastes expensive resources such as GPU, storage, and network I/O.",1,0,0,0,0,0
931,This paper presents the first comprehensive empirical study on program failures of deep learning jobs.,0,0,1,0,0,0
932,4960 real failures are collected from a deep learning platform in Microsoft.,0,0,0,1,0,0
933,We manually examine their failure messages and classify them into 20 categories.,0,0,0,1,0,0
934,"In addition, we identify the common root causes and bug-fix solutions on a sample of 400 failures.",0,0,0,0,1,0
935,"To better understand the current testing and debugging practices for deep learning, we also conduct developer interviews.",0,0,0,1,0,0
936,"Our major findings include: (1) 48.0% of the failures occur in the interaction with the platform rather than in the execution of code logic, mostly due to the discrepancies between local and platform execution environments; (2) Deep learning specific failures (13.5%) are mainly caused by inappropriate model parameters/structures and framework API misunderstanding; (3) Current debugging practices are not efficient for fault localization in many cases, and developers need more deep learning specific tools.",0,0,0,0,1,0
937,"Based on our findings, we further suggest possible research topics and tooling support that could facilitate future deep learning development.",0,0,0,0,0,1
938,"
Open Source Software (OSS) has come to play a critical role in the software industry.",1,0,0,0,0,0
939,"Some large ecosystems enjoy the participation of large numbers of companies, each of which has its own focus and goals.",1,0,0,0,0,0
940,"Indeed, companies that otherwise compete, may become collaborators within the OSS ecosystem they participate in.",1,0,0,0,0,0
941,"Prior research has largely focused on commercial involvement in OSS projects, but there is a scarcity of research focusing on company collaborations within OSS ecosystems.",1,0,0,0,0,0
942,"Some of these ecosystems have become critical building blocks for organizations worldwide; hence, a clear understanding of how companies collaborate within large ecosystems is essential.",1,0,0,0,0,0
943,"This paper presents the results of an empirical study of the OpenStack ecosystem, in which hundreds of companies collaborate on thousands of project repositories to deliver cloud distributions.",0,0,1,0,0,0
944,"Based on a detailed analysis, we identify clusters of collaborations, and identify four strategies that companies adopt to engage with the OpenStack ecosystem.",0,0,0,0,1,0
945,"We alsofind that companies may engage in intentional or passive collaborations, or may work in an isolated fashion.",0,0,0,0,1,0
946,"Further, wefi nd that a company's position in the collaboration network is positively associated with its productivity in OpenStack.",0,0,0,0,1,0
947,"Our study sheds light on how large OSS ecosystems work, and in particular on the patterns of collaboration within one such large ecosystem.",0,0,0,0,0,1
948,"
Open source is ubiquitous and many projects act as critical infrastructure, yet funding and sustaining the whole ecosystem is challenging.",1,0,0,0,0,0
949,"While there are many different funding models for open source and concerted efforts through foundations, donation platforms like PayPal, Patreon, and OpenCollective are popular and low-bar platforms to raise funds for open-source development.",1,0,0,0,0,0
950,"With a mixed-method study, we investigate the emerging and largely unexplored phenomenon of donations in open source.",0,0,1,0,0,0
951,"Specifically, we quantify how commonly open-source projects ask for donations, statistically model characteristics of projects that ask for and receive donations, analyze for what the requested funds are needed and used, and assess whether the received donations achieve the intended outcomes.",0,0,0,0,1,0
952,"We find 25,885 projects asking for donations on GitHub, often to support engineering activities; however, we also find no clear evidence that donations influence the activity level of a project.",0,0,0,0,1,0
953,"In fact, we find that donations are used in a multitude of ways, raising new research questions about effective funding.",0,0,0,0,0,1
954,"
The assessment of information flows is an essential part of analyzing Android apps, and is frequently supported by static taint analysis.",1,0,0,0,0,0
955,"Its precision, however, can suffer from the analysis not being able to precisely determine what elements a pointer can (and cannot) point to.",1,0,0,0,0,0
956,"Recent advances in static analysis suggest that incorporating dynamic heap snapshots, taken at one point at runtime, can significantly improve general static analysis.",1,0,0,0,0,0
957,"In this paper, we investigate to what extent this also holds for taint analysis, and how various design decisions, such as when and how many snapshots are collected during execution, and how exactly they are used, impact soundness and precision.",0,0,1,0,0,0
958,"We have extended FlowDroid to incorporate heap snapshots, yielding our prototype Heapster, and evaluated it on DroidMacroBench, a novel benchmark comprising real-world Android apps that we also make available as an artifact.",0,0,0,1,0,0
959,"The results show (1) the use of heap snapshots lowers analysis time and memory consumption while increasing precision; (2) a very good trade-off between precision and recall is achieved by a mixed mode in which the analysis falls back to static points-to relations for objects for which no dynamic data was recorded; and (3) while a single heap snapshot (ideally taken at the end of the execution) suffices to improve performance and precision, a better trade-off can be obtained by using multiple snapshots.",0,0,0,0,1,0
960,"
Automatic test generation typically aims to generate inputs that explore new paths in the program under test in order to find bugs.",1,0,0,0,0,0
961,"Existing work has, therefore, focused on guiding the exploration toward program parts that are more likely to contain bugs by using an offline static analysis.",1,0,0,0,0,0
962,"In this paper, we introduce a novel technique for targeted greybox fuzzing using an online static analysis that guides the fuzzer toward a set of target locations, for instance, located in recently modified parts of the program.",0,1,0,0,0,0
963,This is achieved by first semantically analyzing each program path that is explored by an input in the fuzzer's test suite.,0,1,0,0,0,0
964,"The results of this analysis are then used to control the fuzzer's specialized power schedule, which determines how often to fuzz inputs from the test suite.",0,1,0,0,0,0
965,"We implemented our technique by extending a state-of-the-art, industrial fuzzer for Ethereum smart contracts and evaluate its effectiveness on 27 real-world benchmarks.",0,0,0,1,0,0
966,Using an online analysis is particularly suitable for the domain of smart contracts since it does not require any code instrumentation---adding instrumentation to contracts changes their semantics.,1,0,0,0,0,0
967,Our experiments show that targeted fuzzing significantly outperforms standard greybox fuzzing for reaching 83% of the challenging target locations (up to 14x of median speed-up).,0,0,0,0,1,0
968,"
GUI animations, such as card movement, menu slide in/out, snackbar display, provide appealing user experience and enhance the usability of mobile applications.",1,0,0,0,0,0
969,"These GUI animations should not violate the platform's UI design guidelines (referred to as design-don't guideline in this work) regarding component motion and interaction, content appearing and disappearing, and elevation and shadow changes.",1,0,0,0,0,0
970,"However, none of existing static code analysis, functional GUI testing and GUI image comparison techniques can ""see"" the GUI animations on the scree, and thus they cannot support the linting of GUI animations against design-don't guidelines.",1,0,0,0,0,0
971,"In this work, we formulate this GUI animation linting problem as a multi-class screencast classification task, but we do not have sufficient labeled GUI animations to train the classifier.",0,0,1,0,0,0
972,"Instead, we propose an unsupervised, computer-vision based adversarial autoencoder to solve this linting problem.",0,0,1,0,0,0
973,"Our autoencoder learns to group similar GUI animations by ""seeing"" lots of unlabeled real-application GUI animations and learning to generate them.",0,0,0,1,0,0
974,"As the first work of its kind, we build the datasets of synthetic and real-world GUI animations.",0,0,0,1,0,0
975,"Through experiments on these datasets, we systematically investigate the learning capability of our model and its effectiveness and practicality for linting GUI animations, and identify the challenges in this linting problem for future work.",0,0,0,0,0,1
976,"
Detecting regression bugs in software evolution, analyzing side-channels in programs and evaluating robustness in deep neural networks (DNNs) can all be seen as instances of differential software analysis, where the goal is to generate diverging executions of program paths.",1,0,0,0,0,0
977,"Two executions are said to be diverging if the observable program behavior differs, e.g., in terms of program output, execution time, or (DNN) classification.",1,0,0,0,0,0
978,"The key challenge of differential software analysis is to simultaneously reason about multiple program paths, often across program variants.",1,0,0,0,0,0
979,"This paper presents HyDiff, the first hybrid approach for differential software analysis.",0,1,0,0,0,0
980,HyDiff integrates and extends two very successful testing techniques: Feedback-directed greybox fuzzing for efficient program testing and shadow symbolic execution for systematic program exploration.,0,1,0,0,0,0
981,HyDiff extends greybox fuzzing with divergence-driven feedback based on novel cost metrics that also take into account the control flow graph of the program.,0,1,0,0,0,0
982,Furthermore HyDiff extends shadow symbolic execution by applying four-way forking in a systematic exploration and still having the ability to incorporate concrete inputs in the analysis.,0,1,0,0,0,0
983,"HyDiff applies divergence revealing heuristics based on resource consumption and control-flow information to efficiently guide the symbolic exploration, which allows its efficient usage beyond regression testing applications.",0,1,0,0,0,0
984,"We introduce differential metrics such as output, decision and cost difference, as well as patch distance, to assist the fuzzing and symbolic execution components in maximizing the execution divergence.",0,0,0,0,1,0
985,We implemented our approach on top of the fuzzer AFL and the symbolic execution framework Symbolic PathFinder.,0,0,0,0,0,1
986,"Weillustrate HyDiff on regression and side-channel analysis for Java bytecode programs, and further show how to use HyDiff for robustness analysis of neural networks.",0,0,0,0,0,1
987,"
Database-backed web applications manipulate large amounts of persistent data, and such applications often contain constraints that restrict data length, data value, and other data properties.",1,0,0,0,0,0
988,Such constraints are critical in ensuring the reliability and usability of these applications.,1,0,0,0,0,0
989,"In this paper, we present a comprehensive study on where data constraints are expressed, what they are about, how often they evolve, and how their violations are handled.",0,0,1,0,0,0
990,"The results show that developers struggle with maintaining consistent data constraints and checking them across different components and versions of their web applications, leading to various problems.",0,0,0,0,1,0
991,"Guided by our study, we developed checking tools and API enhancements that can automatically detect such problems and improve the quality of such applications.",0,0,0,0,0,1
992,"
Many automated test generation techniques have been proposed for finding crashes in Android apps.",1,0,0,0,0,0
993,"Despite recent advancement in these approaches, a study shows that Android app developers prefer reading test cases written in natural language.",1,0,0,0,0,0
994,"Meanwhile, there exist redundancies in bug reports (written in natural language) across different apps that have not been previously reused.",1,0,0,0,0,0
995,"We propose collaborative bug finding, a novel approach that uses bugs in other similar apps to discover bugs in the app under test.",0,1,0,0,0,0
996,"We design three settings with varying degrees of interactions between programmers: (1) bugs from programmers who develop a different app, (2) bugs from manually searching for bug reports in GitHub repositories, (3) bugs from a bug recommendation system, Bugine.",0,1,0,0,0,0
997,Our studies of the first two settings in a software testing course show that collaborative bug finding helps students who are novice Android app testers to discover 17 new bugs.,0,0,0,0,1,0
998,"As students admit that searching for relevant bug reports could be time-consuming, we introduce Bugine, an approach that automatically recommends relevant GitHub issues for a given app.",0,0,0,0,1,0
999,"Bugine uses (1) natural language processing to find GitHub issues that mention common UI components shared between the app under test and other apps in our database, and (2) a ranking algorithm to select GitHub issues that are of the best quality.",0,0,0,0,1,0
1000,Our results show that Bugine is able to find 34 new bugs.,0,0,0,0,1,0
1001,"In total, collaborative bug finding helps us find 51 new bugs, in which eight have been confirmed and 11 have been fixed by the developers.",0,0,0,0,1,0
1002,These results confirm our intuition that our proposed technique is useful in discovering new bugs for Android apps.,0,0,0,0,0,1
1003,"
In recent years, machine translation software has increasingly been integrated into our daily lives.",1,0,0,0,0,0
1004,"People routinely use machine translation for various applications, such as describing symptoms to a foreign doctor and reading political news in a foreign language.",1,0,0,0,0,0
1005,"However, the complexity and intractability of neural machine translation (NMT) models that power modern machine translation make the robustness of these systems difficult to even assess, much less guarantee.",1,0,0,0,0,0
1006,"Machine translation systems can return inferior results that lead to misunderstanding, medical misdiagnoses, threats to personal safety, or political conflicts.",1,0,0,0,0,0
1007,"Despite its apparent importance, validating the robustness of machine translation systems is very difficult and has, therefore, been much under-explored.",1,0,0,0,0,0
1008,"To tackle this challenge, we introduce structure-invariant testing (SIT), a novel metamorphic testing approach for validating machine translation software.",0,1,0,0,0,0
1009,"Our key insight is that the translation results of ""similar"" source sentences should typically exhibit similar sentence structures.",0,1,0,0,0,0
1010,"Specifically, SIT (1) generates similar source sentences by substituting one word in a given sentence with semantically similar, syntactically equivalent words; (2) represents sentence structure by syntax parse trees (obtained via constituency or dependency parsing); (3) reports sentence pairs whose structures differ quantitatively by more than some threshold.",0,0,0,0,1,0
1011,"To evaluate SIT, we use it to test Google Translate and Bing Microsoft Translator with 200 source sentences as input, which led to 64 and 70 buggy issues with 69.5% and 70% top-1 accuracy, respectively.",0,0,0,1,1,0
1012,"The translation errors are diverse, including under-translation, over-translation, incorrect modification, word/phrase mistranslation, and unclear logic.",0,0,0,0,0,1
1013,"
Misleading names of the methods in a project or the APIs in a software library confuse developers about program functionality and API usages, leading to API misuses and defects.",1,0,0,0,0,0
1014,"In this paper, we introduce MNire, a machine learning approach to check the consistency between the name of a given method and its implementation.",0,1,0,0,0,0
1015,MNire first generates a candidate name and compares the current name against it.,0,1,0,0,0,0
1016,"If the two names are sufficiently similar, we consider the method as consistent.",0,1,0,0,0,0
1017,"To generate the method name, we draw our ideas and intuition from an empirical study on the nature of method names in a large dataset.",0,0,0,1,0,0
1018,"Our key finding is that high proportions of the tokens of method names can be found in the three contexts of a given method including its body, the interface (the method's parameter types and return type), and the enclosing class' name.",0,0,0,0,1,0
1019,"Even when such tokens are not there, MNire uses the contexts to predict the tokens due to the high likelihoods of their co-occurrences.",0,0,0,0,1,0
1020,Our unique idea is to treat the name generation as an abstract summarization on the tokens collected from the names of the program entities in the three above contexts.,0,0,0,0,1,0
1021,We conducted several experiments to evaluate MNire in method name consistency checking and in method name recommending on large datasets with +14M methods.,0,0,0,1,0,0
1022,"In detecting inconsistency method names, MNire improves the state-of-the-art approach by 10.4% and 11% relatively in recall and precision, respectively.",0,0,0,0,1,0
1023,"In method name recommendation, MNire improves relatively over the state-of-the-art technique, code2vec, in both recall (18.2% higher) and precision (11.1% higher).",0,0,0,0,1,0
1024,"To assess MNire's usefulness, we used it to detect inconsistent methods and suggest new names in several active, GitHub projects.",0,0,0,1,0,0
1025,We made 50 pull requests (PRs) and received 42 responses.,0,0,0,1,0,0
1026,"Among them, five PRs were merged into the main branch, and 13 were approved for later merging.",0,0,0,0,1,0
1027,"In total, in 31/42 cases, the developer teams agree that our suggested names are more meaningful than the current names, showing MNire's usefulness.",0,0,0,0,0,1
1028,"
Developers build programs based on software libraries to reduce coding effort.",1,0,0,0,0,0
1029,"If a program inappropriately sets an API parameter, the program may exhibit unexpected runtime behaviors.",1,0,0,0,0,0
1030,"To help developers correctly use library APIs, researchers built tools to mine API parameter rules.",1,0,0,0,0,0
1031,"However, it is still unknown (1) what types of parameter rules there are, and (2) how these rules distribute inside documents and source files.",1,0,0,0,0,0
1032,"In this paper, we conducted an empirical study to investigate the above-mentioned questions.",0,0,1,1,0,0
1033,"To analyze as many parameter rules as possible, we took a hybrid approach that combines automatic localization of constrained parameters with manual inspection.",0,0,0,1,0,0
1034,"Our automatic approach---PaRu---locates parameters that have constraints either documented in Javadoc (i.e., document rules) or implied by source code (i.e., code rules).",0,0,0,1,0,0
1035,"Our manual inspection (1) identifies and categorizes rules for the located parameters, and (2) establishes mapping between document and code rules.",0,0,0,0,1,0
1036,"By applying PaRu to 9 widely used libraries, we located 5,334 parameters with either document or code rules.",0,0,0,0,1,0
1037,"Interestingly, there are only 187 parameters that have both types of rules, and 79 pairs of these parameter rules are unmatched.",0,0,0,0,1,0
1038,"Additionally, PaRu extracted 1,688 rule sentences from Javadoc and code.",0,0,0,0,1,0
1039,"We manually classified these sentences into six categories, two of which are overlooked by prior approaches.",0,0,0,0,1,0
1040,We found that 86.2% of parameters have only code rules; 10.3% of parameters have only document rules; and only 3.5% of parameters have both document and code rules.,0,0,0,0,1,0
1041,Our research reveals the challenges for automating parameter rule extraction.,0,0,0,0,0,1
1042,"Based on our findings, we discuss the potentials of prior approaches and present our insights for future tool design.",0,0,0,0,0,1
1043,"
The number of vulnerabilities increases rapidly in recent years, due to advances in vulnerability discovery solutions.",1,0,0,0,0,0
1044,It enables a thorough analysis on the vulnerability distribution and provides support for correlation analysis and prediction of vulnerabilities.,1,0,0,0,0,0
1045,"Previous research either focuses on analyzing bugs rather than vulnerabilities, or only studies general vulnerability distribution among projects rather than the distribution within each project.",1,0,0,0,0,0
1046,"In this paper, we collected a large vulnerability dataset, consisting of all known vulnerabilities associated with five representative open source projects, by utilizing automated crawlers and spending months of manual efforts.",0,0,1,0,0,0
1047,"We then analyzed the vulnerability distribution within each project over four dimensions, including files, functions, vulnerability types and responsible developers.",0,0,1,0,0,0
1048,"Based on the results analysis, we presented 12 practical insights on the distribution of vulnerabilities.",0,0,0,0,1,0
1049,"Finally, we applied such insights on several vulnerability discovery solutions (including static analysis and dynamic fuzzing), and helped them find 10 zero-day vulnerabilities in target projects, showing that our insights are useful.",0,0,0,0,1,0
1050,"
Test-to-code traceability links model the relationships between test artefacts and code artefacts.",1,0,0,0,0,0
1051,"When utilised during the development process, these links help developers to keep test code in sync with tested code, reducing the rate of test failures and missed faults.",1,0,0,0,0,0
1052,"Test-to-code traceability links can also help developers to maintain an accurate mental model of the system, reducing the risk of architectural degradation when making changes.",1,0,0,0,0,0
1053,"However, establishing and maintaining these links manually places an extra burden on developers and is error-prone.",1,0,0,0,0,0
1054,"This paper presents TCtracer, an approach and implementation for the automatic establishment of test-to-code traceability links.",0,1,0,0,0,0
1055,"Unlike existing work, TCtracer operates at both the method level and the class level, allowing us to establish links between tests and functions, as well as between test classes and tested classes.",0,1,0,0,0,0
1056,We improve over existing techniques by combining an ensemble of new and existing techniques and exploiting a synergistic flow of information between the method and class levels.,0,1,0,0,0,0
1057,"An evaluation of TCtracer using four large, well-studied open source systems demonstrates that, on average, we can establish test-to-function links with a mean average precision (MAP) of 78% and test-class-to-class links with an MAP of 93%.",0,0,0,0,1,0
1058,"
Large-scale open source communities, such as the Linux kernel, have gone through decades of development, substantially growing in scale and complexity.",1,0,0,0,0,0
1059,"In the traditional workflow, maintainers serve as ""gatekeepers"" for the subsystems that they maintain.",1,0,0,0,0,0
1060,"As the number of patches and authors significantly increases, maintainers come under considerable pressure, which may hinder the operation and even the sustainability of the community.",1,0,0,0,0,0
1061,A few subsystems have begun to use new workflows to address these issues.,1,0,0,0,0,0
1062,"However, it is unclear to what extent these new workflows are successful, or how to apply them.",1,0,0,0,0,0
1063,"Therefore, we conduct an empirical study on the multiple-committer model (MCM) that has provoked extensive discussion in the Linux kernel community.",0,0,1,0,0,0
1064,"We explore the effect of the model on the i915 subsystem with respect to four dimensions: pressure, latency, complexity, and quality assurance.",0,0,1,0,0,0
1065,"We find that after this model was adopted, the burden of the i915 maintainers was significantly reduced.",0,0,0,0,1,0
1066,"Also, the model scales well to allow more committers.",0,0,0,0,1,0
1067,"After analyzing the online documents and interviewing the maintainers of i915, we propose that overloaded subsystems which have trustworthy candidate committers are suitable for adopting the model.",0,0,0,0,0,1
1068,"We further suggest that the success of the model is closely related to a series of measures for risk mitigation---sufficient precommit testing, strict review process, and the use of tools to simplify work and reduce errors.",0,0,0,0,0,1
1069,We employ a network analysis approach to locate candidate committers for the target subsystems and validate this approach and contextual success factors through email interviews with their maintainers.,0,0,0,1,0,0
1070,"To the best of our knowledge, this is the first study focusing on how to scale open source communities.",0,0,0,1,0,0
1071,We expect that our study will help the rapidly growing Linux kernel and other similar communities to adapt to changes and remain sustainable.,0,0,0,0,0,1
1072,"We present SAVER, a new memory-error repair technique for C programs.",1,0,0,0,0,0
1073,"Memory errors such as memory leak, double-free, and use-after-free are highly prevalent and fixing them requires significant effort.",1,0,0,0,0,0
1074,Automated program repair techniques hold the promise of reducing this burden but the state-of-the-art is still unsatisfactory.,1,0,0,0,0,0
1075,"In particular, no existing techniques are able to fix those errors in a scalable, precise, and safe way, all of which are required for a truly practical tool.",1,0,0,0,0,0
1076,SAVER aims to address these shortcomings.,0,1,0,0,0,0
1077,"To this end, we propose a method based on a novel representation of the program called object flow graph, which summarizes the program's heap-related behavior using static analysis.",0,0,1,0,0,0
1078,We show that fixing memory errors can be formulated as a graph labeling problem over object flow graph and present an efficient algorithm.,0,0,1,0,0,0
1079,"We evaluated SAVER in combination with Infer, an industrial-strength static bug-finder, and show that 74% of the reported errors can be fixed automatically for a range of open-source C programs.",0,0,0,1,1,0
1080,Rust is a promising systems programming language that embraces both high-level memory safety and low-level resource manipulation.,1,0,0,0,0,0
1081,"However, the dark side of Rust, unsafe Rust, leaves a large security hole as it bypasses the Rust type system in order to support low-level operations.",1,0,0,0,0,0
1082,"Recently, several real-world memory corruption vulnerabilities have been discovered in Rust's standard libraries.",1,0,0,0,0,0
1083,"We present XRust, a new technique that mitigates the security threat of unsafe Rust by ensuring the integrity of data flow from unsafe Rust code to safe Rust code.",0,1,1,0,0,0
1084,"The cornerstone of XRust is a novel heap allocator that isolates the memory of unsafe Rust from that accessed only in safe Rust, and prevents any cross-region memory corruption.",0,0,1,0,0,0
1085,Our design of XRust supports both single-and multi-threaded Rust programs.,0,0,1,0,0,0
1086,Our extensive experiments on real-world Rust applications and standard libraries show that XRust is both highly efficient and effective in practice.,0,0,0,1,1,0
1087,"Code injection attacks, like the one used in the high-profile 2017 Equifax breach, have become increasingly common, now ranking #1 on OWASP's list of critical web application vulnerabilities.",1,0,0,0,0,0
1088,Static analyses for detecting these vulnerabilities can overwhelm developers with false positive reports.,1,0,0,0,0,0
1089,"Meanwhile, most dynamic analyses rely on detecting vulnerabilities as they occur in the field, which can introduce a high performance overhead in production code.",1,0,0,0,0,0
1090,This paper describes a new approach for detecting injection vulnerabilities in applications by harnessing the combined power of human developers' test suites and automated dynamic analysis.,0,1,1,0,0,0
1091,"Our new approach, Rivulet, monitors the execution of developer-written functional tests in order to detect information flows that may be vulnerable to attack.",0,0,1,0,0,0
1092,"Then, Rivulet uses a white-box test generation technique to repurpose those functional tests to check if any vulnerable flow could be exploited.",0,0,1,0,0,0
1093,"When applied to the version of Apache Struts exploited in the 2017 Equifax attack, Rivulet quickly identifies the vulnerability, leveraging only the tests that existed in Struts at that time.",0,0,0,0,1,0
1094,"We compared Rivulet to the state-of-the-art static vulnerability detector Julia on benchmarks, finding that Rivulet outperformed Julia in both false positives and false negatives.",0,0,0,1,1,0
1095,We also used Rivulet to detect new vulnerabilities.,0,0,0,0,1,0
1096,"According to the World Health Organization(WHO), it is estimated that approximately 1.3 billion people live with some forms of vision impairment globally, of whom 36 million are blind.",1,0,0,0,0,0
1097,"Due to their disability, engaging these minority into the society is a challenging problem.",1,0,0,0,0,0
1098,The recent rise of smart mobile phones provides a new solution by enabling blind users' convenient access to the information and service for understanding the world.,1,0,0,0,0,0
1099,"Users with vision impairment can adopt the screen reader embedded in the mobile operating systems to read the content of each screen within the app, and use gestures to interact with the phone.",1,0,0,0,0,0
1100,"However, the prerequisite of using screen readers is that developers have to add natural-language labels to the image-based components when they are developing the app.",1,0,0,0,0,0
1101,"Unfortunately, more than 77% apps have issues of missing labels, according to our analysis of 10,408 Android apps.",1,0,0,0,0,0
1102,Most of these issues are caused by developers' lack of awareness and knowledge in considering the minority.,1,0,0,0,0,0
1103,"And even if developers want to add the labels to UI components, they may not come up with concise and clear description as most of them are of no visual issues.",1,0,0,0,0,0
1104,"To overcome these challenges, we develop a deep-learning based model, called LabelDroid, to automatically predict the labels of image-based buttons by learning from large-scale commercial apps in Google Play.",0,1,1,0,0,0
1105,The experimental results show that our model can make accurate predictions and the generated labels are of higher quality than that from real Android developers.,0,0,0,1,1,0
1106,"Screen recordings of mobile applications are easy to obtain and capture a wealth of information pertinent to software developers (e.g., bugs or feature requests), making them a popular mechanism for crowdsourced app feedback.",1,0,0,0,0,0
1107,"Thus, these videos are becoming a common artifact that developers must manage.",1,0,0,0,0,0
1108,"In light of unique mobile development constraints, including swift release cycles and rapidly evolving platforms, automated techniques for analyzing all types of rich software artifacts provide benefit to mobile developers.",1,0,0,0,0,0
1109,"Unfortunately, automatically analyzing screen recordings presents serious challenges, due to their graphical nature, compared to other types of (textual) artifacts.",1,0,0,0,0,0
1110,"To address these challenges, this paper introduces V2S, a lightweight, automated approach for translating video recordings of Android app usages into replayable scenarios.",0,1,1,0,0,0
1111,"V2S is based primarily on computer vision techniques and adapts recent solutions for object detection and image classification to detect and classify user actions captured in a video, and convert these into a replayable test scenario.",0,0,1,0,0,0
1112,"We performed an extensive evaluation of V2S involving 175 videos depicting 3,534 GUI-based actions collected from users exercising features and reproducing bugs from over 80 popular Android apps.",0,0,0,1,0,0
1113,"Our results illustrate that V2S can accurately replay scenarios from screen recordings, and is capable of reproducing ≈89% of our collected videos with minimal overhead.",0,0,0,0,1,0
1114,A case study with three industrial partners illustrates the potential usefulness of V2S from the viewpoint of developers.,0,0,0,0,1,0
1115,"When a program fails to process an input, it need not be the program code that is at fault.",1,0,0,0,0,0
1116,"It can also be that the input data is faulty, for instance as result of data corruption.",1,0,0,0,0,0
1117,"To get the data processed, one then has to debug the input data---that is, (1) identify which parts of the input data prevent processing, and (2) recover as much of the (valuable) input data as possible.",1,0,0,0,0,0
1118,"In this paper, we present a general-purpose algorithm called ddmax that addresses these problems automatically.",0,1,1,0,0,0
1119,"Through experiments, ddmax maximizes the subset of the input that can still be processed by the program, thus recovering and repairing as much data as possible; the difference between the original failing input and the ""maximized"" passing input includes all input fragments that could not be processed.",0,0,1,0,0,0
1120,"To the best of our knowledge, ddmax is the first approach that fixes faults in the input data without requiring program analysis.",0,0,1,0,0,0
1121,"In our evaluation, ddmax repaired about 69% of input files and recovered about 78% of data within one minute per input.",0,0,0,0,1,0
1122,"Cognitive biases are hard-wired behaviors that influence developer actions and can set them on an incorrect course of action, necessitating backtracking.",1,0,0,0,0,0
1123,"While researchers have found that cognitive biases occur in development tasks in controlled lab studies, we still don't know how these biases affect developers' everyday behavior.",1,0,0,0,0,0
1124,"Without such an understanding, development tools and practices remain inadequate.",1,0,0,0,0,0
1125,"To close this gap, we conducted a 2-part field study to examine the extent to which cognitive biases occur, the consequences of these biases on developer behavior, and the practices and tools that developers use to deal with these biases.",0,1,1,1,0,0
1126,About 70% of observed actions that were reversed were associated with at least one cognitive bias.,0,0,0,0,1,0
1127,"Further, even though developers recognized that biases frequently occur, they routinely are forced to deal with such issues with ad hoc processes and sub-optimal tool support.",0,0,0,0,1,0
1128,As one participant (IP12) lamented: There is no salvation!,0,0,0,0,0,1
1129,"Informal technology 'meetups' have become an important aspect of the software development community, engaging many thousands of practitioners on a regular basis.",1,0,0,0,0,0
1130,"However, although local technology meetups are well-attended by developers, little is known about their motivations for participating, the type or usefulness of information that they acquire, and how local meetups might differ from and complement other available communication channels for software engineering information.",1,0,1,0,0,0
1131,"We interviewed the leaders of technology-oriented Meetup groups, and collected quantitative information via a survey distributed to participants in technology-oriented groups.",0,1,0,1,0,0
1132,"Our findings suggest that participants in these groups are primarily experienced software practitioners, who use Meetup for staying abreast of new developments, building local networks and achieving transfer of rich tacit knowledge with peers to improve their practice.",0,0,0,0,1,0
1133,We also suggest that face to face meetings are useful forums for exchanging tacit knowledge and contextual information needed for software engineering practice.,0,0,0,0,0,1
1134,"Smart contracts are Turing-complete programs that execute on the infrastructure of the blockchain, which often manage valuable digital assets.",1,0,0,0,0,0
1135,Solidity is one of the most popular programming languages for writing smart contracts on the Ethereum platform.,1,0,0,0,0,0
1136,"Like traditional programs, smart contracts may contain vulnerabilities.",1,0,0,0,0,0
1137,"Unlike traditional programs, smart contracts cannot be easily patched once they are deployed.",1,0,0,0,0,0
1138,It is thus important that smart contracts are tested thoroughly before deployment.,1,0,0,0,0,0
1139,"In this work, we present an adaptive fuzzer for smart contracts on the Ethereum platform called sFuzz.",0,1,1,0,0,0
1140,"Compared to existing Solidity fuzzers, sFuzz combines the strategy in the AFL fuzzer and an efficient lightweight multi-objective adaptive strategy targeting those hard-to-cover branches.",0,0,1,0,0,0
1141,"sFuzz has been applied to more than 4 thousand smart contracts and the experimental results show that (1) sFuzz is efficient, e.g., two orders of magnitude faster than state-of-the-art tools; (2) sFuzz is effective in achieving high code coverage and discovering vulnerabilities; and (3) the different fuzzing strategies in sFuzz complement each other.",0,0,0,1,1,0
1142,"As deep neural networks are increasingly being deployed in practice, their efficiency has become an important issue.",1,0,0,0,0,0
1143,"While there are compression techniques for reducing the network's size, energy consumption and computational requirement, they only demonstrate empirically that there is no loss of accuracy, but lack formal guarantees of the compressed network, e.g., in the presence of adversarial examples.",1,0,0,0,0,0
1144,"Existing verification techniques such as Reluplex, ReluVal, and DeepPoly provide formal guarantees, but they are designed for analyzing a single network instead of the relationship between two networks.",1,0,0,0,0,0
1145,"To fill the gap, we develop a new method for differential verification of two closely related networks.",0,1,1,0,0,0
1146,Our method consists of a fast but approximate forward interval analysis pass followed by a backward pass that iteratively refines the approximation until the desired property is verified.,0,0,1,0,0,0
1147,We have two main innovations.,0,0,1,0,0,0
1148,"During the forward pass, we exploit structural and behavioral similarities of the two networks to more accurately bound the difference between the output neurons of the two networks.",0,0,1,0,0,0
1149,"Then in the backward pass, we leverage the gradient differences to more accurately compute the most beneficial refinement.",0,0,1,0,0,0
1150,"Our experiments show that, compared to state-of-the-art verification tools, our method can achieve orders-of-magnitude speedup and prove many more properties than existing tools.",0,0,0,1,1,0
1151,Test-based automated program repair has been a prolific field of research in software engineering in the last decade.,1,0,0,0,0,0
1152,"Many approaches have indeed been proposed, which leverage test suites as a weak, but affordable, approximation to program specifications.",1,0,0,0,0,0
1153,"Although the literature regularly sets new records on the number of benchmark bugs that can be fixed, several studies increasingly raise concerns about the limitations and biases of state-of-the-art approaches.",1,0,0,0,0,0
1154,"For example, the correctness of generated patches has been questioned in a number of studies, while other researchers pointed out that evaluation schemes may be misleading with respect to the processing of fault localization results.",1,0,0,0,0,0
1155,"Nevertheless, there is little work addressing the efficiency of patch generation, with regard to the practicality of program repair.",1,0,0,0,0,0
1156,"In this paper, we fill this gap in the literature, by providing an extensive review on the efficiency of test suite based program repair.",0,1,1,1,0,0
1157,"Our objective is to assess the number of generated patch candidates, since this information is correlated to (1) the strategy to traverse the search space efficiently in order to select sensical repair attempts, (2) the strategy to minimize the test effort for identifying a plausible patch, (3) as well as the strategy to prioritize the generation of a correct patch.",0,1,1,0,0,0
1158,"To that end, we perform a large-scale empirical study on the efficiency, in terms of quantity of generated patch candidates of the 16 open-source repair tools for Java programs.",0,0,0,1,0,0
1159,The experiments are carefully conducted under the same fault localization configurations to limit biases.,0,0,0,1,0,0
1160,"Eventually, among other findings, we note that: (1) many irrelevant patch candidates are generated by changing wrong code locations; (2) however, if the search space is carefully triaged, fault localization noise has little impact on patch generation efficiency; (3) yet, current template-based repair systems, which are known to be most effective in fixing a large number of bugs, are actually least efficient as they tend to generate majoritarily irrelevant patch candidates.",0,0,0,0,1,0
1161,Heterogeneous computing with field-programmable gate-arrays (FPGAs) has demonstrated orders of magnitude improvement in computing efficiency for many applications.,1,0,0,0,0,0
1162,"However, the use of such platforms so far is limited to a small subset of programmers with specialized hardware knowledge.",1,0,0,0,0,0
1163,"High-level synthesis (HLS) tools made significant progress in raising the level of programming abstraction from hardware programming languages to C/C++, but they usually cannot compile and generate accelerators for kernel programs with pointers, memory management, and recursion, and require manual refactoring to make them HLS-compatible.",1,0,0,0,0,0
1164,"Besides, experts also need to provide heavily handcrafted optimizations to improve resource efficiency, which affects the maximum operating frequency, parallelization, and power efficiency.",1,0,0,0,0,0
1165,"We propose a new dynamic invariant analysis and automated refactoring technique, called HeteroRefactor.",0,1,1,0,0,0
1166,"First, HeteroRefactor monitors FPGA-specific dynamic invariants---the required bitwidth of integer and floating-point variables, and the size of recursive data structures and stacks.",0,0,1,0,0,0
1167,"Second, using this knowledge of dynamic invariants, it refactors the kernel to make traditionally HLS-incompatible programs synthesizable and to optimize the accelerator's resource usage and frequency further.",0,0,1,0,0,0
1168,"Third, to guarantee correctness, it selectively offloads the computation from CPU to FPGA, only if an input falls within the dynamic invariant.",0,0,1,0,0,0
1169,"On average, for a recursive program of size 175 LOC, an expert FPGA programmer would need to write 185 more LOC to implement an HLS compatible version, while HeteroRefactor automates such transformation.",0,0,0,0,1,0
1170,Our results on Xilinx FPGA show that HeteroRefactor minimizes BRAM by 83% and increases frequency by 42% for recursive programs; reduces BRAM by 41% through integer bitwidth reduction; and reduces DSP by 50% through floating-point precision tuning.,0,0,0,0,1,0
1171,Automated Program Repair (APR) is very useful in helping developers in the process of software development and maintenance.,1,0,0,0,0,0
1172,"Despite recent advances in deep learning (DL), the DL-based APR approaches still have limitations in learning bug-fixing code changes and the context of the surrounding source code of the bug-fixing code changes.",1,0,0,0,0,0
1173,These limitations lead to incorrect fixing locations or fixes.,1,0,0,0,0,0
1174,"In this paper, we introduce DLFix, a two-tier DL model that treats APR as code transformation learning from the prior bug fixes and the surrounding code contexts of the fixes.",0,1,1,0,0,0
1175,The first layer is a tree-based RNN model that learns the contexts of bug fixes and its result is used as an additional weighting input for the second layer designed to learn the bug-fixing code transformations.,0,0,1,0,0,0
1176,"We conducted several experiments to evaluate DLFix in two benchmarks: Defect4j and Bugs.jar, and a newly built bug datasets with a total of +20K real-world bugs in eight projects.",0,0,0,1,0,0
1177,We compared DLFix against a total of 13 state-of-the-art pattern-based APR tools.,0,0,0,1,0,0
1178,"Our results show that DLFix can auto-fix more bugs than 11 of them, and is comparable and complementary to the top two pattern-based APR tools in which there are 7 and 11 unique bugs that they cannot detect, respectively, but we can.",0,0,0,0,1,0
1179,"Importantly, DLFix is fully automated and data-driven, and does not require hard-coding of bug-fixing patterns as in those tools.",0,0,1,0,0,0
1180,We compared DLFix against 4 state-of-the-art deep learning based APR models.,0,0,0,1,0,0
1181,DLFix is able to fix 2.5 times more bugs than the best performing baseline.,0,0,0,0,1,0
1182,Existing GUI testing approaches of Android apps usually test apps from a single entry.,1,0,0,0,0,0
1183,"In this way, the marginal activities far away from the default entry are difficult to be covered.",1,0,0,0,0,0
1184,"The marginal activities may fail to be launched due to requiring a great number of activity transitions or involving complex user operations, leading to uneven coverage on activity components.",1,0,0,0,0,0
1185,"Besides, since the test space of GUI programs is infinite, it is difficult to test activities under complete launching contexts using single-entry testing approaches.",1,0,0,0,0,0
1186,"In this paper, we address these issues by constructing activity launching contexts and proposing a multiple-entry testing framework.",0,1,1,0,0,0
1187,"We perform an inter-procedural, flow-, context- and path-sensitive analysis to build activity launching models and generate complete launching contexts.",0,1,1,0,0,0
1188,"By activity exposing and static analysis, we could launch activities directly under various contexts without performing long event sequence on GUI.",0,0,1,0,0,0
1189,"Besides, to achieve an in-depth exploration, we design an adaptive exploration framework which supports the multiple-entry exploration and dynamically assigns weights to entries in each turn.",0,0,1,0,0,0
1190,"Our approach is implemented in a tool called Fax, with an activity launching strategy Faxla and an exploration strategy Faxex.",0,0,1,0,0,0
1191,"The experiments on 20 real-world apps show that Faxla can cover 96.4% and successfully launch 60.6% activities, based on which Faxex further achieves a relatively 19.7% improvement on method coverage compared with the most popular tool Monkey.",0,0,0,1,1,0
1192,Our tool also behaves well in revealing hidden bugs.,0,0,0,0,1,0
1193,"Fax can trigger over seven hundred unique crashes, including 180 Errors and 539 Warnings, which is significantly higher than those of other tools.",0,0,0,0,1,0
1194,"Among the 46 bugs reported to developers on Github, 33 have been fixed up to now.",0,0,0,0,1,0
1195,Software engineering involves writing new code or editing existing code.,1,0,0,0,0,0
1196,"Recent efforts have investigated the neural processes associated with reading and comprehending code --- however, we lack a thorough understanding of the human cognitive processes underlying code writing.",1,0,0,0,0,0
1197,"While prose reading and writing have been studied thoroughly, that same scrutiny has not been applied to code writing.",1,0,0,0,0,0
1198,"In this paper, we leverage functional brain imaging to investigate neural representations of code writing in comparison to prose writing.",0,1,1,0,0,0
1199,"We present the first human study in which participants wrote code and prose while undergoing a functional magnetic resonance imaging (fMRI) brain scan, making use of a full-sized fMRI-safe QWERTY keyboard.",0,0,0,1,0,0
1200,We find that code writing and prose writing are significantly dissimilar neural tasks.,0,0,0,0,1,0
1201,"While prose writing entails significant left hemisphere activity associated with language, code writing involves more activations of the right hemisphere, including regions associated with attention control, working memory, planning and spatial cognition.",0,0,0,0,1,0
1202,These findings are unlike existing work in which code and prose comprehension were studied.,0,0,0,0,1,0
1203,"By contrast, we present the first evidence suggesting that code and prose writing are quite dissimilar at the neural level.",0,0,0,0,1,0
1204,"Once a programmer knows one language, they can leverage concepts and knowledge already learned, and easily pick up another programming language.",1,0,0,0,0,0
1205,But is that always the case?,1,0,0,0,0,0
1206,"To understand if programmers have difficulty learning additional programming languages, we conductedan empirical study of Stack Overflow questions across 18 different programming languages.",0,1,1,1,0,0
1207,We hypothesized that previous knowledge could potentially interfere with learning a new programming language.,0,0,0,0,1,0
1208,"From our inspection of 450 Stack Overflow questions, we found 276 instances of interference that occurred due to faulty assumptions originating from knowledge about a different language.",0,0,0,0,1,0
1209,"To understand why these difficulties occurred, we conducted semi-structured interviews with 16 professional programmers.",0,0,0,1,0,0
1210,The interviews revealed that programmers make failed attempts to relate a new programming language with what they already know.,0,0,0,0,1,0
1211,"Our findings inform design implications for technical authors, toolsmiths, and language designers, such as designing documentation and automated tools that reduce interference, anticipating uncommon language transitions during language design, and welcoming programmers not just into a language, but its entire ecosystem.",0,0,0,0,0,1
1212,Deep Neural Networks (DNNs) are the core component of modern autonomous driving systems.,1,0,0,0,0,0
1213,"To date, it is still unrealistic that a DNN will generalize correctly to all driving conditions.",1,0,0,0,0,0
1214,Current testing techniques consist of offline solutions that identify adversarial or corner cases for improving the training phase.,1,0,0,0,0,0
1215,"In this paper, we address the problem of estimating the confidence of DNNs in response to unexpected execution contexts with the purpose of predicting potential safety-critical misbehaviours and enabling online healing of DNN-based vehicles.",0,1,1,0,0,0
1216,"Our approach SelfOracle is based on a novel concept of self-assessment oracle, which monitors the DNN confidence at runtime, to predict unsupported driving scenarios in advance.",0,0,1,0,0,0
1217,"SelfOracle uses autoencoder-and time series-based anomaly detection to reconstruct the driving scenarios seen by the car, and to determine the confidence boundary between normal and unsupported conditions.",0,0,1,0,0,0
1218,"In our empirical assessment, we evaluated the effectiveness of different variants of SelfOracle at predicting injected anomalous driving contexts, using DNN models and simulation environment from Udacity.",0,0,0,1,0,0
1219,"Results show that, overall, SelfOracle can predict 77% misbehaviours, up to six seconds in advance, outperforming the online input validation approach of DeepRoad.",0,0,0,0,1,0
1220,The sheer complexity of web applications leaves open a large attack surface of business logic.,1,0,0,0,0,0
1221,"Particularly, in some scenarios, developers have to expose a portion of the logic to the client-side in order to coordinate multiple parties (e.g. merchants, client users, and third-party payment services) involved in a business process.",1,0,0,0,0,0
1222,"However, such client-side code can be tampered with on the fly, leading to business logic perturbations and financial loss.",1,0,0,0,0,0
1223,"Although developers become familiar with concepts that the client should never be trusted, given the size and the complexity of the client-side code that may be even incorporated from third parties, it is extremely challenging to understand and pinpoint the vulnerability.",1,0,0,0,0,0
1224,"To this end, we investigate client-side business flow tampering vulnerabilities and develop a dynamic analysis based approach to automatically identifying such vulnerabilities.",0,1,1,0,0,0
1225,We evaluate our technique on 200 popular real-world websites.,0,0,0,1,0,0
1226,"With negligible overhead, we have successfully identified 27 unique vulnerabilities on 23 websites, such as New York Times, HBO, and YouTube, where an adversary can interrupt business logic to bypass paywalls, disable adblocker detection, earn reward points illicitly, etc.",0,0,0,0,1,0
1227,Online chatting is gaining popularity and plays an increasingly significant role in software development.,1,0,0,0,0,0
1228,"When discussing functionalities, developers might reveal their desired features to other developers.",1,0,0,0,0,0
1229,Automated mining techniques towards retrieving feature requests from massive chat messages can benefit the requirements gathering process.,1,0,0,0,0,0
1230,"But it is quite challenging to perform such techniques because detecting feature requests from dialogues requires a thorough understanding of the contextual information, and it is also extremely expensive on annotating feature-request dialogues for learning.",1,0,0,0,0,0
1231,"To bridge that gap, we recast the traditional text classification task of mapping single dialog to its class into the task of determining whether two dialogues are similar or not by incorporating few-shot learning.",0,1,0,0,0,0
1232,"We propose a novel approach, named FRMiner, which can detect feature-request dialogues from chat messages via deep Siamese network.",0,0,1,0,0,0
1233,We design a BiLSTM-based dialog model that can learn the contextual information of a dialog in both forward and reverse directions.,0,0,1,0,0,0
1234,"Evaluation on the real-world projects shows that our approach achieves average precision, recall and F1-score of 88.52%, 88.50% and 88.51%, which confirms that our approach could effectively detect hidden feature requests from chat messages, thus can facilitate gathering comprehensive requirements from the crowd in an automated way.",0,0,0,1,1,0
1235,Data-driven defect prediction has become increasingly important in software engineering process.,1,0,0,0,0,0
1236,"Since it is not uncommon that data from a software project is insufficient for training a reliable defect prediction model, transfer learning that borrows data/konwledge from other projects to facilitate the model building at the current project, namely cross-project defect prediction (CPDP), is naturally plausible.",1,0,0,0,0,0
1237,"Most CPDP techniques involve two major steps, i.e., transfer learning and classification, each of which has at least one parameter to be tuned to achieve their optimal performance.",1,0,0,0,0,0
1238,This practice fits well with the purpose of automated parameter optimization.,1,0,0,0,0,0
1239,"However, there is a lack of thorough understanding about what are the impacts of automated parameter optimization on various CPDP techniques.",1,0,0,0,0,0
1240,"In this paper, we present the first empirical study that looks into such impacts on 62 CPDP techniques, 13 of which are chosen from the existing CPDP literature while the other 49 ones have not been explored before.",0,1,1,1,0,0
1241,We build defect prediction models over 20 real-world software projects that are of different scales and characteristics.,0,0,1,0,0,0
1242,Our findings demonstrate that: (1) Automated parameter optimization substantially improves the defect prediction performance of 77% CPDP techniques with a manageable computational cost.,0,0,0,0,1,0
1243,Thus more efforts on this aspect are required in future CPDP studies.,0,0,0,0,1,0
1244,(2) Transfer learning is of ultimate importance in CPDP.,0,0,0,0,1,0
1245,"Given a tight computational budget, it is more cost-effective to focus on optimizing the parameter configuration of transfer learning algorithms (3) The research on CPDP is far from mature where it is 'not difficult' to find a better alternative by making a combination of existing transfer learning and classification techniques.",0,0,0,0,1,0
1246,This finding provides important insights about the future design of CPDP techniques.,0,0,0,0,0,1
1247,Existing work on software patches often use features specific to a single task.,1,0,0,0,0,0
1248,"These works often rely on manually identified features, and human effort is required to identify these features for each task.",1,0,0,0,0,0
1249,"In this work, we propose CC2Vec, a neural network model that learns a representation of code changes guided by their accompanying log messages, which represent the semantic intent of the code changes.",0,1,1,0,0,0
1250,CC2Vec models the hierarchical structure of a code change with the help of the attention mechanism and uses multiple comparison functions to identify the differences between the removed and added code.,0,0,1,0,0,0
1251,"To evaluate if CC2Vec can produce a distributed representation of code changes that is general and useful for multiple tasks on software patches, we use the vectors produced by CC2Vec for three tasks: log message generation, bug fixing patch identification, and just-in-time defect prediction.",0,0,0,1,0,0
1252,"In all tasks, the models using CC2Vec outperform the state-of-the-art techniques.",0,0,0,0,1,0
1253,"Over the last few years, there has been substantial research on automated analysis, testing, and debugging of Ethereum smart contracts.",1,0,0,0,0,0
1254,"However, it is not trivial to compare and reproduce that research.",1,0,0,0,0,0
1255,"To address this, we present an empirical evaluation of 9 state-of-the-art automated analysis tools using two new datasets: i) a dataset of 69 annotated vulnerable smart contracts that can be used to evaluate the precision of analysis tools; and ii) a dataset with all the smart contracts in the Ethereum Blockchain that have Solidity source code available on Etherscan (a total of 47,518 contracts).",0,1,1,1,0,0
1256,"The datasets are part of SmartBugs, a new extendable execution framework that we created to facilitate the integration and comparison between multiple analysis tools and the analysis of Ethereum smart contracts.",0,0,0,1,0,0
1257,We used SmartBugs to execute the 9 automated analysis tools on the two datasets.,0,0,0,1,0,0
1258,"In total, we ran 428,337 analyses that took approximately 564 days and 3 hours, being the largest experimental setup to date both in the number of tools and in execution time.",0,0,0,1,1,0
1259,"We found that only 42% of the vulnerabilities from our annotated dataset are detected by all the tools, with the tool Mythril having the higher accuracy (27%).",0,0,0,0,1,0
1260,"When considering the largest dataset, we observed that 97% of contracts are tagged as vulnerable, thus suggesting a considerable number of false positives.",0,0,0,0,1,0
1261,"Indeed, only a small number of vulnerabilities (and of only two categories) were detected simultaneously by four or more tools.",0,0,0,0,1,0
1262,"Over the past decade, deep learning (DL) has been successfully applied to many industrial domain-specific tasks.",1,0,0,0,0,0
1263,"However, the current state-of-the-art DL software still suffers from quality issues, which raises great concern especially in the context of safety- and security-critical scenarios.",1,0,0,0,0,0
1264,"Adversarial examples (AEs) represent a typical and important type of defects needed to be urgently addressed, on which a DL software makes incorrect decisions.",1,0,0,0,0,0
1265,"Such defects occur through either intentional attack or physical-world noise perceived by input sensors, potentially hindering further industry deployment.",1,0,0,0,0,0
1266,The intrinsic uncertainty nature of deep learning decisions can be a fundamental reason for its incorrect behavior.,1,0,0,0,0,0
1267,"Although some testing, adversarial attack and defense techniques have been recently proposed, it still lacks a systematic study to uncover the relationship between AEs and DL uncertainty.",1,0,0,0,0,0
1268,"In this paper, we conduct a large-scale study towards bridging this gap.",0,1,1,0,0,0
1269,"We first investigate the capability of multiple uncertainty metrics in differentiating benign examples (BEs) and AEs, which enables to characterize the uncertainty patterns of input data.",0,0,1,0,0,0
1270,"Then, we identify and categorize the uncertainty patterns of BEs and AEs, and find that while BEs and AEs generated by existing methods do follow common uncertainty patterns, some other uncertainty patterns are largely missed.",0,0,1,0,0,0
1271,"Based on this, we propose an automated testing technique to generate multiple types of uncommon AEs and BEs that are largely missed by existing techniques.",0,0,1,0,0,0
1272,Our further evaluation reveals that the uncommon data generated by our method is hard to be defended by the existing defense techniques with the average defense success rate reduced by 35%.,0,0,0,1,1,0
1273,Our results call for attention and necessity to generate more diverse data for evaluating quality assurance solutions of DL software.,0,0,0,0,0,1
1274,"In Continuous Integration (CI), regression testing is constrained by the time between commits.",1,0,0,0,0,0
1275,This demands for careful selection and/or prioritization of test cases within test suites too large to be run entirely.,1,0,0,0,0,0
1276,"To this aim, some Machine Learning (ML) techniques have been proposed, as an alternative to deterministic approaches.",1,0,0,0,0,0
1277,"Two broad strategies for ML-based prioritization are learning-to-rank and what we call ranking-to-learn (i.e., reinforcement learning).",1,0,0,0,0,0
1278,Various ML algorithms can be applied in each strategy.,1,0,0,0,0,0
1279,"In this paper we introduce ten of such algorithms for adoption in CI practices, and perform a comprehensive study comparing them against each other using subjects from the Apache Commons project.",0,1,1,1,0,0
1280,We analyze the influence of several features of the code under test and of the test process.,0,1,1,0,0,0
1281,The results allow to draw criteria to support testers in selecting and tuning the technique that best fits their context.,0,0,0,0,1,0
1282,Black-box testing has been extensively applied to test models of Cyber-Physical systems (CPS) since these models are not often amenable to static and symbolic testing and verification.,1,0,0,0,0,0
1283,"Black-box testing, however, requires to execute the model under test for a large number of candidate test inputs.",1,0,0,0,0,0
1284,"This poses a challenge for a large and practically-important category of CPS models, known as compute-intensive CPS (CI-CPS) models, where a single simulation may take hours to complete.",1,0,0,0,0,0
1285,"We propose a novel approach, namely ARIsTEO, to enable effective and efficient testing of CI-CPS models.",0,1,1,0,0,0
1286,Our approach embeds black-box testing into an iterative approximation-refinement loop.,0,0,1,0,0,0
1287,"At the start, some sampled inputs and outputs of the CI-CPS model under test are used to generate a surrogate model that is faster to execute and can be subjected to black-box testing.",0,0,1,0,0,0
1288,Any failure-revealing test identified for the surrogate model is checked on the original model.,0,0,1,0,0,0
1289,"If spurious, the test results are used to refine the surrogate model to be tested again.",0,0,1,0,0,0
1290,"Otherwise, the test reveals a valid failure.",0,0,1,0,0,0
1291,"We evaluated ARIsTEO by comparing it with S-Taliro, an open-source and industry-strength tool for testing CPS models.",0,0,0,1,0,0
1292,"Our results, obtained based on five publicly-available CPS models, show that, on average, ARIsTEO is able to find 24% more requirements violations than S-Taliro and is 31% faster than S-Taliro in finding those violations.",0,0,0,0,1,0
1293,We further assessed the effectiveness and efficiency of ARIsTEO on a large industrial case study from the satellite domain.,0,0,0,1,0,0
1294,"In contrast to S-Taliro, ARIsTEO successfully tested two different versions of this model and could identify three requirements violations, requiring four hours, on average, for each violation.",0,0,0,0,1,0
1295,"Although the need for gender-inclusivity in software is gaining attention among SE researchers and SE practitioners, and at least one method (GenderMag) has been published to help, little has been reported on how to make such methods work in real-world settings.",1,0,0,0,0,0
1296,Real-world teams are ever-mindful of the practicalities of adding new methods on top of their existing processes.,1,0,0,0,0,0
1297,"For example, how can they keep the time costs viable?",1,0,0,0,0,0
1298,How can they maximize impacts of using it?,1,0,0,0,0,0
1299,What about controversies that can arise in talking about gender?,1,0,0,0,0,0
1300,"To find out how software teams ""in the trenches"" handle these and similar questions, we collected the GenderMag-based processes of 10 real-world software teams---more than 50 people---for periods ranging from 5 months to 3.5 years.",0,0,0,1,0,0
1301,"We present these teams' insights and experiences in the form of 9 practices, 2 potential pitfalls, and 2 open issues, so as to provide their insights to other real-world software teams trying to engineer gender-inclusivity into their software products.",0,0,0,0,1,0
1302,Formal methods and tools have a long history of successful applications in the design of safety-critical railway products.,1,0,0,0,0,0
1303,"However, most of the experiences focused on the application of a single method at once, and little work has been performed to compare the applicability of the different available frameworks to the railway context.",1,0,0,0,0,0
1304,"As a result, companies willing to introduce formal methods in their development process have little guidance on the selection of tools that could fit their needs.",1,0,0,0,0,0
1305,"To address this goal, this paper presents a comparison between 9 different formal tools, namely Atelier B, CADP, FDR4, NuSMV, ProB, Simulink, SPIN, UMC, and UPPAAL SMC.",0,1,1,0,0,0
1306,"We performed a judgment study, involving 17 experts with experience in formal methods applied to railways.",0,0,0,1,0,0
1307,"In the study, part of the experts were required to model a railway signaling problem (a moving-block train distancing system) with the different tools, and to provide feedback on their experience.",0,0,0,1,0,0
1308,"The information produced was then synthesized, and the results were validated by the remaining experts.",0,0,0,1,0,0
1309,"Based on the outcome of this process, we provide a synthesis that describes when to use a certain tool, and what are the problems that may be faced by modelers.",0,0,0,0,1,0
1310,"Our experience shows that the different tools serve different purposes, and multiple formal methods are required to fully cover the needs of the railway system design process.",0,0,0,0,1,1
1311,"Developers experience a wide range of emotions during programming tasks, which may have an impact on job performance.",1,0,0,0,0,0
1312,"In this paper, we present an empirical study aimed at (i) investigating the link between emotion and progress, (ii) understanding the triggers for developers' emotions and the strategies to deal with negative ones, (iii) identifying the minimal set of non-invasive biometric sensors for emotion recognition during programming tasks.",0,1,1,1,0,0
1313,Results confirm previous findings about the relation between emotions and perceived productivity.,0,0,0,0,1,0
1314,"Furthermore, we show that developers' emotions can be reliably recognized using only a wristband capturing the electrodermal activity and heart-related metrics.",0,0,0,0,1,0
1315,Understanding the root cause of a defect is critical to isolating and repairing buggy behavior.,1,0,0,0,0,0
1316,"We present Causal Testing, a new method of root-cause analysis that relies on the theory of counterfactual causality to identify a set of executions that likely hold key causal information necessary to understand and repair buggy behavior.",0,1,1,0,0,0
1317,"Using the Defects4J benchmark, we find that Causal Testing could be applied to 71% of real-world defects, and for 77% of those, it can help developers identify the root cause of the defect.",0,0,0,1,1,0
1318,A controlled experiment with 37 developers shows that Causal Testing improves participants' ability to identify the cause of the defect from 80% of the time with standard testing tools to 86% of the time with Causal Testing.,0,0,0,1,1,0
1319,The participants report that Causal Testing provides useful information they cannot get using tools such as JUnit.,0,0,0,0,1,0
1320,"Holmes, our prototype, open-source Eclipse plugin implementation of Causal Testing, is available at http://holmes.cs.umass.edu/.",0,0,0,0,0,1
1321,Deep learning (DL) applications are becoming increasingly popular.,1,0,0,0,0,0
1322,Their reliabilities largely depend on the performance of DL models integrated in these applications as a central classifying module.,1,0,0,0,0,0
1323,Traditional techniques need to retrain the models or rebuild and redeploy the applications for coping with unexpected conditions beyond the models' handling capabilities.,1,0,0,0,0,0
1324,"In this paper, we take a fault tolerance approach, Dissector, to distinguishing those inputs that represent unexpected conditions (beyond-inputs) from normal inputs that are still within the models' handling capabilities (within-inputs), thus keeping the applications still function with expected reliabilities.",0,1,1,1,0,0
1325,"The key insight of Dissector is that a DL model should interpret a within-input with increasing confidence, while a beyond-input would probably cause confused guesses in the prediction process.",0,0,1,0,0,0
1326,"Dissector works in an application-specific way, adaptive to DL models used in applications, and extremely efficiently, scalable to large-size datasets from complex scenarios.",0,0,1,0,0,0
1327,The experimental evaluation shows that Dissector outperformed state-of-the-art techniques in the effectiveness (AUC: avg. 0.8935 and up to 0.9894) and efficiency (runtime overhead: only 3.3--5.8 milliseconds).,0,0,0,1,1,0
1328,"Besides, it also exhibited encouraging usefulness in defensing against adversarial inputs (AUC: avg. 0.9983) and improving a DL model's actual accuracy in use (up to 16% for CIFAR-100 and 20% for ImageNet).",0,0,0,0,1,0
1329,"Finding bugs in commercial cyber-physical system development tools (or ""model-based design"" tools) such as MathWorks's Simulink is important in practice, as these tools are widely used to generate embedded code that gets deployed in safety-critical applications such as cars and planes.",1,0,0,0,0,0
1330,Equivalence Modulo Input (EMI) based mutation is a new twist on differential testing that promises lower use of computational resources and has already been successful at finding bugs in compilers for procedural languages.,1,0,0,0,0,0
1331,"To provide EMI-based mutation for differential testing of cyber-physical system (CPS) development tools, this paper develops several novel mutation techniques.",0,1,1,0,0,0
1332,"These techniques deal with CPS language features that are not found in procedural languages, such as an explicit notion of execution time and zombie code, which combines properties of live and dead procedural code.",0,0,1,0,0,0
1333,In our experiments the most closely related work (SLforge) found two bugs in the Simulink tool.,0,0,0,1,1,0
1334,"In comparison, SLEMI found a super-set of issues, including 9 confirmed as bugs by MathWorks Support.",0,0,0,0,1,0
1335,"Android apps demand high-quality test inputs, whose generation remains an open challenge.",1,0,0,0,0,0
1336,"Existing techniques fall short on exploring complex app functionalities reachable only by a long, meaningful, and effective test input.",1,0,0,0,0,0
1337,"Observing that such test inputs can usually be decomposed into relatively independent short use cases, this paper presents ComboDroid, a fundamentally different Android app testing framework.",0,1,1,0,0,0
1338,"ComboDroid obtains use cases for manifesting a specific app functionality (either manually provided or automatically extracted), and systematically enumerates the combinations of use cases, yielding high-quality test inputs.",0,0,1,0,0,0
1339,The evaluation results of ComboDroid on real-world apps are encouraging.,0,0,0,0,1,0
1340,"Our fully automatic variant outperformed the best existing technique APE by covering 4.6% more code (APE only outperformed Monkey by 2.1%), and revealed four previously unknown bugs in extensively tested subjects.",0,0,0,0,1,0
1341,"Our semi-automatic variant boosts the manual use cases obtained with little manual labor, achieving a comparable coverage (only 3.2% less) with a white-box human testing expert.",0,0,0,0,1,0
1342,Puppet is a popular computer system configuration management tool.,1,0,0,0,0,0
1343,"By providing abstractions that model system resources it allows administrators to set up computer systems in a reliable, predictable, and documented fashion.",1,0,0,0,0,0
1344,Its use suffers from two potential pitfalls.,1,0,0,0,0,0
1345,"First, if ordering constraints are not correctly specified whenever a Puppet resource depends on another, the non-deterministic application of resources can lead to race conditions and consequent failures.",1,0,0,0,0,0
1346,"Second, if a service is not tied to its resources (through the notification construct), the system may operate in a stale state whenever a resource gets modified.",1,0,0,0,0,0
1347,Such faults can degrade a computing infrastructure's availability and functionality.,1,0,0,0,0,0
1348,We have developed an approach that identifies these issues through the analysis of a Puppet program and its system call trace.,0,1,1,0,0,0
1349,"Specifically, a formal model for traces allows us to capture the interactions of Puppet resources with the file system.",0,1,1,0,0,0
1350,"By analyzing these interactions we identify (1) resources that are related to each other (e.g., operate on the same file), and (2) resources that should act as notifiers so that changes are correctly propagated.",0,0,1,0,0,0
1351,We then check the relationships from the trace's analysis against the program's dependency graph: a representation containing all the ordering constraints and notifications declared in the program.,0,0,1,0,0,0
1352,"If a mismatch is detected, our system reports a potential fault.",0,0,1,0,0,0
1353,"We have evaluated our method on a large set of popular Puppet modules, and discovered 92 previously unknown issues in 33 modules.",0,0,0,1,0,0
1354,Performance benchmarking shows that our approach can analyze in seconds real-world configurations with a magnitude measured in thousands of lines and millions of system calls.,0,0,0,0,1,0
1355,A wide range of tools exist to assist developers in creating secure software.,1,0,0,0,0,0
1356,"Many of these tools, such as static analysis engines or security checkers included in compilers, use warnings to communicate security issues to developers.",1,0,0,0,0,0
1357,"The effectiveness of these tools relies on developers heeding these warnings, and there are many ways in which these warnings could be displayed.",1,0,0,0,0,0
1358,Johnson et al. [46] conducted qualitative research and found that warning presentation and integration are main issues.,1,0,0,0,0,0
1359,"We built on Johnson et al.'s work and examined what developers want from security warnings, including what form they should take and how they should integrate into their workflow and work context.",0,1,1,0,0,0
1360,"To this end, we conducted a Grounded Theory study with 14 professional software developers and 12 computer science students as well as a focus group with 7 academic researchers to gather qualitative insights.",0,0,0,1,0,0
1361,"To back up the theory developed from the qualitative research, we ran a quantitative survey with 50 professional software developers.",0,0,0,1,0,0
1362,Our results show that there is significant heterogeneity amongst developers and that no one warning type is preferred over all others.,0,0,0,0,1,0
1363,"The context in which the warnings are shown is also highly relevant, indicating that it is likely to be beneficial if IDEs and other development tools become more flexible in their warning interactions with developers.",0,0,0,0,1,0
1364,"Based on our findings, we provide concrete recommendations for both future research as well as how IDEs and other security tools can improve their interaction with developers.",0,0,0,0,0,1
1365,Software defect prediction aims to automatically locate defective code modules to better focus testing resources and human effort.,1,0,0,0,0,0
1366,"Typically, software defect prediction pipelines are comprised of two parts: the first extracts program features, like abstract syntax trees, by using external tools, and the second applies machine learning-based classification models to those features in order to predict defective modules.",1,0,0,0,0,0
1367,"Since such approaches depend on specific feature extraction tools, machine learning classifiers have to be custom-tailored to effectively build most accurate models.",1,0,0,0,0,0
1368,"To bridge the gap between deep learning and defect prediction, we propose an end-to-end framework which can directly get prediction results for programs without utilizing feature-extraction tools.",0,1,1,0,0,0
1369,"To that end, we first visualize programs as images, apply the self-attention mechanism to extract image features, use transfer learning to reduce the difference in sample distributions between projects, and finally feed the image files into a pre-trained, deep learning model for defect prediction.",0,0,1,0,0,0
1370,Experiments with 10 open source projects from the PROMISE dataset show that our method can improve cross-project and within-project defect prediction.,0,0,0,1,0,0
1371,Our code and data pointers are available at https://zenodo.org/record/3373409#.XV0Oy5Mza35.,0,0,0,0,0,1
1372,Modern JavaScript applications extensively depend on third-party libraries.,1,0,0,0,0,0
1373,"Especially for the Node.js platform, vulnerabilities can have severe consequences to the security of applications, resulting in, e.g., cross-site scripting and command injection attacks.",1,0,0,0,0,0
1374,"Existing static analysis tools that have been developed to automatically detect such issues are either too coarse-grained, looking only at package dependency structure while ignoring dataflow, or rely on manually written taint specifications for the most popular libraries to ensure analysis scalability.",1,0,0,0,0,0
1375,"In this work, we propose a technique for automatically extracting taint specifications for JavaScript libraries, based on a dynamic analysis that leverages the existing test suites of the libraries and their available clients in the npm repository.",0,1,1,0,0,0
1376,"Due to the dynamic nature of JavaScript, mapping observations from dynamic analysis to taint specifications that fit into a static analysis is non-trivial.",1,0,0,0,0,0
1377,"Our main insight is that this challenge can be addressed by a combination of an access path mechanism that identifies entry and exit points, and the use of membranes around the libraries of interest.",0,0,1,0,0,0
1378,We show that our approach is effective at inferring useful taint specifications at scale.,0,0,1,0,0,0
1379,Our prototype tool automatically extracts 146 additional taint sinks and 7840 propagation summaries spanning 1 393 npm modules.,0,0,0,1,1,0
1380,"By integrating the extracted specifications into a commercial, state-of-the-art static analysis, 136 new alerts are produced, many of which correspond to likely security vulnerabilities.",0,0,0,0,1,0
1381,"Moreover, many important specifications that were originally manually written are among the ones that our tool can now extract automatically.",0,0,0,0,1,0
1382,Deep Learning (DL) systems are key enablers for engineering intelligent applications due to their ability to solve complex tasks such as image recognition and machine translation.,1,0,0,0,0,0
1383,"Nevertheless, using DL systems in safety- and security-critical applications requires to provide testing evidence for their dependable operation.",1,0,0,0,0,0
1384,Recent research in this direction focuses on adapting testing criteria from traditional software engineering as a means of increasing confidence for their correct behaviour.,1,0,0,0,0,0
1385,"However, they are inadequate in capturing the intrinsic properties exhibited by these systems.",1,0,0,0,0,0
1386,"We bridge this gap by introducing DeepImportance, a systematic testing methodology accompanied by an Importance-Driven (IDC) test adequacy criterion for DL systems.",0,1,1,0,0,0
1387,Applying IDC enables to establish a layer-wise functional understanding of the importance of DL system components and use this information to assess the semantic diversity of a test set.,0,0,1,0,0,0
1388,"Our empirical evaluation on several DL systems, across multiple DL datasets and with state-of-the-art adversarial generation techniques demonstrates the usefulness and effectiveness of DeepImportance and its ability to support the engineering of more robust DL systems.",0,0,0,1,1,0
1389,"Failure to account for human values in software (e.g., equality and fairness) can result in user dissatisfaction and negative socio-economic impact.",1,0,0,0,0,0
1390,"Engineering these values in software, however, requires technical and methodological support throughout the development life cycle.",1,0,0,0,0,0
1391,This paper investigates to what extent top Software Engineering (SE) conferences and journals have included research on human values in SE.,0,1,1,0,0,0
1392,We investigate the prevalence of human values in recent (2015 -- 2018) publications in these top venues.,0,0,1,0,0,0
1393,"We classify these publications, based on their relevance to different values, against a widely used value structure adopted from the social sciences.",0,0,0,1,0,0
1394,"Our results show that: (a) only a small proportion of the publications directly consider values, classified as directly relevant publications; (b) for the majority of the values, very few or no directly relevant publications were found; and (c) the prevalence of directly relevant publications was higher in SE conferences compared to SE journals.",0,0,0,0,1,0
1395,This paper shares these and other insights that may motivate future research on human values in software engineering.,0,0,0,0,0,1
1396,"Research has established the wide variety of security failures in mobile apps, their consequences, and how app developers introduce or exacerbate them.",1,0,0,0,0,0
1397,What is not well known is why developers do so---what is the rationale underpinning the decisions they make which eventually strengthen or weaken app security?,1,0,0,0,0,0
1398,"This is all the more complicated in modern app development's increasingly diverse demographic: growing numbers of independent, solo, or small team developers who do not have the organizational structures and support that larger software development houses enjoy.",1,0,0,0,0,0
1399,"Through two studies, we open the box on developer rationale, by performing a holistic analysis of the rationale underpinning various activities in which app developers engage when developing an app.",0,1,1,0,0,0
1400,"The first study does so through a task-based study with app developers (N=44) incorporating six distinct tasks for which this developer demographic must take responsibility: setting up a development environment, reviewing code, seeking help, seeking testers, selecting an advertisement SDK, and software licensing.",0,0,0,1,0,0
1401,"We found that, while on first glance in several activities participants seemed to prioritize security, only in the code task such prioritization was underpinned by a security rationale-indicating that development behavior perceived to be secure may only be an illusion until the box is opened on their rationale.",0,0,0,0,1,0
1402,The second study confirms these findings through a wider survey of app developers (N=274) investigating to what extent they find the activities of the task-based study to affect their app's security.,0,0,0,1,0,0
1403,"In line with the task-based study, we found that developers perceived actively writing code and actively using external SDKs as the only security-relevant, while similarly disregarding other activities having an impact on app security.",0,0,0,0,1,0
1404,Our results suggest the need for a stronger focus on the tasks and activities surrounding the coding task - all of which need to be underpinned by a security rationale.,0,0,0,0,1,0
1405,"Without such a holistic focus, developers may write ""secure code"" but not produce ""secure apps"".",0,0,0,0,0,1
1406,Uncontrolled memory consumption is a kind of critical software security weaknesses.,1,0,0,0,0,0
1407,It can also become a security-critical vulnerability when attackers can take control of the input to consume a large amount of memory and launch a Denial-of-Service attack.,1,0,0,0,0,0
1408,"However, detecting such vulnerability is challenging, as the state-of-the-art fuzzing techniques focus on the code coverage but not memory consumption.",1,0,0,0,0,0
1409,"To this end, we propose a memory usage guided fuzzing technique, named MemLock, to generate the excessive memory consumption inputs and trigger uncontrolled memory consumption bugs.",0,1,1,0,0,0
1410,The fuzzing process is guided with memory consumption information so that our approach is general and does not require any domain knowledge.,0,0,1,0,0,0
1411,We perform a thorough evaluation for MemLock on 14 widely-used real-world programs.,0,0,0,1,0,0
1412,"Our experiment results show that MemLock substantially outperforms the state-of-the-art fuzzing techniques, including AFL, AFLfast, PerfFuzz, FairFuzz, Angora and QSYM, in discovering memory consumption bugs.",0,0,0,0,1,0
1413,"During the experiments, we discovered many previously unknown memory consumption bugs and received 15 new CVEs.",0,0,0,0,1,0
1414,"Self-driving cars, or Autonomous Vehicles (AVs), are increasingly becoming an integral part of our daily life.",1,0,0,0,0,0
1415,"About 50 corporations are actively working on AVs, including large companies such as Google, Ford, and Intel.",1,0,0,0,0,0
1416,"Some AVs are already operating on public roads, with at least one unfortunate fatality recently on record.",1,0,0,0,0,0
1417,"As a result, understanding bugs in AVs is critical for ensuring their security, safety, robustness, and correctness.",1,0,0,0,0,0
1418,"While previous studies have focused on a variety of domains (e.g., numerical software; machine learning; and error-handling, concurrency, and performance bugs) to investigate bug characteristics, AVs have not been studied in a similar manner.",1,0,0,0,0,0
1419,"Recently, two software systems for AVs, Baidu Apollo and Autoware, have emerged as frontrunners in the open-source community and have been used by large companies and governments (e.g., Lincoln, Volvo, Ford, Intel, Hitachi, LG, and the US Department of Transportation).",1,0,0,0,0,0
1420,"From these two leading AV software systems, this paper describes our investigation of 16,851 commits and 499 AV bugs and introduces our classification of those bugs into 13 root causes, 20 bug symptoms, and 18 categories of software components those bugs often affect.",0,1,1,0,0,0
1421,"We identify 16 major findings from our study and draw broader lessons from them to guide the research community towards future directions in software bug detection, localization, and repair.",0,0,0,0,1,1
1422,Android testing tools generate sequences of input events to exercise the state space of the app-under-test.,1,0,0,0,0,0
1423,Existing search-based techniques systematically evolve a population of event sequences so as to achieve certain objectives such as maximal code coverage.,1,0,0,0,0,0
1424,The hope is that the mutation of fit event sequences leads to the generation of even fitter sequences.,1,0,0,0,0,0
1425,"However, the evolution of event sequences may be ineffective.",1,0,0,0,0,0
1426,Our key insight is that pertinent app states which contributed to the original sequence's fitness may not be reached by a mutated event sequence.,1,0,0,0,0,0
1427,The original path through the state space is truncated at the point of mutation.,1,0,0,0,0,0
1428,"In this paper, we propose instead to evolve a population of states which can be captured upon discovery and resumed when needed.",0,1,1,0,0,0
1429,The hope is that generating events on a fit program state leads to the transition to even fitter states.,1,0,0,0,0,0
1430,"For instance, we can quickly deprioritize testing the main screen state which is visited by most event sequences, and instead focus our limited resources on testing more interesting states that are otherwise difficult to reach.",0,0,1,0,0,0
1431,We call our approach time-travel testing because of this ability to travel back to any state that has been observed in the past.,0,0,1,0,0,0
1432,"We implemented time-travel testing into TimeMachine, a time-travel enabled version of the successful, automated Android testing tool Monkey.",0,0,1,0,0,0
1433,"In our experiments on a large number of open- and closed source Android apps, TimeMachine outperforms the state-of-the-art search-based/model-based Android testing tools Sapienz and Stoat, both in terms of coverage achieved and crashes found.",0,0,0,0,1,0
1434,Just-In-Time Software Defect Prediction (JIT-SDP) is concerned with predicting whether software changes are defect-inducing or clean based on machine learning classifiers.,1,0,0,0,0,0
1435,Building such classifiers requires a sufficient amount of training data that is not available at the beginning of a software project.,1,0,0,0,0,0
1436,"Cross-Project (CP) JIT-SDP can overcome this issue by using data from other projects to build the classifier, achieving similar (not better) predictive performance to classifiers trained on Within-Project (WP) data.",1,0,0,0,0,0
1437,"However, such approaches have never been investigated in realistic online learning scenarios, where WP software changes arrive continuously over time and can be used to update the classifiers.",1,0,0,0,0,0
1438,It is unknown to what extent CP data can be helpful in such situation.,1,0,0,0,0,0
1439,"In particular, it is unknown whether CP data are only useful during the very initial phase of the project when there is little WP data, or whether they could be helpful for extended periods of time.",1,0,0,0,0,0
1440,This work thus provides the first investigation of when and to what extent CP data are useful for JIT-SDP in a realistic online learning scenario.,0,1,1,0,0,0
1441,"For that, we develop three different CP JIT-SDP approaches that can operate in online mode and be updated with both incoming CP and WP training examples over time.",0,0,1,0,0,0
1442,"We also collect 2048 commits from three software repositories being developed by a software company over the course of 9 to 10 months, and use 19,8468 commits from 10 active open source GitHub projects being developed over the course of 6 to 14 years.",0,0,0,1,0,0
1443,The study shows that training classifiers with incoming CP+WP data can lead to improvements in G-mean of up to 53.90% compared to classifiers using only WP data at the initial stage of the projects.,0,0,0,0,1,0
1444,"For the open source projects, which have been running for longer periods of time, using CP data to supplement WP data also helped the classifiers to reduce or prevent large drops in predictive performance that may occur over time, leading to up to around 40% better G-Mean during such periods.",0,0,0,0,1,0
1445,"Such use of CP data was shown to be beneficial even after a large number of WP data were received, leading to overall G-means up to 18.5% better than those of WP classifiers.",0,0,0,0,1,0
1446,"In theory, (good) documentation is an invaluable asset to any software project, as it helps stakeholders to use, understand, maintain, and evolve a system.",1,0,0,0,0,0
1447,"In practice, however, documentation is generally affected by numerous shortcomings and issues, such as insufficient and inadequate content and obsolete, ambiguous information.",1,0,0,0,0,0
1448,"To counter this, researchers are investigating the development of advanced recommender systems that automatically suggest high-quality documentation, useful for a given task.",1,0,0,0,0,0
1449,A crucial first step is to understand what quality means for practitioners and what information is actually needed for specific tasks.,1,0,0,0,0,0
1450,We present two surveys performed with 146 practitioners to investigate (i) the documentation issues they perceive as more relevant together with solutions they apply when these issues arise; and (ii) the types of documentation considered as important in different tasks.,0,1,1,1,0,0
1451,Our findings can help researchers in designing the next generation of documentation recommender systems.,0,0,0,0,0,1
1452,"With the growing use of DevOps tools and frameworks, there is an increased need for tools and techniques that support more than code.",1,0,0,0,0,0
1453,The current state-of-the-art in static developer assistance for tools like Docker is limited to shallow syntactic validation.,1,0,0,0,0,0
1454,"We identify three core challenges in the realm of learning from, understanding, and supporting developers writing DevOps artifacts: (i) nested languages in DevOps artifacts, (ii) rule mining, and (iii) the lack of semantic rule-based analysis.",0,1,0,0,0,0
1455,"To address these challenges we introduce a toolset, binnacle, that enabled us to ingest 900,000 GitHub repositories.",0,1,0,0,0,0
1456,"Focusing on Docker, we extracted approximately 178,000 unique Dockerfiles, and also identified a Gold Set of Dockerfiles written by Docker experts.",0,1,0,0,0,0
1457,We addressed challenge (i) by reducing the number of effectively uninterpretable nodes in our ASTs by over 80% via a technique we call phased parsing.,0,0,1,0,0,0
1458,"To address challenge (ii), we introduced a novel rule-mining technique capable of recovering two-thirds of the rules in a benchmark we curated.",0,0,1,0,0,0
1459,"Through this automated mining, we were able to recover 16 new rules that were not found during manual rule collection.",0,0,0,0,1,0
1460,"To address challenge (iii), we manually collected a set of rules for Dockerfiles from commits to the files in the Gold Set.",0,1,0,0,0,0
1461,"These rules encapsulate best practices, avoid docker build failures, and improve image size and build latency.",0,1,0,0,0,0
1462,"We created an analyzer that used these rules, and found that, on average, Dockerfiles on GitHub violated the rules five times more frequently than the Dockerfiles in our Gold Set.",0,0,0,0,1,0
1463,We also found that industrial Dockerfiles fared no better than those sourced from GitHub.,0,0,0,0,1,0
1464,"The learned rules and analyzer in binnacle can be used to aid developers in the IDE when creating Dockerfiles, and in a post-hoc fashion to identify issues in, and to improve, existing Dockerfiles.",0,0,0,0,0,1
1465,"Successful cross-language clone detection could enable researchers and developers to create robust language migration tools, facilitate learning additional programming languages once one is mastered, and promote reuse of code snippets over a broader codebase.",1,0,0,0,0,0
1466,"However, identifying cross-language clones presents special challenges to the clone detection problem.",1,0,0,0,0,0
1467,"A lack of common underlying representation between arbitrary languages means detecting clones requires one of the following solutions: 1) a static analysis framework replicated across each targeted language with annotations matching language features across all languages, or 2) a dynamic analysis framework that detects clones based on runtime behavior.",1,0,0,0,0,0
1468,"In this work, we demonstrate the feasibility of the latter solution, a dynamic analysis approach called SLACC for cross-language clone detection.",0,1,1,0,0,0
1469,"Like prior clone detection techniques, we use input/output behavior to match clones, though we overcome limitations of prior work by amplifying the number of inputs and covering more data types; and as a result, achieve better clusters than prior attempts.",0,0,1,0,0,0
1470,"Since clusters are generated based on input/output behavior, SLACC supports cross-language clone detection.",0,0,1,0,0,0
1471,"As an added challenge, we target a static typed language, Java, and a dynamic typed language, Python.",0,0,1,0,0,0
1472,"Compared to HitoshiIO, a recent clone detection tool for Java, SLACC retrieves 6 times as many clusters and has higher precision (86.7% vs. 30.7%).",0,0,0,0,1,0
1473,This is the first work to perform clone detection for dynamic typed languages (precision = 87.3%) and the first to perform clone detection across languages that lack a common underlying representation (precision = 94.1%).,0,0,0,0,1,0
1474,It provides a first step towards the larger goal of scalable language migration tools.,0,0,0,0,0,1
1475,Software logging is widely used in practice.,1,0,0,0,0,0
1476,"Logs have been used for a variety of purposes like debugging, monitoring, security compliance, and business analytics.",1,0,0,0,0,0
1477,"Instead of directly invoking the standard output functions, developers usually prefer to use logging utilities (LUs) (e.g., SLF4J), which provide additional functionalities like thread-safety and verbosity level support, to instrument their source code.",1,0,0,0,0,0
1478,Many of the previous research works on software logging are focused on the log printing code.,1,0,0,0,0,0
1479,"There are very few works studying the use of LUs, although new LUs are constantly being introduced by companies and researchers.",1,0,0,0,0,0
1480,"In this paper, we conducted a large-scale empirical study on the use of Java LUs in the wild.",0,1,1,1,0,0
1481,"We analyzed the use of 3, 856 LUs from 11,194 projects in GitHub and found that many projects have complex usage patterns for LUs.",0,0,0,1,1,0
1482,"For example, 75.8% of the large-sized projects have implemented their own LUs in their projects.",0,0,0,0,1,0
1483,More than 50% of these projects use at least three LUs.,0,0,0,0,1,0
1484,We conducted further qualitative studies to better understand and characterize the complex use of LUs.,0,0,0,1,0,0
1485,"Our findings show that different LUs are used for a variety of reasons (e.g., internationalization of the log messages).",0,0,0,0,1,0
1486,"Some projects develop their own LUs to satisfy project-specific logging needs (e.g., defining the logging format).",0,0,0,0,1,0
1487,Multiple uses of LUs in one project are pretty common for large and very largesized projects mainly for context like enabling and configuring the logging behavior for the imported packages.,0,0,0,0,1,0
1488,Interviewing with 13 industrial developers showed that our findings are also generally true for industrial projects and are considered as very helpful for them to better configure and manage the logging behavior for their projects.,0,0,0,1,1,0
1489,The findings and the implications presented in this paper will be useful for developers and researchers who are interested in developing and maintaining LUs.,0,0,0,0,0,1
1490,"Defects in infrastructure as code (IaC) scripts can have serious consequences, for example, creating large-scale system outages.",1,0,0,0,0,0
1491,"A taxonomy of IaC defects can be useful for understanding the nature of defects, and identifying activities needed to fix and prevent defects in IaC scripts.",1,0,0,0,0,0
1492,The goal of this paper is to help practitioners improve the quality of infrastructure as code (IaC) scripts by developing a defect taxonomy for IaC scripts through qualitative analysis.,0,1,1,0,0,0
1493,"We develop a taxonomy of IaC defects by applying qualitative analysis on 1,448 defect-related commits collected from open source software (OSS) repositories of the Openstack organization.",0,0,1,0,0,0
1494,We conduct a survey with 66 practitioners to assess if they agree with the identified defect categories included in our taxonomy.,0,0,0,1,0,0
1495,"We quantify the frequency of identified defect categories by analyzing 80,425 commits collected from 291 OSS repositories spanning across 2005 to 2019.",0,0,0,1,0,0
1496,"Our defect taxonomy for IaC consists of eight categories, including a category specific to IaC called idempotency (i.e., defects that lead to incorrect system provisioning when the same IaC script is executed multiple times).",0,0,0,1,0,0
1497,We observe the surveyed 66 practitioners to agree most with idempotency.,0,0,0,1,0,0
1498,"The most frequent defect category is configuration data i.e., providing erroneous configuration data in IaC scripts.",0,0,0,0,1,0
1499,Our taxonomy and the quantified frequency of the defect categories may help in advancing the science of IaC script quality.,0,0,0,0,0,1
1500,"The notion of forking has changed with the rise of distributed version control systems and social coding environments, like GitHub.",1,0,0,0,0,0
1501,"Traditionally forking refers to splitting off an independent development branch (which we call hard forks); research on hard forks, conducted mostly in pre-GitHub days showed that hard forks were often seen critical as they may fragment a community Today, in social coding environments, open-source developers are encouraged to fork a project in order to contribute to the community (which we call social forks), which may have also influenced perceptions and practices around hard forks.",1,0,0,0,0,0
1502,"To revisit hard forks, we identify, study, and classify 15,306 hard forks on GitHub and interview 18 owners of hard forks or forked repositories.",0,1,1,1,0,0
1503,"We find that, among others, hard forks often evolve out of social forks rather than being planned deliberately and that perception about hard forks have indeed changed dramatically, seeing them often as a positive noncompetitive alternative to the original project.",0,0,0,0,1,0
1504,"Rust, an emerging programming language with explosive growth, provides a robust type system that enables programmers to write memory-safe and data-race free code.",1,0,0,0,0,0
1505,"To allow access to a machine's hardware and to support low-level performance optimizations, a second language, Unsafe Rust, is embedded in Rust.",1,0,0,0,0,0
1506,"It contains support for operations that are difficult to statically check, such as C-style pointers for access to arbitrary memory locations and mutable global variables.",1,0,0,0,0,0
1507,"When a program uses these features, the compiler is unable to statically guarantee the safety properties Rust promotes.",1,0,0,0,0,0
1508,"In this work, we perform a large-scale empirical study to explore how software developers are using Unsafe Rust in real-world Rust libraries and applications.",0,1,1,1,0,0
1509,"Our results indicate that software engineers use the keyword unsafe in less than 30% of Rust libraries, but more than half cannot be entirely statically checked by the Rust compiler because of Unsafe Rust hidden somewhere in a library's call chain.",0,0,0,0,1,0
1510,"We conclude that although the use of the keyword unsafe is limited, the propagation of unsafeness offers a challenge to the claim of Rust as a memory-safe language.",0,0,0,0,0,1
1511,"Furthermore, we recommend changes to the Rust compiler and to the central Rust repository's interface to help Rust software developers be aware of when their Rust code is unsafe.",0,0,0,0,0,1
1512,"During code review, developers critically examine each others' code to improve its quality, share knowledge, and ensure conformance to coding standards.",1,0,0,0,0,0
1513,"In the process, developers may have negative interpersonal interactions with their peers, which can lead to frustration and stress; these negative interactions may ultimately result in developers abandoning projects.",1,0,0,0,0,0
1514,"In this mixed-methods study at one company, we surveyed 1,317 developers to characterize the negative experiences and cross-referenced the results with objective data from code review logs to predict these experiences.",0,0,1,1,0,0
1515,"Our results suggest that such negative experiences, which we call ""pushback"", are relatively rare in practice, but have negative repercussions when they occur.",0,0,0,0,1,0
1516,"Our metrics can predict feelings of pushback with high recall but low precision, making them potentially appropriate for highlighting interactions that may benefit from a self-intervention.",0,0,0,0,1,0
1517,"Automated web testing techniques infer models from a given web app, which are used for test generation.",1,0,0,0,0,0
1518,"From a testing viewpoint, such an inferred model should contain the minimal set of states that are distinct, yet, adequately cover the app's main functionalities.",1,0,0,0,0,0
1519,"In practice, models inferred automatically are affected by near-duplicates, i.e., replicas of the same functional webpage differing only by small insignificant changes.",1,0,0,0,0,0
1520,We present the first study of near-duplicate detection algorithms used in within app model inference.,0,1,1,0,0,0
1521,"We first characterize functional near-duplicates by classifying a random sample of state-pairs, from 493k pairs of webpages obtained from over 6,000 websites, into three categories, namely clone, near-duplicate, and distinct.",0,0,1,0,0,0
1522,We systematically compute thresholds that define the boundaries of these categories for each detection technique.,0,0,0,1,0,0
1523,"We then use these thresholds to evaluate 10 near-duplicate detection techniques from three different domains, namely, information retrieval, web testing, and computer vision on nine open-source web apps.",0,0,0,1,0,0
1524,Our study highlights the challenges posed in automatically inferring a model for any given web app.,0,0,0,0,0,1
1525,"Our findings show that even with the best thresholds, no algorithm is able to accurately detect all functional near-duplicates within apps, without sacrificing coverage.",0,0,0,0,1,0
1526,Deep Neural Networks (DNNs) have been widely applied in autonomous systems such as self-driving vehicles.,1,0,0,0,0,0
1527,"Recently, DNN testing has been intensively studied to automatically generate adversarial examples, which inject small-magnitude perturbations into inputs to test DNNs under extreme situations.",1,0,0,0,0,0
1528,"While existing testing techniques prove to be effective, particularly for autonomous driving, they mostly focus on generating digital adversarial perturbations, e.g., changing image pixels, which may never happen in the physical world.",1,0,0,0,0,0
1529,"Thus, there is a critical missing piece in the literature on autonomous driving testing: understanding and exploiting both digital and physical adversarial perturbation generation for impacting steering decisions.",1,0,0,0,0,0
1530,"In this paper, we propose a systematic physical-world testing approach, namely DeepBillboard, targeting at a quite common and practical driving scenario: drive-by billboards.",0,1,1,0,0,0
1531,"DeepBillboard is capable of generating a robust and resilient printable adversarial billboard test, which works under dynamic changing driving conditions including viewing angle, distance, and lighting.",0,0,1,0,0,0
1532,"The objective is to maximize the possibility, degree, and duration of the steering-angle errors of an autonomous vehicle driving by our generated adversarial billboard.",0,1,0,0,0,0
1533,We have extensively evaluated the efficacy and robustness of DeepBillboard by conducting both experiments with digital perturbations and physical-world case studies.,0,0,0,1,0,0
1534,The digital experimental results show that DeepBillboard is effective for various steering models and scenes.,0,0,0,1,1,0
1535,"Furthermore, the physical case studies demonstrate that DeepBillboard is sufficiently robust and resilient for generating physical-world adversarial billboard tests for real-world driving under various weather conditions, being able to mislead the average steering angle error up to 26.44 degrees.",0,0,0,1,1,0
1536,"To the best of our knowledge, this is the first study demonstrating the possibility of generating realistic and continuous physical-world tests for practical autonomous driving systems; moreover, DeepBillboard can be directly generalized to a variety of other physical entities/surfaces along the curbside, e.g., a graffiti painted on a wall.",0,0,0,0,1,1
1537,"Ethereum, one of the most popular blockchain platforms, provides financial transactions like payments and auctions through smart contracts.",1,0,0,0,0,0
1538,"Due to the immense interest in smart contracts in academia, the research community of smart contract security has made a significant improvement recently.",1,0,0,0,0,0
1539,"Researchers have reported various security vulnerabilities in smart contracts, and developed static analysis tools and verification frameworks to detect them.",1,0,0,0,0,0
1540,"However, it is unclear whether such great efforts from academia has indeed enhanced the security of smart contracts in reality.",1,0,0,0,0,0
1541,"To understand the security level of smart contracts in the wild, we empirically studied 55,046 real-world Ethereum smart contracts written in Solidity, the most popular programming language used by Ethereum smart contract developers.",0,1,1,1,0,0
1542,"We first examined how many well-known vulnerabilities the Solidity compiler has patched, and how frequently the Solidity team publishes compiler releases.",0,0,1,0,0,0
1543,"Unfortunately, we observed that many known vulnerabilities are not yet patched, and some patches are not even sufficient to avoid their target vulnerabilities.",0,0,0,0,1,0
1544,"Subsequently, we investigated whether smart contract developers use the most recent compiler with vulnerabilities patched.",0,0,1,0,0,0
1545,"We reported that developers of more than 98% of real-world Solidity contracts still use older compilers without vulnerability patches, and more than 25% of the contracts are potentially vulnerable due to the missing security patches.",0,0,0,0,1,0
1546,"To understand actual impacts of the missing patches, we manually investigated potentially vulnerable contracts that are detected by our static analyzer and identified common mistakes by Solidity developers, which may cause serious security issues such as financial loss.",0,0,0,1,0,0
1547,We detected hundreds of vulnerable contracts and about one fourth of the vulnerable contracts are used by thousands of people.,0,0,0,0,1,0
1548,"We recommend the Solidity team to make patches that resolve known vulnerabilities correctly, and developers to use the latest Solidity compiler to avoid missing security patches.",0,0,0,0,1,0
1549,The PyPI ecosystem has indexed millions of Python libraries to allow developers to automatically download and install dependencies of their projects based on the specified version constraints.,1,0,0,0,0,0
1550,"Despite the convenience brought by automation, version constraints in Python projects can easily conflict, resulting in build failures.",1,0,0,0,0,0
1551,We refer to such conflicts as Dependency Confict (DC) issues.,1,0,0,0,0,0
1552,"Although DC issues are common in Python projects, developers lack tool support to gain a comprehensive knowledge for diagnosing the root causes of these issues.",1,0,0,0,0,0
1553,"In this paper, we conducted an empirical study on 235 real-world DC issues.",0,1,1,1,0,0
1554,We studied the manifestation patterns and fixing strategies of these issues and found several key factors that can lead to DC issues and their regressions.,0,0,1,0,0,0
1555,"Based on our findings, we designed and implemented Watchman, a technique to continuously monitor dependency conflicts for the PyPI ecosystem.",0,0,0,1,0,0
1556,"In our evaluation, Watchman analyzed PyPI snapshots between 11 Jul 2019 and 16 Aug 2019, and found 117 potential DC issues.",0,0,0,1,1,0
1557,We reported these issues to the developers of the corresponding projects.,0,0,0,0,0,1
1558,"So far, 63 issues have been confirmed, 38 of which have been quickly fixed by applying our suggested patches.",0,0,0,0,1,1
1559,"Existing intrusive test automation techniques for touch screen applications (e.g., Appium and Sikuli) are difficult to work on many closed or uncommon systems, such as a GoPro.",1,0,0,0,0,0
1560,Being non-intrusive can largely extend the application scope of the test automation techniques.,1,0,0,0,0,0
1561,"To this end, this paper presents RoScript, a truly non-intrusive test-script-driven robotic testing system for test automation of touch screen applications.",0,1,1,0,0,0
1562,RoScript leverages visual test scripts to express GUI actions on a touch screen application and uses a physical robot to drive automated test execution.,0,0,1,0,0,0
1563,"To reduce the test script creation cost, a non-intrusive computer vision based technique is also introduced in RoScript to automatically record touch screen actions into test scripts from videos of human actions on the device under test.",0,0,1,0,0,0
1564,"RoScript is applicable to touch screen applications running on almost arbitrary platforms, whatever the underlying operating systems or GUI frameworks are.",0,0,1,0,0,0
1565,We conducted experiments applying it to automate the testing of 21 touch screen applications on 6 different devices.,0,0,0,1,0,0
1566,The results show that RoScript is highly usable.,0,0,0,0,1,0
1567,"In the experiments, it successfully automated 104 test scenarios containing over 650 different GUI actions on the subject applications.",0,0,0,0,1,0
1568,RoScript accurately performed GUI actions on over 90% of the test script executions and accurately recorded about 85% of human screen click actions into test code.,0,0,0,0,1,0
1569,"Modern machine learning programs are often written in Python, with the main computations specified through calls to some highly optimized libraries (e.g., TensorFlow, PyTorch).",1,0,0,0,0,0
1570,"How to maximize the computing efficiency of such programs is essential for many application domains, which has drawn lots of recent attention.",1,0,0,0,0,0
1571,"This work points out a common limitation in existing efforts: they focus their views only on the static computation graphs specified by library APIs, but leave the influence from the hosting Python code largely unconsidered.",0,1,0,0,0,0
1572,The limitation often causes them to miss the big picture and hence many important optimization opportunities.,0,1,0,0,0,0
1573,This work proposes a new approach named HARP to address the problem.,0,0,1,0,0,0
1574,HARP enables holistic analysis that spans across computation graphs and their hosting Python code.,0,0,1,0,0,0
1575,"HARP achieves it through a set of novel techniques: analytics-conscious speculative analysis to circumvent Python complexities, a unified representation augmented computation graphs to capture all dimensions of knowledge related with the holistic analysis, and conditioned feedback mechanism to allow risk-controlled aggressive analysis.",0,0,1,0,0,0
1576,Refactoring based on HARP gives 1.3--3X and 2.07X average speedups on a set of TensorFlow and PyTorch programs.,0,0,0,0,1,0
1577,"In modern software development, software libraries play a crucial role in reducing software development effort and improving software quality.",1,0,0,0,0,0
1578,"However, at the same time, the asynchronous upgrades of software libraries and client software projects often result in incompatibilities between different versions of libraries and client projects.",1,0,0,0,0,0
1579,"When libraries evolve, it is often very challenging for library developers to maintain the so-called backward compatibility and keep all their external behavior untouched, and behavioral backward incompatibilities (BBIs) may occur.",1,0,0,0,0,0
1580,"In practice, the regression test suites of library projects often fail to detect all BBIs.",1,0,0,0,0,0
1581,"Therefore, in this paper, we propose DeBBI to detect BBIs via cross-project testing and analysis, i.e., using the test suites of various client projects to detect library BBIs.",0,1,1,0,0,0
1582,"Since executing all the possible client projects can be extremely time consuming, DeBBI transforms the problem of cross-project BBI detection into a traditional information retrieval (IR) problem to execute the client projects with higher probability to detect BBIs earlier.",0,0,1,0,0,0
1583,"Furthermore, DeBBI considers project diversity and test relevance information for even faster BBI detection.",0,0,1,0,0,0
1584,The experimental results show that DeBBI can reduce the end-to-end testing time for detecting the first and average unique BBIs by 99.1% and 70.8% for JDK compared to naive cross-project BBI detection.,0,0,0,1,1,0
1585,"Also, DeBBI has been applied to other popular 3rd-party libraries.",0,0,0,1,0,0
1586,"To date, DeBBI has detected 97 BBI bugs with 19 already confirmed as previously unknown bugs.",0,0,0,0,1,0
1587,Continuous integration (CI) is a widely used practice in modern software engineering.,1,0,0,0,0,0
1588,"Unfortunately, it is also an expensive practice --- Google and Mozilla estimate their CI systems in millions of dollars.",1,0,0,0,0,0
1589,"In this paper, we propose a novel approach for reducing the cost of CI.",0,1,1,0,0,0
1590,The cost of CI lies in the computing power to run builds and its value mostly lies on letting developers find bugs early --- when their size is still small.,0,0,1,0,0,0
1591,"Thus, we target reducing the number of builds that CI executes by still executing as many failing builds as early as possible.",0,0,1,0,0,0
1592,"To achieve this goal, we propose SmartBuildSkip, a technique which predicts the first builds in a sequence of build failures and the remaining build failures separately.",0,0,1,0,0,0
1593,"SmartBuildSkip is customizable, allowing developers to select different preferred trade-offs of saving many builds vs. observing build failures early.",0,0,1,0,0,0
1594,"We evaluate the motivating hypothesis of SmartBuildSkip, its prediction power, and its cost savings in a realistic scenario.",0,0,0,1,0,0
1595,"In its most conservative configuration, SmartBuildSkip saved a median 30% of builds by only incurring a median delay of 1 build in a median of 15% failing builds.",0,0,0,0,1,0
1596,"Return-oriented programming (ROP) is an effective code-reuse attack in which short code sequences (i.e., gadgets) ending in a ret instruction are found within existing binaries and then executed by taking control of the call stack.",1,0,0,0,0,0
1597,"The shadow stack, control flow integrity (CFI) and code (re)randomization are three popular techniques for protecting programs against return address overwrites.",1,0,0,0,0,0
1598,"However, existing runtime rerandomization techniques operate on concrete return addresses, requiring expensive pointer tracking.",1,0,0,0,0,0
1599,"By adding one level of indirection, we introduce BarRA, the first shadow stack mechanism that applies continuous runtime rerandomization to abstract return addresses for protecting their corresponding concrete return addresses (protected also by CFI), thus avoiding expensive pointer tracking.",0,1,1,0,0,0
1600,"As a nice side-effect, BarRA naturally combines the shadow stack, CFI and runtime rerandomization in the same framework.",0,0,1,0,0,0
1601,"The key novelty of BarRA, however, is that once some abstract return addresses are leaked, BarRA will enforce the burn-after-reading property by rerandomizing the mapping from the abstract to the concrete return address space in the order of microseconds instead of seconds required for rerandomizing a concrete return address space.",0,0,1,0,0,0
1602,"As a result, BarRA can be used as a superior replacement for the shadow stack, as demonstrated by comparing both using the 19 C/C++ benchmarks in SPEC CPU2006 (totalling 2,047,447 LOC) and analyzing a proof-of-concept attack, provided that we can tolerate some slight binary code size increases (by an average of 29.44%) and are willing to use 8MB of dedicated memory for holding up to 220 return addresses (on a 64-bit platform).",0,0,0,1,1,0
1603,"Under an information leakage attack (for some return addresses), the shadow stack is always vulnerable but BarRA is significantly more resilient (by reducing an attacker's success rate to 1/220 on average).",0,0,0,0,1,0
1604,"In terms of the average performance overhead introduced, both are comparable: 6.09% (BarRA) vs. 5.38% (the shadow stack).",0,0,0,0,1,0
1605,"Software projects are increasingly forming social-technical ecosystems within which individual projects rely on the infrastructures or functional components provided by other projects, leading to complex inter-dependencies.",1,0,0,0,0,0
1606,"Through inter-project dependencies, a bug in an upstream project may have profound impact on a large number of downstream projects, resulting in cross-project bugs.",1,0,0,0,0,0
1607,This emerging type of bugs has brought new challenges in bug fixing due to their unclear influence on downstream projects.,1,0,0,0,0,0
1608,"In this paper, we present an approach to estimating the impact of a cross-project bug within its ecosystem by identifying the affected downstream modules (classes/methods).",0,1,1,0,0,0
1609,Note that a downstream project that uses a buggy upstream function may not be affected as the usage does not satisfy the failure inducing preconditions.,1,0,0,0,0,0
1610,"For a reported bug with the known root cause function and failure inducing preconditions, we first collect the candidate downstream modules that call the upstream function through an ecosystem-wide dependence analysis.",0,0,1,0,0,0
1611,"Then, the paths to the call sites of the buggy upstream function are encoded as symbolic constraints.",0,0,1,0,0,0
1612,"Solving the constraints, together with the failure inducing preconditions, identifies the affected downstream modules.",0,0,1,0,0,0
1613,"Our evaluation of 31 existing upstream bugs on the scientific Python ecosystem containing 121 versions of 22 popular projects (with a total of 16 millions LOC) shows that the approach is highly effective: from the 25490 candidate downstream modules that invoke the buggy upstream functions, it identifies 1132 modules where the upstream bugs can be triggered, pruning 95.6% of the candidates.",0,0,0,1,1,0
1614,The technique has no false negatives and an average false positive rate of 7.9%.,0,0,0,0,1,0
1615,Only 49 downstream modules (out of the 1132 we found) were reported before to be affected.,0,0,0,0,1,0
1616,A user's review of an app often describes the user's interactions with the app.,1,0,0,0,0,0
1617,"These interactions, which we interpret as mini stories, are prominent in reviews with negative ratings.",1,0,0,0,0,0
1618,"In general, a story in an app review would contain at least two types of events: user actions and associated app behaviors.",1,0,0,0,0,0
1619,Being able to identify such stories would enable an app's developer in better maintaining and improving the app's functionality and enhancing user experience.,1,0,0,0,0,0
1620,"We present Caspar, a method for extracting and synthesizing user-reported mini stories regarding app problems from reviews.",0,1,1,0,0,0
1621,"By extending and applying natural language processing techniques, Caspar extracts ordered events from app reviews, classifies them as user actions or app problems, and synthesizes action-problem pairs.",0,0,1,0,0,0
1622,Our evaluation shows that Caspar is effective in finding action-problem pairs from reviews.,0,0,0,0,1,0
1623,"First, Caspar classifies the events with an accuracy of 82.0% on manually labeled data.",0,0,0,0,1,0
1624,"Second, relative to human evaluators, Caspar extracts event pairs with 92.9% precision and 34.2% recall.",0,0,0,0,1,0
1625,"In addition, we train an inference model on the extracted action-problem pairs that automatically predicts possible app problems for different use cases.",0,0,0,1,0,0
1626,Preliminary evaluation shows that our method yields promising results.,0,0,0,0,1,0
1627,Caspar illustrates the potential for a deeper understanding of app reviews and possibly other natural language artifacts arising in software engineering.,0,0,0,0,0,1
1628,"Background: Despite a lot of research on the effectiveness of Pair Programming (PP), the question when it is useful or less useful remains unsettled.",1,0,0,0,0,0
1629,Method: We analyze recordings of many industrial PP sessions with Grounded Theory Methodology and build on prior work that identified various phenomena related to within-session knowledge build-up and transfer.,0,0,1,1,0,0
1630,We validate our findings with practitioners.,0,0,0,1,0,0
1631,Result: We identify two fundamentally different types of required knowledge and explain how different constellations of knowledge gaps in these two respects lead to different session dynamics.,0,0,0,0,1,0
1632,Gaps in project-specific systems knowledge are more hampering than gaps in general programming knowledge and are dealt with first and foremost in a PP session.,0,0,0,0,1,0
1633,Conclusion: Partner constellations with complementary knowledge make PP a particularly effective practice.,0,0,0,0,0,1
1634,"In PP sessions, differences in system understanding are more important than differences in general software development knowledge.",0,0,0,0,0,1
1635,The engineering of high-quality software requirements generally relies on properties and assumptions about the environment in which the software-to-be has to operate.,1,0,0,0,0,0
1636,"Such properties and assumptions, referred to as environment conditions in this paper, are highly subject to change over time or from one software variant to another.",1,0,0,0,0,0
1637,"As a consequence, the requirements engineered for a specific set of environment conditions may no longer be adequate, complete and consistent for another set.",1,0,0,0,0,0
1638,The paper addresses this problem through a tool-supported requirements adaptation technique.,0,1,1,0,0,0
1639,A goal-oriented requirements modelling framework is considered to make requirements' refinements and dependencies on environment conditions explicit.,0,0,1,0,0,0
1640,"When environment conditions change, an adapted goal model is computed that is correct with respect to the new environment conditions.",0,0,1,0,0,0
1641,The space of possible adaptations is not fixed a priori; the required changes are expected to meet one or more environment-independent goal(s) to be satisfied in any version of the system.,0,0,1,0,0,0
1642,"The adapted goal model is generated using a new counterexample-guided learning procedure that ensures the correctness of the updated goal model, and prefers more local adaptations and more similar goal models.",0,0,1,0,0,0
1643,Static analysis is increasingly used by companies and individual code developers to detect and fix bugs and security vulnerabilities.,1,0,0,0,0,0
1644,"As programs grow more complex, the analyses have to support new code concepts, frameworks and libraries.",1,0,0,0,0,0
1645,"However, static-analysis code itself is also prone to bugs.",1,0,0,0,0,0
1646,"While more complex analyses are written and used in production systems every day, the cost of debugging and fixing them also increases tremendously.",1,0,0,0,0,0
1647,"To understand the difficulties of debugging static analysis, we surveyed 115 static-analysis writers.",0,0,1,1,0,0
1648,"From their responses, we determined the core requirements to build a debugger for static analyses, which revolve around two main issues: abstracting from both the analysis code and the code it analyses at the same time, and tracking the analysis internal state throughout both code bases.",0,0,0,0,1,0
1649,Most tools used by our survey participants lack the capabilities to address both issues.,0,0,0,0,1,0
1650,"Focusing on those requirements, we introduce Visuflow, a debugging environment for static data-flow analysis.",0,1,0,0,0,0
1651,Visuflow features graph visualizations and custom breakpoints that enable users to view the state of an analysis at any time.,0,0,1,0,0,0
1652,"In a user study on 20 static-analysis writers, Visuflow helped identify 25 and fix 50 percent more errors in the analysis code compared to the standard Eclipse debugging environment.",0,0,0,1,1,0
1653,Selecting reviewers for code changes is a critical step for an efficient code review process.,1,0,0,0,0,0
1654,Recent studies propose automated reviewer recommendation algorithms to support developers in this task.,1,0,0,0,0,0
1655,"However, the evaluation of recommendation algorithms, when done apart from their target systems and users (i.e., code review tools and change authors), leaves out important aspects: perception of recommendations, influence of recommendations on human choices, and their effect on user experience.",1,0,0,0,0,0
1656,This study is the first to evaluate a reviewer recommender in vivo.,0,0,1,0,0,0
1657,"We compare historical reviewers and recommendations for over 21,000 code reviews performed with a deployed recommender in a company environment and set out to measure the influence of recommendations on users' choices, along with other performance metrics.",0,0,0,1,0,0
1658,"Having found no evidence of influence, we turn to the users of the recommender.",0,0,0,0,1,0
1659,"Through interviews and a survey we find that, though perceived as relevant, reviewer recommendations rarely provide additional value for the respondents.",0,0,0,1,1,0
1660,We confirm this finding with a larger study at another company.,0,0,0,0,1,0
1661,The confirmation of this finding brings up a case for more user-centric approaches to designing and evaluating the recommenders.,0,0,0,0,0,1
1662,"Finally, we investigate information needs of developers during reviewer selection and discuss promising directions for the next generation of reviewer recommendation tools.",0,0,1,0,0,0
1663,Abbreviations are widely used in identifiers.,1,0,0,0,0,0
1664,"However, they have severe negative impact on program comprehension and IR-based software maintenance activities, e.g., concept location, software clustering, and recovery of traceability links.",1,0,0,0,0,0
1665,"Consequently, a number of efficient approaches have been proposed successfully to expand abbreviations in identifiers.",1,0,0,0,0,0
1666,"Most of such approaches rely heavily on dictionaries, and rarely exploit the specific and fine-grained context of identifiers.",1,0,0,0,0,0
1667,"As a result, such approaches are less accurate in expanding abbreviations (especially short ones) that may match multiple dictionary words.",1,0,0,0,0,0
1668,"To this end, in this paper we propose an automatic approach to improve the accuracy of abbreviation expansion by exploiting the specific and fine-grained context.",0,1,0,0,0,0
1669,"It focuses on a special but common category of abbreviations (abbreviations in parameter names), and thus it can exploit the specific and fine-grained context, i.e., the type of the enclosing parameter as well the corresponding formal (or actual) parameter name.",0,0,1,0,0,0
1670,The recent empirical study on parameters suggest that actual parameters are often lexically similar to their corresponding formal parameters.,0,0,0,1,0,0
1671,"Consequently, it is likely that an abbreviation in a formal parameter can find its full terms in the corresponding actual parameter, and vice versa.",0,0,1,0,0,0
1672,"Based on this assumption, a series of heuristics are proposed to look for full terms from the corresponding actual (or formal) parameter names.",0,0,0,1,0,0
1673,"To the best of our knowledge, we are the first to expand abbreviations by exploiting the lexical similarity between actual and formal parameters.",0,0,0,1,0,0
1674,We also search for full terms in the data type of the enclosing parameter.,0,0,1,0,0,0
1675,"Only if all such heuristics fail, the approach turns to the traditional abbreviation dictionaries.",0,0,1,0,0,0
1676,We evaluate the proposed approach on seven well known open-source projects.,0,0,0,1,0,0
1677,"Evaluation results suggest that when only parameter abbreviations are involved, the proposed approach can improve the precision from 26 to 95 percent and recall from 26 to 65 percent compared against the state-of-the-art general purpose approach.",0,0,0,0,1,0
1678,"Consequently, the proposed approach could be employed as a useful supplement to existing approaches to expand parameter abbreviations.",0,0,0,0,0,1
1679,Test adequacy criteria are widely used to guide test creation.,1,0,0,0,0,0
1680,"However, many of these criteria are sensitive to statement structure or the choice of test oracle.",1,0,0,0,0,0
1681,"This is because such criteria ensure that execution reaches the element of interest, but impose no constraints on the execution path after this point.",1,0,0,0,0,0
1682,We are not guaranteed to observe a failure just because a fault is triggered.,1,0,0,0,0,0
1683,"To address this issue, we have proposed the concept of observability-an extension to coverage criteria based on Boolean expressions that combines the obligations of a host criterion with an additional path condition that increases the likelihood that a fault encountered will propagate to a monitored variable.",0,1,0,0,0,0
1684,"Our study, conducted over five industrial systems and an additional forty open-source systems, has revealed that adding observability tends to improve efficacy over satisfaction of the traditional criteria, with average improvements of 125.98 percent in mutation detection with the common output-only test oracle and per-model improvements of up to 1760.52 percent.",0,0,0,1,1,0
1685,"Ultimately, there is merit to our hypothesis-observability reduces sensitivity to the choice of oracle and to the program structure.",0,0,0,0,0,1
1686,"We present Supa, a value-flow-based demand-driven flow- and context-sensitive pointer analysis with strong updates for C and C++ programs.",0,1,0,0,0,0
1687,"Supa enables computing points-to information via value-flow refinement, in environments with small time and memory budgets.",0,1,0,0,0,0
1688,"We formulate Supa by solving a graph-reachability problem on an inter-procedural value-flow graph representing a program's def-use chains, which are pre-computed efficiently but over-approximately.",0,0,1,0,0,0
1689,"To answer a client query (a request for a variable's points-to set), Supa reasons about the flow of values along the pre-computed def-use chains sparsely (rather than across all program points), by performing only the work necessary for the query (rather than analyzing the whole program).",0,0,1,0,0,0
1690,"In particular, strong updates are performed to filter out spurious def-use chains through value-flow refinement as long as the total budget is not exhausted.",0,0,1,0,0,0
1691,"We have implemented Supa on top of LLVM (4.0.0) together with a comprehensive micro-benchmark suite after a years-long effort (consisting of around 400 test cases, including hand-written ones and the ones extracted from real programs).",0,0,1,0,0,0
1692,"We have evaluated Supa by choosing uninitialized pointer detection and C++ virtual table resolution as two major clients, using 24 real-world programs including 18 open-source C programs and 6 large CPU2000/2006 C++ benchmarks.",0,0,0,1,0,0
1693,"For uninitialized pointer client, Supa achieves improved precision as the analysis budget increases, with its flow-sensitive (context-insensitive) analysis reaching 97.4 percent of that achieved by whole-program Sparse Flow-Sensitive analysis (SFS) by consuming about 0.18 seconds and 65 KB of memory per query, on average (with a budget of at most 10,000 value-flow edges per query).",0,0,0,0,1,0
1694,"With context-sensitivity also considered, Supa becomes more precise for some programs but also incurs more analysis times.",0,0,0,0,0,1
1695,"To further demonstrate the effectiveness of Supa, we have also evaluated Supa in resolving C++ virtual tables by querying the function pointers at every virtual callsite.",0,0,0,1,0,0
1696,"Compared to analysis without strong updates for heap objects, Supa's demand-driven context-sensitive strong update analysis reduces 7.35 percent spurious virtual table targets with only 0.4 secs per query, on average.",0,0,0,0,1,0
1697,"Developers always focus on delivering high-quality updates to improve, or maintain the rating of their apps.",1,0,0,0,0,0
1698,Prior work has studied user reviews by analyzing all reviews of an app.,1,0,0,0,0,0
1699,"However, this app-level analysis misses the point that users post reviews to provide their feedback on a certain update.",1,0,0,0,0,0
1700,"For example, two bad updates of an app with a history of good updates would not be spotted using app-level analysis.",1,0,0,0,0,0
1701,"In this paper, we examine reviews at the update-level to better understand how users perceive bad updates.",0,0,1,0,0,0
1702,"We focus our study on the top 250 bad updates (i.e., updates with the highest increase in the percentage of negative reviews relative to the prior updates of the app) from 26,726 updates of 2,526 top free-to-download apps in the Google Play Store.",0,0,0,1,0,0
1703,We find that feature removal and UI issues have the highest increase in the percentage of negative reviews.,0,0,0,0,1,0
1704,Bad updates with crashes and functional issues are the most likely to be fixed by a later update.,1,0,0,0,0,0
1705,"However, developers often do not mention these fixes in the release notes.",1,0,0,0,0,0
1706,Our work demonstrates the necessity of an update-level analysis of reviews to capture the feelings of an app's user-base about a particular update.,0,0,0,0,0,1
1707,Bug reports play an important role in the process of debugging and fixing bugs.,1,0,0,0,0,0
1708,"To reduce the burden of bug report managers and facilitate the process of bug fixing, a great amount of software engineering research has been invested toward automated bug report management techniques.",1,0,0,0,0,0
1709,"However, the verdict is still open whether such techniques are actually required and applicable outside the domain of theoretical research.",1,0,0,0,0,0
1710,"To fill this gap, we conducted a survey among 327 practitioners to gain their insights into various categories of automated bug report management techniques.",0,0,0,1,0,0
1711,"Specifically, we asked the respondents to rate the importance of such techniques and provide the rationale.",0,0,0,1,0,0
1712,"To get deeper insights into practitioners' perspective, we conducted follow-up interviews with 25 interviewees selected from the survey respondents.",0,0,0,1,0,0
1713,"Through the survey and the interviews, we gained a better understanding of the perceived usefulness (or its lack) of different categories of automated bug report management techniques.",0,0,0,0,1,0
1714,"Based on our findings, we summarized some potential research directions in developing techniques to help developers better manage bug reports.",0,0,0,0,0,1
1715,Finding good configurations of a software system is often challenging since the number of configuration options can be large.,1,0,0,0,0,0
1716,"Software engineers often make poor choices about configuration or, even worse, they usually use a sub-optimal configuration in production, which leads to inadequate performance.",1,0,0,0,0,0
1717,"To assist engineers in finding the better configuration, this article introduces Flash, a sequential model-based method that sequentially explores the configuration space by reflecting on the configurations evaluated so far to determine the next best configuration to explore.",0,1,0,0,0,0
1718,Flash scales up to software systems that defeat the prior state-of-the-art model-based methods in this area.,0,0,1,0,0,0
1719,Flash runs much faster than existing methods and can solve both single-objective and multi-objective optimization problems.,0,1,0,0,0,0
1720,The central insight of this article is to use the prior knowledge of the configuration space (gained from prior runs) to choose the next promising configuration.,0,0,1,0,0,0
1721,"This strategy reduces the effort (i.e., number of measurements) required to find the better configuration.",0,0,1,0,0,0
1722,We evaluate Flash using 30 scenarios based on 7 software systems to demonstrate that Flash saves effort in 100 and 80 percent of cases in single-objective and multi-objective problems respectively by up to several orders of magnitude compared to state-of-the-art techniques.,0,0,0,1,1,0
1723,A linter is a static analysis tool that warns software developers about possible code errors or violations to coding standards.,1,0,0,0,0,0
1724,"By using such a tool, errors can be surfaced early in the development process when they are cheaper to fix.",1,0,0,0,0,0
1725,"For a linter to be successful, it is important to understand the needs and challenges of developers when using a linter.",1,0,0,0,0,0
1726,"In this paper, we examine developers' perceptions on JavaScript linters.",0,0,1,0,0,0
1727,We study why and how developers use linters along with the challenges they face while using such tools.,0,0,1,0,0,0
1728,"For this purpose we perform a case study on ESLint, the most popular JavaScript linter.",0,0,0,1,0,0
1729,"We collect data with three different methods where we interviewed 15 developers from well-known open source projects, analyzed over 9,500 ESLint configuration files, and surveyed 337 developers from the JavaScript community.",0,0,0,1,0,0
1730,Our results provide practitioners with reasons for using linters in their JavaScript projects as well as several configuration strategies and their advantages.,0,0,0,0,1,0
1731,"We also provide a list of linter rules that are often enabled and disabled, which can be interpreted as the most important rules to reason about when configuring linters.",0,0,0,0,1,0
1732,"Finally, we propose several feature suggestions for tool makers and future work for researchers.",0,0,0,0,0,1
1733,"When multiple developers change a software system in parallel, these concurrent changes need to be merged to all appear in the software being developed.",1,0,0,0,0,0
1734,"Numerous merge techniques have been proposed to support this task, but none of them can fully automate the merge process.",1,0,0,0,0,0
1735,"Indeed, it has been reported that as much as 10 to 20 percent of all merge attempts result in a merge conflict, meaning that a developer has to manually complete the merge.",1,0,0,0,0,0
1736,"To date, we have little insight into the nature of these merge conflicts.",1,0,0,0,0,0
1737,"What do they look like, in detail?",1,0,0,0,0,0
1738,How do developers resolve them?,1,0,0,0,0,0
1739,Do any patterns exist that might suggest new merge techniques that could reduce the manual effort?,1,0,0,0,0,0
1740,"This paper contributes an in-depth study of the merge conflicts found in the histories of 2,731 open source Java projects.",0,0,1,1,0,0
1741,"Seeded by the manual analysis of the histories of five projects, our automated analysis of all 2,731 projects: (1) characterizes the merge conflicts in terms of number of chunks, size, and programming language constructs involved, (2) classifies the manual resolution strategies that developers use to address these merge conflicts, and (3) analyzes the relationships between various characteristics of the merge conflicts and the chosen resolution strategies.",0,0,1,1,0,0
1742,"Our results give rise to three primary recommendations for future merge techniques, that - when implemented - could on one hand help in automatically resolving certain types of conflicts and on the other hand provide the developer with tool-based assistance to more easily resolve other types of conflicts that cannot be automatically resolved.",0,0,0,0,0,1
1743,"With the advent of multicore processors, there is a great need to write parallel programs to take advantage of parallel computing resources.",1,0,0,0,0,0
1744,"However, due to the nondeterminism of parallel execution, the malware behaviors sensitive to thread scheduling are extremely difficult to detect.",1,0,0,0,0,0
1745,Dynamic taint analysis is widely used in security problems.,1,0,0,0,0,0
1746,"By serializing a multithreaded execution and then propagating taint tags along the serialized schedule, existing dynamic taint analysis techniques lead to under-tainting with respect to other possible interleavings under the same input.",1,0,0,0,0,0
1747,"In this paper, we propose an approach called DSTAM that integrates symbolic analysis and guided execution to systematically detect tainted instances on all possible executions under a given input.",0,1,0,0,0,0
1748,"Symbolic analysis infers alternative interleavings of an executed trace that cover new tainted instances, and computes thread schedules that guide future executions.",1,0,0,0,0,0
1749,Guided execution explores new execution traces that drive future symbolic analysis.,1,0,0,0,0,0
1750,"We have implemented a prototype as part of an educational tool that teaches secure C programming, where accuracy is more critical than efficiency.",0,1,0,0,0,0
1751,"To the best of our knowledge, DSTAM is the first algorithm that addresses the challenge of taint analysis for multithreaded program under fixed inputs.",0,0,1,0,0,0
1752,Successful software products evolve through a process of continual change.,1,0,0,0,0,0
1753,"However, this process may weaken the design of the software and make it unnecessarily complex, leading to significantly reduced productivity and increased fault-proneness.",1,0,0,0,0,0
1754,"Refactoring improves the software design while preserving overall functionality and behavior, and is an important technique in managing the growing complexity of software systems.",1,0,0,0,0,0
1755,Most of the existing work on software refactoring uses either an entirely manual or a fully automated approach.,1,0,0,0,0,0
1756,"Manual refactoring is time-consuming, error-prone and unsuitable for large-scale, radical refactoring.",1,0,0,0,0,0
1757,"On the other hand, fully automated refactoring yields a static list of refactorings which, when applied, leads to a new and often hard to comprehend design.",1,0,0,0,0,0
1758,"Furthermore, it is difficult to merge these refactorings with other changes performed in parallel by developers.",1,0,0,0,0,0
1759,"In this paper, we propose a refactoring recommendation approach that dynamically adapts and interactively suggests refactorings to developers and takes their feedback into consideration.",0,1,0,0,0,0
1760,Our approach uses NSGA-II to find a set of good refactoring solutions that improve software quality while minimizing the deviation from the initial design.,0,0,1,0,0,0
1761,These refactoring solutions are then analyzed to extract interesting common features between them such as the frequently occurring refactorings in the best non-dominated solutions.,0,0,1,0,0,0
1762,"Based on this analysis, the refactorings are ranked and suggested to the developer in an interactive fashion as a sequence of transformations.",0,0,1,0,0,0
1763,"The developer can approve, modify or reject each of the recommended refactorings, and this feedback is then used to update the proposed rankings of recommended refactorings.",0,0,1,0,0,0
1764,"After a number of introduced code changes and interactions with the developer, the interactive NSGA-II algorithm is executed again on the new modified system to repair the set of refactoring solutions based on the new changes and the feedback received from the developer.",0,0,1,0,0,0
1765,We evaluated our approach on a set of eight open source systems and two industrial projects provided by an industrial partner.,0,0,0,1,0,0
1766,Statistical analysis of our experiments shows that our dynamic interactive refactoring approach performed significantly better than four existing search-based refactoring techniques and one fully-automated refactoring tool not based on heuristic search.,0,0,0,0,1,0
1767,"Free/Libre and Open Source Software (FLOSS) communities are composed, in part, of volunteers, many of whom contribute infrequently.",1,0,0,0,0,0
1768,"However, these infrequent volunteers contribute to the sustainability of FLOSS projects, and should ideally be encouraged to continue participating, even if they cannot be persuaded to contribute regularly.",1,0,0,0,0,0
1769,"Infrequent contributions are part of a trend which has been widely observed in other sectors of volunteering, where it has been termed “episodic volunteering” (EV).",1,0,0,0,0,0
1770,"Previous FLOSS research has focused on the Onion model, differentiating core and peripheral developers, with the latter considered as a homogeneous group.",1,0,0,0,0,0
1771,"We argue this is too simplistic, given the size of the periphery group and the myriad of valuable activities they perform beyond coding.",0,0,1,0,0,0
1772,Our exploratory qualitative survey of 13 FLOSS communities investigated what episodic volunteering looks like in a FLOSS context.,0,0,0,1,0,0
1773,"EV is widespread in FLOSS communities, although not specifically managed.",0,0,0,0,1,0
1774,We suggest several recommendations for managing EV based on a framework drawn from the volunteering literature.,0,0,0,0,0,1
1775,"Also, episodic volunteers make a wide range of value-added contributions other than code, and they should neither be expected nor coerced into becoming habitual volunteers.",0,0,0,0,0,1
1776,"With the thriving of mobile app markets, third-party libraries are pervasively used in Android applications.",1,0,0,0,0,0
1777,"The libraries provide functionalities such as advertising, location, and social networking services, making app development much more productive.",1,0,0,0,0,0
1778,"However, the spread of vulnerable and harmful third-party libraries can also hurt the mobile ecosystem, leading to various security problems.",1,0,0,0,0,0
1779,"Therefore, third-party library identification has emerged as an important problem, being the basis of many security applications such as repackaging detection, vulnerability identification, and malware analysis.",1,0,0,0,0,0
1780,"Previously, we proposed a novel approach to identifying third-party Android libraries at a massive scale.",1,0,0,0,0,0
1781,Our method uses the internal code dependencies of an app to recognize library candidates and further classify them.,0,0,1,0,0,0
1782,"With a fine-grained feature hashing strategy, we can better handle code whose package and method names are obfuscated than historical work.",0,0,1,0,0,0
1783,"We have developed a prototypical tool called LibD and evaluated it with an up-to-date dataset containing 1,427,395 Android apps.",0,0,0,1,0,0
1784,"Our experiment results show that LibD outperforms existing tools in detecting multi-package third-party libraries with the presence of name-based obfuscation, leading to significantly improved precision without the loss of scalability.",0,0,0,0,1,0
1785,"In this paper, we extend our early work by investigating the possibility of employing effective and scalable library detection to boost the performance of large-scale app analyses in the real world.",0,1,0,0,0,0
1786,We show that the technique of LibD can be used to accelerate whole-app Android vulnerability detection and quickly identify variants of vulnerable third-party libraries.,0,0,0,0,1,0
1787,This extension paper sheds light on the practical value of our previous research.,0,0,0,0,0,1
1788,Application Programming Interfaces (APIs) represent key tools for software developers to build complex software systems.,1,0,0,0,0,0
1789,"However, several studies have revealed that even major API providers tend to have incomplete or inconsistent API documentation.",1,0,0,0,0,0
1790,"This can severely hamper the API comprehension and, as a consequence, the quality of the software built on them.",1,0,0,0,0,0
1791,"In this paper, we propose DRONE (Detect and Repair of dOcumentatioN dEfects), a framework to automatically detect and repair defects from API documents by leveraging techniques from program analysis, natural language processing, and constraint solving.",0,1,0,0,0,0
1792,"Specifically, we target at the directives of API documents, which are related to parameter constraints and exception handling declarations.",0,0,1,0,0,0
1793,"Furthermore, in presence of defects, we also provide a prototypical repair recommendation system.",0,1,0,0,0,0
1794,We evaluate our approach on parts of the well-documented APIs of JDK 1.8 APIs (including javaFX) and Android 7.0 (level 24).,0,0,0,1,0,0
1795,"Across the two empirical studies, our approach can detect API defects with an average F-measure of 79.9, 71.7, and 81.4 percent, respectively.",0,0,0,1,1,0
1796,The API repairing capability has also been evaluated on the generated recommendations in a further experiment.,0,0,0,1,0,0
1797,User judgments indicate that the constraint information is addressed correctly and concisely in the rendered directives.,0,0,0,0,0,1
1798,"To ensure the quality of its shared knowledge, Stack Overflow encourages users to revise answers through a badge system, which is based on quantitative measures (e.g., a badge is awarded after revising more than 500 answers).",1,0,0,0,0,0
1799,"Prior studies show that badges can positively steer the user behavior on Stack Overflow (e.g., increasing user participation).",1,0,0,0,0,0
1800,"However, little is known whether revision-related badges have a negative impact on the quality of revisions since some studies show that certain users may game incentive systems to gain rewards.",1,0,0,0,0,0
1801,"In this study, we analyze 3,871,966 revision records that are collected from 2,377,692 Stack Overflow answers.",0,0,0,1,0,0
1802,We find that: 1) Users performed a much larger than usual revisions on the badge-awarding days compared to normal days; 25% of the users did not make any more revisions once they received their first revision-related badge.,0,0,0,0,1,0
1803,"2) Performing more revisions than usual in a single day increased the likelihood of such revisions being rolled back (e.g., due to undesired or incorrect revisions).",0,0,0,0,1,0
1804,3) Users were more likely to perform text and small revisions if they performed many revisions in a single day.,0,0,0,0,1,0
1805,"Our findings are concurred by the Stack Overflow community, and they highlight the need for changes to the current badge system in order to provide a better balance between the quality and quantity of revisions.",0,0,0,0,0,1
1806,Automated program repair is the problem of automatically fixing bugs in programs in order to significantly reduce the debugging costs and improve the software quality.,1,0,0,0,0,0
1807,"To address this problem, test-suite based repair techniques regard a given test suite as an oracle and modify the input buggy program to make the entire test suite pass.",1,0,0,0,0,0
1808,"GenProg is well recognized as a prominent repair approach of this kind, which uses genetic programming (GP) to rearrange the statements already extant in the buggy program.",1,0,0,0,0,0
1809,"However, recent empirical studies show that the performance of GenProg is not fully satisfactory, particularly for Java.",1,0,0,0,0,0
1810,"In this paper, we propose ARJA, a new GP based repair approach for automated repair of Java programs.",0,1,0,0,0,0
1811,"To be specific, we present a novel lower-granularity patch representation that properly decouples the search subspaces of likely-buggy locations, operation types and potential fix ingredients, enabling GP to explore the search space more effectively.",0,0,1,0,0,0
1812,"Based on this new representation, we formulate automated program repair as a multi-objective search problem and use NSGA-II to look for simpler repairs.",0,0,1,0,0,0
1813,"To reduce the computational effort and search space, we introduce a test filtering procedure that can speed up the fitness evaluation of GP and three types of rules that can be applied to avoid unnecessary manipulations of the code.",0,0,1,0,0,0
1814,"Moreover, we also propose a type matching strategy that can create new potential fix ingredients by exploiting the syntactic patterns of existing statements.",0,1,0,0,0,0
1815,We conduct a large-scale empirical evaluation of ARJA along with its variants on both seeded bugs and real-world bugs in comparison with several state-of-the-art repair approaches.,0,0,0,1,0,0
1816,Our results verify the effectiveness and efficiency of the search mechanisms employed in ARJA and also show its superiority over the other approaches.,0,0,0,0,1,0
1817,"In particular, compared to jGenProg (an implementation of GenProg for Java), an ARJA version fully following the redundancy assumption can generate a test-suite adequate patch for more than twice the number of bugs (from 27 to 59), and a correct patch for nearly four times of the number (from 5 to 18), on 224 real-world bugs considered in Defects4J.",0,0,0,0,1,1
1818,"Furthermore, ARJA is able to correctly fix several real multi-location bugs that are hard to be repaired by most of the existing repair approaches.",0,0,0,0,0,1
1819,The standard approach to applying text retrieval models to code repositories is to train models on documents representing program elements.,1,0,0,0,0,0
1820,"However, code changes lead to model obsolescence and to the need to retrain the model from the latest snapshot.",1,0,0,0,0,0
1821,"To address this, we previously introduced an approach that trains a model on documents representing changesets from a repository and demonstrated its feasibility for feature location.",1,0,0,0,0,0
1822,"In this paper, we expand our work by investigating: a second task (developer identification), the effects of including different changeset parts in the model, the repository characteristics that affect the accuracy of our approach, and the effects of the time invariance assumption on evaluation results.",0,0,1,0,0,0
1823,"Our results demonstrate that our approach is as accurate as the standard approach for projects with most changes localized to a subset of the code, but less accurate when changes are highly distributed throughout the code.",0,0,0,0,1,0
1824,"Moreover, our results demonstrate that context and messages are key to the accuracy of changeset-based models and that the time invariance assumption has a statistically significant effect on evaluation results, providing overly-optimistic results.",0,0,0,0,1,0
1825,"Our findings indicate that our approach is a suitable alternative to the standard approach, providing comparable accuracy while eliminating retraining costs.",0,0,0,0,0,1
1826,Developers increasingly rely on text matching tools to analyze the relation between natural language words and APIs.,1,0,0,0,0,0
1827,"However, semantic gaps, namely textual mismatches between words and APIs, negatively affect these tools.",1,0,0,0,0,0
1828,"Previous studies have transformed words or APIs into low-dimensional vectors for matching; however, inaccurate results were obtained due to the failure of modeling words and APIs simultaneously.",1,0,0,0,0,0
1829,"To resolve this problem, two main challenges are to be addressed: the acquisition of massive words and APIs for mining and the alignment of words and APIs for modeling.",1,0,0,0,0,0
1830,"Therefore, this study proposes Word2API to effectively estimate relatedness of words and APIs.",0,1,0,0,0,0
1831,Word2API collects millions of commonly used words and APIs from code repositories to address the acquisition challenge.,0,0,0,1,0,0
1832,"Then, a shuffling strategy is used to transform related words and APIs into tuples to address the alignment challenge.",0,0,1,0,0,0
1833,"Using these tuples, Word2API models words and APIs simultaneously.",0,0,1,0,0,0
1834,Word2API outperforms baselines by 10-49.6 percent of relatedness estimation in terms of precision and NDCG.,0,0,0,0,1,0
1835,"Word2API is also effective on solving typical software tasks, e.g., query expansion and API documents linking.",0,0,0,0,1,0
1836,A simple system with Word2API-expanded queries recommends up to 21.4 percent more related APIs for developers.,0,0,0,0,1,0
1837,"Meanwhile, Word2API improves comparison algorithms by 7.9-17.4 percent in linking questions in Question&Answer communities to API documents.",0,0,0,0,1,0
1838,"Software defect prediction, which aims to identify defective modules, can assist developers in finding bugs and prioritizing limited quality assurance resources.",1,0,0,0,0,0
1839,Various features to build defect prediction models have been proposed and evaluated.,1,0,0,0,0,0
1840,"Among them, process metrics are one important category.",1,0,0,0,0,0
1841,"Yet, existing process metrics are mainly encoded manually from change histories and ignore the sequential information arising from the changes during software evolution.",1,0,0,0,0,0
1842,Are the change sequences derived from such information useful to characterize buggy program modules?,1,0,0,0,0,0
1843,How can we leverage such sequences to build good defect prediction models?,1,0,0,0,0,0
1844,"Unlike traditional process metrics used for existing defect prediction models, change sequences are mostly vectors of variable length.",1,0,0,0,0,0
1845,This makes it difficult to apply such sequences directly in prediction models that are driven by conventional classifiers.,1,0,0,0,0,0
1846,"To resolve this challenge, we utilize Recurrent Neural Network (RNN), which is a deep learning technique, to encode features from sequence data automatically.",0,0,1,0,0,0
1847,"In this paper, we propose a novel approach called Fences, which extracts six types of change sequences covering different aspects of software changes via fine-grained change analysis.",0,1,0,0,0,0
1848,It approaches defects prediction by mapping it to a sequence labeling problem solvable by RNN.,0,0,1,0,0,0
1849,Our evaluations on 10 open source projects show that Fences can predict defects with high performance.,0,0,0,1,1,0
1850,"In particular, our approach achieves an average F-measure of 0.657, which improves the prediction models built on traditional metrics significantly.",0,0,0,0,1,0
1851,The improvements vary from 31.6 to 46.8 percent on average.,0,0,0,0,1,0
1852,"In terms of AUC, Fences achieves an average value of 0.892, and the improvements over baselines vary from 4.2 to 16.1 percent.",0,0,0,0,1,0
1853,Fences also outperforms the state-of-the-art technique which learns semantic features automatically from static code via deep learning.,0,0,0,0,0,1
1854,Developers frequently discuss aspects of the systems they are developing online.,1,0,0,0,0,0
1855,The comments they post to discussions form a rich information source about the system.,1,0,0,0,0,0
1856,"Intention mining, a process introduced by Di Sorbo et al., classifies sentences in developer discussions to enable further analysis.",1,0,0,0,0,0
1857,"As one example of use, intention mining has been used to help build various recommenders for software developers.",1,0,0,0,0,0
1858,The technique introduced by Di Sorbo et al. to categorize sentences is based on linguistic patterns derived from two projects.,1,0,0,0,0,0
1859,"The limited number of data sources used in this earlier work introduces questions about the comprehensiveness of intention categories and whether the linguistic patterns used to identify the categories are generalizable to developer discussion recorded in other kinds of software artifacts (e.g., issue reports).",1,0,0,0,0,0
1860,"To assess the comprehensiveness of the previously identified intention categories and the generalizability of the linguistic patterns for category identification, we manually created a new dataset, categorizing 5,408 sentences from issue reports of four projects in GitHub.",0,0,0,1,0,0
1861,"Based on this manual effort, we refined the previous categories.",0,0,1,0,0,0
1862,"We assess Di Sorbo et al.'s patterns on this dataset, finding that the accuracy rate achieved is low (0.31).",0,0,0,0,1,0
1863,"To address the deficiencies of Di Sorbo et al.'s patterns, we propose and investigate a convolution neural network (CNN)-based approach to automatically classify sentences into different categories of intentions.",0,0,1,0,0,0
1864,"Our approach optimizes CNN by integrating batch normalization to accelerate the training speed, and an automatic hyperparameter tuning approach to tune appropriate hyperparameters of CNN.",0,0,1,0,0,0
1865,"Our approach achieves an accuracy of 0.84 on the new dataset, improving Di Sorbo et al.'s approach by 171 percent.",0,0,0,0,1,0
1866,"We also apply our approach to improve an automated software engineering task, in which we use our proposed approach to rectify misclassified issue reports, thus reducing the bias introduced by such data to other studies.",0,0,1,0,0,0
1867,"A case study on four open source projects with 2,076 issue reports shows that our approach achieves an average AUC score of 0.687, which improves other baselines by at least 16 percent.",0,0,0,0,1,1
1868,"Modern information technology paradigms, such as online services and off-the-shelf products, often involve a wide variety of users with different or even conflicting objectives.",1,0,0,0,0,0
1869,"Every software output may satisfy some users, but may also fail to satisfy others.",1,0,0,0,0,0
1870,"Furthermore, users often do not know the internal working mechanisms of the systems.",1,0,0,0,0,0
1871,"This situation is quite different from bespoke software, where developers and users typically know each other.",1,0,0,0,0,0
1872,"This paper proposes an approach to help users to better understand the software that they use, and thereby more easily achieve their objectives-even when they do not fully understand how the system is implemented.",0,1,0,0,0,0
1873,"Our approach borrows the concept of metamorphic relations from the field of metamorphic testing (MT), using it in an innovative way that extends beyond MT.",0,0,1,0,0,0
1874,We also propose a “symmetry” metamorphic relation pattern and a “change direction” metamorphic relation input pattern that can be used to derive multiple concrete metamorphic relations.,0,0,1,0,0,0
1875,"Empirical studies reveal previously unknown failures in some of the most popular applications in the world, and show how our approach can help users to better understand and better use the systems.",1,0,0,1,1,0
1876,"The empirical results provide strong evidence of the simplicity, applicability, and effectiveness of our methodology.",0,0,0,1,1,0
1877,Android ecosystem is heavily fragmented.,1,0,0,0,0,0
1878,"The numerous combinations of different device models and operating system versions make it impossible for Android app developers to exhaustively test their apps, and thus various compatibility issues arise.",1,0,0,0,0,0
1879,"Unfortunately, little is known on the characteristics of such fragmentation-induced compatibility issues.",1,0,0,0,0,0
1880,No mature tools exist to help developers quickly diagnose and fix these issues.,1,0,0,0,0,0
1881,"To bridge the gap, we conducted an empirical study on 220 real-world compatibility issues collected from five popular open-source Android apps.",0,0,0,1,0,0
1882,We further interviewed Android practitioners and conducted an online survey to gain insights from real practices.,0,0,0,1,0,0
1883,"Via the studies, we characterized compatibility issues, investigated common practices to handle compatibility issues, and disclosed that these issues exhibit common patterns.",0,0,1,0,0,0
1884,"With these findings, we propose a technique, FicFinder, to automatically detect compatibility issues in Android apps.",0,1,0,0,0,0
1885,FicFinder performs static code analysis based on a model that captures Android APIs as well as their associated context by which compatibility issues can be triggered.,0,0,1,0,0,0
1886,FicFinder reports actionable debugging information to developers when it detects potential issues.,0,0,0,0,1,0
1887,We evaluated FicFinder with 53 large-scale open-source Android apps.,0,0,0,1,0,0
1888,The results show that FicFinder can precisely detect compatibility issues in these apps and uncover previously-unknown issues.,0,0,0,0,0,1
1889,"Defect models that are trained on class imbalanced datasets (i.e., the proportion of defective and clean modules is not equally represented) are highly susceptible to produce inaccurate prediction models.",1,0,0,0,0,0
1890,"Prior research compares the impact of class rebalancing techniques on the performance of defect models but arrives at contradictory conclusions due to the use of different choice of datasets, classification techniques, and performance measures.",1,0,0,0,0,0
1891,Such contradictory conclusions make it hard to derive practical guidelines for whether class rebalancing techniques should be applied in the context of defect models.,1,0,0,0,0,0
1892,"In this paper, we investigate the impact of class rebalancing techniques on the performance measures and interpretation of defect models.",0,0,1,0,0,0
1893,We also investigate the experimental settings in which class rebalancing techniques are beneficial for defect models.,0,0,1,0,0,0
1894,"Through a case study of 101 datasets that span across proprietary and open-source systems, we conclude that the impact of class rebalancing techniques on the performance of defect prediction models depends on the used performance measure and the used classification techniques.",0,0,0,1,0,0
1895,"We observe that the optimized SMOTE technique and the under-sampling technique are beneficial when quality assurance teams wish to increase AUC and Recall, respectively, but they should be avoided when deriving knowledge and understandings from defect models.",0,0,0,0,0,1
1896,Discrete event controllers are at the heart of many software systems that require continuous operation.,1,0,0,0,0,0
1897,Changing these controllers at runtime to cope with changes in its execution environment or system requirements change is a challenging open problem.,1,0,0,0,0,0
1898,In this paper we address the problem of dynamic update of controllers in reactive systems.,0,0,1,0,0,0
1899,"We present a general approach to specifying correctness criteria for dynamic update and a technique for automatically computing a controller that handles the transition from the old to the new specification, assuring that the system will reach a state in which such a transition can correctly occur and in which the underlying system architecture can reconfigure.",0,0,1,0,0,0
1900,Our solution uses discrete event controller synthesis to automatically build a controller that guarantees both progress towards update and safe update.,0,0,0,0,0,1
1901,"Software defect prediction, which predicts defective code regions, can assist developers in finding bugs and prioritizing their testing efforts.",1,0,0,0,0,0
1902,Traditional defect prediction features often fail to capture the semantic differences between different programs.,1,0,0,0,0,0
1903,This degrades the performance of the prediction models built on these traditional features.,1,0,0,0,0,0
1904,"Thus, the capability to capture the semantics in programs is required to build accurate prediction models.",1,0,0,0,0,0
1905,"To bridge the gap between semantics and defect prediction features, we propose leveraging a powerful representation-learning algorithm, deep learning, to learn the semantic representations of programs automatically from source code files and code changes.",0,1,0,0,0,0
1906,"Specifically, we leverage a deep belief network (DBN) to automatically learn semantic features using token vectors extracted from the programs' abstract syntax trees (AST) (for file-level defect prediction models) and source code changes (for change-level defect prediction models).",0,0,1,0,0,0
1907,"We examine the effectiveness of our approach on two file-level defect prediction tasks (i.e., file-level within-project defect prediction and file-level cross-project defect prediction) and two change-level defect prediction tasks (i.e., change-level within-project defect prediction and change-level cross-project defect prediction).",0,0,0,1,0,0
1908,Our experimental results indicate that the DBN-based semantic features can significantly improve the examined defect prediction tasks.,0,0,0,0,1,0
1909,"Specifically, the improvements of semantic features against existing traditional features (in F1) range from 2.1 to 41.9 percentage points for file-level within-project defect prediction, from 1.5 to 13.4 percentage points for file-level cross-project defect prediction, from 1.0 to 8.6 percentage points for change-level within-project defect prediction, and from 0.6 to 9.9 percentage points for change-level cross-project defect prediction.",0,0,0,0,1,0
1910,Software systems fail.,1,0,0,0,0,0
1911,"These failures are often reported to issue tracking systems, where they are prioritized and assigned to responsible developers to be investigated.",1,0,0,0,0,0
1912,"When developers debug software, they need to reproduce the reported failure in order to verify whether their fix actually prevents the failure from happening again.",1,0,0,0,0,0
1913,"Since manually reproducing each failure could be a complex task, several automated techniques have been proposed to tackle this problem.",1,0,0,0,0,0
1914,"Despite showing advancements in this area, the proposed techniques showed various types of limitations.",1,0,0,0,0,0
1915,"In this paper, we present EvoCrash, a new approach to automated crash reproduction based on a novel evolutionary algorithm, called Guided Genetic Algorithm (GGA).",0,1,0,0,0,0
1916,"We report on our empirical study on using EvoCrash to reproduce 54 real-world crashes, as well as the results of a controlled experiment, involving human participants, to assess the impact of EvoCrash tests in debugging.",0,0,0,1,0,0
1917,"Based on our results, EvoCrash outperforms state-of-the-art techniques in crash reproduction and uncovers failures that are undetected by classical coverage-based unit test generation tools.",0,0,0,0,1,0
1918,"In addition, we observed that using EvoCrash helps developers provide fixes more often and take less time when debugging, compared to developers debugging and fixing code without using EvoCrash tests.",0,0,0,0,1,0
1919,Defect prediction has been an active research area for over four decades.,1,0,0,0,0,0
1920,"Despite numerous studies on defect prediction, the potential value of defect prediction in practice remains unclear.",1,0,0,0,0,0
1921,"To address this issue, we performed a mixed qualitative and quantitative study to investigate what practitioners think, behave and expect in contrast to research findings when it comes to defect prediction.",0,0,0,1,0,0
1922,"We collected hypotheses from open-ended interviews and a literature review of defect prediction papers that were published at ICSE, ESEC/FSE, ASE, TSE and TOSEM in the last 6 years (2012-2017).",0,0,0,1,0,0
1923,We then conducted a validation survey where the hypotheses became statements or options of our survey questions.,0,0,0,1,0,0
1924,We received 395 responses from practitioners from over 33 countries across five continents.,0,0,0,1,0,0
1925,Some of our key findings include: 1) Over 90 percent of respondents are willing to adopt defect prediction techniques.,0,0,0,0,1,0
1926,2) There exists a disconnect between practitioners' perceptions and well supported research evidence regarding defect density distribution and the relationship between file size and defectiveness.,0,0,0,0,1,0
1927,3) 7.2 percent of the respondents reveal an inconsistency between their behavior and perception regarding defect prediction.,0,0,0,0,1,0
1928,4) Defect prediction at the feature level is the most preferred level of granularity by practitioners.,0,0,0,0,1,0
1929,"5) During bug fixing, more than 40 percent of the respondents acknowledged that they would make a “work-around” fix rather than correct the actual error-causing code.",0,0,0,0,1,0
1930,"Through a qualitative analysis of free-form text responses, we identified reasons why practitioners are reluctant to adopt defect prediction tools.",0,0,0,1,0,0
1931,We also noted features that practitioners expect defect prediction tools to deliver.,0,0,0,0,1,0
1932,"Based on our findings, we highlight future research directions and provide recommendations for practitioners.",0,0,0,0,0,1
1933,One source of software project challenges and failures is the systematic errors introduced by human cognitive biases.,1,0,0,0,0,0
1934,"Although extensively explored in cognitive psychology, investigations concerning cognitive biases have only recently gained popularity in software engineering research.",1,0,0,0,0,0
1935,"This paper therefore systematically maps, aggregates and synthesizes the literature on cognitive biases in software engineering to generate a comprehensive body of knowledge, understand state-of-the-art research and provide guidelines for future research and practise.",0,0,1,0,0,0
1936,"Focusing on bias antecedents, effects and mitigation techniques, we identified 65 articles (published between 1990 and 2016), which investigate 37 cognitive biases.",0,0,0,1,0,0
1937,"Despite strong and increasing interest, the results reveal a scarcity of research on mitigation techniques and poor theoretical foundations in understanding and interpreting cognitive biases.",0,0,0,0,1,0
1938,"Although bias-related research has generated many new insights in the software engineering community, specific bias mitigation techniques are still needed for software professionals to overcome the deleterious effects of cognitive biases on their work.",0,0,0,0,0,1
1939,"Previous approaches to dynamic taint analysis for JavaScript are implemented directly in a browser or JavaScript engine, limiting their applicability to a single platform and requiring ongoing maintenance as platforms evolve, or they require nontrivial program transformations.",1,0,0,0,0,0
1940,We present an approach that relies on instrumentation to encode taint propagation as instructions for an abstract machine.,0,1,0,0,0,0
1941,"Our approach has two key advantages: it is platform-independent and can be used with any existing JavaScript engine, and it can track taint on primitive values without requiring the introduction of wrapper objects.",0,0,1,0,0,0
1942,"Furthermore, our technique enables multiple deployment scenarios by varying when and where the generated instructions are executed and it supports indirect taint sources, i.e., situations where taint enters an application via arguments passed to dynamically registered event-listener functions.",0,0,1,0,0,0
1943,"We implemented the technique for the ECMAScript 5 language in a tool called Ichnaea, and evaluated it on 22 NPM modules containing several types of injection vulnerabilities, including 4 modules containing vulnerabilities that were not previously discovered and reported.",0,0,0,1,0,0
1944,"On these modules, run-time overheads range from 3.17x to 38.42x, which is significantly better than a previous transformation-based technique.",0,0,0,0,1,0
1945,We also report on a case study that shows how Ichnaea can be used to detect privacy leaks in a Tizen web application for the Samsung Gear S2 smart watch.,0,0,0,1,0,0
1946,Numerous software companies are adopting value-based decision making.,1,0,0,0,0,0
1947,"However, what does value mean for key stakeholders making decisions?",1,0,0,0,0,0
1948,How do different stakeholder groups understand value?,1,0,0,0,0,0
1949,"Without an explicit understanding of what value means, decisions are subject to ambiguity and vagueness, which are likely to bias them.",1,0,0,0,0,0
1950,This case study provides an in-depth analysis of key stakeholders' value propositions when selecting features for a large telecommunications company's software-intensive product.,0,0,1,0,0,0
1951,"Stakeholders' value propositions were elicited via interviews, which were analyzed using Grounded Theory coding techniques (open and selective coding).",0,0,0,1,0,0
1952,"Thirty-six value propositions were identified and classified into six dimensions: customer value, market competitiveness, economic value/profitability, cost efficiency, technology & architecture, and company strategy.",0,0,0,0,1,0
1953,"Our results show that although propositions in the customer value dimension were those mentioned the most, the concept of value for feature selection encompasses a wide range of value propositions.",0,0,0,0,0,1
1954,"Moreover, stakeholder groups focused on different and complementary value dimensions, calling to the importance of involving all key stakeholders in the decision making process.",0,0,0,0,0,1
1955,"Although our results are particularly relevant to companies similar to the one described herein, they aim to generate a learning process on value-based feature selection for practitioners and researchers in general.",0,0,0,0,0,1
1956,One of the major trends in research on Self-Protecting Systems is to use a model of the system to be protected to predict its evolution.,1,0,0,0,0,0
1957,"However, very often, devising the model requires special knowledge of mathematical frameworks, that prevents the adoption of this technique outside of the academic environment.",1,0,0,0,0,0
1958,"Furthermore, some of the proposed approaches suffer from the curse of dimensionality, as their complexity is exponential in the size of the protected system.",1,0,0,0,0,0
1959,"In this paper, we introduce a model-integrated approach for the design of Self-Protecting Systems, which automatically generates and solves Markov Decision Processes (MDPs) to obtain optimal defense strategies for systems under attack.",0,1,0,0,0,0
1960,"MDPs are created in such a way that the size of the state space does not depend on the size of the system, but on the scope of the attack, which allows us to apply it to systems of arbitrary size.",0,0,1,0,0,0
1961,"We present a quasi-experiment to investigate whether, and to what extent, sleep deprivation impacts the performance of novice software developers using the agile practice of test-first development (TFD).",0,1,1,1,0,0
1962,"We recruited 45 undergraduates, and asked them to tackle a programming task.",0,0,0,1,0,0
1963,"Among the participants, 23 agreed to stay awake the night before carrying out the task, while 22 slept normally.",0,0,0,1,0,0
1964,"We analyzed the quality (i.e., the functional correctness) of the implementations delivered by the participants in both groups, their engagement in writing source code (i.e., the amount of activities performed in the IDE while tackling the programming task) and ability to apply TFD (i.e., the extent to which a participant is able to apply this practice).",0,0,0,1,0,0
1965,"By comparing the two groups of participants, we found that a single night of sleep deprivation leads to a reduction of 50 percent in the quality of the implementations.",0,0,0,0,1,0
1966,There is notable evidence that the developers' engagement and their prowess to apply TFD are negatively impacted.,0,0,0,0,1,0
1967,Our results also show that sleep-deprived developers make more fixes to syntactic mistakes in the source code.,0,0,0,0,1,0
1968,We conclude that sleep deprivation has possibly disruptive effects on software development activities.,0,0,0,0,0,1
1969,The results open opportunities for improving developers' performance by integrating the study of sleep with other psycho-physiological factors in which the software engineering research community has recently taken an interest in.,0,0,0,0,0,1
1970,Informal language and the absence of a standard taxonomy for software technologies make it difficult to reliably analyze technology trends on discussion forums and other on-line venues.,1,0,0,0,0,0
1971,We propose an automated approach called Witt for the categorization of software technologies (an expanded version of the hypernym discovery problem).,0,1,1,0,0,0
1972,"Witt takes as input a phrase describing a software technology or concept and returns a general category that describes it (e.g., integrated development environment), along with attributes that further qualify it (commercial, php, etc.).",0,0,1,0,0,0
1973,"By extension, the approach enables the dynamic creation of lists of all technologies of a given type (e.g., web application frameworks).",0,0,1,0,0,0
1974,"Our approach relies on Stack Overflow and Wikipedia, and involves numerous original domain adaptations and a new solution to the problem of normalizing automatically-detected hypernyms.",0,0,1,0,0,0
1975,"We compared Witt with six independent taxonomy tools and found that, when applied to software terms, Witt demonstrated better coverage than all evaluated alternative solutions, without a corresponding degradation in false positive rate.",0,0,0,1,1,0
1976,Continuous Integration (CI) is a popular practice where software systems are automatically compiled and tested as changes appear in the version control system of a project.,1,0,0,0,0,0
1977,"Like other software artifacts, CI specifications require maintenance effort.",1,0,0,0,0,0
1978,"Although there are several service providers like TRAVIS CI offering various CI features, it is unclear which features are being (mis)used.",1,0,0,0,0,0
1979,"In this paper, we present a study of feature use and misuse in 9,312 open source systems that use TRAVIS CI.",0,1,1,0,0,0
1980,Analysis of the features that are adopted by projects reveals that explicit deployment code is rare-48.16 percent of the studied TRAVIS CI specification code is instead associated with configuring job processing nodes.,0,0,0,0,1,0
1981,"To analyze feature misuse, we propose HANSEL-an anti-pattern detection tool for TRAVIS CI specifications.",0,0,1,0,0,0
1982,"We define four anti-patterns and HANSEL detects anti-patterns in the TRAVIS CI specifications of 894 projects in the corpus (9.60 percent), and achieves a recall of 82.76 percent in a sample of 100 projects.",0,0,0,1,1,0
1983,"Furthermore, we propose GRETEL-an anti-pattern removal tool for TRAVIS CI specifications, which can remove 69.60 percent of the most frequently occurring antipattern automatically.",0,0,0,0,1,0
1984,"Using GRETEL, we have produced 36 accepted pull requests that remove TRAVIS CI anti-patterns automatically.",0,0,0,0,1,0
1985,An important question in a software economy is how to incentivize deep rather than shallow fixes.,1,0,0,0,0,0
1986,A deep fix corrects the root cause of a bug instead of suppressing the symptoms.,1,0,0,0,0,0
1987,This paper initiates the study of the problem of incentive design for open workflows in fixing code.,0,1,1,0,0,0
1988,We model the dynamics of the software ecosystem and introduce subsumption mechanisms.,0,0,1,0,0,0
1989,These mechanisms only make use of externally observable information in determining payments and promote competition between workers.,0,0,1,0,0,0
1990,"We use a mean field equilibrium methodology to evaluate the performance of these mechanisms, demonstrating in simulation that subsumption mechanisms perform robustly across various environment configurations and satisfy important criteria for market design.",0,0,0,1,0,0
1991,Context: The proper management of people can help software organisations to achieve higher levels of success.,1,0,0,0,0,0
1992,"However, the limited attention paid to the appropriate use of theories to underpin the research in this area leaves it unclear how to deal with human aspects of software engineers, such as motivation and satisfaction.",1,0,0,0,0,0
1993,Objectives: This article aims to expose what drives the motivation and satisfaction of software engineers at work.,0,1,1,0,0,0
1994,Methods: A multiple case study was conducted at four software organisations in Brazil.,0,0,0,1,0,0
1995,"For 11 months, data was collected using semi-structured interviews, diary studies, and document analyses.",0,0,0,1,0,0
1996,"Results: The Theory of Motivation and Satisfaction of Software Engineers (TMS-SE), presented in this article, combines elements from well established theories with new findings, and translates them into the software engineering context.",0,0,0,0,1,0
1997,Conclusion: The TMS-SE advances the understanding of people management in the software engineering field and presents a strong conceptual framework for future investigations in this area.,0,0,0,0,0,1
1998,Dead code is a bad smell and it appears to be widespread in open-source and commercial software systems.,1,0,0,0,0,0
1999,"Surprisingly, dead code has received very little empirical attention from the software engineering research community.",1,0,0,0,0,0
2000,"In this paper, we present a multi-study investigation with an overarching goal to study, from the perspective of researchers and developers, when and why developers introduce dead code, howthey perceive and cope with it, and whether dead code is harmful.",0,1,1,1,0,0
2001,"To this end, we conducted semi-structured interviews with software professionals and four experiments at the University of Basilicata and the College of William & Mary.",0,0,0,1,0,0
2002,"The results suggest that it is worth studying dead code not only in the maintenance and evolution phases, where our results suggest that dead code is harmful, but also in the design and implementation phases.",0,0,0,0,1,0
2003,Our results motivate future work to develop techniques for detecting and removing dead code and suggest that developers should avoid this smell.,0,0,0,0,0,1
2004,Combinatorial testing (CT) has been proven effective in revealing the failures caused by the interaction of factors that affect the behavior of a system.,1,0,0,0,0,0
2005,The theory of Minimal Failure-Causing Schema (MFS) has been proposed to isolate the cause of a failure after CT.,1,0,0,0,0,0
2006,Most algorithms that aim to identify MFS focus on handling a single fault in the System Under Test (SUT).,1,0,0,0,0,0
2007,"However, we argue that multiple faults are more common in practice, under which masking effects may be triggered so that some failures cannot be observed.",1,0,0,0,0,0
2008,"The traditional MFS theory lacks a mechanism to handle such effects; hence, they may incorrectly isolate the MFS.",1,0,0,0,0,0
2009,"To address this problem, we propose a new MFS model that takes into account multiple faults.",0,1,1,0,0,0
2010,"We first formally analyze the impact of the multiple faults on existing MFS identifying algorithms, especially in situations where masking effects are triggered by multiple faults.",0,0,1,0,0,0
2011,We then develop an approach that can assist traditional algorithms to better handle multiple faults.,0,0,1,0,0,0
2012,"Empirical studies were conducted using several kinds of open-source software, which showed that multiple faults with masking effects do negatively affect traditional MFS identifying approaches and that our approach can help to alleviate these effects.",0,0,0,1,1,0
2013,Malicious users can attack Web applications by exploiting injection vulnerabilities in the source code.,1,0,0,0,0,0
2014,This work addresses the challenge of detecting injection vulnerabilities in the server-side code of Java Web applications in a scalable and effective way.,0,1,1,0,0,0
2015,We propose an integrated approach that seamlessly combines security slicing with hybrid constraint solving; the latter orchestrates automata-based solving with meta-heuristic search.,0,0,1,0,0,0
2016,We use static analysis to extract minimal program slices relevant to security from Web programs and to generate attack conditions.,0,0,1,0,0,0
2017,We then apply hybrid constraint solving to determine the satisfiability of attack conditions and thus detect vulnerabilities.,0,0,1,0,0,0
2018,"The experimental results, using a benchmark comprising a set of diverse and representative Web applications/services as well as security benchmark applications, show that our approach (implemented in the JOACO tool) is significantly more effective at detecting injection vulnerabilities than state-of-the-art approaches, achieving 98 percent recall, without producing any false alarm.",0,0,0,1,1,0
2019,"We also compared the constraint solving module of our approach with state-of-the-art constraint solvers, using six different benchmark suites; our approach correctly solved the highest number of constraints (665 out of 672), without producing any incorrect result, and was the one with the least number of time-out/failing cases.",0,0,0,0,1,0
2020,"In both scenarios, the execution time was practically acceptable, given the offline nature of vulnerability detection.",0,0,0,0,1,0
2021,It is common practice for developers of user-facing software to transform a mock-up of a graphical user interface (GUI) into code.,1,0,0,0,0,0
2022,This process takes place both at an application's inception and in an evolutionary context as GUI changes keep pace with evolving features.,1,0,0,0,0,0
2023,"Unfortunately, this practice is challenging and time-consuming.",1,0,0,0,0,0
2024,"In this paper, we present an approach that automates this process by enabling accurate prototyping of GUIs via three tasks: detection, classification, and assembly.",0,1,1,0,0,0
2025,"First, logical components of a GUI are detected from a mock-up artifact using either computer vision techniques or mock-up metadata.",0,0,1,0,0,0
2026,"Then, software repository mining, automated dynamic analysis, and deep convolutional neural networks are utilized to accurately classify GUI-components into domain-specific types (e.g., toggle-button).",0,0,1,0,0,0
2027,"Finally, a data-driven, K-nearest-neighbors algorithm generates a suitable hierarchical GUI structure from which a prototype application can be automatically assembled.",0,0,1,0,0,0
2028,We implemented this approach for Android in a system called ReDraw.,0,0,0,1,0,0
2029,Our evaluation illustrates that ReDraw achieves an average GUI-component classification accuracy of 91 percent and assembles prototype applications that closely mirror target mock-ups in terms of visual affinity while exhibiting reasonable code structure.,0,0,0,0,1,0
2030,Interviews with industrial practitioners illustrate ReDraw's potential to improve real development workflows.,0,0,0,1,1,0
2031,"Conventional wisdom on model transformations in Model-Driven Engineering (MDE) suggests that they are crucial components in modeling environments to achieve superior automation, whether it be refactoring, simulation, or code generation.",1,0,0,0,0,0
2032,"While their relevance is well-accepted, model transformations are challenging to design, implement, and verify because of the inherent complexity that they must encode.",1,0,0,0,0,0
2033,"Thus, defining transformations by chaining existing ones is key to success for enhancing their reusability.",1,0,0,0,0,0
2034,"This paper proposes an approach, based on well-established algorithms, to support modellers when multiple transformation chains are available to bridge a source metamodel with a target one.",0,1,1,0,0,0
2035,The all-important goal of selecting the optimal chain has been based on the quality criteria of coverage and information loss.,0,0,1,0,0,0
2036,The feasibility of the approach has been demonstrated by means of experiments operated on chains obtained from transformations borrowed from a publicly available repository.,0,0,0,1,0,0
2037,Context: Software is an important part in safety-critical system (SCS) development since it is becoming a major source of hazards.,1,0,0,0,0,0
2038,Requirements-related hazards have been associated with many accidents and safety incidents.,1,0,0,0,0,0
2039,"Requirements issues tend to be mitigated in companies with high processes maturity levels since they do their business in a systematic, consistent and proactive approach.",1,0,0,0,0,0
2040,"However, requirements engineers need systematic guidance to consider safety concerns early in the development process.",1,0,0,0,0,0
2041,Goal: the paper investigates which safety practices are suitable to be used in the Requirements Engineering (RE) process for SCS and how to design a safety maturity model for this area.,0,1,1,0,0,0
2042,"Method: we followed the design science methodology to propose Uni-REPM SCS, a safety module for Unified Requirements Engineering Process Maturity Model (Uni-REPM).",0,0,0,1,0,0
2043,"We also conducted a static validation with two practitioners and nine academic experts to evaluate its coverage, correctness, usefulness, and applicability.",0,0,0,1,0,0
2044,"Results: The module has seven main processes, fourteen sub-processes and 148 practices that form the basis of safety processes maturity.",0,0,0,0,1,0
2045,"Moreover, we describe its usage through a tool.",0,0,0,0,1,0
2046,Conclusions: The validation indicates a good coverage of practices and well receptivity by the experts.,0,0,0,0,0,1
2047,"Finally, the module can help companies in evaluating their current practices.",0,0,0,0,0,1
2048,"Critical systems that integrate software components (e.g., from third-parties) need to address the risk of residual software defects in these components.",1,0,0,0,0,0
2049,Software fault injection is an experimental solution to gauge such risk.,1,0,0,0,0,0
2050,"Many error models have been proposed for emulating faulty components, such as by injecting error codes and exceptions, or by corrupting data with bit-flips, boundary values, and random values.",1,0,0,0,0,0
2051,"Even if these error models have been able to find breaches in fragile systems, it is unclear whether these errors are in fact representative of software faults.",1,0,0,0,0,0
2052,"To pursue this open question, we propose a methodology to analyze how software faults in C/C++ software components turn into errors at components' interfaces (interface error propagation), and present an experimental analysis on what, where, and when to inject interface errors.",0,1,1,1,0,0
2053,"The results point out that the traditional error models, as used so far, do not accurately emulate software faults, but that richer interface errors need to be injected, by: injecting both fail-stop behaviors and data corruptions; targeting larger amounts of corrupted data structures; emulating silent data corruptions not signaled by the component; combining bit-flips, boundary values, and data perturbations.",0,0,0,0,1,0
2054,"We present an empirical comparison of three test generation techniques, namely, Combinatorial Testing (CT), Random Testing (RT) and Adaptive Random Testing (ART), under different test scenarios.",0,1,1,1,0,0
2055,"This is the first study in the literature to account for the (more realistic) testing setting in which the tester may not have complete information about the parameters and constraints that pertain to the system, and to account for the challenge posed by faults (in terms of failure rate).",0,0,1,0,0,0
2056,Our study was conducted on nine real-world programs under a total of 1683 test scenarios (combinations of available parameter and constraint information and failure rate).,0,0,0,1,0,0
2057,The results show significant differences in the techniques' fault detection ability when faults are hard to detect (failure rates are relatively low).,0,0,0,0,1,0
2058,CT performs best overall; no worse than any other in 98 percent of scenarios studied.,0,0,0,0,1,0
2059,"ART enhances RT, and is comparable to CT in 96 percent of scenarios, but its computational cost can be up to 3.5 times higher than CT when the program is highly constrained.",0,0,0,0,1,0
2060,"Additionally, when constraint information is unavailable for a highly-constrained program, a large random test suite is as effective as CT or ART, yet its computational cost of test generation is significantly lower than that of other techniques.",0,0,0,0,1,0
2061,"This paper presents our approach to the quantitative modeling and analysis of highly (re)configurable systems, such as software product lines.",0,1,1,0,0,0
2062,Different combinations of the optional features of such a system give rise to combinatorially many individual system variants.,0,0,1,0,0,0
2063,"We use a formal modeling language that allows us to model systems with probabilistic behavior, possibly subject to quantitative feature constraints, and able to dynamically install, remove or replace features.",0,0,1,0,0,0
2064,"More precisely, our models are defined in the probabilistic feature-oriented language QFLan, a rich domain specific language (DSL) for systems with variability defined in terms of features.",0,0,1,0,0,0
2065,"QFLan specifications are automatically encoded in terms of a process algebra whose operational behavior interacts with a store of constraints, and hence allows to separate system configuration from system behavior.",0,0,1,0,0,0
2066,"The resulting probabilistic configurations and behavior converge seamlessly in a semantics based on discrete-time Markov chains, thus enabling quantitative analysis.",0,0,1,0,0,0
2067,"Our analysis is based on statistical model checking techniques, which allow us to scale to larger models with respect to precise probabilistic analysis techniques.",0,0,1,0,0,0
2068,"The analyses we can conduct range from the likelihood of specific behavior to the expected average cost, in terms of feature attributes, of specific system variants.",0,0,1,0,0,0
2069,Our approach is supported by a novel Eclipse-based tool which includes state-of-the-art DSL utilities for QFLan based on the Xtext framework as well as analysis plug-ins to seamlessly run statistical model checking analyses.,0,0,1,0,0,0
2070,We provide a number of case studies that have driven and validated the development of our framework.,0,0,0,1,1,0
2071,We have conducted in-depth interviews with experienced practitioners in the Safety-Critical Systems (SCS) domain in order to investigate several aspects related to requirements specification and safety analysis for SCS.,0,1,1,1,0,0
2072,"We interviewed 19 practitioners from eleven SCS companies in different domains with the intention of verifying which approaches they use day-to-day, and what their perceptions are in relation to the approaches used to elicit, analyze, specify and validate safety requirements.",0,1,1,1,0,0
2073,The aim of this study is to obtain an in-depth understanding of how requirements engineering is carried out in companies that develop SCS.,0,1,1,0,0,0
2074,Temporal properties are important in a wide variety of domains for different purposes.,1,0,0,0,0,0
2075,"For example, they can be used to avoid architectural drift in software engineering orto support the regulatory compliance of business processes.",1,0,0,0,0,0
2076,"In this work, we study the understandability of three majortemporal property representations: (1) LinearTemporal Logic (LTL) is a formal and well-established logic that offers temporal operators to describe temporal properties; (2) Property Specification Patterns (PSP) are a collection of recurring temporal properties that abstract underlying formal and technical representations; (3) Event Processing Language (EPL) can be used for runtime monitoring of event streams using Complex Event Processing.",0,1,1,0,0,0
2077,We conducted two controlled experiments with 216 participants in total to study the understandability of those approaches using a completely randomized design with one alternative per experimental unit.,0,0,0,1,0,0
2078,"We hypothesized that PSP, as a highly abstracting pattern language, is easier to understand than LTL and EPL, and that EPL, due to separation of concerns (as one or more queries can be used to explicitly define the truth value change that an observed event pattern causes), is easier to understand than LTL.",0,0,0,0,1,0
2079,We found evidence supporting our hypotheses which was statistically significant and reproducible.,0,0,0,0,1,0
2080,"In Domain-Specific Modelling (DSM) the general goal is to provide Domain-Specific Modelling Languages (DSMLs) for domain users to model systems using concepts and notations they are familiar with, in their problem domain.",1,0,0,0,0,0
2081,"Verifying whether a model satisfies a set of requirements is considered to be an important challenge in DSM, but is nevertheless mostly neglected.",1,0,0,0,0,0
2082,"We present a solution in the form of ProMoBox, a framework that integrates the definition and verification of temporal properties in discrete-time behavioural DSMLs, whose semantics can be described as a schedule of graph rewrite rules.",0,1,1,0,0,0
2083,"Thanks to the expressiveness of graph rewriting, this covers a very large class of problems.",0,0,1,0,0,0
2084,"With ProMoBox, the domain user models not only the system with a DSML, but also its properties, input model, run-time state and output trace.",0,0,1,0,0,0
2085,"A DSML is thus comprised of five sublanguages, which share domain-specific syntax, and are generated from a single metamodel.",0,0,1,0,0,0
2086,Generic transformations to and from a verification backbone ensure that both the language engineer and the domain user are shielded from underlying notations and techniques.,0,0,1,0,0,0
2087,We explicitly model the ProMoBox framework's process in the paper.,0,0,1,0,0,0
2088,"Furthermore, we evaluate ProMoBox to assert that it supports the specification and verification of properties in a highly flexible and automated way.",0,0,0,1,0,0
2089,"As software evolves, test suite augmentation techniques may be used to identify which part of the program needs to be tested due to code changes and how to generate these new test cases for regression testing.",1,0,0,0,0,0
2090,"However, existing techniques focus exclusively on sequential software, without considering concurrent software in which multiple threads may interleave with each other during the execution and thus lead to a combinatorial explosion.",1,0,0,0,0,0
2091,"To fill the gap, we propose ConTesa, the first test suite augmentation tool for concurrent software.",0,1,1,0,0,0
2092,The goal is to generate new test cases capable of exercising both code changes and the thread interleavings affected by these code changes.,0,1,0,0,0,0
2093,At the center of ConTesa is a two-pronged approach.,0,0,1,0,0,0
2094,"First, it judiciously reuses the current test inputs while amplifying their interleaving coverage using random thread schedules.",0,0,1,0,0,0
2095,"Then, it leverages an incremental symbolic execution technique to generate more test inputs and interleavings, to cover the new concurrency-related program behaviors.",0,0,1,0,0,0
2096,We have implemented ConTesa and evaluated it on a set of real-world multithreaded Linux applications.,0,0,0,1,0,0
2097,Our results show that it can achieve a significantly high interleaving coverage and reveal more bugs than state-of-the-art testing techniques.,0,0,0,0,1,0
2098,"Dependency information (data- and/or control-dependencies) among program variables and program statements is playing crucial roles in a wide range of software-engineering activities, e.g., program slicing, information flow security analysis, debugging, code-optimization, code-reuse, code-understanding.",1,0,0,0,0,0
2099,Most existing dependency analyzers focus on mainstream languages and they do not support database applications embedding queries and data-manipulation commands.,1,0,0,0,0,0
2100,"The first extension to the languages for relational database management systems, proposed by Willmor et al. in 2004, suffers from the lack of precision in the analysis primarily due to its syntax-based computation and flow insensitivity.",1,0,0,0,0,0
2101,Since then no significant contribution is found in this research direction.,1,0,0,0,0,0
2102,"This paper extends the Abstract Interpretation framework for static dependency analysis of database applications, providing a semantics-based computation tunable with respect to precision.",0,1,1,0,0,0
2103,"More specifically, we instantiate dependency computation by using various relational and non-relational abstract domains, yielding to a detailed comparative analysis with respect to precision and efficiency.",0,0,1,0,0,0
2104,"Finally, we present a prototype semDDA, a semantics-based Database Dependency Analyzer integrated with various abstract domains, and we present experimental evaluation results to establish the effectiveness of our approach.",0,0,0,1,0,0
2105,"We show an improvement of the precision on an average of 6 percent in the interval, 11 percent in the octagon, 21 percent in the polyhedra and 7 percent in the powerset of intervals abstract domains, as compared to their syntax-based counterpart, for the chosen set of Java Server Page (JSP)-based open-source database-driven web applications as part of the GotoCode project.",0,0,0,0,1,0
2106,"As new requirements are introduced and implemented in a software system, developers must identify the set of source code classes which need to be changed.",1,0,0,0,0,0
2107,"Therefore, past effort has focused on predicting the set of classes impacted by a requirement.",1,0,0,0,0,0
2108,"In this paper, we introduce and evaluate a new type of information based on the intuition that the set of requirements which are associated with historical changes to a specific class are likely to exhibit semantic similarity to new requirements which impact that class.",0,1,1,0,0,0
2109,This new Requirements to Requirements Set (R2RS) family of metrics captures the semantic similarity between a new requirement and the set of existing requirements previously associated with a class.,0,0,1,0,0,0
2110,The aim of this paper is to present and evaluate the usefulness of R2RS metrics in predicting the set of classes impacted by a requirement.,0,1,1,0,0,0
2111,"We consider 18 different R2RS metrics by combining six natural language processing techniques to measure the semantic similarity among texts (e.g., VSM) and three distribution scores to compute overall similarity (e.g., average among similarity scores).",0,0,1,0,0,0
2112,"We evaluate if R2RS is useful for predicting impacted classes in combination and against four other families of metrics that are based upon temporal locality of changes, direct similarity to code, complexity metrics, and code smells.",0,0,0,1,0,0
2113,"Our evaluation features five classifiers and 78 releases belonging to four large open-source projects, which result in over 700,000 candidate impacted classes.",0,0,0,1,0,0
2114,Experimental results show that leveraging R2RS information increases the accuracy of predicting impacted classes practically by an average of more than 60 percent across the various classifiers and projects.,0,0,0,0,1,0
2115,"Program comprehension is an important, but hard to measure cognitive process.",1,0,0,0,0,0
2116,"This makes it difficult to provide suitable programming languages, tools, or coding conventions to support developers in their everyday work.",1,0,0,0,0,0
2117,"Here, we explore whether functional magnetic resonance imaging (fMRI) is feasible for soundly measuring program comprehension.",0,1,1,0,0,0
2118,"To this end, we observed 17 participants inside an fMRI scanner while they were comprehending source code.",0,0,0,1,0,0
2119,"The results show a clear, distinct activation of five brain regions, which are related to working memory, attention, and language processing, which all fit well to our understanding of program comprehension.",0,0,0,0,1,0
2120,"Furthermore, we found reduced activity in the default mode network, indicating the cognitive effort necessary for program comprehension.",0,0,0,0,1,0
2121,We also observed that familiarity with Java as underlying programming language reduced cognitive effort during program comprehension.,0,0,0,0,1,0
2122,"To gain confidence in the results and the method, we replicated the study with 11 new participants and largely confirmed our findings.",0,0,0,1,0,0
2123,"Our results encourage us and, hopefully, others to use fMRI to observe programmers and, in the long run, answer questions, such as: How should we train programmers?",0,0,0,0,0,1
2124,Can we train someone to become an excellent programmer?,0,0,0,0,0,1
2125,How effective are new languages and tools for program comprehension?,0,0,0,0,0,1
2126,Bounded model checking is among the most efficient techniques for the automated verification of concurrent programs.,1,0,0,0,0,0
2127,"However, due to the nondeterministic thread interleavings, a large and complex formula is usually required to give an exact encoding of all possible behaviors, which significantly limits the scalability.",1,0,0,0,0,0
2128,"Observing that the large formula is usually dominated by the exact encoding of the scheduling constraint, this paper proposes a novel scheduling constraint based abstraction refinement method for multi-threaded C program verification.",0,1,1,0,0,0
2129,"Our method is both efficient in practice and complete in theory, which is challenging for existing techniques.",0,0,1,0,0,0
2130,"To achieve this, we first proposed an effective and powerful technique which works well for nearly all benchmarks we evaluated.",0,0,1,0,0,0
2131,"We have proposed the notion of Event Order Graph (EOG), and have devised two graph-based algorithms over EOG for counterexample validation and refinement generation, which can often obtain a small yet effective refinement constraint.",0,0,1,0,0,0
2132,"Then, to ensure completeness, our method was enhanced with two constraint-based algorithms for counterexample validation and refinement generation.",0,0,0,1,0,0
2133,Experimental results on SV-COMP 2017 benchmarks and two real-world server systems indicate that our method is promising and significantly outperforms the state-of-the-art tools.,0,0,0,1,1,0
2134,We present a new method for the accurate analysis of the quality-of-service (QoS) properties of component-based systems.,0,1,1,0,0,0
2135,"Our method takes as input a QoS property of interest and a high-level continuous-time Markov chain (CTMC) model of the analysed system, and refines this CTMC based on observations of the execution times of the system components.",0,0,1,0,0,0
2136,The refined CTMC can then be analysed with existing probabilistic model checkers to accurately predict the value of the QoS property.,0,0,0,1,0,0
2137,"The paper describes the theoretical foundation underlying this model refinement, the tool we developed to automate it, and two case studies that apply our QoS analysis method to a service-based system implemented using public web services and to an IT support system at a large university, respectively.",0,1,1,1,0,0
2138,Our experiments show that traditional CTMC-based QoS analysis can produce highly inaccurate results and may lead to invalid engineering and business decisions.,0,0,0,1,1,0
2139,"In contrast, our new method reduced QoS analysis errors by 84.4-89.6 percent for the service-based system and by 94.7-97 percent for the IT support system, significantly lowering the risk of such invalid decisions.",0,0,0,0,1,0
2140,Developers use bug reports to triage and fix bugs.,1,0,0,0,0,0
2141,"When triaging a bug report, developers must decide whether the bug report is valid (i.e., a real bug).",1,0,0,0,0,0
2142,"A large amount of bug reports are submitted every day, with many of them end up being invalid reports.",1,0,0,0,0,0
2143,Manually determining valid bug report is a difficult and tedious task.,1,0,0,0,0,0
2144,"Thus, an approach that can automatically analyze the validity of a bug report and determine whether a report is valid can help developers prioritize their triaging tasks and avoid wasting time and effort on invalid bug reports.",1,0,0,0,0,0
2145,"In this study, motivated by the above needs, we propose an approach which can determine whether a newly submitted bug report is valid.",0,1,1,0,0,0
2146,Our approach first extracts 33 features from bug reports.,0,0,1,0,0,0
2147,"The extracted features are grouped along 5 dimensions, i.e., reporter experience, collaboration network, completeness, readability and text.",0,0,1,0,0,0
2148,"Based on these features, we use a random forest classifier to identify valid bug reports.",0,0,1,0,0,0
2149,"To evaluate the effectiveness of our approach, we experiment on large-scale datasets containing a total of 560,697 bug reports from five open source projects (i.e., Eclipse, Netbeans, Mozilla, Firefox and Thunderbird).",0,0,0,1,0,0
2150,"On average, across the five datasets, our approach achieves an F1-score for valid bug reports and F1-score for invalid ones of 0.74 and 0.67, respectively.",0,0,0,0,1,0
2151,"Moreover, our approach achieves an average AUC of 0.81.",0,0,0,0,1,0
2152,"In terms of AUC and F1-scores for valid and invalid bug reports, our approach statistically significantly outperforms two baselines using features that are proposed by Zanetti et al. [104] .",0,0,0,0,1,0
2153,We also study the most important features that distinguish valid bug reports from invalid ones.,0,0,0,0,1,0
2154,We find that the textual features of a bug report and reporter's experience are the most important factors to distinguish valid bug reports from invalid ones.,0,0,0,0,1,0
2155,"Context: Families of experiments (i.e., groups of experiments with the same goal) are on the rise in Software Engineering (SE).",1,0,0,0,0,0
2156,Selecting unsuitable aggregation techniques to analyze families may undermine their potential to provide in-depth insights from experiments' results.,1,0,0,0,0,0
2157,Objectives: Identifying the techniques used to aggregate experiments' results within families in SE.,0,1,1,0,0,0
2158,Raising awareness of the importance of applying suitable aggregation techniques to reach reliable conclusions within families.,0,1,0,0,0,0
2159,Method: We conduct a systematic mapping study (SMS) to identify the aggregation techniques used to analyze families of experiments in SE.,0,0,1,1,0,0
2160,We outline the advantages and disadvantages of each aggregation technique according to mature experimental disciplines such as medicine and pharmacology.,0,1,1,0,0,0
2161,We provide preliminary recommendations to analyze and report families of experiments in view of families' common limitations with regard to joint data analysis.,0,1,1,0,0,0
2162,"Results: Several aggregation techniques have been used to analyze SE families of experiments, including Narrative synthesis, Aggregated Data (AD), Individual Participant Data (IPD) mega-trial or stratified, and Aggregation of p-values.",0,0,0,1,1,0
2163,The rationale used to select aggregation techniques is rarely discussed within families.,0,0,0,0,1,0
2164,Families of experiments are commonly analyzed with unsuitable aggregation techniques according to the literature of mature experimental disciplines.,0,0,0,0,1,0
2165,Conclusion: Data analysis' reporting practices should be improved to increase the reliability and transparency of joint results.,0,0,0,0,0,1
2166,AD and IPD stratified appear to be suitable to analyze SE families of experiments.,0,0,0,0,0,1
2167,Combinatorial testing (CT) seeks to detect potential faults caused by various interactions of factors that can influence the software systems.,1,0,0,0,0,0
2168,"When applying CT, it is a common practice to first generate a set of test cases to cover each possible interaction and then to identify the failure-inducing interaction after a failure is detected.",1,0,0,0,0,0
2169,"Although this conventional procedure is simple and forthright, we conjecture that it is not the ideal choice in practice.",1,0,0,0,0,0
2170,This is because 1) testers desire to identify the root cause of failures before all the needed test cases are generated and executed 2) the early identified failure-inducing interactions can guide the remaining test case generation so that many unnecessary and invalid test cases can be avoided.,1,0,0,0,0,0
2171,"For these reasons, we propose a novel CT framework that allows both generation and identification process to interact with each other.",0,1,1,0,0,0
2172,"As a result, both generation and identification stages will be done more effectively and efficiently.",0,0,1,0,0,0
2173,"We conducted a series of empirical studies on several open-source software, the results of which show that our framework can identify the failure-inducing interactions more quickly than traditional approaches while requiring fewer test cases.",0,0,0,1,1,0
2174,Combinatorial testing has been shown to be a very effective strategy for software testing.,1,0,0,0,0,0
2175,"After a failure is detected, the next task is to identify one or more faulty statements in the source code that have caused the failure.",1,0,0,0,0,0
2176,"In this paper, we present a fault localization approach, called BEN, which produces a ranking of statements in terms of their likelihood of being faulty by leveraging the result of combinatorial testing.",0,1,1,0,0,0
2177,BEN consists of two major phases.,0,0,1,0,0,0
2178,"In the first phase, BEN identifies a combination that is very likely to be failure-inducing.",0,0,1,0,0,0
2179,A combination is failure-inducing if it causes any test in which it appears to fail.,0,0,1,0,0,0
2180,"In the second phase, BEN takes as input a failure-inducing combination identified in the first phase and produces a ranking of statements in terms of their likelihood to be faulty.",0,0,1,0,0,0
2181,"We conducted an experiment in which our approach was applied to the Siemens suite and four real-world programs, flex, grep, gzip and sed, from Software Infrastructure Repository (SIR).",0,0,0,1,0,0
2182,The experimental results show that our approach can effectively and efficiently localize the faulty statements in these programs.,0,0,0,0,1,0
2183,"Modern software applications are adapted to different situations (e.g., memory limits, enabling/disabling features, database credentials) by changing the values of configuration options, without any source code modifications.",1,0,0,0,0,0
2184,"According to several studies, this flexibility is expensive as configuration failures represent one of the most common types of software failures.",1,0,0,0,0,0
2185,"They are also hard to debug and resolve as they require a lot of effort to detect which options are misconfigured among a large number of configuration options and values, while comprehension of the code also is hampered by sprinkling conditional checks of the values of configuration options.",1,0,0,0,0,0
2186,"Although researchers have proposed various approaches to help debug or prevent configuration failures, especially from the end users' perspective, this paper takes a step back to understand the process required by practitioners to engineer the run-time configuration options in their source code, the challenges they experience as well as best practices that they have or could adopt.",0,1,1,0,0,0
2187,"By interviewing 14 software engineering experts, followed by a large survey on 229 Java software engineers, we identified 9 major activities related to configuration engineering, 22 challenges faced by developers, and 24 expert recommendations to improve software configuration quality.",0,0,0,1,1,0
2188,"We complemented this study by a systematic literature review to enrich the experts' recommendations, and to identify possible solutions discussed and evaluated by the research community for the developers' problems and challenges.",0,0,0,1,0,0
2189,"We find that developers face a variety of challenges for all nine configuration engineering activities, starting from the creation of options, which generally is not planned beforehand and increases the complexity of a software system, to the non-trivial comprehension and debugging of configurations, and ending with the risky maintenance of configuration options, since developers avoid touching and changing configuration options in a mature system.",0,0,0,0,1,0
2190,"We also find that researchers thus far focus primarily on testing and debugging configuration failures, leaving a large range of opportunities for future work.",0,0,0,0,1,0
2191,Regression testing is performed during maintenance activities to assess whether the unchanged parts of a software behave as intended.,1,0,0,0,0,0
2192,"To reduce its cost, test case prioritization techniques can be used to schedule the execution of the available test cases to increase their ability to reveal regression faults earlier.",1,0,0,0,0,0
2193,"Optimal test ordering can be determined using various techniques, such as greedy algorithms and meta-heuristics, and optimizing multiple fitness functions, such as the average percentage of statement and branch coverage.",1,0,0,0,0,0
2194,These fitness functions condense the cumulative coverage scores achieved when incrementally running test cases in a given ordering using Area Under Curve (AUC) metrics.,1,0,0,0,0,0
2195,"In this paper, we notice that AUC metrics represent a bi-dimensional (simplified) version of the hypervolume metric, which is widely used in many-objective optimization.",0,1,0,0,0,0
2196,"Thus, we propose a Hypervolume-based Genetic Algorithm, namely HGA, to solve the Test Case Prioritization problem when using multiple test coverage criteria.",0,0,1,0,0,0
2197,"An empirical study conducted with respect to five state-of-the-art techniques shows that (i) HGA is more cost-effective, (ii) HGA improves the efficiency of Test Case Prioritization, (iii) HGA has a stronger selective pressure when dealing with more than three criteria.",0,0,0,1,1,0
2198,"Open source developers, particularly the elite developers who own the administrative privileges for a project, maintain a diverse portfolio of contributing activities.",1,0,0,0,0,0
2199,"They not only commit source code but also exert significant efforts on other communicative, organizational, and supportive activities.",1,0,0,0,0,0
2200,"However, almost all prior research focuses on specific activities and fails to analyze elite developers’ activities in a comprehensive way.",1,0,0,0,0,0
2201,"To bridge this gap, we conduct an empirical study with fine-grained event data from 20 large open source projects hosted on GITHUB.",0,0,1,1,0,0
2202,We investigate elite developers’ contributing activities and their impacts on project outcomes.,0,0,1,0,0,0
2203,"Our analyses reveal three key findings: (1) elite developers participate in a variety of activities, of which technical contributions (e.g., coding) only account for a small proportion; (2) as the project grows, elite developers tend to put more effort into supportive and communicative activities and less effort into coding; and (3) elite developers’ efforts in nontechnical activities are negatively correlated with the project’s outcomes in terms of productivity and quality in general, except for a positive correlation with the bug fix rate (a quality indicator).",0,0,0,0,1,0
2204,"These results provide an integrated view of elite developers’ activities and can inform an individual’s decision making about effort allocation, which could lead to improved project outcomes.",0,0,0,0,1,0
2205,The results also provide implications for supporting these elite developers.,0,0,0,0,1,0
2206,The behavioural comparison of systems is an important concern of software engineering research.,1,0,0,0,0,0
2207,"For example, the areas of specification discovery and specification mining are concerned with measuring the consistency between a collection of execution traces and a program specification.",1,0,0,0,0,0
2208,This problem is also tackled in process mining with the help of measures that describe the quality of a process specification automatically discovered from execution logs.,1,0,0,0,0,0
2209,"Though various measures have been proposed, it was recently demonstrated that they neither fulfil essential properties, such as monotonicity, nor can they handle infinite behaviour.",1,0,0,0,0,0
2210,"In this article, we address this research problem by introducing a new framework for the definition of behavioural quotients.",0,0,1,0,0,0
2211,We prove that corresponding quotients guarantee desired properties that existing measures have failed to support.,0,0,0,0,1,0
2212,We demonstrate the application of the quotients for capturing precision and recall measures between a collection of recorded executions and a system specification.,0,0,0,0,1,0
2213,We use a prototypical implementation of these measures to contrast their monotonic assessment with measures that have been defined in prior research.,0,0,0,1,0,0
2214,"Coverage criteria provide a useful and widely used means to guide software testing; however, indiscriminately pursuing full coverage may not always be convenient or meaningful, as not all entities are of interest in any usage context.",1,0,0,0,0,0
2215,We aim at introducing a more meaningful notion of coverage that takes into account how the software is going to be used.,0,1,0,0,0,0
2216,Entities that are not going to be exercised by the user should not contribute to the coverage ratio.,0,0,1,0,0,0
2217,"We revisit the definition of coverage measures, introducing a notion of relative coverage.",0,0,1,0,0,0
2218,"According to this notion, we provide a definition and a theoretical framework of relative coverage, within which we discuss implications on testing theory and practice.",0,0,1,1,0,0
2219,"Through the evaluation of three different instances of relative coverage, we could observe that relative coverage measures provide a more effective strategy than traditional ones: we could reach higher coverage measures, and test cases selected by relative coverage could achieve higher reliability.",0,0,0,0,1,0
2220,We hint at several other useful implications of relative coverage notion on different aspects of software testing.,0,0,0,0,1,0
2221,"Automated system test generation for web/enterprise systems requires either a sequence of actions on a GUI (e.g., clicking on HTML links and form buttons) or direct HTTP calls when dealing with web services (e.g., REST and SOAP).",1,0,0,0,0,0
2222,"When doing white-box testing of such systems, their code can be analyzed, and the same type of heuristics (e.g., the branch distance) used in search-based unit testing can be employed to improve performance.",1,0,0,0,0,0
2223,"However, web/enterprise systems do often interact with a database.",1,0,0,0,0,0
2224,"To obtain higher coverage and find new faults, the state of the databases needs to be taken into account when generating white-box tests.",1,0,0,0,0,0
2225,"In this work, we present a novel heuristic to enhance search-based software testing of web/enterprise systems, which takes into account the state of the accessed databases.",0,1,1,0,0,0
2226,"Furthermore, we enable the generation of SQL data directly from the test cases.",0,0,1,0,0,0
2227,This is useful when it is too difficult or time consuming to generate the right sequence of events to put the database in the right state.,0,0,1,0,0,0
2228,"Also, it is useful when dealing with databases that are “read-only” for the system under test, and the actual data are generated by other services.",0,0,1,0,0,0
2229,"We implemented our technique as an extension of EVOMASTER, where system tests are generated in the JUnit format.",0,0,0,1,0,0
2230,"Experiments on six RESTful APIs (five open-source and one industrial) show that our novel techniques improve coverage significantly (up to +16.5%), finding seven new faults in those systems.",0,0,0,1,1,0
2231,UI design is an integral part of software development.,1,0,0,0,0,0
2232,"For many developers who do not have much UI design experience, exposing them to a large database of real-application UI designs can help them quickly build up a realistic understanding of the design space for a software feature and get design inspirations from existing applications.",1,0,0,0,0,0
2233,"However, existing keyword-based, image-similarity-based, and component-matching-based methods cannot reliably find relevant high-fidelity UI designs in a large database alike to the UI wireframe that the developers sketch, in face of the great variations in UI designs.",1,0,0,0,0,0
2234,"In this article, we propose a deep-learning-based UI design search engine to fill in the gap.",0,1,0,0,0,0
2235,"The key innovation of our search engine is to train a wireframe image autoencoder using a large database of real-application UI designs, without the need for labeling relevant UI designs.",0,0,1,0,0,0
2236,"We implement our approach for Android UI design search, and conduct extensive experiments with artificially created relevant UI designs and human evaluation of UI design search results.",0,0,0,1,0,0
2237,Our experiments confirm the superior performance of our search engine over existing image-similarity or component-matching-based methods and demonstrate the usefulness of our search engine in real-world UI design tasks.,0,0,0,0,1,1
2238,Test-suite minimization is one key technique for optimizing the software testing process.,1,0,0,0,0,0
2239,"Due to the need to balance multiple factors, multi-criteria test-suite minimization (MCTSM) becomes a popular research topic in the recent decade.",1,0,0,0,0,0
2240,The MCTSM problem is typically modeled as integer linear programming (ILP) problem and solved with weighted-sum single objective approach.,1,0,0,0,0,0
2241,"However, there is no existing approach that can generate sound (i.e., being Pareto-optimal) and complete (i.e., covering the entire Pareto front) Pareto-optimal solution set, to the knowledge of the authors.",1,0,0,0,0,0
2242,"In this work, we first prove that the ILP formulation can accurately model the MCTSM problem and then propose the multi-objective integer programming (MOIP) approaches to solve it.",0,0,1,0,0,0
2243,"We apply our MOIP approaches on three specific MCTSM problems and compare the results with those of the cutting-edge methods, namely, NonlinearFormulation_LinearSolver (NF_LS) and two Multi-Objective Evolutionary Algorithms (MOEAs).",0,0,1,0,0,0
2244,"The results show that our MOIP approaches can always find sound and complete solutions on five subject programs, using similar or significantly less time than NF_LS and two MOEAs do.",0,0,0,0,1,0
2245,"The current experimental results are quite promising, and our approaches have the potential to be applied for other similar search-based software engineering problems.",0,0,0,0,0,1
2246,"Programming screencasts have become a pervasive resource on the Internet, which help developers learn new programming technologies or skills.",1,0,0,0,0,0
2247,The source code in programming screencasts is an important and valuable information for developers.,1,0,0,0,0,0
2248,"But the streaming nature of programming screencasts (i.e., a sequence of screen-captured images) limits the ways that developers can interact with the source code in the screencasts.",1,0,0,0,0,0
2249,"Many studies use the Optical Character Recognition (OCR) technique to convert screen images (also referred to as video frames) into textual content, which can then be indexed and searched easily.",1,0,0,0,0,0
2250,"However, noisy screen images significantly affect the quality of source code extracted by OCR, for example, no-code frames (e.g., PowerPoint slides, web pages of API specification), non-code regions (e.g., Package Explorer view, Console view), and noisy code regions with code in completion suggestion popups.",1,0,0,0,0,0
2251,"Furthermore, due to the code characteristics (e.g., long compound identifiers like ItemListener), even professional OCR tools cannot extract source code without errors from screen images.",1,0,0,0,0,0
2252,"The noisy OCRed source code will negatively affect the downstream applications, such as the effective search and navigation of the source code content in programming screencasts.",1,0,0,0,0,0
2253,"In this article, we propose an approach named psc2code to denoise the process of extracting source code from programming screencasts.",0,1,0,0,0,0
2254,"First, psc2code leverages the Convolutional Neural Network (CNN) based image classification to remove non-code and noisy-code frames.",0,0,1,0,0,0
2255,"Then, psc2code performs edge detection and clustering-based image segmentation to detect sub-windows in a code frame, and based on the detected sub-windows, it identifies and crops the screen region that is most likely to be a code editor.",0,0,1,0,0,0
2256,"Finally, psc2code calls the API of a professional OCR tool to extract source code from the cropped code regions and leverages the OCRed cross-frame information in the programming screencast and the statistical language model of a large corpus of source code to correct errors in the OCRed source code.We conduct an experiment on 1,142 programming screencasts from YouTube.",0,0,1,0,0,0
2257,"We find that our CNN-based image classification technique can effectively remove the non-code and noisy-code frames, which achieves an F1-score of 0.95 on the valid code frames.",0,0,0,0,1,0
2258,We also find that psc2code can significantly improve the quality of the OCRed source code by truly correcting about half of incorrectly OCRed words.,0,0,0,0,1,0
2259,"Based on the source code denoised by psc2code, we implement two applications: (1) a programming screencast search engine; (2) an interaction-enhanced programming screencast watching tool.",0,1,0,0,0,0
2260,"Based on the source code extracted from the 1,142 collected programming screencasts, our experiments show that our programming screencast search engine achieves the [email protected], 10, and 20 of 0.93, 0.81, and 0.63, respectively.",0,0,0,1,1,0
2261,We also conduct a user study of our interaction-enhanced programming screencast watching tool with 10 participants.,0,0,0,1,0,0
2262,This user study shows that our interaction-enhanced watching tool can help participants learn the knowledge in the programming video more efficiently and effectively.,0,0,0,0,1,0
2263,"Deep neural network (DNN) has become increasingly popular and DNN testing is very critical to guarantee the correctness of DNN, i.e., the accuracy of DNN in this work.",1,0,0,0,0,0
2264,"However, DNN testing suffers from a serious efficiency problem, i.e., it is costly to label each test input to know the DNN accuracy for the testing set, since labeling each test input involves multiple persons (even with domain-specific knowledge) in a manual way and the testing set is large-scale.",1,0,0,0,0,0
2265,"To relieve this problem, we propose a novel and practical approach, called PACE (which is short for Practical ACcuracy Estimation), which selects a small set of test inputs that can precisely estimate the accuracy of the whole testing set.",0,1,0,0,0,0
2266,"In this way, the labeling costs can be largely reduced by just labeling this small set of selected test inputs.",0,1,0,0,0,0
2267,"Besides achieving a precise accuracy estimation, to make PACE more practical it is also required that it is interpretable, deterministic, and as efficient as possible.",0,1,0,0,0,0
2268,"Therefore, PACE first incorporates clustering to interpretably divide test inputs with different testing capabilities (i.e., testing different functionalities of a DNN model) into different groups.",0,0,1,0,0,0
2269,"Then, PACE utilizes the MMD-critic algorithm, a state-of-the-art example-based explanation algorithm, to select prototypes (i.e., the most representative test inputs) from each group, according to the group sizes, which can reduce the impact of noise due to clustering.",0,0,1,0,0,0
2270,"Meanwhile, PACE also borrows the idea of adaptive random testing to select test inputs from the minority space (i.e., the test inputs that are not clustered into any group) to achieve great diversity under the required number of test inputs.",0,0,1,0,0,0
2271,"The two parallel selection processes (i.e., selection from both groups and the minority space) compose the final small set of selected test inputs.",0,0,1,0,0,0
2272,"We conducted an extensive study to evaluate the performance of PACE based on a comprehensive benchmark (i.e., 24 pairs of DNN models and testing sets) by considering different types of models (i.e., classification and regression models, high-accuracy and low-accuracy models, and CNN and RNN models) and different types of test inputs (i.e., original, mutated, and automatically generated test inputs).",0,0,0,1,0,0
2273,"The results demonstrate that PACE is able to precisely estimate the accuracy of the whole testing set with only 1.181%∼2.302% deviations, on average, significantly outperforming the state-of-the-art approaches.",0,0,0,0,1,0
2274,Software engineers get questions of “how much testing is enough” on a regular basis.,1,0,0,0,0,0
2275,"Existing approaches in software testing management employ experience-, risk-, or value-based analysis to prioritize and manage testing processes.",1,0,0,0,0,0
2276,"However, very few is applicable to the emerging crowdtesting paradigm to cope with extremely limited information and control over unknown, online crowdworkers.",1,0,0,0,0,0
2277,"In practice, deciding when to close a crowdtesting task is largely done by experience-based guesswork and frequently results in ineffective crowdtesting.",1,0,0,0,0,0
2278,"More specifically, it is found that an average of 32% testing cost was wasteful spending in current crowdtesting practice.",1,0,0,0,0,0
2279,"This article intends to address this challenge by introducing automated decision support for monitoring and determining appropriate time to close crowdtesting tasks.To that end, it first investigates the necessity and feasibility of close prediction of crowdtesting tasks based on an industrial dataset.",0,0,1,0,0,0
2280,"Next, it proposes a close prediction approach named iSENSE2.0, which applies incremental sampling technique to process crowdtesting reports arriving in chronological order and organizes them into fixed-sized groups as dynamic inputs.",0,0,1,0,0,0
2281,"Then, a duplicate tagger analyzes the duplicate status of received crowd reports, and a CRC-based (Capture-ReCapture) close estimator generates the close decision based on the dynamic bug arrival status.",0,0,1,0,0,0
2282,"In addition, a coverage-based sanity checker is designed to reinforce the stability and performance of close prediction.",0,0,1,0,0,0
2283,"Finally, the evaluation of iSENSE2.0 is conducted on 56,920 reports of 306 crowdtesting tasks from one of the largest crowdtesting platforms.",0,0,0,1,0,0
2284,The results show that a median of 100% bugs can be detected with 30% saved cost.,0,0,0,0,1,0
2285,"The performance of iSENSE2.0 does not demonstrate significant difference with the state-of-the-art approach iSENSE, while the later one relies on the duplicate tag, which is generally considered as time-consuming and tedious to obtain.",0,0,0,0,1,0
2286,Task-related conflict and person-related conflict in software testing are inevitable and can impact the effectiveness and efficiency of the software development process.,1,0,0,0,0,0
2287,"The dimensionality of conflict in software testing is reasonably well understood, although in past research both types of conflict have frequently been modeled as reflective constructs that can obstruct the effectiveness of their use as organizational assessment and training tools.",1,0,0,0,0,0
2288,One contribution of this study is an empirical model of conflict sources in software engineering; such sources of conflict threaten to derail efficient software development outcomes in firms.,0,1,1,0,0,0
2289,A second contribution of this research is the development of a formative measurement model for purposes of development of assessing task conflict and person conflict in software teams.,0,1,1,0,0,0
2290,These validated measures can be utilized as training and development instruments for on-the-job remediation of development team conflict.,0,1,0,0,0,0
2291,"As is indicated in the organizational behavior and software engineering literature, deploying valid measures of workplace stressors such as conflict can lead to the managerial application of effective strategies and tactics to improve workplace morale and satisfaction, to the great benefit of productivity and retention.",1,0,0,0,0,0
2292,"Today, there are millions of third-party Android applications.",1,0,0,0,0,0
2293,Some of them are buggy or even malicious.,1,0,0,0,0,0
2294,"To identify such applications, novel frameworks for automated black-box testing and dynamic analysis are being developed by the Android community.",1,0,0,0,0,0
2295,Code coverage is one of the most common metrics for evaluating effectiveness of these frameworks.,1,0,0,0,0,0
2296,"Furthermore, code coverage is used as a fitness function for guiding evolutionary and fuzzy testing techniques.",1,0,0,0,0,0
2297,"However, there are no reliable tools for measuring fine-grained code coverage in black-box Android app testing.",1,0,0,0,0,0
2298,"We present the Android Code coVerage Tool, ACVTool for short, that instruments Android apps and measures code coverage in the black-box setting at class, method and instruction granularity.",0,1,0,0,0,0
2299,ACVTool has successfully instrumented 96.9% of apps in our experiments.,0,0,0,1,1,0
2300,"It introduces a negligible instrumentation time overhead, and its runtime overhead is acceptable for automated testing tools.",0,0,0,0,1,0
2301,"We demonstrate practical value of ACVTool in a large-scale experiment with Sapienz, a state-of-the-art automated testing tool.",0,0,0,1,0,0
2302,"Using ACVTool on the same cohort of apps, we have compared different coverage granularities applied by Sapienz in terms of the found amount of crashes.",0,0,0,1,0,0
2303,Our results show that none of the applied coverage granularities clearly outperforms others in this aspect.,0,0,0,0,1,0
2304,Stack Overflow has been heavily used by software developers as a popular way to seek programming-related information from peers via the internet.,1,0,0,0,0,0
2305,The Stack Overflow community recommends users to provide the related code snippet when they are creating a question to help others better understand it and offer their help.,1,0,0,0,0,0
2306,Previous studies have shown that a significant number of these questions are of low-quality and not attractive to other potential experts in Stack Overflow.,1,0,0,0,0,0
2307,These poorly asked questions are less likely to receive useful answers and hinder the overall knowledge generation and sharing process.,1,0,0,0,0,0
2308,"Considering one of the reasons for introducing low-quality questions in SO is that many developers may not be able to clarify and summarize the key problems behind their presented code snippets due to their lack of knowledge and terminology related to the problem, and/or their poor writing skills, in this study we propose an approach to assist developers in writing high-quality questions by automatically generating question titles for a code snippet using a deep sequence-to-sequence learning approach.",1,1,0,0,0,0
2309,"Our approach is fully data-driven and uses an attention mechanism to perform better content selection, a copy mechanism to handle the rare-words problem and a coverage mechanism to eliminate word repetition problem.",0,0,1,0,0,0
2310,"We evaluate our approach on Stack Overflow datasets over a variety of programming languages (e.g., Python, Java, Javascript, C# and SQL) and our experimental results show that our approach significantly outperforms several state-of-the-art baselines in both automatic and human evaluation.",0,0,0,1,1,0
2311,We have released our code and datasets to facilitate other researchers to verify their ideas and inspire the follow up work.,0,1,0,0,0,0
2312,Smart contracts are automated or self-enforcing contracts that can be used to exchange assets without having to place trust in third parties.,1,0,0,0,0,0
2313,Many commercial transactions use smart contracts due to their potential benefits in terms of secure peer-to-peer transactions independent of external parties.,1,0,0,0,0,0
2314,"Experience shows that many commonly used smart contracts are vulnerable to serious malicious attacks, which may enable attackers to steal valuable assets of involving parties.",1,0,0,0,0,0
2315,"There is, therefore, a need to apply analysis and automated repair techniques to detect and repair bugs in smart contracts before being deployed.",1,0,0,0,0,0
2316,"In this work, we present the first general-purpose automated smart contract repair approach that is also gas-aware.",0,1,0,0,0,0
2317,Our repair method is search-based and searches among mutations of the buggy contract.,0,0,1,0,0,0
2318,Our method also considers the gas usage of the candidate patches by leveraging our novel notion of gas dominance relationship.,0,0,1,0,0,0
2319,"We have made our smart contract repair tool SCRepair available open-source, for investigation by the wider community.",0,1,0,0,0,0
2320,Refactoring aims at improving code non-functional attributes without modifying its external behavior.,1,0,0,0,0,0
2321,Previous studies investigated the motivations behind refactoring by surveying developers.,1,0,0,0,0,0
2322,"With the aim of generalizing and complementing their findings, we present a large-scale study quantitatively and qualitatively investigating why developers perform refactoring in open source projects.",0,0,1,1,0,0
2323,"First, we mine 287,813 refactoring operations performed in the history of 150 systems.",0,0,0,1,0,0
2324,"Using this dataset, we investigate the interplay between refactoring operations and process (e.g., previous changes/fixes) and product (e.g., quality metrics) metrics.",0,0,0,1,0,0
2325,"Then, we manually analyze 551 merged pull requests implementing refactoring operations and classify the motivations behind the implemented refactorings (e.g., removal of code duplication).",0,0,0,1,0,0
2326,"Our results led to (i) quantitative evidence of the relationship existing between certain process/product metrics and refactoring operations and (ii) a detailed taxonomy, generalizing and complementing the ones existing in the literature, of motivations pushing developers to refactor source code.",0,0,0,0,1,0
2327,"Raw lines of code (LOC) is a metric that does not, at first glance, seem extremely useful for automated test generation.",1,0,0,0,0,0
2328,"It is both highly language-dependent and not extremely meaningful, semantically, within a language: one coder can produce the same effect with many fewer lines than another.",1,0,0,0,0,0
2329,"However, relative LOC, between components of the same project, turns out to be a highly useful metric for automated testing.",1,0,0,0,0,0
2330,"In this article, we make use of a heuristic based on LOC counts for tested functions to dramatically improve the effectiveness of automated test generation.",0,0,1,0,0,0
2331,This approach is particularly valuable in languages where collecting code coverage data to guide testing has a very high overhead.,0,0,1,0,0,0
2332,We apply the heuristic to property-based Python testing using the TSTL (Template Scripting Testing Language) tool.,0,0,0,1,0,0
2333,"In our experiments, the simple LOC heuristic can improve branch and statement coverage by large margins (often more than 20%, up to 40% or more) and improve fault detection by an even larger margin (usually more than 75% and up to 400% or more).",0,0,0,0,1,0
2334,"The LOC heuristic is also easy to combine with other approaches and is comparable to, and possibly more effective than, two well-established approaches for guiding random testing.",0,0,1,0,0,0
2335,Learning representation for source code is a foundation of many program analysis tasks.,1,0,0,0,0,0
2336,"In recent years, neural networks have already shown success in this area, but most existing models did not make full use of the unique structural information of programs.",1,0,0,0,0,0
2337,"Although abstract syntax tree (AST)-based neural models can handle the tree structure in the source code, they cannot capture the richness of different types of substructure in programs.",1,0,0,0,0,0
2338,"In this article, we propose a modular tree network that dynamically composes different neural network units into tree structures based on the input AST.",0,1,1,0,0,0
2339,"Different from previous tree-structural neural network models, a modular tree network can capture the semantic differences between types of AST substructures.",0,0,1,0,0,0
2340,We evaluate our model on two tasks: program classification and code clone detection.,0,0,0,1,0,0
2341,"Our model achieves the best performance compared with state-of-the-art approaches in both tasks, showing the advantage of leveraging more elaborate structure information of the source code.",0,0,0,0,1,0
2342,We introduce two complementary approaches to monitor decentralized systems.,0,1,1,0,0,0
2343,"The first approach relies on systems with a centralized specification, i.e., when the specification is written for the behavior of the entire system.",0,0,1,0,0,0
2344,"To do so, our approach introduces a data structure that (i) keeps track of the execution of an automaton (ii) has predictable parameters and size, and (iii) guarantees strong eventual consistency.",0,0,1,0,0,0
2345,The second approach defines decentralized specifications wherein multiple specifications are provided for separate parts of the system.,0,0,1,0,0,0
2346,We study two properties of decentralized specifications pertaining to monitorability and compatibility between specification and architecture.,0,1,1,0,0,0
2347,We also present a general algorithm for monitoring decentralized specifications.,0,1,1,0,0,0
2348,We map three existing algorithms to our approaches and provide a framework for analyzing their behavior.,0,1,1,0,0,0
2349,"Furthermore, we present THEMIS, a framework for designing such decentralized algorithms and simulating their behavior.",0,1,1,0,0,0
2350,We demonstrate the usage of THEMIS to compare multiple algorithms and validate the trends predicted by the analysis in two scenarios: a synthetic benchmark and the Chiron user interface.,0,1,1,1,0,0
2351,Generic programming is a key paradigm for developing reusable software components.,1,0,0,0,0,0
2352,The inherent support for generic constructs is therefore important in programming languages.,1,0,0,0,0,0
2353,"As for C++, the generic construct, templates, has been supported since the language was first released.",1,0,0,0,0,0
2354,"However, little is currently known about how C++ templates are actually used in developing real software.",1,0,0,0,0,0
2355,"In this study, we conduct an experiment to investigate the use of templates in practice.",0,1,1,1,0,0
2356,"We analyze 1,267 historical revisions of 50 open source systems, consisting of 566 million lines of C++ code, to collect the data of the practical use of templates.",0,0,0,1,0,0
2357,We perform statistical analyses on the collected data and produce many interesting results.,0,0,0,1,1,0
2358,"We uncover the following important findings: (1) templates are practically used to prevent code duplication, but this benefit is largely confined to a few highly used templates; (2) function templates do not effectively replace C-style generics, and developers with a C background do not show significant preference between the two language constructs; (3) developers seldom convert dynamic polymorphism to static polymorphism by using CRTP (Curiously Recursive Template Pattern); (4) the use of templates follows a power-law distribution in most cases, and C++ developers who prefer using templates are those without other language background; (5) C developer background seems to override C++ project guidelines.",0,0,0,0,1,0
2359,These findings are helpful not only for researchers to understand the tendency of template use but also for tool builders to implement better tools to support generic programming.,0,0,0,0,0,1
2360,"In model-driven design of embedded systems, how to generate code from high-level control models seamlessly and correctly is challenging.",1,0,0,0,0,0
2361,"This is because hybrid systems are involved with continuous evolution, discrete jumps, and the complicated entanglement between them, while code only contains discrete actions.",1,0,0,0,0,0
2362,"In this article, we investigate the code generation from Hybrid Communicating Sequential Processes (HCSP), a formal hybrid control model, to SystemC.",0,1,1,0,0,0
2363,"We first introduce the notion of approximate bisimulation as a criterion to check the consistency between two different systems, especially between the original control model and the final generated code.",0,1,1,0,0,0
2364,"We prove that it is decidable whether two HCSPs are approximately bisimilar in bounded time and unbounded time with some conditions, respectively.",0,1,1,0,0,0
2365,"For both the cases, we present two sets of rules correspondingly for discretizing HCSPs and prove that the original HCSP model and the corresponding discretization are approximately bisimilar.",0,1,1,0,0,0
2366,"Furthermore, based on the discretization, we define a transformation function to map a discretized HCSP model to SystemC code such that they are also approximately bisimilar.",0,1,1,0,0,0
2367,We finally implement a tool to automatically realize the translation from HCSP to SystemC code and illustrate our approach through some case studies.,0,1,1,1,0,0
2368,"Bug repair is a major component of software maintenance, which requires a huge amount of manpower.",1,0,0,0,0,0
2369,"Evolutionary computation, particularly genetic programming (GP), is a class of promising techniques for automating this time-consuming and expensive process.",1,0,0,0,0,0
2370,"Although recent research in evolutionary program repair has made significant progress, major challenges still remain.",1,0,0,0,0,0
2371,"In this article, we propose ARJA-e, a new evolutionary repair system for Java code that aims to address challenges for the search space, search algorithm, and patch overfitting.",0,1,1,0,0,0
2372,"To determine a search space that is more likely to contain correct patches, ARJA-e combines two sources of fix ingredients (i.e., the statement-level redundancy assumption and repair templates) with contextual analysis-based search space reduction, thereby leveraging their complementary strengths.",0,0,1,0,0,0
2373,"To encode patches in GP more properly, ARJA-e unifies the edits at different granularities into statement-level edits and then uses a lower-granularity patch representation that is characterized by the decoupling of statements for replacement and statements for insertion.",0,0,1,0,0,0
2374,"ARJA-e also uses a finer-grained fitness function that can make full use of semantic information contained in the test suite, which is expected to better guide the search of GP.",0,0,1,0,0,0
2375,"To alleviate patch overfitting, ARJA-e further includes a postprocessing tool that can serve the purposes of overfit detection and patch ranking.",0,0,1,0,0,0
2376,We evaluate ARJA-e on 224 real Java bugs from Defects4J and compare it with the state-of-the-art repair techniques.,0,0,0,1,0,0
2377,"The evaluation results show that ARJA-e can correctly fix 39 bugs in terms of the patches ranked first, achieving substantial performance improvements over the state of the art.",0,0,0,0,1,0
2378,"In addition, we analyze the effect of the components of ARJA-e qualitatively and quantitatively to demonstrate their effectiveness and advantages.",0,0,0,0,0,1
2379,"A Software Product Line (SPL) is a set of products built from a number of features, the set of valid products being defined by a feature model.",1,0,0,0,0,0
2380,"Typically, it does not make sense to test all products defined by an SPL and one instead chooses a set of products to test (test selection) and, ideally, derives a good order in which to test them (test prioritisation).",1,0,0,0,0,0
2381,"Since one cannot know in advance which products will reveal faults, test selection and prioritisation are normally based on objective functions that are known to relate to likely effectiveness or cost.",1,0,0,0,0,0
2382,"This article introduces a new technique, the grid-based evolution strategy (GrES), which considers several objective functions that assess a selection or prioritisation and aims to optimise on all of these.",0,1,1,0,0,0
2383,The problem is thus a many-objective optimisation problem.,0,0,1,0,0,0
2384,"We use a new approach, in which all of the objective functions are considered but one (pairwise coverage) is seen as the most important.",0,0,1,0,0,0
2385,We also derive a novel evolution strategy based on domain knowledge.,0,1,1,0,0,0
2386,"The results of the evaluation, on randomly generated and realistic feature models, were promising, with GrES outperforming previously proposed techniques and a range of many-objective optimisation algorithms.",0,0,0,1,1,0
2387,We address the problem of engineering a sociotechnical system (STS) with respect to its stakeholders’ requirements.,0,1,1,0,0,0
2388,"We motivate a two-tier STS conception composed of a technical tier that provides control mechanisms and describes what actions are allowed by the software components, and a social tier that characterizes the stakeholders’ expectations of each other in terms of norms.",0,1,1,0,0,0
2389,"We adopt agents as computational entities, each representing a different stakeholder.",0,1,1,0,0,0
2390,"Unlike previous approaches, our framework, DESEN, incorporates the social dimension into the formal verification process.",0,0,1,0,0,0
2391,"Thus, DESEN supports agents potentially violating applicable norms—a consequence of their autonomy.",0,0,1,0,0,0
2392,"In addition to requirements verification, DESEN supports refinement of STS specifications via design patterns to meet stated requirements.",0,0,1,0,0,0
2393,We evaluate DESEN at three levels.,0,0,0,1,0,0
2394,We illustrate how DESEN carries out refinement via the application of patterns on a hospital emergency scenario.,0,0,0,1,0,0
2395,We show via a human-subject study that a design process based on our patterns is helpful for participants who are inexperienced in conceptual modeling and norms.,0,0,0,1,1,0
2396,"We provide an agent-based environment to simulate the hospital emergency scenario to compare STS specifications (including participant solutions from the human-subject study) with metrics indicating social welfare and norm compliance, and other domain dependent metrics.",0,0,0,1,0,0
2397,Grown software systems often contain code that is not necessary anymore.,1,0,0,0,0,0
2398,"Such unnecessary code wastes resources during development and maintenance, for example, when preparing code for migration or certification.",1,0,0,0,0,0
2399,"Running a profiler may reveal code that is not used in production, but it is often time-consuming to obtain representative data in this way.",1,0,0,0,0,0
2400,"We investigate to what extent a static analysis approach, which is based on code stability and code centrality, is able to identify unnecessary code and whether its recommendations are relevant in practice.",0,1,1,0,0,0
2401,"To study the feasibility and usefulness of our approach, we conducted a study involving 14 open-source and closed-source software systems.",0,0,0,1,0,0
2402,"As there is no perfect oracle for unnecessary code, we compared recommendations for unnecessary code with historical cleanups, runtime usage data, and feedback from 25 developers of five software projects.",0,0,0,1,0,0
2403,Our study shows that recommendations generated from stability and centrality information point to unnecessary code that cannot be identified by dead code detectors.,0,0,0,0,1,0
2404,Developers confirmed that 34% of recommendations were indeed unnecessary and deleted 20% of the recommendations shortly after our interviews.,0,0,0,0,1,0
2405,"Overall, our results suggest that static analysis can provide quick feedback on unnecessary code and is useful in practice.",0,0,0,0,0,1
2406,Machine learning–based classification dominates current malware detection approaches for Android.,1,0,0,0,0,0
2407,"However, due to the evolution of both the Android platform and its user apps, existing such techniques are widely limited by their reliance on new malware samples, which may not be timely available, and constant retraining, which is often very costly.",1,0,0,0,0,0
2408,"As a result, new and emerging malware slips through, as seen from the continued surging of malware in the wild.",1,0,0,0,0,0
2409,"Thus, a more practical detector needs not only to be accurate on particular datasets but, more critically, to be able to sustain its capabilities over time without frequent retraining.",1,0,0,0,0,0
2410,"In this article, we propose and study the sustainability problem for learning-based app classifiers.",0,1,1,0,0,0
2411,We define sustainability metrics and compare them among five state-of-the-art malware detectors for Android.,0,1,1,0,0,0
2412,"We further developed DroidSpan, a novel classification system based on a new behavioral profile for Android apps that captures sensitive access distribution from lightweight profiling.",0,0,1,0,0,0
2413,"We evaluated the sustainability of DroidSpan versus the five detectors as baselines on longitudinal datasets across the past eight years, which include 13,627 benign apps and 12,755 malware.",0,0,0,1,0,0
2414,"Through our extensive experiments, we showed that DroidSpan significantly outperformed all the baselines in substainability at reasonable costs, by 6%–32% for same-period detection and 21%–37% for over-time detection.",0,0,0,1,0,0
2415,"The main takeaway, which also explains the superiority of DroidSpan, is that the use of features consistently differentiating malware from benign apps over time is essential for sustainable learning-based malware detection, and that these features can be learned from studies on app evolution.",0,0,0,0,1,0
2416,Distributed systems pose unique challenges for software developers.,1,0,0,0,0,0
2417,Understanding the system’s communication topology and reasoning about concurrent activities of system hosts can be difficult.,1,0,0,0,0,0
2418,"The standard approach, analyzing system logs, can be a tedious and complex process that involves reconstructing a system log from multiple hosts’ logs, reconciling timestamps among hosts with non-synchronized clocks, and understanding what took place during the execution encoded by the log.",1,0,0,0,0,0
2419,"This article presents a novel approach for tackling three tasks frequently performed during analysis of distributed system executions: (1) understanding the relative ordering of events, (2) searching for specific patterns of interaction between hosts, and (3) identifying structural similarities and differences between pairs of executions.",0,1,1,0,0,0
2420,"Our approach consists of XVector, which instruments distributed systems to capture partial ordering information that encodes the happens-before relation between events, and ShiViz, which processes the resulting logs and presents distributed system executions as interactive time-space diagrams.",0,0,1,0,0,0
2421,"Two user studies with a total of 109 students and a case study with 2 developers showed that our method was effective, helping participants answer statistically significantly more system-comprehension questions correctly, with a very large effect size.",0,0,0,1,1,0
2422,Search-Based Software Engineering (SBSE) researchers who apply multi-objective search algorithms (MOSAs) often assess the quality of solutions produced by MOSAs with one or more quality indicators (QIs).,1,0,0,0,0,0
2423,"However, SBSE lacks evidence providing insights on commonly used QIs, especially about agreements among them and their relations with SBSE problems and applied MOSAs.",1,0,0,0,0,0
2424,"Such evidence about QIs agreements is essential to understand relationships among QIs, identify redundant QIs, and consequently devise guidelines for SBSE researchers to select appropriate QIs for their specific contexts.",1,0,0,0,0,0
2425,"To this end, we conducted an extensive empirical evaluation to provide insights on commonly used QIs in the context of SBSE, by studying agreements among QIs with and without considering differences of SBSE problems and MOSAs.",0,1,1,1,0,0
2426,"In addition, by defining a systematic process based on three common ways of comparing MOSAs in SBSE, we present additional observations that were automatically produced based on the results of our empirical evaluation.",0,1,0,1,0,0
2427,"These observations can be used by SBSE researchers to gain a better understanding of the commonly used QIs in SBSE, in particular, regarding their agreements.",0,0,0,0,1,0
2428,"Finally, based on the results, we also provide a set of guidelines for SBSE researchers to select appropriate QIs for their particular context.",0,0,0,0,0,1
2429,The ability to generate test data is often a necessary prerequisite for automated software testing.,1,0,0,0,0,0
2430,"For the generated data to be fit for their intended purpose, the data usually have to satisfy various logical constraints.",1,0,0,0,0,0
2431,"When testing is performed at a system level, these constraints tend to be complex and are typically captured in expressive formalisms based on first-order logic.",1,0,0,0,0,0
2432,"Motivated by improving the feasibility and scalability of data generation for system testing, we present a novel approach, whereby we employ a combination of metaheuristic search and Satisfiability Modulo Theories (SMT) for constraint solving.",0,1,1,0,0,0
2433,Our approach delegates constraint solving tasks to metaheuristic search and SMT in such a way as to take advantage of the complementary strengths of the two techniques.,0,0,1,0,0,0
2434,"We ground our work on test data models specified in UML, with OCL used as the constraint language.",0,0,1,0,0,0
2435,We present tool support and an evaluation of our approach over three industrial case studies.,0,0,0,1,0,0
2436,"The results indicate that, for complex system test data generation problems, our approach presents substantial benefits over the state-of-the-art in terms of applicability and scalability.",0,0,0,0,1,0
2437,"An important issue faced during software development is to identify defects and the properties of those defects, if found, in a given source file.",1,0,0,0,0,0
2438,Determining defectiveness of source code assumes significance due to its implications on software development and maintenance cost.,1,0,0,0,0,0
2439,"We present a novel system to estimate the presence of defects in source code and detect attributes of the possible defects, such as the severity of defects.",0,1,1,0,0,0
2440,"The salient elements of our system are: (i) a dataset of newly introduced source code metrics, called PROgramming CONstruct (PROCON) metrics, and (ii) a novel Machine-Learning (ML)-based system, called Defect Estimator for Source Code (DESCo), that makes use of PROCON dataset for predicting defectiveness in a given scenario.",0,0,1,0,0,0
2441,"The dataset was created by processing 30,400+ source files written in four popular programming languages, viz., C, C++, Java, and Python.",0,0,1,0,0,0
2442,The results of our experiments show that DESCo system outperforms one of the state-of-the-art methods with an improvement of 44.9%.,0,0,0,1,1,0
2443,"To verify the correctness of our system, we compared the performance of 12 different ML algorithms with 50+ different combinations of their key parameters.",0,0,0,1,0,0
2444,Our system achieves the best results with SVM technique with a mean accuracy measure of 80.8%.,0,0,0,0,1,0
2445,"Many software services today are hosted on cloud computing platforms, such as Amazon EC2, due to many benefits like reduced operational costs.",1,0,0,0,0,0
2446,"However, node failures in these platforms can impact the availability of their hosted services and potentially lead to large financial losses.",1,0,0,0,0,0
2447,"Predicting node failures before they actually occur is crucial, as it enables DevOps engineers to minimize their impact by performing preventative actions.",1,0,0,0,0,0
2448,"However, such predictions are hard due to many challenges like the enormous size of the monitoring data and the complexity of the failure symptoms.",1,0,0,0,0,0
2449,"AIOps (Artificial Intelligence for IT Operations), a recently introduced approach in DevOps, leverages data analytics and machine learning to improve the quality of computing platforms in a cost-effective manner.",1,0,0,0,0,0
2450,"However, the successful adoption of such AIOps solutions requires much more than a top-performing machine learning model.",1,0,0,0,0,0
2451,"Instead, AIOps solutions must be trustable, interpretable, maintainable, scalable, and evaluated in context.",1,0,0,0,0,0
2452,"To cope with these challenges, in this article we report our process of building an AIOps solution for predicting node failures for an ultra-large-scale cloud computing platform at Alibaba.",0,1,1,0,0,0
2453,"We expect our experiences to be of value to researchers and practitioners, who are interested in building and maintaining AIOps solutions for large-scale cloud computing platforms.",0,0,0,0,0,1
2454,Spectre-style attacks disclosed in early 2018 expose data leakage scenarios via cache side channels.,1,0,0,0,0,0
2455,"Specifically, speculatively executed paths due to branch mis-prediction may bring secret data into the cache, which are then exposed via cache side channels even after the speculative execution is squashed.",1,0,0,0,0,0
2456,Symbolic execution is a well-known test generation method to cover program paths at the level of the application software.,1,0,0,0,0,0
2457,"In this article, we extend symbolic execution with modeling of cache and speculative execution.",0,1,1,0,0,0
2458,"Our tool KLEESPECTRE, built on top of the KLEE symbolic execution engine, can thus provide a testing engine to check for data leakage through the cache side channel as shown via Spectre attacks.",0,0,1,0,0,0
2459,Our symbolic cache model can verify whether the sensitive data leakage due to speculative execution can be observed by an attacker at a given program point.,0,0,1,0,0,0
2460,Our experiments show that KLEESPECTRE can effectively detect data leakage along speculatively executed paths and our cache model can make the leakage detection more precise.,0,0,0,1,1,0
2461,"The alignment of observed and modeled behavior is an essential element for organizations, since it opens the door for conformance checking and enhancement of processes.",1,0,0,0,0,0
2462,"The state-of-the-art technique for computing alignments has exponential time and space complexity, hindering its applicability for medium and large instances.",1,0,0,0,0,0
2463,"In this article, a novel approach is presented to tackle the challenge of computing an alignment for large-problem instances that correspond to well-formed process models.",0,1,1,0,0,0
2464,"Given an observed trace, first it uses a novel replay technique to find an initial candidate trace in the model.",0,0,1,0,0,0
2465,Then a local search framework is applied to try to improve the alignment until no further improvement is possible.,0,0,1,0,0,0
2466,The implementation of the presented technique reveals a magnificent reduction both in computation time and in memory usage.,0,0,0,0,1,0
2467,"Moreover, although the proposed technique does not guarantee the derivation of an alignment with minimal cost, the experiments show that in practice the quality of the obtained solutions is close to optimal.",0,0,0,1,1,0
2468,"
The rise of highly configurable complex software and its widespread usage requires design of efficient testing methodology.",1,0,0,0,0,0
2469,t-wise coverage is a leading metric to measure the quality of the testing suite and the underlying test generation engine.,1,0,0,0,0,0
2470,"While uniform sampling-based test generation is widely believed to be the state of the art approach to achieve t-wise coverage in presence of constraints on the set of configurations, such a scheme often fails to achieve high t-wise coverage in presence of complex constraints.",1,0,0,0,0,0
2471,"In this work, we propose a novel approach Baital, based on adaptive weighted sampling using literal weighted functions, to generate test sets with high t-wise coverage.",0,1,0,0,0,0
2472,We demonstrate that our approach reaches significantly higher t-wise coverage than uniform sampling.,0,0,0,0,1,0
2473,"The novel usage of literal weighted sampling leaves open several interesting directions, empirical as well as theoretical, for future research.",0,0,0,0,0,1
2474,"
Although deep neural networks have been very successful in image-classification tasks, they are prone to adversarial attacks.",1,0,0,0,0,0
2475,"To generate adversarial inputs, there has emerged a wide variety of techniques, such as black- and whitebox attacks for neural networks.",1,0,0,0,0,0
2476,"In this paper, we present DeepSearch, a novel fuzzing-based, query-efficient, blackbox attack for image classifiers.",0,1,0,0,0,0
2477,"Despite its simplicity, DeepSearch is shown to be more effective in finding adversarial inputs than state-of-the-art blackbox approaches.",0,0,0,0,1,1
2478,DeepSearch is additionally able to generate the most subtle adversarial inputs in comparison to these approaches.,0,0,0,0,1,1
2479,"
Good documentation offers the promise of enabling developers to easily understand design decisions.",1,0,0,0,0,0
2480,"Unfortunately, in practice, design documents are often rarely updated, becoming inaccurate, incomplete, and untrustworthy.",1,0,0,0,0,0
2481,A better solution is to enable developers to write down design rules which are checked against code for consistency.,1,0,0,0,0,0
2482,"But existing rule checkers require learning specialized query languages or program analysis frameworks, creating a barrier to writing project-specific rules.",1,0,0,0,0,0
2483,We introduce two new techniques for authoring design rules: snippet-based authoring and semi-natural-language authoring.,0,1,0,0,0,0
2484,"In snippet-based authoring, developers specify characteristics of elements to match by writing partial code snippets.",0,0,0,0,1,0
2485,"In semi-natural language authoring, a textual representation offers a representation for understanding design rules and resolving ambiguities.",0,0,0,0,1,0
2486,We implemented these approaches in RulePad.,0,0,0,1,0,0
2487,"To evaluate RulePad, we conducted a between-subjects study with 14 participants comparing RulePad to the PMD Designer, a utility for writing rules in a popular rule checker.",0,0,0,1,0,0
2488,We found that those with RulePad were able to successfully author 13 times more query elements in significantly less time and reported being significantly more willing to use RulePad in their everyday work.,0,0,0,0,1,1
2489,"
The Android ecosystem offers different facilities to enable communication among app components and across apps to ensure that rich services can be composed through functionality reuse.",1,0,0,0,0,0
2490,"At the heart of this system is the Inter-component communication (ICC) scheme, which has been largely studied in the literature.",1,0,0,0,0,0
2491,"Less known in the community is another powerful mechanism that allows for direct inter-app code invocation which opens up for different reuse scenarios, both legitimate or malicious.",1,0,0,0,0,0
2492,"This paper exposes the general workflow for this mechanism, which beyond ICCs, enables app developers to access and invoke functionalities (either entire Java classes, methods or object fields) implemented in other apps using official Android APIs.",0,1,0,0,0,0
2493,"We experimentally showcase how this reuse mechanism can be leveraged to “plagiarize"" supposedly-protected functionalities.",0,0,0,1,0,0
2494,"Typically, we were able to leverage this mechanism to bypass security guards that a popular video broadcaster has placed for preventing access to its video database from outside its provided app.",0,0,0,0,1,0
2495,"We further contribute with a static analysis toolkit, named DICIDer, for detecting direct inter-app code invocations in apps.",0,1,0,0,0,0
2496,An empirical analysis of the usage prevalence of this reuse mechanism is then conducted.,0,0,0,1,0,0
2497,"Finally, we discuss the usage contexts as well as the implications of this studied reuse mechanism.",0,0,0,0,0,1
2498,"
Software systems are designed and implemented with assumptions about the environment.",1,0,0,0,0,0
2499,"However, once the system is deployed, the actual environment may deviate from its expected behavior, possibly undermining desired properties of the system.",1,0,0,0,0,0
2500,"To enable systematic design of systems that are robust against potential environmental deviations, we propose a rigorous notion of robustness for software systems.",0,1,0,0,0,0
2501,"In particular, the robustness of a system is defined as the largest set of deviating environmental behaviors under which the system is capable of guaranteeing a desired property.",1,0,0,0,0,0
2502,"We describe a new set of design analysis problems based on our notion of robustness, and a technique for automatically computing robustness of a system given its behavior description.",0,1,0,0,0,0
2503,We demonstrate potential applications of our robustness notion on two case studies involving network protocols and safety-critical interfaces.,0,0,0,1,0,0
2504,"
JavaScript is widely used for implementing client-side web applications, and it is common to include JavaScript code from many different hosts.",1,0,0,0,0,0
2505,"However, in a web browser, all the scripts loaded in the same frame share a single global namespace.",1,0,0,0,0,0
2506,"As a result, a script may read or even overwrite the global objects or functions in other scripts, causing unexpected behaviors.",1,0,0,0,0,0
2507,"For example, a script can redefine a function in a different script as an object, so that any call of that function would cause an exception at run time.",1,0,0,0,0,0
2508,We systematically investigate the client-side JavaScript code integrity problem caused by JavaScript global identifier conflicts in this paper.,0,0,1,0,0,0
2509,"We developed a browser-based analysis framework, JSObserver, to collect and analyze the write operations to global memory locations by JavaScript code.",0,0,0,1,0,0
2510,"We identified three categories of conflicts using JSObserver on the Alexa top 100K websites, and detected 145,918 conflicts on 31,615 websites.",0,0,0,0,1,0
2511,We reveal that JavaScript global identifier conflicts are prevalent and could cause behavior deviation at run time.,0,0,0,0,0,1
2512,"In particular, we discovered that 1,611 redefined functions were called after being overwritten, and many scripts modified the value of cookies or redefined cookie-related functions.",0,0,0,0,1,0
2513,Our research demonstrated that JavaScript global identifier conflict is an emerging threat to both the web users and the integrity of web applications.,0,0,0,0,0,1
2514,"
Keeping a good influx of newcomers is critical for open source software projects' survival, while newcomers face many barriers to contributing to a project for the first time.",1,0,0,0,0,0
2515,"To support newcomers onboarding, GitHub encourages projects to apply labels such as good first issue (GFI) to tag issues suitable for newcomers.",1,0,0,0,0,0
2516,"However, many newcomers still fail to contribute even after many attempts, which not only reduces the enthusiasm of newcomers to contribute but makes the efforts of project members in vain.",1,0,0,0,0,0
2517,"To better support the onboarding of newcomers, this paper reports a preliminary study on this mechanism from its application status, effect, problems, and best practices.",0,1,1,0,0,0
2518,"By analyzing 9,368 GFIs from 816 popular GitHub projects and conducting email surveys with newcomers and project members, we obtain the following results.",0,0,0,1,0,0
2519,"We find that more and more projects are applying this mechanism in the past decade, especially the popular projects.",0,0,0,0,1,0
2520,"Compared to common issues, GFIs usually need more days to be solved.",0,0,0,0,1,0
2521,"While some newcomers really join the projects through GFIs, almost half of GFIs are not solved by newcomers.",0,0,0,0,1,0
2522,"We also discover a series of problems covering mechanism (e.g., inappropriate GFIs), project (e.g., insufficient GFIs) and newcomer (e.g., uneven skills) that makes this mechanism ineffective.",0,0,0,0,1,0
2523,"We discover the practices that may address the problems, including identifying GFIs that have informative description and available support, and require limited scope and skill, etc.",0,0,0,0,1,0
2524,"Newcomer onboarding is an important but challenging question in open source projects and our work enables a better understanding of GFI mechanism and its problems, as well as highlights ways in improving them.",0,0,0,0,0,1
2525,"
Loop invariant generation has long been a challenging problem.",1,0,0,0,0,0
2526,Black-box learning has recently emerged as a promising method for inferring loop invariants.,1,0,0,0,0,0
2527,"However, the performance depends heavily on the quality of collected examples.",1,0,0,0,0,0
2528,"In many cases, only after tens or even hundreds of constraint queries, can a feasible invariant be successfully inferred.",1,0,0,0,0,0
2529,"To reduce the gigantic number of constraint queries and improve the performance of black-box learning, we introduce interval counterexamples into the learning framework.",0,1,0,0,0,0
2530,Each interval counterexample represents a set of counterexamples from constraint solvers.,0,0,0,0,1,0
2531,We propose three different generalization techniques to compute interval counterexamples.,0,0,0,0,1,0
2532,The existing decision tree algorithm is also improved to adapt interval counterexamples.,0,0,0,0,1,0
2533,We evaluate our techniques and report over 40% improvement on learning rounds and verification time over the state-of-the-art approach.,0,0,0,0,1,1
2534,"
Machine translation software has become heavily integrated into our daily lives due to the recent improvement in the performance of deep neural networks.",1,0,0,0,0,0
2535,"However, machine translation software has been shown to regularly return erroneous translations, which can lead to harmful consequences such as economic loss and political conflicts.",1,0,0,0,0,0
2536,"Additionally, due to the complexity of the underlying neural models, testing machine translation systems presents new challenges.",1,0,0,0,0,0
2537,"To address this problem, we introduce a novel methodology called PatInv.",0,1,0,0,0,0
2538,The main intuition behind PatInv is that sentences with different meanings should not have the same translation.,0,1,0,0,0,0
2539,"Under this general idea, we provide two realizations of PatInv that given an arbitrary sentence, generate syntactically similar but semantically different sentences by: (1) replacing one word in the sentence using a masked language model or (2) removing one word or phrase from the sentence based on its constituency structure.",0,0,0,1,0,0
2540,We then test whether the returned translations are the same for the original and modified sentences.,0,0,0,1,0,0
2541,We have applied PatInv to test Google Translate and Bing Microsoft Translator using 200 English sentences.,0,0,0,1,0,0
2542,Two language settings are considered: English-Hindi (En-Hi) and English-Chinese (En-Zh).,0,0,0,1,0,0
2543,"The results show that PatInv can accurately find 308 erroneous translations in Google Translate and 223 erroneous translations in Bing Microsoft Translator, most of which cannot be found by the state-of-the-art approaches.",0,0,0,0,1,1
2544,"
Mutation testing research has often used the number of mutants as a surrogate measure for the true execution cost of generating and executing mutants.",1,0,0,0,0,0
2545,This poses a potential threat to the validity of the scientific findings reported in the literature.,1,0,0,0,0,0
2546,"Out of 75 works surveyed in this paper, we found that 54 (72%) are vulnerable to this threat.",0,0,0,1,1,0
2547,"To investigate the magnitude of the threat, we conducted an empirical evaluation using 10 real-world programs.",0,0,1,1,0,0
2548,"The results reveal that: i) percentages of randomly sampled mutants differ from the true execution time, on average, by 44%, varying in difference from 19% to 91%; ii) errors arising from using the surrogate correlate with program size (ρ = 0.74) and number of mutants (ρ = 0.76), making the problem more pernicious for more realistic programs; iii) scientific findings concerning sampling strategies would have approximately 37% rank disagreement, indicating potentially dramatic impact on experiment validity.",0,0,0,0,1,0
2549,"To investigate whether this threat matters in practice, we reproduced a seminal study on Selective Mutation (widely relied upon for more than two decades).",0,0,0,1,0,0
2550,The impact is stark: an inconclusive scientific finding using the surrogate is transformed to an unequivocal finding when using the true execution cost.,0,0,0,0,0,1
2551,"
Robots that support humans by performing useful tasks (a.k.a., service robots) are booming worldwide.",1,0,0,0,0,0
2552,"In contrast to industrial robots, the development of service robots comes with severe software engineering challenges, since they require high levels of robustness and autonomy to operate in highly heterogeneous environments.",1,0,0,0,0,0
2553,"As a domain with critical safety implications, service robotics faces a need for sound software development practices.",1,0,0,0,0,0
2554,"In this paper, we present the first large-scale empirical study to assess the state of the art and practice of robotics software engineering.",1,0,1,0,0,0
2555,We conducted 18 semi-structured interviews with industrial practitioners working in 15 companies from 9 different countries and a survey with 156 respondents from 26 countries from the robotics domain.,0,0,0,1,0,0
2556,"Our results provide a comprehensive picture of (i) the practices applied by robotics industrial and academic practitioners, including processes, paradigms, languages, tools, frameworks, and reuse practices, (ii) the distinguishing characteristics of robotics software engineering, and (iii) recurrent challenges usually faced, together with adopted solutions.",0,0,0,0,1,0
2557,"The paper concludes by discussing observations, derived hypotheses, and proposed actions for researchers and practitioners.",0,0,0,0,0,1
2558,"
Equivalence checking techniques help establish whether two versions of a program exhibit the same behavior.",1,0,0,0,0,0
2559,The majority of popular techniques for formally proving/refuting equivalence relies on symbolic execution – a static analysis approach that reasons about program behaviors in terms of symbolic input variables.,1,0,0,0,0,0
2560,"Yet, symbolic execution is difficult to scale in practice due to complex programming constructs, such as loops and non-linear arithmetic.",1,0,0,0,0,0
2561,"This paper proposes an approach, named ARDiff, for improving the scalability of symbolic-execution-based equivalence checking techniques when comparing syntactically-similar versions of a program, e.g., for verifying the correctness of code upgrades and refactoring.",0,1,0,0,0,0
2562,"Our approach relies on a set of novel heuristics to determine which parts of the versions’ common code can be effectively pruned during the analysis, reducing the analysis complexity without sacrificing its effectiveness.",0,0,0,1,0,0
2563,"Furthermore, we devise a new equivalence checking benchmark, extending existing benchmarks with a set of real-life methods containing complex math functions and loops.",0,0,0,1,0,0
2564,"We evaluate the effectiveness and efficiency of ARDiff on this benchmark and show that it outperforms existing method-level equivalence checking techniques by solving 86% of all equivalent and 55% of non-equivalent cases, compared with 47% to 69% for equivalent and 38% to 52% for non-equivalent cases in related work.",0,0,0,0,1,1
2565,"
In large-scale cloud systems, unplanned service interruptions and outages may cause severe degradation of service availability.",1,0,0,0,0,0
2566,"Such incidents can occur in a bursty manner, which will deteriorate user satisfaction.",1,0,0,0,0,0
2567,Identifying incidents rapidly and accurately is critical to the operation and maintenance of a cloud system.,1,0,0,0,0,0
2568,"In industrial practice, incidents are typically detected through analyzing the issue reports, which are generated over time by monitoring cloud services.",1,0,0,0,0,0
2569,Identifying incidents in a large number of issue reports is quite challenging.,1,0,0,0,0,0
2570,An issue report is typically multi-dimensional: it has many categorical attributes.,1,0,0,0,0,0
2571,It is difficult to identify a specific attribute combination that indicates an incident.,1,0,0,0,0,0
2572,"Existing methods generally rely on pruning-based search, which is time-consuming given high-dimensional data, thus not practical to incident detection in large-scale cloud systems.",1,0,0,0,0,0
2573,"In this paper, we propose MID (Multi-dimensional Incident Detection), a novel framework for identifying incidents from large-amount, multi-dimensional issue reports effectively and efficiently.",0,1,0,0,0,0
2574,Key to the MID design is encoding the problem into a combinatorial optimization problem.,0,0,0,1,0,0
2575,"Then a specific-tailored meta-heuristic search method is designed, which can rapidly identify attribute combinations that indicate incidents.",0,0,0,1,0,0
2576,We evaluate MID with extensive experiments using both synthetic data and real-world data collected from a large-scale production cloud system.,0,0,0,1,0,0
2577,The experimental results show that MID significantly outperforms the current state-of-the-art methods in terms of effectiveness and efficiency.,0,0,0,0,1,0
2578,"Additionally, MID has been successfully applied to Microsoft's cloud systems and helped greatly reduce manual maintenance effort.",0,0,0,0,1,1
2579,"
We present HOMI, a new technique to enhance symbolic execution by maintaining only a small number of promising states.",0,1,0,0,0,0
2580,"In practice, symbolic execution typically maintains as many states as possible in a fear of losing important states.",1,0,0,0,0,0
2581,"In this paper, however, we show that only a tiny subset of the states plays a significant role in increasing code coverage or reaching bug points.",0,0,0,0,1,0
2582,"Based on this observation, HOMI aims to minimize the total number of states while keeping “promising” states during symbolic execution.",0,0,0,1,0,0
2583,We identify promising states by a learning algorithm that continuously updates the probabilistic pruning strategy based on data accumulated during the testing process.,0,0,0,1,0,0
2584,Experimental results show that HOMI greatly increases code coverage and the ability to find bugs of KLEE on open-source C programs.,0,0,0,0,1,1
2585,"
Fuzz testing has been proved its effectiveness in discovering software vulnerabilities.",1,0,0,0,0,0
2586,"Empowered its randomness nature along with a coverage-guiding feature, fuzzing has been identified a vast number of vulnerabilities in real-world programs.",1,0,0,0,0,0
2587,This paper begins with an observation that the design of the current state-of-the-art fuzzers is not well suited for a particular (but yet important) set of software programs.,1,0,0,0,0,0
2588,"Specifically, current fuzzers have limitations in fuzzing programs serving multiple purposes, where each purpose is controlled by extra options.",1,0,0,0,0,0
2589,"This paper proposes CrFuzz, which overcomes this limitation.",0,1,0,0,0,0
2590,CrFuzz designs a clustering analysis to automatically predict if a newly given input would be accepted or not by a target program.,0,0,0,1,0,0
2591,"Exploiting this prediction capability, CrFuzz is designed to efficiently explore the programs with multiple purposes.",0,0,0,1,0,0
2592,"We employed CrFuzz for three state-of-the-art fuzzers, AFL, QSYM, and MOpt, and CrFuzz-augmented versions have shown 19.3% and 5.68% better path and edge coverage on average.",0,0,0,0,1,0
2593,"More importantly, during two weeks of long-running experiments, CrFuzz discovered 277 previously unknown vulnerabilities where 212 of those are already confirmed and fixed by the respected vendors.",0,0,0,0,1,0
2594,"We would like to emphasize that many of these vulnerabilities were discoverd from FFMpeg, ImageMagick, and Graphicsmagick, all of which are targets of Google's OSS-Fuzz project and thus heavily fuzzed for last three years by far.",0,0,0,0,1,0
2595,"Nevertheless, CrFuzz identified a remarkable number of vulnerabilities, demonstrating its effectiveness of vulnerability finding capability.",0,0,0,0,0,1
2596,"
In large-scale online service systems, incidents occur frequently due to a variety of causes, from updates of software and hardware to changes in operation environment.",1,0,0,0,0,0
2597,These incidents could significantly degrade system’s availability and customers’ satisfaction.,1,0,0,0,0,0
2598,Some incidents are linked because they are duplicate or inter-related.,1,0,0,0,0,0
2599,The linked incidents can greatly help on-call engineers find mitigation solutions and identify the root causes.,1,0,0,0,0,0
2600,"In this work, we investigate the incidents and their links in a representative real-world incident management (IcM) system.",0,0,1,0,0,0
2601,"Based on the identified indicators of linked incidents, we further propose LiDAR (Linked Incident identification with DAta-driven Representation), a deep learning based approach to incident linking.",0,1,0,0,0,0
2602,"More specifically, we incorporate the textual description of incidents and structural information extracted from historical linked incidents to identify possible links among a large number of incidents.",0,1,0,0,0,0
2603,"To show the effectiveness of our method, we apply our method to a real-world IcM system and find that our method outperforms other state-of-the-art methods.",0,0,0,1,0,0
2604,"
Recent effort to test deep learning systems has produced an intuitive and compelling test criterion called neuron coverage (NC), which resembles the notion of traditional code coverage.",1,0,0,0,0,0
2605,NC measures the proportion of neurons activated in a neural network and it is implicitly assumed that increasing NC improves the quality of a test suite.,1,0,0,0,0,0
2606,"In an attempt to automatically generate a test suite that increases NC, we design a novel diversity promoting regularizer that can be plugged into existing adversarial attack algorithms.",0,1,0,0,0,0
2607,"We then assess whether such attempts to increase NC could generate a test suite that (1) detects adversarial attacks successfully, (2) produces natural inputs, and (3) is unbiased to particular class predictions.",0,0,1,0,0,0
2608,"Contrary to expectation, our extensive evaluation finds that increasing NC actually makes it harder to generate an effective test suite: higher neuron coverage leads to fewer defects detected, less natural inputs, and more biased prediction preferences.",0,0,0,0,1,0
2609,"Our results invoke skepticism that increasing neuron coverage may not be a meaningful objective for generating tests for deep neural networks and call for a new test generation technique that considers defect detection, naturalness, and output impartiality in tandem.",0,0,0,0,0,1
2610,"
Smart contracts are computer programs allowing users to define and execute transactions automatically on top of the blockchain platform.",1,0,0,0,0,0
2611,Many of such smart contracts can be viewed as games.,1,0,0,0,0,0
2612,"A game-like contract accepts inputs from multiple participants, and upon ending, automatically derives an outcome while distributing assets according to some predefined rules.",1,0,0,0,0,0
2613,"Without clear understanding of the game rules, participants may suffer from fraudulent advertisements and financial losses.",1,0,0,0,0,0
2614,"In this paper, we present a framework to perform (semi-)automated verification of smart contract fairness, whose results can be used to refute false claims with concrete examples or certify contract implementations with respect to desired fairness properties.",0,1,0,0,0,0
2615,"We implement FairCon, which is able to check fairness properties including truthfulness, efficiency, optimality, and collusion-freeness for Ethereum smart contracts.",0,0,0,1,0,0
2616,We evaluate FairCon on a set of real-world benchmarks and the experiment result indicates that FairCon is effective in detecting property violations and able to prove fairness for common types of contracts.,0,0,0,1,0,1
2617,"
Exception handling is an effective mechanism to avoid unexpected runtime errors.",1,0,0,0,0,0
2618,"However, novice programmers might fail to handle exceptions properly, causing serious errors like system crashing or resource leaking.",1,0,0,0,0,0
2619,"In this paper, we introduce FuzzyCatch, a code recommendation tool for handling exceptions.",0,1,0,0,0,0
2620,"Based on fuzzy logic, FuzzyCatch can predict if a runtime exception would occur in a given code snippet and recommend code to handle that exception.",0,0,0,1,0,0
2621,FuzzyCatch is implemented as a plugin for Android Studio.,0,0,0,1,0,0
2622,The empirical evaluation suggests that FuzzyCatch is highly effective.,0,0,0,1,1,0
2623,"For example, it has top-1 accuracy of 77% on recommending what exception to catch in a try catch block and of 70% on recommending what method should be called when such an exception occurs.",0,0,0,0,1,0
2624,FuzzyCatch also achieves a high level of accuracy and outperforms baselines significantly on detecting and fixing real exception bugs.,0,0,0,0,0,1
2625,"
Software reuse lowers development costs and improves the quality of software systems.",1,0,0,0,0,0
2626,Two strategies are common: clone & own (copying and adapting a system) and platform-oriented reuse (building a configurable platform).,1,0,0,0,0,0
2627,"The former is readily available, flexible, and initially cheap, but does not scale with the frequency of reuse, imposing high maintenance costs.",1,0,0,0,0,0
2628,"The latter scales, but imposes high upfront investments for building the platform, and reduces flexibility.",1,0,0,0,0,0
2629,"As such, each strategy has distinctive advantages and disadvantages, imposing different development activities and software architectures.",1,0,0,0,0,0
2630,Deciding for one strategy is a core decision with long-term impact on an organization’s software development.,1,0,0,0,0,0
2631,"Unfortunately, the strategies’ costs are not well-understood - not surprisingly, given the lack of systematically elicited empirical data, which is difficult to collect.",1,0,0,0,0,0
2632,"We present an empirical study of the development activities, costs, cost factors, and benefits associated with either reuse strategy.",0,0,1,1,0,0
2633,"For this purpose, we combine quantitative and qualitative data that we triangulated from 26 interviews at a large organization and a systematic literature review covering 57 publications.",0,0,0,1,0,0
2634,Our study both confirms and refutes common hypotheses on software reuse.,0,0,0,0,1,0
2635,"For instance, we confirm that developing for platform-oriented reuse is more expensive, but simultaneously reduces reuse costs; and that platform-orientation results in higher code quality compared to clone & own.",0,0,0,0,1,0
2636,"Surprisingly, refuting common hypotheses, we find that change propagation can be more expensive in a platform, that platforms can facilitate the advancement into innovative markets, and that there is no strict distinction of clone & own and platform-oriented reuse in practice.",0,0,0,0,0,1
2637,"
A large percentage of real-world software configuration issues, such as misconfigurations, involve multiple interdependent configuration parameters.",1,0,0,0,0,0
2638,"However, existing techniques and tools either do not consider dependencies among configuration parameters— termed configuration dependencies—or rely on one or two dependency types and code patterns as input.",1,0,0,0,0,0
2639,"Without rigorous understanding of configuration dependencies, it is hard to deal with many resulting configuration issues.",1,0,0,0,0,0
2640,"This paper presents our study of software configuration dependencies in 16 widely-used cloud and datacenter systems, including dependencies within and across software components.",0,0,1,0,0,0
2641,"To understand types of configuration dependencies, we conduct an exhaustive search of descriptions in structured configuration metadata and unstructured user manuals.",0,0,0,1,0,0
2642,We find and manually analyze 521 configuration dependencies.,0,0,0,1,0,0
2643,We define five types of configuration dependencies and identify their common code patterns.,0,0,0,0,1,0
2644,We report on consequences of not satisfying these dependencies and current software engineering practices for handling the consequences.,0,0,0,0,1,0
2645,"We mechanize the knowledge gained from our study in a tool, cDep, which detects configuration dependencies.",0,0,0,0,1,0
2646,cDep automatically discovers five types of configuration dependencies from bytecode using static program analysis.,0,0,0,0,1,0
2647,We apply cDep to the eight Java and Scala software systems in our study.,0,0,0,1,0,0
2648,cDep finds 87.9% (275/313) of the related subset of dependencies from our study.,0,0,0,0,1,0
2649,"cDep also finds 448 previously undocumented dependencies, with a 6.0% average false positive rate.",0,0,0,0,1,0
2650,"Overall, our results show that configuration dependencies are more prevalent and diverse than previously reported and should henceforth be considered a first-class issue in software configuration engineering.",0,0,0,0,0,1
2651,"
Deep neural networks (DNNs) have been widely applied in the software development process to automatically learn patterns from massive data.",1,0,0,0,0,0
2652,"However, many applications still make decisions based on rules that are manually crafted and verified by domain experts due to safety or security concerns.",1,0,0,0,0,0
2653,"In this paper, we aim to close the gap between DNNs and rule-based systems by automating the rule generation process via extracting knowledge from well-trained DNNs.",0,1,0,0,0,0
2654,Existing techniques with similar purposes either rely on specific DNNs input instances or use inherently unstable random sampling of the input space.,1,0,0,0,0,0
2655,"Therefore, these approaches either limit the exploration area to a local decision-space of the DNNs or fail to converge to a consistent set of rules.",1,0,0,0,0,0
2656,The resulting rules thus lack representativeness and stability.,1,0,0,0,0,0
2657,"In this paper, we address the two aforementioned shortcomings by discovering a global property of the DNNs and use it to remodel the DNNs decision-boundary.",0,0,1,0,0,0
2658,"We name this property as the activation probability, and show that this property is stable.",0,0,0,0,1,0
2659,"With this insight, we propose an approach named DENAS including a novel rule-generation algorithm.",0,1,0,0,0,0
2660,Our proposed algorithm approximates the non-linear decision boundary of DNNs by iteratively superimposing a linearized optimization function.,0,1,0,0,0,0
2661,"We evaluate the representativeness, stability, and accuracy of DENAS against five state-of-the-art techniques (LEMNA, Gradient, IG, DeepTaylor, and DTExtract) on three software engineering and security applications: Binary analysis, PDF malware detection, and Android malware detection.",0,0,0,1,0,0
2662,Our results show that DENAS can generate more representative rules consistently in a more stable manner over other approaches.,0,0,0,0,1,1
2663,We further offer case studies that demonstrate the applications of DENAS such as debugging faults in the DNNs and generating signatures that can detect zero-day malware.,0,0,0,0,1,0
2664,"
We present a new framework and associated synthesis algorithms for program synthesis over noisy data, i.e., data that may contain incorrect/corrupted input-output examples.",0,1,0,0,0,0
2665,This framework is based on an extension of finite tree automata called state-weighted finite tree automata.,0,1,0,0,0,0
2666,We show how to apply this framework to formulate and solve a variety of program synthesis problems over noisy data.,0,0,0,1,0,0
2667,"Results from our implemented system running on problems from the SyGuS 2018 benchmark suite highlight its ability to successfully synthesize programs in the face of noisy data sets, including the ability to synthesize a correct program even when every input-output example in the data set is corrupted.",0,0,0,0,1,0
2668,"
The Intel Security Guard Extensions (SGX) architecture enables the abstraction of enclaved execution, using which an application can protect its code and data from powerful adversaries, including system software that executes with the highest processor privilege.",1,0,0,0,0,0
2669,"While the Intel SGX architecture exports an ISA with low-level instructions that enable applications to create enclaves, the task of writing applications using this ISA has been left to the software community.",1,0,0,0,0,0
2670,We consider the problem of porting legacy applications to SGX enclaves.,0,0,1,0,0,0
2671,"In the approximately four years to date since the Intel SGX became commercially available, the community has developed three different models to port applications to enclaves---the library OS, the library wrapper, and the instruction wrapper models.",1,0,0,0,0,0
2672,"In this paper, we conduct an empirical evaluation of the merits and costs of each model.",0,1,1,0,0,0
2673,"We report on our attempt to port a handful of real-world application benchmarks (including OpenSSL, Memcached, a Web server and a Python interpreter) to SGX enclaves using prototypes that embody each of the above models.",0,0,0,1,0,0
2674,"Our evaluation focuses on the merits and costs of each of these models from the perspective of the effort required to port code under each of these models, the effort to re-engineer an application to work with enclaves, the security offered by each model, and the runtime performance of the applications under these models.",0,0,0,1,0,0
2675,"
This paper discusses the problem of testing the performance of the adaptation layer in a self-adaptive system.",1,0,0,0,0,0
2676,"The problem is notoriously hard, due to the high degree of uncertainty and variability inherent in an adaptive software application.",1,0,0,0,0,0
2677,"In particular, providing any type of formal guarantee for this problem is extremely difficult.",1,0,0,0,0,0
2678,In this paper we propose the use of a rigorous probabilistic approach to overcome the mentioned difficulties and provide probabilistic guarantees on the software performance.,0,1,1,0,0,0
2679,We describe the set up needed for the application of a probabilistic approach.,0,0,0,1,0,0
2680,"We then discuss the traditional tools from statistics that could be applied to analyse the results, highlighting their limitations and motivating why they are unsuitable for the given problem.",0,0,1,0,0,0
2681,We propose the use of a novel tool – the scenario theory – to overcome said limitations.,0,1,0,0,0,0
2682,"We conclude the paper with a thorough empirical evaluation of the proposed approach, using two adaptive software applications: the Tele-Assistance Service and the Self-Adaptive Video Encoder.",0,0,0,1,0,0
2683,"With the first, we empirically expose the trade-off between data collection and confidence in the testing campaign.",0,0,0,0,1,0
2684,"With the second, we demonstrate how to compare different adaptation strategies.",0,0,0,0,1,0
2685,"
Detecting Graphical User Interface (GUI) elements in GUI images is a domain-specific object detection task.",1,0,0,0,0,0
2686,"It supports many software engineering tasks, such as GUI animation and testing, GUI search and code generation.",1,0,0,0,0,0
2687,"Existing studies for GUI element detection directly borrow the mature methods from computer vision (CV) domain, including old fashioned ones that rely on traditional image processing features (e.g., canny edge, contours), and deep learning models that learn to detect from large-scale GUI data.",1,0,0,0,0,0
2688,"Unfortunately, these CV methods are not originally designed with the awareness of the unique characteristics of GUIs and GUI elements and the high localization accuracy of the GUI element detection task.",1,0,0,0,0,0
2689,"We conduct the first large-scale empirical study of seven representative GUI element detection methods on over 50k GUI images to understand the capabilities, limitations and effective designs of these methods.",0,0,1,0,0,0
2690,This study not only sheds the light on the technical challenges to be addressed but also informs the design of new GUI element detection methods.,0,0,1,0,0,0
2691,"We accordingly design a new GUI-specific old-fashioned method for non-text GUI element detection which adopts a novel top-down coarse-to-fine strategy, and incorporate it with the mature deep learning model for GUI text detection.Our evaluation on 25,000 GUI images shows that our method significantly advances the start-of-the-art performance in GUI element detection.",0,0,0,1,1,0
2692,"
A program fails.",1,0,0,0,0,0
2693,Under which circumstances does the failure occur?,1,0,0,0,0,0
2694,Our Alhazenapproach starts with a run that exhibits a particular behavior and automatically determines input features associated with the behavior in question: (1) We use a grammar to parse the input into individual elements.,0,0,0,1,0,0
2695,(2) We use a decision tree learner to observe and learn which input elements are associated with the behavior in question.,0,0,0,1,0,0
2696,(3) We use the grammar to generate additional inputs to further strengthen or refute hypotheses as learned associations.,0,0,0,1,0,0
2697,"(4) By repeating steps 2 and 3, we obtain a theory that explains and predicts the given behavior.",0,0,0,1,0,0
2698,"In our evaluation using inputs for find, grep, NetHack, and a JavaScript transpiler, the theories produced by Alhazen predict and produce failures with high accuracy and allow developers to focus on a small set of input features: “grep fails whenever the --fixed-strings option is used in conjunction with an empty search string.”",0,0,0,0,1,0
2699,"
Mastering the knowledge about security-sensitive functions that can potentially result in bugs is valuable to detect them.",1,0,0,0,0,0
2700,"However, identifying this kind of functions is not a trivial task.",1,0,0,0,0,0
2701,Introducing machine learning-based techniques to do the task is a natural choice.,1,0,0,0,0,0
2702,"Unfortunately, the approach also requires considerable prior knowledge, e.g., sufficient labelled training samples.",1,0,0,0,0,0
2703,"In practice, the requirement is often hard to meet.",1,0,0,0,0,0
2704,"In this paper, to solve the problem, we propose a novel and practical method called SinkFinder to automatically discover function pairs that we are interested in, which only requires very limited prior knowledge.",0,1,0,0,0,0
2705,SinkFinder first takes just one pair of well-known interesting functions as the initial seed to infer enough positive and negative training samples by means of sub-word word embedding.,0,0,0,1,0,0
2706,"By using these samples, a support vector machine classifier is trained to identify more interesting function pairs.",0,0,0,1,0,0
2707,"Finally, checkers equipped with the obtained knowledge can be easily developed to detect bugs in target systems.",0,0,0,1,0,0
2708,"The experiments demonstrate that SinkFinder can successfully discover hundreds of interesting functions and detect dozens of previously unknown bugs from large-scale systems, such as Linux, OpenSSL and PostgreSQL.",0,0,0,0,1,1
2709,"
With the increasing adoption of Deep Learning (DL) for critical tasks, such as autonomous driving, the evaluation of the quality of systems that rely on DL has become crucial.",1,0,0,0,0,0
2710,"Once trained, DL systems produce an output for any arbitrary numeric vector provided as input, regardless of whether it is within or outside the validity domain of the system under test.",1,0,0,0,0,0
2711,"Hence, the quality of such systems is determined by the intersection between their validity domain and the regions where their outputs exhibit a misbehaviour.",1,0,0,0,0,0
2712,"In this paper, we introduce the notion of frontier of behaviours, i.e., the inputs at which the DL system starts to misbehave.",0,0,1,0,0,0
2713,"If the frontier of misbehaviours is outside the validity domain of the system, the quality check is passed.",0,0,0,1,0,0
2714,"Otherwise, the inputs at the intersection represent quality deficiencies of the system.",0,0,0,1,0,0
2715,"We developed DeepJanus, a search-based tool that generates frontier inputs for DL systems.",0,1,0,0,0,0
2716,"The experimental results obtained for the lane keeping component of a self-driving car show that the frontier of a well trained system contains almost exclusively unrealistic roads that violate the best practices of civil engineering, while the frontier of a poorly trained one includes many valid inputs that point to serious deficiencies of the system.",0,0,0,0,1,1
2717,"
Developers frequently change the type of a program element and update all its references for performance, security, concurrency,library migration, or better maintainability.",1,0,0,0,0,0
2718,"Despite type changes being a common program transformation, it is the least automated and the least studied.",1,0,0,0,0,0
2719,"With this knowledge gap, researchers miss opportunities to improve the state of the art in automation for software evolution, tool builders do not invest resources where automation is most needed, language and library designers can-not make informed decisions when introducing new types, and developers fail to use common practices when changing types.",1,0,0,0,0,0
2720,"To fill this gap, we present the first large-scale and most fine-grained empirical study on type changes in Java.",0,1,0,0,0,0
2721,"We develop state-of-the-art tools to statically mine 297,543 type changes and their subsequent code adaptations from a diverse corpus of 129 Java projects containing 416,652 commits.",0,1,0,0,0,0
2722,With this rich data set we answer research questions about the practice of type changes.,0,0,1,0,0,0
2723,"Among others, we found that type changes are actually more common than renaming,but the current research and tools for type changes are inadequate.Based on our extensive and reliable data, we present actionable,empirically-justified implications.",0,0,0,0,0,1
2724,"
Due to the lexical gap between functionality descriptions and user queries, documentation-based API retrieval often produces poor results.Verb phrases and their phrase patterns are essential in both describing API functionalities and interpreting user queries.",1,0,0,0,0,0
2725,Thus we hypothesize that API retrieval can be facilitated by explicitly recognizing and matching between the fine-grained structures of functionality descriptions and user queries.,0,0,1,0,0,0
2726,"To verify this hypothesis, we conducted a large-scale empirical study on the functionality descriptions of 14,733 JDK and Android API methods.",0,0,0,1,0,0
2727,"We identified 356 different functionality verbs from the descriptions, which were grouped into 87 functionality categories, and we extracted 523 phrase patterns from the verb phrases of the descriptions.",0,0,0,0,1,0
2728,"Building on these findings, we propose an API method recommendation approach based on explicit matching of functionality verb phrases in functionality descriptions and user queries, called PreMA.",0,1,0,0,0,0
2729,"Our evaluation shows that PreMA can accurately recognize the functionality categories (92.8%) and phrase patterns (90.4%) of functionality description sentences; and when used for API retrieval tasks, PreMA can help participants complete their tasks more accurately and with fewer retries compared to a baseline approach.",0,0,0,0,1,1
2730,"
The cloud runs on REST APIs.",1,0,0,0,0,0
2731,"In this paper, we study how to intelligently generate data payloads embedded in REST API requests in order to find data-processing bugs in cloud services.",0,0,1,0,0,0
2732,"We discuss how to leverage REST API specifications, which, by definition, contain data schemas for API request bodies.",0,0,1,0,0,0
2733,"We then propose and evaluate a range of data fuzzing techniques, including structural schema fuzzing rules, various rule combinations, search heuristics, extracting data values from examples included in REST API specifications, and learning data values on-the-fly from previous service responses.",0,0,0,1,0,0
2734,"After evaluating these techniques, we identify the top-performing combination and use this algorithm to fuzz several Microsoft Azure cloud services.",0,0,0,1,0,0
2735,"During our experiments, we found 100s of “Internal Server Error” service crashes, which we triaged into 17 unique bugs and reported to Azure developers.",0,0,0,0,1,0
2736,"All these bugs are reproducible, confirmed, and fixed or in the process of being fixed.",0,0,0,0,1,0
2737,"
Smart home devices provide the convenience of remotely control-ling and automating home appliances.",1,0,0,0,0,0
2738,"The most advanced smart home environments allow developers to write apps to make smart home devices work together to accomplish tasks, e.g., home security and energy conservation.",1,0,0,0,0,0
2739,A smart home app typically implements narrow functionality and thus to fully implement desired functionality homeowners may need to install multiple apps.,1,0,0,0,0,0
2740,These different apps can conflict with each other and these conflicts can result in undesired actions such as locking the door during a fire.,1,0,0,0,0,0
2741,"In this paper, we study conflicts between apps on Samsung SmartThings, the most popular platform for developing and deploying smart home IoT devices.",0,0,1,0,0,0
2742,"By collecting and studying 198 official and 69 third-party apps, we found significant app conflicts in 3 categories: (1) close to 60% of app pairs that access the same device, (2) more than 90% of app pairs with physical interactions, and (3) around 11% of app pairs that access the same global variable.",0,0,0,1,0,0
2743,Our results suggest that the problem of conflicts between smart home apps is serious and can create potential safety risks.,0,0,0,0,1,0
2744,We then developed a conflict detection tool that uses model checking to automatically detect up to 96% of the conflicts.,0,0,0,1,0,0
2745,"
Trained DNN models are increasingly adopted as integral parts of software systems, but they often perform deficiently in the field.",1,0,0,0,0,0
2746,"A particularly damaging problem is that DNN models often give false predictions with high confidence, due to the unavoidable slight divergences between operation data and training data.",1,0,0,0,0,0
2747,"To minimize the loss caused by inaccurate confidence, operational calibration, i.e., calibrating the confidence function of a DNN classifier against its operation domain, becomes a necessary debugging step in the engineering of the whole system.",1,0,0,0,0,0
2748,Operational calibration is difficult considering the limited budget of labeling operation data and the weak interpretability of DNN models.,1,0,0,0,0,0
2749,We propose a Bayesian approach to operational calibration that gradually corrects the confidence given by the model under calibration with a small number of labeled operation data deliberately selected from a larger set of unlabeled operation data.,0,1,0,0,0,0
2750,The approach is made effective and efficient by leveraging the locality of the learned representation of the DNN model and modeling the calibration as Gaussian Process Regression.,0,0,0,1,0,0
2751,"Comprehensive experiments with various practical datasets and DNN models show that it significantly outperformed alternative methods, and in some difficult tasks it eliminated about 71% to 97% high-confidence (>0.9) errors with only about 10% of the minimal amount of labeled operation data needed for practical learning techniques to barely work",0,0,0,0,1,0
2752,"
UI testing is tedious and time-consuming due to the manual effort required.",1,0,0,0,0,0
2753,Recent research has explored opportunities for reusing existing UI tests from an app to automatically generate new tests for other apps.,1,0,0,0,0,0
2754,"However, the evaluation of such techniques currently remains manual, unscalable, and unreproducible, which can waste effort and impede progress in this emerging area.",1,0,0,0,0,0
2755,"We introduce FrUITeR, a framework that automatically evaluates UI test reuse in a reproducible way.",0,1,0,0,0,0
2756,"We apply FrUITeR to existing test-reuse techniques on a uniform benchmark we established, resulting in 11,917 test reuse cases from 20 apps.",0,0,0,1,0,0
2757,We report several key findings aimed at improving UI test reuse that are missed by existing work.,0,0,0,0,0,1
2758,"
Detecting bugs in deep learning software at the architecture level provides additional benefits that detecting bugs at the model level does not provide.",1,0,0,0,0,0
2759,This paper makes the first attempt to conduct static analysis for detecting numerical bugs at the architecture level.,0,0,0,1,0,0
2760,We propose a static analysis approach for detecting numerical bugs in neural architectures based on abstract interpretation.,0,1,0,0,0,0
2761,"Our approach mainly comprises two kinds of abstraction techniques, i.e., one for tensors and one for numerical values.",0,0,0,1,0,0
2762,"Moreover, to scale up while maintaining adequate detection precision, we propose two abstraction techniques: tensor partitioning and (elementwise) affine relation analysis to abstract tensors and numerical values, respectively.",0,1,0,0,0,0
2763,"We realize the combination scheme of tensor partitioning and affine relation analysis (together with interval analysis) as DEBAR, and evaluate it on two datasets: neural architectures with known bugs (collected from existing studies) and real-world neural architectures.",0,0,0,1,0,0
2764,The evaluation results show that DEBAR outperforms other tensor and numerical abstraction techniques on accuracy without losing scalability.,0,0,0,0,1,0
2765,DEBAR successfully detects all known numerical bugs with no false positives within 1.7–2.3 seconds per architecture.,0,0,0,0,1,0
2766,"On the real-world architectures, DEBAR reports 529 warnings within 2.6–135.4 seconds per architecture, where 299 warnings are true positives.",0,0,0,0,1,0
2767,"
Deep learning is being incorporated in many modern software systems.",1,0,0,0,0,0
2768,"Deep learning approaches train a deep neural network (DNN) model using training examples, and then use the DNN model for prediction.",1,0,0,0,0,0
2769,"While the structure of a DNN model as layers is observable, the model is treated in its entirety as a monolithic component.",1,0,0,0,0,0
2770,"To change the logic implemented by the model, e.g. to add/remove logic that recognizes inputs belonging to a certain class, or to replace the logic with an alternative, the training examples need to be changed and the DNN needs to be retrained using the new set of examples.",1,0,0,0,0,0
2771,We argue that decomposing a DNN into DNN modules— akin to decomposing a monolithic software code into modules—can bring the benefits of modularity to deep learning.,0,0,1,0,0,0
2772,"In this work, we develop a methodology for decomposing DNNs for multi-class problems into DNN modules.",0,1,0,0,0,0
2773,"For four canonical problems, namely MNIST, EMNIST, FMNIST, and KMNIST, we demonstrate that such decomposition enables reuse of DNN modules to create different DNNs, enables replacement of one DNN module in a DNN with another without needing to retrain.",0,0,0,0,1,0
2774,The DNN models formed by composing DNN modules are at least as good as traditional monolithic DNNs in terms of test accuracy for our problems.,0,0,0,0,0,1
2775,"
Machine learning software is increasingly being used to make decisions that affect people's lives.",1,0,0,0,0,0
2776,"But sometimes, the core part of this software (the learned model), behaves in a biased manner that gives undue advantages to a specific group of people (where those groups are determined by sex, race, etc.).",1,0,0,0,0,0
2777,"This ""algorithmic discrimination"" in the AI software systems has become a matter of serious concern in the machine learning and software engineering community.",1,0,0,0,0,0
2778,"There have been works done to find ""algorithmic bias"" or ""ethical bias"" in the software system.",1,0,0,0,0,0
2779,"Once the bias is detected in the AI software system, the mitigation of bias is extremely important.",1,0,0,0,0,0
2780,"In this work, we a)explain how ground-truth bias in training data affects machine learning model fairness and how to find that bias in AI software,b)propose a method Fairway which combines pre-processing and in-processing approach to remove ethical bias from training data and trained model.",0,0,1,0,0,0
2781,"Our results show that we can find bias and mitigate bias in a learned model, without much damaging the predictive performance of that model.",0,0,0,0,1,0
2782,We propose that (1) testing for bias and (2) bias mitigation should be a routine part of the machine learning software development life cycle.,0,0,0,0,0,1
2783,Fairway offers much support for these two purposes.,0,0,0,0,0,1
2784,"
Executing software microbenchmarks, a form of small-scale performance tests predominantly used for libraries and frameworks, is a costly endeavor.",1,0,0,0,0,0
2785,"Full benchmark suites take up to multiple hours or days to execute, rendering frequent checks, e.g., as part of continuous integration (CI), infeasible.",1,0,0,0,0,0
2786,"However, altering benchmark configurations to reduce execution time without considering the impact on result quality can lead to benchmark results that are not representative of the software’s true performance.",1,0,0,0,0,0
2787,We propose the first technique to dynamically stop software microbenchmark executions when their results are sufficiently stable.,0,1,0,0,0,0
2788,Our approach implements three statistical stoppage criteria and is capable of reducing Java Microbenchmark Harness (JMH) suite execution times by 48.4% to 86.0%.,0,0,0,0,1,0
2789,"At the same time it retains the same result quality for 78.8% to 87.6% of the benchmarks, compared to executing the suite for the default duration.",0,0,0,0,1,0
2790,"The proposed approach does not require developers to manually craft custom benchmark configurations; instead, it provides automated mechanisms for dynamic reconfiguration.",0,0,0,0,0,1
2791,"Hence, making dynamic reconfiguration highly effective and efficient, potentially paving the way to inclusion of JMH microbenchmarks in CI.",0,0,0,0,0,1
2792,"
Recommendations between colleagues are effective for encouraging developers to adopt better practices.",1,0,0,0,0,0
2793,"Research shows these peer interactions are useful for improving developer behaviors, or the adoption of activities to help software engineers complete programming tasks.",1,0,0,0,0,0
2794,"However, in-person recommendations between developers in the workplace are declining.",1,0,0,0,0,0
2795,"One form of online recommendations between developers are pull requests, which allow users to propose code changes and provide feedback on contributions.",1,0,0,0,0,0
2796,"GitHub, a popular code hosting platform, recently introduced the suggested changes feature, which allows users to recommend improvements for pull requests.",1,0,0,0,0,0
2797,"To better understand this feature and its impact on recommendations between developers, we report an empirical study of this system, measuring usage, effectiveness, and perception.",0,0,1,1,0,0
2798,Our results show that suggested changes support code review activities and significantly impact the timing and communication between developers on pull requests.,0,0,0,0,1,0
2799,"This work provides insight into the suggested changes feature and implications for improving future systems for automated developer recommendations, such as providing situated, concise, and actionable feedback.",0,0,0,0,0,1
2800,"
Fuzzing is a widely used technique for detecting software bugs and vulnerabilities.",1,0,0,0,0,0
2801,Most popular fuzzers generate new inputs using an evolutionary search to maximize code coverage.,1,0,0,0,0,0
2802,"Essentially, these fuzzers start with a set of seed inputs, mutate them to generate new inputs, and identify the promising inputs using an evolutionary fitness function for further mutation.Despite their success, evolutionary fuzzers tend to get stuck in long sequences of unproductive mutations.",1,0,0,0,0,0
2803,"In recent years, machine learning (ML) based mutation strategies have reported promising results.",1,0,0,0,0,0
2804,"However, the existing ML-based fuzzers are limited by the lack of quality and diversity of the training data.",1,0,0,0,0,0
2805,"As the input space of the target programs is high dimensional and sparse, it is prohibitively expensive to collect many diverse samples demonstrating successful and unsuccessful mutations to train the model.In this paper, we address these issues by using a Multi-Task Neural Network that can learn a compact embedding of the input space based on diverse training samples for multiple related tasks (i.e.,predicting for different types of coverage).",0,1,0,0,0,0
2806,The compact embedding can guide the mutation process by focusing most of the mutations on the parts of the embedding where the gradient is high.,0,0,0,0,1,0
2807,MTFuzz uncovers 11 previously unseen bugs and achieves an average of 2× more edge coverage compared with 5 state-of-the-art fuzzer on 10 real-world programs,0,0,0,0,1,0
2808,"
Code coverage analysis plays an important role in the software testing process.",1,0,0,0,0,0
2809,"More recently, the remarkable effectiveness of coverage feedback has triggered a broad interest in feedback-guided fuzzing.",1,0,0,0,0,0
2810,"In this work, we introduce bcov, a tool for binary-level coverage analysis.",0,1,0,0,0,0
2811,Our tool statically instruments x86-64 binaries in the ELF format without compiler support.,0,1,0,0,0,0
2812,We implement several techniques to improve efficiency and scale to large real-world software.,0,1,0,0,0,0
2813,"First, we bring Agrawal’s probe pruning technique to binary-level instrumentation and effectively leverage its superblocks to reduce overhead.",0,0,0,1,0,0
2814,"Second, we introduce sliced microexecution, a robust technique for jump table analysis which improves CFG precision and enables us to instrument jump table entries.",0,0,0,1,0,0
2815,"To address this challenge, we aggressively exploit padding bytes and systematically host detours in neighboring basic blocks.",0,0,0,1,0,0
2816,We evaluate bcov on a corpus of 95 binaries compiled from eight popular and well-tested packages like FFmpeg and LLVM.,0,0,0,1,0,0
2817,"Two instrumentation policies, with different edge-level precision, are used to patch all functions in this corpus - over 1.6 million functions.",0,0,0,1,0,0
2818,Our precise policy has average performance and memory overheads of 14% and 22% respectively.,0,0,0,0,1,0
2819,Instrumented binaries do not introduce any test regressions.,0,0,0,0,0,1
2820,The reported coverage is highly accurate with an average F-score of 99.86%.,0,0,0,0,1,0
2821,"Finally, our jump table analysis is comparable to that of IDA Pro on gcc binaries and outperforms it on clang binaries.",0,0,0,0,0,1
2822,"
Facing the limited resource of smartphones, asynchronous programming significantly improves the performance of Android applications.",1,0,0,0,0,0
2823,Android provides several packaged components to ease the development of asynchronous programming.,1,0,0,0,0,0
2824,"Among them, the AsyncTask component is widely used by developers since it is easy to implement.",1,0,0,0,0,0
2825,"However, the abuse of AsyncTask component can decrease responsiveness and even lead to crashes.",1,0,0,0,0,0
2826,"By investigating the Android Developer Documentation and technical forums, we summarize five misuse patterns about AsyncTask.",0,0,1,0,0,0
2827,"To detect them, we propose a flow, context, object and field-sensitive inter-procedural static analysis approach.",0,0,0,1,0,0
2828,"Specifically, the static analysis includes typestate analysis, reference analysis and loop analysis.",0,0,0,1,0,0
2829,"Based on the AsyncTask-related information obtained during static analysis, we check the misuse according to predefined detection rules.",0,0,0,1,0,0
2830,The proposed approach is implemented into a tool called AsyncChecker.,0,1,0,0,0,0
2831,"We evaluate AsyncChecker on a self-designed benchmark suite called AsyncBench and 1,759 real-world apps.",0,0,0,1,0,0
2832,"AsyncChecker finds 17,946 misused AsyncTask instances in 1,417 real-world apps (80.6%).",0,0,0,0,1,0
2833,"The precision, recall and F-measure of AsyncChecker on real-world applications are 97.2%, 89.8% and 0.93, respectively.",0,0,0,0,1,0
2834,"Compared with existing tools, AsyncChecker can detect more asynchronous problems.",0,0,0,0,1,0
2835,We report the misuse problems to developers via GitHub.,0,0,0,0,1,0
2836,Several developers have confirmed and fixed the problems found by AsyncChecker.,0,0,0,0,1,0
2837,The result implies that our approach is effective and developers do take the misuse of AsyncTask as a serious problem.,0,0,0,0,0,1
2838,"
Higher-order mutation has the potential for improving major drawbacks of traditional first-order mutation, such as by simulating more realistic faults or improving test-optimization techniques.",1,0,0,0,0,0
2839,"Despite interest in studying promising higher-order mutants, such mutants are difficult to find due to the exponential search space of mutation combinations.",1,0,0,0,0,0
2840,"State-of-the-art approaches rely on genetic search, which is often incomplete and expensive due to its stochastic nature.",1,0,0,0,0,0
2841,"First, we propose a novel way of finding a complete set of higher-order mutants by using variational execution, a technique that can, in many cases, explore large search spaces completely and often efficiently.",0,1,0,0,0,0
2842,"Second, we use the identified complete set of higher-order mutants to study their characteristics.",0,0,1,0,0,0
2843,"Finally, we use the identified characteristics to design and evaluate a new search strategy, independent of variational execution, that is highly effective at finding higher-order mutants even in large codebases.",0,0,0,0,1,1
2844,"
Inspired by the great success of using code coverage as guidance in software testing, a lot of neural network coverage criteria have been proposed to guide testing of neural network models (e.g., model accuracy under adversarial attacks).",1,0,0,0,0,0
2845,"However, while the monotonic relation between code coverage and software quality has been supported by many seminal studies in software engineering, it remains largely unclear whether similar monotonicity exists between neural network model coverage and model quality.",1,0,0,0,0,0
2846,This paper sets out to answer this question.,0,0,1,0,0,0
2847,"Specifically, this paper studies the correlation between DNN model quality and coverage criteria, effects of coverage guided adversarial example generation compared with gradient decent based methods, effectiveness of coverage based retraining compared with existing adversarial training, and the internal relationships among coverage criteria.",0,0,1,0,0,0
2848,"
Credit scoring systems are critical FinTech applications that concern the analysis of the creditworthiness of a person or organization.",1,0,0,0,0,0
2849,"While decisions were previously based on human expertise, they are now increasingly relying on data analysis and machine learning.",1,0,0,0,0,0
2850,"In this paper, we assess the ability of state-of-the-art adversarial machine learning to craft attacks on a real-world credit scoring system.",0,0,1,0,0,0
2851,"Interestingly, we find that, while these techniques can generate large numbers of adversarial data, these are practically useless as they all violate domain-specific constraints.",0,0,0,0,1,0
2852,"In other words, the generated examples are all false positives as they cannot occur in practice.",0,0,0,0,1,0
2853,"To circumvent this limitation, we propose CoEvA2, a search-based method that generates valid adversarial examples (satisfying the domain constraints).",0,1,0,0,0,0
2854,"CoEvA2 utilizes multi-objective search in order to simultaneously handle constraints, perform the attack and maximize the overdraft amount requested.",0,1,0,0,0,0
2855,We evaluate CoEvA2 on a major bank's real-world system by checking its ability to craft valid attacks.,0,0,0,1,0,0
2856,"CoEvA2 generates thousands of valid adversarial examples, revealing a high risk for the banking system.",0,0,0,0,1,0
2857,"Fortunately, by improving the system through adversarial training (based on the produced examples), we increase its robustness and make our attack fail.",0,0,0,0,0,1
2858,"
Machine learning models are increasingly being used in important decision-making software such as approving bank loans, recommending criminal sentencing, hiring employees, and so on.",1,0,0,0,0,0
2859,"It is important to ensure the fairness of these models so that no discrimination is made based on protected attribute (e.g., race, sex, age) while decision making.",1,0,0,0,0,0
2860,Algorithms have been developed to measure unfairness and mitigate them to a certain extent.,1,0,0,0,0,0
2861,"In this paper, we have focused on the empirical evaluation of fairness and mitigations on real-world machine learning models.",0,0,1,1,0,0
2862,"We have created a benchmark of 40 top-rated models from Kaggle used for 5 different tasks, and then using a comprehensive set of fairness metrics, evaluated their fairness.",0,0,0,1,0,0
2863,"Then, we have applied 7 mitigation techniques on these models and analyzed the fairness, mitigation results, and impacts on performance.",0,0,0,1,0,0
2864,We have found that some model optimization techniques result in inducing unfairness in the models.,0,0,0,0,1,0
2865,"On the other hand, although there are some fairness control mechanisms in machine learning libraries, they are not documented.",0,0,0,0,1,0
2866,The mitigation algorithm also exhibit common patterns such as mitigation in the post-processing is often costly (in terms of performance) and mitigation in the pre-processing stage is preferred in most cases.,0,0,0,0,1,0
2867,We have also presented different trade-off choices of fairness mitigation decisions.,0,0,0,0,1,0
2868,Our study suggests future research directions to reduce the gap between theoretical fairness aware algorithms and the software engineering methods to leverage them in practice.,0,0,0,0,0,1
2869,"
Database Management Systems (DBMS) are used ubiquitously.",1,0,0,0,0,0
2870,"To efficiently access data, they apply sophisticated optimizations.",1,0,0,0,0,0
2871,"Incorrect optimizations can result in logic bugs, which cause a query to compute an incorrect result set.",1,0,0,0,0,0
2872,"We propose Non-Optimizing Reference Engine Construction (NoREC), a fully-automatic approach to detect optimization bugs in DBMS.",0,1,0,0,0,0
2873,"Conceptually, this approach aims to evaluate a query by an optimizing and a non-optimizing version of a DBMS, to then detect differences in their returned result set, which would indicate a bug in the DBMS.",0,1,0,0,0,0
2874,"Obtaining a non-optimizing version of a DBMS is challenging, because DBMS typically provide limited control over optimizations.",1,0,0,0,0,0
2875,"Our core insight is that a given, potentially randomly-generated optimized query can be rewritten to one that the DBMS cannot optimize.",0,1,0,0,0,0
2876,"We evaluated NoREC in an extensive testing campaign on four widely-used DBMS, namely PostgreSQL, MariaDB, SQLite, and CockroachDB.",0,0,0,1,0,0
2877,"We found 159 previously unknown bugs in the latest versions of these systems, 141 of which have been fixed by the developers.",0,0,0,0,1,0
2878,"Of these, 51 were optimization bugs, while the remaining were error and crash bugs.",0,0,0,0,1,0
2879,"Our results suggest that NoREC is effective, general and requires little implementation effort, which makes the technique widely applicable in practice.",0,0,0,0,0,1
2880,"
Performance issues compromise the response time and resource consumption of a software system.",1,0,0,0,0,0
2881,"Modern software systems use issue tracking systems to manage all kinds of issue reports, including performance issues.",1,0,0,0,0,0
2882,The problem is that performance issues are often not explicitly tagged.,1,0,0,0,0,0
2883,"The tagging mechanism, if exists, is completely voluntary, depending on the project’s convention and on submitters’ discipline.",1,0,0,0,0,0
2884,"For example, the performance tag rate in Apache’s Jira system is below 1%.",1,0,0,0,0,0
2885,This paper contributes a hybrid classification approach that combines linguistic patterns and machine/deep learning techniques to automatically detect performance issue reports.,0,1,0,0,0,0
2886,We manually analyzed 980 real-life performance issue reports and derived 80 project-agnostic linguistic patterns that recur in the reports.,0,0,0,1,0,0
2887,Our approach uses these linguistic patterns to construct the sentence-level and issue-level learning features for training effective machine/deep learning classifiers.,0,0,0,1,0,0
2888,"We test our approach on two separate datasets, each consisting of 980 unclassified issue reports, and compare the results with 31 baseline methods.",0,0,0,1,0,0
2889,Our approach can reach up to 83% precision and up to 59% recall.,0,0,0,0,1,0
2890,"The only comparable baseline method is BERT, which is still 25% lower in the F1-score.",0,0,0,0,0,1
2891,"
Atoms of confusion are small patterns of code that have been empirically validated to be difficult to hand-evaluate by programmers.",1,0,0,0,0,0
2892,"Previous research focused on defining and quantifying this phenomenon, but not on explaining or critiquing it.",1,0,0,0,0,0
2893,"In this work, we address core omissions to the body of work on atoms of confusion, focusing on the ‘how’ and ‘why’ of programmer misunderstanding.",0,0,1,0,0,0
2894,"We performed a think-aloud study in which we observed programmers, both professionals and students, as they hand-evaluated confusing code.",0,0,0,1,0,0
2895,"We performed a qualitative analysis of the data and found several surprising results, which explain previous results, outline avenues of further research, and suggest improvements of the research methodology.",0,0,0,1,0,0
2896,"A notable observation is that correct hand-evaluations do not imply understanding, and incorrect evaluations not misunderstanding.",0,0,0,0,1,0
2897,We believe this and other observations may be used to improve future studies and models of program comprehension.,0,0,0,0,0,1
2898,We argue that thinking of confusion as an atomic construct may pose challenges to formulating new candidates for atoms of confusion.,0,0,0,0,0,1
2899,"Ultimately, we question whether hand-evaluation correctness is, itself, a sufficient instrument to study program comprehension.",0,0,0,0,0,1
2900,"
We consider a usage model for automated machine learning (AutoML) in which users can influence the generated pipeline by providing a weak pipeline specification: an unordered set of API components from which the AutoML system draws the components it places into the generated pipeline.",1,0,0,0,0,0
2901,"Such specifications allow users to express preferences over the components that appear in the pipeline, for example a desire for interpretable components to appear in the pipeline.",1,0,0,0,0,0
2902,"We present AMS, an approach to automatically strengthen weak specifications to include unspecified complementary and functionally related API components, populate the space of hyperparameters and their values, and pair this configuration with a search procedure to produce a strong pipeline specification: a full description of the search space for candidate pipelines.",0,1,0,0,0,0
2903,"ams uses normalized pointwise mutual information on a code corpus to identify complementary components, BM25 as a lexical similarity score over the target API's documentation to identify functionally related components, and frequency distributions in the code corpus to extract key hyperparameters and values.",0,0,0,1,0,0
2904,"We show that strengthened specifications can produce pipelines that outperform the pipelines generated from the initial weak specification and an expert-annotated variant, while producing pipelines that still reflect the user preferences captured in the original weak specification.",0,0,0,0,1,1
2905,"
We present counterintuitive results for the scalability of fuzzing.",0,1,0,0,0,0
2906,"Given the same non-deterministic fuzzer, finding the same bugs linearly faster requires linearly more machines.",1,0,0,0,0,0
2907,"For instance, with twice the machines, we can find all known bugs in half the time.",1,0,0,0,0,0
2908,"Yet, finding linearly more bugs in the same time requires exponentially more machines.",1,0,0,0,0,0
2909,"For instance, for every new bug we want to find in 24 hours, we might need twice more machines.",1,0,0,0,0,0
2910,Similarly for coverage.,1,0,0,0,0,0
2911,"With exponentially more machines, we can cover the same code exponentially faster, but uncovered code only linearly faster.",1,0,0,0,0,0
2912,"In other words, re-discovering the same vulnerabilities is cheap but finding new vulnerabilities is expensive.",0,0,0,0,1,0
2913,This holds even under the simplifying assumption of no parallelization overhead.,0,0,0,0,1,0
2914,"We derive these observations from over four CPU years worth of fuzzing campaigns involving almost three hundred open source programs, two state-of-the-art greybox fuzzers, four measures of code coverage, and two measures of vulnerability discovery.",0,0,0,1,0,0
2915,We provide a probabilistic analysis and conduct simulation experiments to explain this phenomenon.,0,0,0,1,0,0
2916,"
Energy efficiency is an increasingly important quality attribute for software, particularly for mobile apps.",1,0,0,0,0,0
2917,"Just like any other software attribute, energy behavior of mobile apps should be properly tested prior to their release.",1,0,0,0,0,0
2918,"However, mobile apps are riddled with energy defects, as currently there is a lack of proper energy testing tools.",1,0,0,0,0,0
2919,"Indeed, energy testing is a fledgling area of research and recent advances have mainly focused on test input generation.",1,0,0,0,0,0
2920,"This paper presents ACETON, the first approach aimed at solving the oracle problem for testing the energy behavior of mobile apps.",0,1,0,0,0,0
2921,"ACETON employs Deep Learning to automatically construct an oracle that not only determines whether a test execution reveals an energy defect, but also the type of energy defect.",0,1,0,0,0,0
2922,"By carefully selecting features that can be monitored on any app and mobile device, we are assured the oracle constructed using ACETON is highly reusable.",0,0,0,1,1,0
2923,"Our experiments show that the oracle produced by ACETON is both highly accurate, achieving an overall precision and recall of 99%, and efficient, detecting the existence of energy defects in only 37 milliseconds on average.",0,0,0,0,1,1
2924,"
Energy accounting is a fundamental problem in energy management, defined as attributing global energy consumption to individual components of interest.",1,0,0,0,0,0
2925,"In this paper, we take on this problem at the application level, where the components for accounting are application logical units, such as methods, classes, and packages.",0,0,1,0,0,0
2926,"Given a Java application, our novel runtime system Chappie produces an energy footprint, i.e., the relative energy consumption of all programming abstraction units within the application.",0,0,0,1,0,0
2927,"First, relative to targeted energy profiling where the profiler determines the energy consumption of a pre-defined application logical unit, e.g., a specific method, Chappie is total: the energy footprint encompasses all methods within an application.",0,0,0,0,1,0
2928,"Second, Chappie is concurrency-aware: energy attribution is fully aware of the multi-threaded behavior of Java applications, including JVM bookkeeping threads.",0,0,0,0,1,0
2929,"Third, Chappie is an embodiment of a novel philosophy for application-level energy accounting and profiling, which states that the accounting run should preserve the temporal phased power behavior of the application, and the spatial power distribution among the underlying hardware system.",0,0,0,0,1,0
2930,We term this important property as calmness.,0,0,0,0,1,0
2931,"Against state-of-the-art DaCapo benchmarks, we show that the energy footprint generated by Chappie is precise while incurring negligible overhead.",0,0,0,0,0,1
2932,"In addition, all results are produced with a high degree of calmness.",0,0,0,0,0,1
2933,"
Android deep link is a URL that takes users to a specific page of a mobile app, enabling seamless user experience from a webpage to an app.",1,0,0,0,0,0
2934,"Android app link, a new type of deep link introduced in Android 6.0, is claimed to offer more benefits, such as supporting instant apps and providing more secure verification to protect against hijacking attacks that previous deep links can not.",1,0,0,0,0,0
2935,"However, we find that the app link is not as secure as claimed, because the verification process can be bypassed by exploiting instant apps.",0,1,0,0,0,0
2936,"In this paper, we explore the weakness of the existing app link mechanism and propose three feasible hijacking attacks.",0,0,1,0,0,0
2937,"Our findings show that even popular apps are subject to these attacks, such as Twitter, Whatsapp, Facebook Message.",0,0,0,0,1,0
2938,Our observation is confirmed by Google.,0,0,0,0,1,0
2939,"To measure the severity of these vulnerabilities, we develop an automatic tool to detect vulnerable apps, and perform a large-scale empirical study on 400,000 Android apps.",0,0,0,1,0,0
2940,Experiment results suggest that app link hijacking vulnerabilities are prevalent in the ecosystem.,0,0,0,0,1,0
2941,"Specifically, 27.1% apps are vulnerable to link hijacking with smart text selection (STS); 30.0% apps are vulnerable to link hijacking without STS, and all instant apps are vulnerable to instant app attack.",0,0,0,0,1,0
2942,We provide an in-depth understanding of the mechanisms behind these types of attacks.,0,0,0,0,1,0
2943,"Furthermore, we propose the corresponding detection and defense methods that can successfully prevent the proposed hijackings for all the evaluated apps, thus raising the bar against the attacks on Android app links.",0,0,0,0,1,0
2944,Our insights and findings demonstrate the urgency to identify and prevent app link hijacking attacks.,0,0,0,0,0,1
2945,"
Program slicing has been widely applied in a variety of software engineering tasks.",1,0,0,0,0,0
2946,"However, existing program slicing techniques only deal with traditional programs that are constructed with instructions and variables, rather than neural networks that are composed of neurons and synapses.",1,0,0,0,0,0
2947,"In this paper, we introduce NNSlicer, the first approach for slicing deep neural networks based on data-flow analysis.",0,1,0,0,0,0
2948,Our method understands the reaction of each neuron to an input based on the difference between its behavior activated by the input and the average behavior over the whole dataset.,0,1,0,0,0,0
2949,"Then we quantify the neuron contributions to the slicing criterion by recursively backtracking from the output neurons, and calculate the slice as the neurons and the synapses with larger contributions.",0,1,0,0,0,0
2950,"We demonstrate the usefulness and effectiveness of NNSlicer with three applications, including adversarial input detection, model pruning, and selective model protection.",0,0,0,1,0,0
2951,"In all applications, NNSlicer significantly outperforms other baselines that do not rely on data flow analysis.",0,0,0,0,0,1
2952,"
Deep learning (DL) becomes increasingly pervasive, being used in a wide range of software applications.",1,0,0,0,0,0
2953,"These software applications, named as DL based software (in short as DL software), integrate DL models trained using a large data corpus with DL programs written based on DL frameworks such as TensorFlow and Keras.",1,0,0,0,0,0
2954,A DL program encodes the network structure of a desirable DL model and the process by which the model is trained using the training data.,1,0,0,0,0,0
2955,"To help developers of DL software meet the new challenges posed by DL, enormous research efforts in software engineering have been devoted.",1,0,0,0,0,0
2956,Existing studies focus on the development of DL software and extensively analyze faults in DL programs.,1,0,0,0,0,0
2957,"However, the deployment of DL software has not been comprehensively studied.",1,0,0,0,0,0
2958,"To fill this knowledge gap, this paper presents a comprehensive study on understanding challenges in deploying DL software.",0,0,1,0,0,0
2959,"We mine and analyze 3,023 relevant posts from Stack Overflow, a popular Q&A website for developers, and show the increasing popularity and high difficulty of DL software deployment among developers.",0,0,0,1,0,0
2960,"We build a taxonomy of specific challenges encountered by developers in the process of DL software deployment through manual inspection of 769 sampled posts and report a series of actionable implications for researchers, developers, and DL framework vendors.",0,0,0,0,1,0
2961,"
Using online Q&A forums, such as Stack Overflow (SO), for guidance to resolve program bugs, among other development issues, is commonplace in modern software development practice.",1,0,0,0,0,0
2962,Runtime exceptions (RE) is one such important class of bugs that is actively discussed on SO.,1,0,0,0,0,0
2963,In this work we present a technique and prototype tool called MAESTRO that can automatically recommend an SO post that is most relevant to a given Java RE in a developer's code.,0,1,0,0,0,0
2964,MAESTRO compares the exception-generating program scenario in the developer's code with that discussed in an SO post and returns the post with the closest match.,0,1,0,0,0,0
2965,"To extract and compare the exception scenario effectively, MAESTRO first uses the answer code snippets in a post to implicate a subset of lines in the post's question code snippet as responsible for the exception and then compares these lines with the developer's code in terms of their respective Abstract Program Graph (APG) representations.",0,1,0,0,0,0
2966,"The APG is a simplified and abstracted derivative of an abstract syntax tree, proposed in this work, that allows an effective comparison of the functionality embodied in the high-level program structure, while discarding many of the low-level syntactic or semantic differences.",0,1,0,0,0,0
2967,"We evaluate MAESTRO on a benchmark of 78 instances of Java REs extracted from the top 500 Java projects on GitHub and show that MAESTRO can return either a highly relevant or somewhat relevant SO post corresponding to the exception instance in 71% of the cases, compared to relevant posts returned in only 8% - 44% instances, by four competitor tools based on state-of-the-art techniques.",0,0,0,1,0,0
2968,"We also conduct a user experience study of MAESTRO with 10 Java developers, where the participants judge MAESTRO reporting a highly relevant or somewhat relevant post in 80% of the instances.",0,0,0,1,0,0
2969,In some cases the post is judged to be even better than the one manually found by the participant.,0,0,0,0,1,0
2970,"
Assertion oracles are executable boolean expressions placed inside the program that should pass (return true) for all correct executions and fail (return false) for all incorrect executions.",1,0,0,0,0,0
2971,"Because designing perfect assertion oracles is difficult, assertions often fail to distinguish between correct and incorrect executions.",1,0,0,0,0,0
2972,"In other words, they are prone to false positives and false negatives.",1,0,0,0,0,0
2973,"In this paper, we propose GAssert (Genetic ASSERTion improvement), the first technique to automatically improve assertion oracles.",0,1,0,0,0,0
2974,"Given an assertion oracle and evidence of false positives and false negatives, GAssert implements a novel co-evolutionary algorithm that explores the space of possible assertions to identify one with fewer false positives and false negatives.",0,1,0,0,0,0
2975,Our empirical evaluation on 34 Java methods from 7 different Java code bases shows that GAssert effectively improves assertion oracles.,0,0,0,1,0,0
2976,"GAssert outperforms two baselines (random and invariant-based oracle improvement), and is comparable with and in some cases even outperformed human-improved assertions.",0,0,0,0,1,1
2977,"
Formal methods use SMT solvers extensively for deciding formula satisfiability, for instance, in software verification, systematic test generation, and program synthesis.",1,0,0,0,0,0
2978,"However, due to their complex implementations, solvers may contain critical bugs that lead to unsound results.",1,0,0,0,0,0
2979,"Given the wide applicability of solvers in software reliability, relying on such unsound results may have detrimental consequences.",1,0,0,0,0,0
2980,"In this paper, we present STORM, a novel blackbox mutational fuzzing technique for detecting critical bugs in SMT solvers.",0,1,0,0,0,0
2981,We run our fuzzer on seven mature solvers and find 29 previously unknown critical bugs.,0,0,0,1,0,0
2982,STORM is already being used in testing new features of popular solvers before deployment.,0,0,0,0,0,1
2983,"
Build systems are essential for modern software maintenance and development, while build failures occur frequently across software systems, inducing non-negligible costs in development activities.",1,0,0,0,0,0
2984,"Build failure resolution is a challenging problem and multiple studies have demonstrated that developers spend non-trivial time in resolving encountered build failures; to relieve manual efforts, automated resolution techniques are emerging recently, which are promising but still limitedly effective.",1,0,0,0,0,0
2985,Understanding how build failures are resolved in practice can provide guidelines for both developers and researchers on build issue resolution.,1,0,0,0,0,0
2986,"Therefore, this work presents a comprehensive study of fix patterns in practical build failures.",0,0,1,0,0,0
2987,"Specifically, we study 1,080 build issues of three popular build systems Maven, Ant, and Gradle from Stack Overflow, construct a fine-granularity taxonomy of 50 categories regarding to the failure symptoms, and summarize the fix patterns for different failure types.",0,0,0,1,0,0
2988,"Our key findings reveal that build issues stretch over a wide spectrum of symptoms; 67.96% of the build issues are fixed by modifying the build script code related to plugins and dependencies; and there are 20 symptom categories, more than half of whose build issues can be fixed by specific patterns.",0,0,0,0,1,0
2989,"Furthermore, we also address the challenges in applying non-intuitive or simplistic fix patterns for developers.",0,0,0,0,0,1
2990,"
In this paper, we take the fundamental perspective of fuzzing as a learning process.",1,0,0,0,0,0
2991,"Suppose before fuzzing, we know nothing about the behaviors of a program P: What does it do?",1,0,0,0,0,0
2992,"Executing the first test input, we learn how P behaves for this input.",1,0,0,0,0,0
2993,"Executing the next input, we either observe the same or discover a new behavior.",1,0,0,0,0,0
2994,"As such, each execution reveals ”some amount” of information about P’s behaviors.",1,0,0,0,0,0
2995,A classic measure of information is Shannon’s entropy.,1,0,0,0,0,0
2996,Measuring entropy allows us to quantify how much is learned from each generated test input about the behaviors of the program.,1,0,0,0,0,0
2997,"Within a probabilistic model of fuzzing, we show how entropy also measures fuzzer efficiency.",1,0,0,0,0,0
2998,"Specifically, it measures the general rate at which the fuzzer discovers new behaviors.",1,0,0,0,0,0
2999,"Intuitively, efficient fuzzers maximize information.",1,0,0,0,0,0
3000,"From this information theoretic perspective, we develop Entropic, an entropy-based power schedule for greybox fuzzing which assigns more energy to seeds that maximize information.",0,1,0,0,0,0
3001,We implemented Entropic into the popular greybox fuzzer LibFuzzer.,0,0,0,1,0,0
3002,Our experiments with more than 250 open-source programs (60 million LoC) demonstrate a substantially improved efficiency and confirm our hypothesis that an efficient fuzzer maximizes information.,0,0,0,0,1,0
3003,Entropic has been independently evaluated and invited for integration into main-line LibFuzzer.,0,0,0,0,1,0
3004,"Entropic now runs on more than 25,000 machines fuzzing hundreds of security-critical software systems simultaneously and continuously.",0,0,0,0,0,1
3005,"
When designing a software system, architects make a series of design decisions that directly impact the system's quality.",1,0,0,0,0,0
3006,"The number of available design alternatives grows rapidly with system size, creating an enormous space of intertwined design concerns that renders manual exploration impractical.",1,0,0,0,0,0
3007,"We present eQual, a model-driven technique for simulation-based assessment of architectural designs.",0,1,0,0,0,0
3008,"While it is not possible to guarantee optimal decisions so early in the design process, eQual improves decision quality.",0,1,0,0,0,0
3009,eQual is effective in practice because it (1) limits the amount of information the architects have to provide and (2) adapts optimization algorithms to effectively explore massive spaces of design alternatives.,0,1,0,0,0,0
3010,We empirically demonstrate that eQual yields designs whose quality is comparable to a set of systems' known optimal designs.,0,0,0,1,0,0
3011,"A user study shows that, compared to the state-of-the-art, engineers using eQual produce statistically significantly higher-quality designs with a large effect size, are statistically significantly more confident in their designs, and find eQual easier to use.",0,0,0,0,1,0
3012,"
Deep learning (DL) techniques are rapidly developed and have been widely adopted in practice.",1,0,0,0,0,0
3013,"However, similar to traditional software systems, DL systems also contain bugs, which could cause serious impacts especially in safety-critical domains.",1,0,0,0,0,0
3014,"Recently, many research approaches have focused on testing DL models, while little attention has been paid for testing DL libraries, which is the basis of building DL models and directly affects the behavior of DL systems.",1,0,0,0,0,0
3015,"In this work, we propose a novel approach, LEMON, to testing DL libraries.",0,1,0,0,0,0
3016,"In particular, we (1) design a series of mutation rules for DL models, with the purpose of exploring different invoking sequences of library code and hard-to-trigger behaviors; and (2) propose a heuristic strategy to guide the model generation process towards the direction of amplifying the inconsistent degrees of the inconsistencies between different DL libraries caused by bugs, so as to mitigate the impact of potential noise introduced by uncertain factors in DL libraries.",0,1,0,0,0,0
3017,"We conducted an empirical study to evaluate the effectiveness of LEMON with 20 release versions of 4 widely-used DL libraries, i.e., TensorFlow, Theano, CNTK, MXNet.",0,0,0,1,0,0
3018,"The results demonstrate that LEMON detected 24 new bugs in the latest release versions of these libraries, where 7 bugs have been confirmed and one bug has been fixed by developers.",0,0,0,0,1,0
3019,"Besides, the results confirm that the heuristic strategy for model generation indeed effectively guides LEMON in amplifying the inconsistent degrees for bugs.",0,0,0,0,0,1
3020,"Vacuity is a well-known quality issue in formal specifications, studied mostly in the context of model checking.",1,0,0,0,0,0
3021,"Inherent vacuity is a type of vacuity that applies to specifications, without the context of a model.",1,0,0,0,0,0
3022,"GR(1) is an expressive assume-guarantee fragment of LTL, which enables efficient symbolic synthesis.",1,0,0,0,0,0
3023,In this work we investigate inherent vacuity for GR(1) specifications.,0,1,1,0,0,0
3024,"We define several general types of inherent vacuity for GR(1), including specification element vacuity and domain value vacuity.",0,1,1,0,0,0
3025,"We detect vacuities using a reduction to LTL satisfiability, specialized for the context of GR(1).",0,1,1,0,0,0
3026,"We further extend vacuity detection to handle GR(1) specifications that are enriched with past LTL, monitors, and patterns.",0,1,1,0,0,0
3027,"Finally, we define a novel notion of vacuity core, which provides means to localize the cause of vacuity.",0,1,1,0,0,0
3028,We implemented our work and evaluated it on benchmarks from the literature.,0,0,0,1,0,0
3029,"The evaluation shows that vacuities are indeed common in GR(1) specifications, and that we are able to efficiently detect them and effectively localize their causes.",0,0,0,0,1,0
3030,"Moreover, our evaluation shows that removal of vacuous specification elements may significantly reduce synthesis time.",0,0,0,0,1,0
3031,The landscape of web APIs is evolving to meet new client requirements and to facilitate how providers fulfill them.,1,0,0,0,0,0
3032,"A recent web API model is GraphQL, which is both a query language and a runtime.",1,0,0,0,0,0
3033,"Using GraphQL, client queries express the data they want to retrieve or mutate, and servers respond with exactly those data or changes.",1,0,0,0,0,0
3034,"GraphQL’s expressiveness is risky for service providers because clients can succinctly request stupendous amounts of data, and responding to overly complex queries can be costly or disrupt service availability.",1,0,0,0,0,0
3035,Recent empirical work has shown that many service providers are at risk.,1,0,0,0,0,0
3036,"Using traditional API management methods is not sufficient, and practitioners lack principled means of estimating and measuring the cost of the GraphQL queries they receive.",1,0,0,0,0,0
3037,"In this work, we present a linear-time GraphQL query analysis that can measure the cost of a query without executing it.",0,1,1,0,0,0
3038,Our approach can be applied in a separate API management layer and used with arbitrary GraphQL backends.,0,0,1,0,0,0
3039,"In contrast to existing static approaches, our analysis supports common GraphQL conventions that affect query cost, and our analysis is provably correct based on our formal specification of GraphQL semantics.",0,0,1,0,0,0
3040,We demonstrate the potential of our approach using a novel GraphQL query-response corpus for two commercial GraphQL APIs.,0,0,0,1,0,0
3041,"Our query analysis consistently obtains upper cost bounds, tight enough relative to the true response sizes to be actionable for service providers.",0,0,0,0,1,0
3042,"In contrast, existing static GraphQL query analyses exhibit over-estimates and under-estimates because they fail to support GraphQL conventions.",0,0,0,0,1,0
3043,Incidents in online service systems could dramatically degrade system availability and destroy user experience.,1,0,0,0,0,0
3044,"To guarantee service quality and reduce economic loss, it is essential to predict the occurrence of incidents in advance so that engineers can take some proactive actions to prevent them.",1,0,0,0,0,0
3045,"In this work, we propose an effective and interpretable incident prediction approach, called eWarn, which utilizes historical data to forecast whether an incident will happen in the near future based on alert data in real time.",0,1,1,0,0,0
3046,"More specifically, eWarn first extracts a set of effective features (including textual features and statistical features) to represent omen alert patterns via careful feature engineering.",0,0,1,0,0,0
3047,"To reduce the influence of noisy alerts (that are not relevant to the occurrence of incidents), eWarn then incorporates the multi-instance learning formulation.",0,0,1,0,0,0
3048,"Finally, eWarn builds a classification model via machine learning and generates an interpretable report about the prediction result via a state-of-the-art explanation technique (i.e., LIME).",0,0,1,0,0,0
3049,"In this way, an early warning signal along with its interpretable report can be sent to engineers to facilitate their understanding and handling for the incoming incident.",0,0,1,0,0,0
3050,"An extensive study on 11 real-world online service systems from a large commercial bank demonstrates the effectiveness of eWarn, outperforming state-of-the-art alert-based incident prediction approaches and the practice of incident prediction with alerts.",0,0,0,1,1,0
3051,"In particular, we have applied eWarn to two large commercial banks in practice and shared some success stories and lessons learned from real deployment.",0,0,0,0,1,0
3052,Natural Language (NL) programming automatically synthesizes code based on inputs expressed in natural language.,1,0,0,0,0,0
3053,It has recently received lots of growing interest.,1,0,0,0,0,0
3054,Recent solutions however all require many labeled training examples for their data-driven nature.,1,0,0,0,0,0
3055,"This paper proposes an NLU-driven approach, a new approach inspired by how humans learn programming.",0,1,1,0,0,0
3056,"It centers around Natural Language Understanding and draws on a novel graph-based mapping algorithm, foregoing the need of large numbers of labeled examples.",0,0,1,0,0,0
3057,"The resulting NL programming framework, HISyn, using no training examples, gives synthesis accuracy comparable to those by data-driven methods trained on hundreds of training numbers.",0,0,0,0,1,0
3058,"HISyn meanwhile demonstrates advantages in interpretability, error diagnosis support, and cross-domain extensibility.",0,0,0,0,0,1
3059,"With the rise of containerization, cloud development, and continuous integration and delivery, configuration has become an essential aspect not only to tailor software to user requirements, but also to configure a software system’s environment and infrastructure.",1,0,0,0,0,0
3060,"This heterogeneity of activities, domains, and processes blurs the term configuration, as it is not clear anymore what tasks, artifacts, or stakeholders are involved and intertwined.",1,0,0,0,0,0
3061,"However, each re- search study and each paper involving configuration places their contributions and findings in a certain context without making the context explicit.",1,0,0,0,0,0
3062,"This makes it difficult to compare findings, translate them to practice, and to generalize the results.",1,0,0,0,0,0
3063,"Thus, we set out to evaluate whether these different views on configuration are really distinct or can be summarized under a common umbrella.",0,0,1,0,0,0
3064,"By interviewing practitioners from different domains and in different roles about the aspects of configuration and by analyzing two qualitative studies in similar areas, we derive a model of configuration that provides terminology and context for research studies, identifies new research opportunities, and allows practitioners to spot possible challenges in their current tasks.",0,0,1,1,0,0
3065,"Although our interviewees have a clear view about configuration, it substantially differs due to their personal experience and role.",0,0,0,0,1,0
3066,This indicates that the term configuration might be overloaded.,0,0,0,0,1,0
3067,"However, when taking a closer look, we see the interconnections and dependencies among all views, arriving at the conclusion that we need to start considering the entire spectrum of dimensions of configuration.",0,0,0,0,1,0
3068,One of the key properties of a program is its input specification.,1,0,0,0,0,0
3069,"Having a formal input specification can be critical in fields such as vulnerability analysis, reverse engineering, software testing, clone detection, or refactoring.",1,0,0,0,0,0
3070,"Unfortunately, accurate input specifications for typical programs are often unavailable or out of date.",1,0,0,0,0,0
3071,"In this paper, we present a general algorithm that takes a program and a small set of sample inputs and automatically infers a readable context-free grammar capturing the input language of the program.",0,1,1,0,0,0
3072,We infer the syntactic input structure only by observing access of input characters at different locations of the input parser.,0,0,1,0,0,0
3073,"This works on all stack based recursive descent input parsers, including parser combinators, and works entirely without program specific heuristics.",0,0,1,0,0,0
3074,"Our Mimid prototype produced accurate and readable grammars for a variety of evaluation subjects, including complex languages such as JSON, TinyC, and JavaScript.",0,0,0,0,1,0
3075,Software engineering bots – automated tools that handle tedious tasks – are increasingly used by industrial and open source projects to improve developer productivity.,1,0,0,0,0,0
3076,"Current research in this area is held back by a lack of consensus of what software engineering bots (DevBots) actually are, what characteristics distinguish them from other tools, and what benefits and challenges are associated with DevBot usage.",1,0,0,0,0,0
3077,In this paper we report on a mixed-method empirical study of DevBot usage in industrial practice.,0,1,1,1,0,0
3078,We report on findings from interviewing 21 and surveying a total of 111 developers.,0,0,0,1,0,0
3079,"We identify three different personas among DevBot users (focusing on autonomy, chat interfaces, and “smartness”), each with different definitions of what a DevBot is, why developers use them, and what they struggle with.We conclude that future DevBot research should situate their work within our framework, to clearly identify what type of bot the work targets, and what advantages practitioners can expect.",0,0,0,0,1,0
3080,"Further, we find that there currently is a lack of general purpose “smart” bots that go beyond simple automation tools or chat interfaces.",0,0,0,0,1,0
3081,"This is problematic, as we have seen that such bots, if available, can have a transformative effect on the projects that use them.",0,0,0,0,1,0
3082,"Code review is a critical step in modern software quality assurance, yet it is vulnerable to human biases.",1,0,0,0,0,0
3083,"Previous studies have clarified the extent of the problem, particularly regarding biases against the authors of code,but no consensus understanding has emerged.",1,0,0,0,0,0
3084,"Advances in medical imaging are increasingly applied to software engineering, supporting grounded neurobiological explorations of computing activities, including the review, reading, and writing of source code.",1,0,0,0,0,0
3085,"In this paper, we present the results of a controlled experiment using both medical imaging and also eye tracking to investigate the neurological correlates of biases and differences between genders of humans and machines (e.g., automated program repair tools) in code review.",0,1,1,1,0,0
3086,"We find that men and women conduct code reviews differently, in ways that are measurable and supported by behavioral, eye-tracking and medical imaging data.",0,0,0,0,1,0
3087,"We also find biases in how humans review code as a function of its apparent author, when controlling for code quality.",0,0,0,0,1,0
3088,"In addition to advancing our fundamental understanding of how cognitive biases relate to the code review process, the results may inform subsequent training and tool design to reduce bias.",0,0,0,0,0,1
3089,Software reuse lowers development costs and improves the quality of software systems.,1,0,0,0,0,0
3090,Two strategies are common: clone & own (copying and adapting a system) and platform-oriented reuse (building a configurable platform).,1,0,0,0,0,0
3091,"The former is readily available, flexible, and initially cheap, but does not scale with the frequency of reuse, imposing high maintenance costs.",1,0,0,0,0,0
3092,"The latter scales, but imposes high upfront investments for building the platform, and reduces flexibility.",1,0,0,0,0,0
3093,"As such, each strategy has distinctive advantages and disadvantages, imposing different development activities and software architectures.",1,0,0,0,0,0
3094,Deciding for one strategy is a core decision with long-term impact on an organization’s software development.,1,0,0,0,0,0
3095,"Unfortunately, the strategies’ costs are not well-understood - not surprisingly, given the lack of systematically elicited empirical data, which is difficult to collect.",1,0,0,0,0,0
3096,"We present an empirical study of the development activities, costs, cost factors, and benefits associated with either reuse strategy.",0,1,1,1,0,0
3097,"For this purpose, we combine quantitative and qualitative data that we triangulated from 26 interviews at a large organization and a systematic literature review covering 57 publications.",0,0,0,1,0,0
3098,Our study both confirms and refutes common hypotheses on software reuse.,0,0,0,0,1,0
3099,"For instance, we confirm that developing for platform-oriented reuse is more expensive, but simultaneously reduces reuse costs; and that platform-orientation results in higher code quality compared to clone & own.",0,0,0,0,1,0
3100,"Surprisingly, refuting common hypotheses, we find that change propagation can be more expensive in a platform, that platforms can facilitate the advancement into innovative markets, and that there is no strict distinction of clone & own and platform-oriented reuse in practice.",0,0,0,0,1,0
3101,"Use-before-Initialization (UBI) bugs in the Linux kernel have serious security impacts, such as information leakage and privilege escalation.",1,0,0,0,0,0
3102,"Developers are adopting forced initialization to cope with UBI bugs, but this approach can still lead to undefined behaviors (e.g., NULL pointer dereference).",1,0,0,0,0,0
3103,"As it is hard to infer correct initialization values, we believe that the best way to mitigate UBI bugs is detection and manual patching.",1,0,0,0,0,0
3104,Precise detection of UBI bugs requires path-sensitive analysis.,1,0,0,0,0,0
3105,The detector needs to track an associated variable’s initialization status along all the possible program execution paths to its uses.,1,0,0,0,0,0
3106,"However, such exhaustive analysis prevents the detection from scaling to the whole Linux kernel.",1,0,0,0,0,0
3107,"This paper presents UBITect, a UBI bug finding tool which combines flow-sensitive type qualifier analysis and symbolic execution to perform precise and scalable UBI bug detection.",0,1,1,0,0,0
3108,The scalable qualifier analysis guides symbolic execution to analyze variables that are likely to cause UBI bugs.,0,0,1,0,0,0
3109,"UBITect also does not require manual effort for annotations and hence, it can be directly applied to the kernel without any source code or intermediate representation (IR) change.",0,0,1,0,0,0
3110,"On the Linux kernel version 4.14, UBITect reported 190 bugs, among which 78 bugs were deemed by us as true positives and 52 were confirmed by Linux maintainers.",0,0,0,0,1,0
3111,"Intelligent services provide the power of AI to developers via simple RESTful API endpoints, abstracting away many complexities of machine learning.",1,0,0,0,0,0
3112,"However, most of these intelligent services---such as computer vision---continually learn with time.",1,0,0,0,0,0
3113,"When the internals within the abstracted 'black box' become hidden and evolve, pitfalls emerge in the robustness of applications that depend on these evolving services.",1,0,0,0,0,0
3114,"Without adapting the way developers plan and construct projects reliant on intelligent services, significant gaps and risks result in both project planning and development.",1,0,0,0,0,0
3115,"Therefore, how can software engineers best mitigate software evolution risk moving forward, thereby ensuring that their own applications maintain quality?",1,0,0,0,0,0
3116,Our proposal is an architectural tactic designed to improve intelligent service-dependent software robustness.,0,1,1,0,0,0
3117,"The tactic involves creating an application-specific benchmark dataset baselined against an intelligent service, enabling evolutionary behaviour changes to be mitigated.",0,0,1,0,0,0
3118,"A technical evaluation of our implementation of this architecture demonstrates how the tactic can identify 1,054 cases of substantial confidence evolution and 2,461 cases of substantial changes to response label sets using a dataset consisting of 331 images that evolve when sent to a service.",0,0,0,1,1,0
3119,"As a mixed result of intensive dependency on third-party libraries, flexible mechanisms to declare dependencies and increased number of modules in a project, different modules of a project directly depend on multiple versions of the same third-party library.",1,0,0,0,0,0
3120,"Such library version inconsistencies could increase dependency maintenance cost, or even lead to dependency conflicts when modules are inter-dependent.",1,0,0,0,0,0
3121,"Although automated build tools (e.g., Maven's enforcer plugin) provide partial support to detect library version inconsistencies, they do not provide any support to harmonize inconsistent library versions.",1,0,0,0,0,0
3122,"We first conduct a survey with 131 Java developers from GitHub to retrieve first-hand information about the root causes, detection methods, reasons for fixing or not fixing, fixing strategies, fixing efforts, and tool expectations on library version inconsistencies.",0,0,1,1,0,0
3123,"Then, based on the insights from our survey, we propose LibHarmo, an interactive, effort-aware library version harmonization technique, to detect library version inconsistencies, interactively suggest a harmonized version with the least harmonization efforts based on library API usage analysis, and refactor build configuration files.",0,0,1,0,0,0
3124,LibHarmo is currently developed for Java Maven projects.,0,0,1,0,0,0
3125,"Our experimental study on 443 highly-starred Java Maven projects from GitHub shows that i) LibHarmo detected 621 library version inconsistencies in 152 (34.3%) projects with a false positive rate of 16.8%, while Maven's enforcer plugin only detected 219 of them; and ii) LibHarmo saved 87.5% of the harmonization efforts.",0,0,0,1,1,0
3126,"Further, 31 library version inconsistencies have been confirmed, and 17 of them have been already harmonized by developers.",0,0,0,0,1,0
3127,"Mining software repositories (MSR) has been shown effective for extracting data used to improve various software engineering tasks, including code completion, code repair, code search, and code summarization.",1,0,0,0,0,0
3128,"Despite a large body of work on MSR, researchers have focused almost exclusively on repositories that contain code written in imperative programming languages, such as Java and C/C++.",1,0,0,0,0,0
3129,"Unlike prior work, in this paper, we focus on mining publicly available hardware descriptions (HDs) written in hardware description languages (HDLs), such as VHDL.",0,1,0,0,0,0
3130,"HDLs have unique syntax and semantics compared to popular imperative languages, and learning-based tools available to hardware designers are well behind those used in other application domains.",0,0,1,0,0,0
3131,We assembled large HD corpora consisting of source code written in several HDLs and report on their characteristics.,0,0,0,1,0,0
3132,Our language model evaluation reveals that HDs possess a high level of naturalness similar to software written in imperative languages.,0,0,0,0,1,0
3133,"Further, by utilizing our corpora, we built several deep learning models for automated code completion in VHDL; our models take into account unique characteristics of HDLs, including similarities of nearby concurrent signal assignment statements, in-built concurrency, and the frequently used signal types.",0,0,0,1,0,0
3134,"These characteristics led to more effective neural models, achieving a BLEU score of 37.3, an 8-14-point improvement over rule-based and neural baselines.",0,0,0,0,1,0
3135,"Today, most developers bundle changes into commits that they submit to a shared code repository.",1,0,0,0,0,0
3136,"Tangled commits intermix distinct concerns, such as a bug fix and a new feature.",1,0,0,0,0,0
3137,"They cause issues for developers, reviewers, and researchers alike: they restrict the usability of tools such as git bisect, make patch comprehension more difficult, and force researchers who mine software repositories to contend with noise.",1,0,0,0,0,0
3138,"We present a novel data structure, the 𝛿-NFG, a multiversion Program Dependency Graph augmented with name flows.",0,1,1,0,0,0
3139,"A 𝛿-NFG directly and simultaneously encodes different program versions, thereby capturing commits, and annotates data flow edges with the names/lexemes that flow across them.",0,0,1,0,0,0
3140,"Our technique, Flexeme, builds a 𝛿-NFG from commits, then applies Agglomerative Clustering using Graph Similarity to that 𝛿-NFG to untangle its commits.",0,0,1,0,0,0
3141,"At the untangling task on a C# corpus, our implementation, Heddle, improves the state-of-the-art on accuracy by 0.14, achieving 0.81, in a fraction of the time: Heddle is 32 times faster than the previous state-of-the-art.",0,0,0,0,1,0
3142,Software refactoring aims at improving code quality while preserving the system's external behavior.,1,0,0,0,0,0
3143,"Although in principle refactoring is a behavior-preserving activity, a study presented by Bavota etal in 2012 reported the proneness of some refactoring actions (eg pull up method) to induce faults.",1,0,0,0,0,0
3144,The study was performed by mining refactoring activities and bugs from three systems.,1,0,0,0,0,0
3145,"Taking profit of the advances made in the mining software repositories field (eg better tools to detect refactoring actions at commit-level granularity), we present a differentiated replication of the work by Bavota etal in which we (i) overcome some of the weaknesses that affect their experimental design, (ii) answer the same research questions of the original study on a much larger dataset (3 vs 103 systems), and (iii) complement the quantitative analysis of the relationship between refactoring and bugs with a qualitative, manual inspection of commits aimed at verifying the extent to which refactoring actions trigger bug-fixing activities.",0,1,1,0,0,0
3146,"The results of our quantitative analysis confirm the findings of the replicated study, while the qualitative analysis partially demystifies the role played by refactoring actions in the bug introduction.",0,0,0,1,1,0
3147,"We propose a novel fine-grained integration of pointer analysis with dynamic analysis, including dynamic symbolic execution.",0,1,1,0,0,0
3148,"This is achieved via past-sensitive pointer analysis, an on-demand pointer analysis instantiated with an abstraction of the dynamic state on which it is invoked.",0,0,1,0,0,0
3149,"We evaluate our technique in three application scenarios: chopped symbolic execution, symbolic pointer resolution, and write integrity testing.",0,0,0,1,0,0
3150,"Our preliminary results show that the approach can have a significant impact in these scenarios, by effectively improving the precision of standard pointer analysis with only a modest performance overhead.",0,0,0,0,1,0
3151,"Polyglot programming, the use of multiple programming languages during the development process, is common practice in modern software development.",1,0,0,0,0,0
3152,This study investigates this practice through a randomized controlled trial conducted under the context of database programming.,0,1,1,0,0,0
3153,Participants in the study were given coding tasks written in Java and one of three SQL-like embedded languages.,0,0,0,1,0,0
3154,"One was plain SQL in strings, one was in Java only, and the third was a hybrid embedded language that was closer to the host language.",0,0,0,1,0,0
3155,We recorded 109 valid data points.,0,0,0,1,0,0
3156,Results showed significant differences in how developers of different experience levels code using polyglot techniques.,0,0,0,0,1,0
3157,"Notably, less experienced programmers wrote correct programs faster in the hybrid condition (frequent, but less severe, switches), while more experienced developers that already knew both languages performed better in traditional SQL (less frequent but more complete switches).",0,0,0,0,1,0
3158,The results indicate that the productivity impact of polyglot programming is complex and experience level dependent.,0,0,0,0,1,0
3159,"Automation tools like continuous integration services, code coverage reporters, style checkers, dependency managers, etc. are all known to provide significant improvements in developer productivity and software quality.",1,0,0,0,0,0
3160,"Some of these tools are widespread, others are not.",1,0,0,0,0,0
3161,"How do these automation ""best practices"" spread?",1,0,0,0,0,0
3162,And how might we facilitate the diffusion process for those that have seen slower adoption?,1,0,0,0,0,0
3163,"In this paper, we rely on a recent innovation in transparency on code hosting platforms like GitHub---the use of repository badges---to track how automation tools spread in open-source ecosystems through different social and technical mechanisms over time.",0,1,1,0,0,0
3164,"Using a large longitudinal data set, multivariate network science techniques, and survival analysis, we study which socio-technical factors can best explain the observed diffusion process of a number of popular automation tools.",0,0,1,1,0,0
3165,"Our results show that factors such as social exposure, competition, and observability affect the adoption of tools significantly, and they provide a roadmap for software engineers and researchers seeking to propagate best practices and tools.",0,0,0,0,1,0
3166,"The typical software tutorial includes step-by-step instructions for installing developer tools, editing files and code, and running commands.",1,0,0,0,0,0
3167,"When these software tutorials are not executable, either due to missing instructions, ambiguous steps, or simply broken commands, their value is diminished.",1,0,0,0,0,0
3168,"Non-executable tutorials impact developers in several ways, including frustrating learning experiences, and limiting usability of developer tools.",1,0,0,0,0,0
3169,"To understand to what extent software tutorials are executable---and why they may fail---we conduct an empirical study on over 600 tutorials, including nearly 15,000 code blocks.",0,1,1,1,0,0
3170,We find a naive execution strategy achieves an overall executability rate of only 26%.,0,0,0,0,1,0
3171,Even a human-annotation-based execution strategy---while doubling executability---still yields no tutorial that can successfully execute all steps.,0,0,0,0,1,0
3172,"We identify several common executability barriers, ranging from potentially innocuous causes, such as interactive prompts requiring human responses, to insidious errors, such as missing steps and inaccessible resources.",0,0,0,0,1,0
3173,"We validate our findings with major stakeholders in technical documentation and discuss possible strategies for improving software tutorials, such as providing accessible alternatives for tutorial takers, and investing in automated tutorial testing to ensure continuous quality of software tutorials.",0,0,0,1,0,0
3174,"Open design discussion is a primary mechanism through which open source projects debate, make and document design decisions.",1,0,0,0,0,0
3175,"However, there are open questions regarding how design discussions are conducted and what effect they have on the design quality of projects.",1,0,0,0,0,0
3176,"Recent work has begun to investigate design discussions, but has thus far focused on a single communication channel, whereas many projects use multiple channels.",1,0,0,0,0,0
3177,"In this study, we examine 37 Apache projects and their design discussions, the project’s design quality evolution, and the relationship between design discussion and design quality.",0,1,1,0,0,0
3178,"A mixed method empirical analysis (data mining and a survey of 130 developers) shows that: I) 89.51% of all design discussions occur in project mailing list, II) both core and non-core developers participate in design discussions, but core developers implement more design related changes (67.06%), and III) the correlation between design discussions and design quality is small.",0,0,0,1,1,0
3179,We conclude the paper with several observations that form the foundation for future research and development.,0,0,0,0,0,1
3180,An effective and efficient application of Continuous Integration (CI) and Delivery (CD) requires software projects to follow certain principles and good practices.,1,0,0,0,0,0
3181,Configuring such a CI/CD pipeline is challenging and error-prone.,1,0,0,0,0,0
3182,"Therefore, automated linters have been proposed to detect errors in the pipeline.",1,0,0,0,0,0
3183,"While existing linters identify syntactic errors, detect security vulnerabilities or misuse of the features provided by build servers, they do not support developers that want to prevent common misconfigurations of a CD pipeline that potentially violate CD principles (“CD smells”).",1,0,0,0,0,0
3184,"To this end, we propose CD-Linter, a semantic linter that can automatically identify four different smells in pipeline configuration files.",0,1,1,0,0,0
3185,"We have evaluated our approach through a large-scale and long-term study that consists of (i) monitoring 145 issues (opened in as many open-source projects) over a period of 6 months, (ii) manually validating the detection precision and recall on a representative sample of issues, and (iii) assessing the magnitude of the observed smells on 5,312 open-source projects on GitLab.",0,0,0,1,0,0
3186,Our results show that CD smells are accepted and fixed by most of the developers and our linter achieves a precision of 87% and a recall of 94%.,0,0,0,0,1,0
3187,"Those smells can be frequently observed in the wild, as 31% of projects with long configurations are affected by at least one smell.",0,0,0,0,1,0
3188,The selection of third-party libraries is an essential element of virtually any software development project.,1,0,0,0,0,0
3189,"However, deciding which libraries to choose is a challenging practical problem.",1,0,0,0,0,0
3190,"Selecting the wrong library can severely impact a software project in terms of cost, time, and development effort, with the severity of the impact depending on the role of the library in the software architecture, among others.",1,0,0,0,0,0
3191,"Despite the importance of following a careful library selection process, in practice, the selection of third-party libraries is still conducted in an ad-hoc manner, where dozens of factors play an influential role in the decision.",1,0,0,0,0,0
3192,"In this paper, we study the factors that influence the selection process of libraries, as perceived by industry developers.",0,1,1,0,0,0
3193,"To that aim, we perform a cross-sectional interview study with 16 developers from 11 different businesses and survey 115 developers that are involved in the selection of libraries.",0,0,0,1,0,0
3194,"We systematically devised a comprehensive set of 26 technical, human, and economic factors that developers take into consideration when selecting a software library.",0,0,0,0,1,0
3195,Eight of these factors are new to the literature.,0,0,0,0,1,0
3196,We explain each of these factors and how they play a role in the decision.,0,0,0,0,1,0
3197,"Finally, we discuss the implications of our work to library maintainers, potential library users, package manager developers, and empirical software engineering researchers.",0,0,0,0,1,0
3198,Software engineering candidates commonly participate in whiteboard technical interviews as part of a hiring assessment.,1,0,0,0,0,0
3199,"During these sessions, candidates write code while thinking aloud as they work towards a solution, under the watchful eye of an interviewer.",1,0,0,0,0,0
3200,"While technical interviews should allow for an unbiased and inclusive assessment of problem-solving ability, surprisingly, technical interviews may be instead a procedure for identifying candidates who best handle and migrate stress solely caused by being examined by an interviewer (performance anxiety).",1,0,0,0,0,0
3201,"To understand if coding interviews—as administered today—can induce stress that significantly hinders performance, we conducted a randomized controlled trial with 48 Computer Science students, comparing them in private and public whiteboard settings.",0,1,1,1,0,0
3202,"We found that performance is reduced by more than half, by simply being watched by an interviewer.",0,0,0,0,1,0
3203,We also observed that stress and cognitive load were significantly higher in a traditional technical interview when compared with our private interview.,0,0,0,0,1,0
3204,"Consequently, interviewers may be filtering out qualified candidates by confounding assessment of problem-solving ability with unnecessary stress.",0,0,0,0,1,0
3205,"We propose interview modifications to make problem-solving assessment more equitable and inclusive, such as through private focus sessions and retrospective think-aloud, allowing companies to hire from a larger and diverse pool of talent.",0,0,0,0,0,1
3206,"Maintaining large code bases written in dynamically typed languages, such as JavaScript or Python, can be challenging due to the absence of type annotations: simple data compatibility errors proliferate, IDE support is limited, and APIs are hard to comprehend.",1,0,0,0,0,0
3207,Recent work attempts to address those issues through either static type inference or probabilistic type prediction.,1,0,0,0,0,0
3208,"Unfortunately, static type inference for dynamic languages is inherently limited, while probabilistic approaches suffer from imprecision.",1,0,0,0,0,0
3209,"This paper presents TypeWriter, the first combination of probabilistic type prediction with search-based refinement of predicted types.",0,1,1,0,0,0
3210,TypeWriter’s predictor learns to infer the return and argument types for functions from partially annotated code bases by combining the natural language properties of code with programming language-level information.,0,0,1,0,0,0
3211,"To validate predicted types, TypeWriter invokes a gradual type checker with different combinations of the predicted types, while navigating the space of possible type combinations in a feedback-directed manner.",0,0,1,0,0,0
3212,"We implement the TypeWriter approach for Python and evaluate it on two code corpora: a multi-million line code base at Facebook and a collection of 1,137 popular open-source projects.",0,0,0,1,0,0
3213,"We show that TypeWriter’s type predictor achieves an F1 score of 0.64 (0.79) in the top-1 (top-5) predictions for return types, and 0.57 (0.80) for argument types, which clearly outperforms prior type prediction models.",0,0,0,0,1,0
3214,"By combining predictions with search-based validation, TypeWriter can fully annotate between 14% to 44% of the files in a randomly selected corpus, while ensuring type correctness.",0,0,0,0,1,0
3215,A comparison with a static type inference tool shows that TypeWriter adds many more non-trivial types.,0,0,0,0,1,0
3216,TypeWriter currently suggests types to developers at Facebook and several thousands of types have already been accepted with minimal changes.,0,0,0,0,0,1
3217,"Formal program specifications are essential for various software engineering tasks, such as program verification, program synthesis, code debugging and software testing.",1,0,0,0,0,0
3218,"However, manually inferring formal program specifications is not only time-consuming but also error-prone.",1,0,0,0,0,0
3219,"In addition, it requires substantial expertise.",1,0,0,0,0,0
3220,"Natural language comments contain rich semantics about behaviors of code, making it feasible to infer program specifications from comments.",1,0,0,0,0,0
3221,"Inspired by this, we develop a tool, named C2S, to automate the specification synthesis task by translating natural language comments into formal program specifications.",0,1,1,0,0,0
3222,Our approach firstly constructs alignments between natural language word and specification tokens from existing comments and their corresponding specifications.,0,0,1,0,0,0
3223,"Then for a given method comment, our approach assembles tokens that are associated with words in the comment from the alignments into specifications guided by specification syntax and the context of the target method.",0,0,1,0,0,0
3224,"Our tool successfully synthesizes 1,145 specifications for 511 methods of 64 classes in 5 different projects, substantially outperforming the state-of-the-art.",0,0,0,0,1,0
3225,"The generated specifications are also used to improve a number of software engineering tasks like static taint analysis, which demonstrates the high quality of the specifications.",0,0,0,0,0,1
3226,"In 2014, a Microsoft study investigated the sort of questions that data science applied to software engineering should answer.",1,0,0,0,0,0
3227,"This resulted in 145 questions that developers considered relevant for data scientists to answer, thus providing a research agenda to the community.",1,0,0,0,0,0
3228,"Fast forward to five years, no further studies investigated whether the questions from the software engineers at Microsoft hold for other software companies, including software-intensive companies with different primary focus (to which we refer as software-defined enterprises).",1,0,0,0,0,0
3229,"Furthermore, it is not evident that the problems identified five years ago are still applicable, given the technological advances in software engineering.",1,0,0,0,0,0
3230,"This paper presents a study at ING, a software-defined enterprise in banking in which over 15,000 IT staff provides in-house software solutions.",0,1,1,0,0,0
3231,This paper presents a comprehensive guide of questions for data scientists selected from the previous study at Microsoft along with our current work at ING.,0,1,1,0,0,0
3232,"We replicated the original Microsoft study at ING, looking for questions that impact both software companies and software-defined enterprises and continue to impact software engineering.",0,0,1,0,0,0
3233,We also add new questions that emerged from differences in the context of the two companies and the five years gap in between.,0,0,1,0,0,0
3234,"Our results show that software engineering questions for data scientists in the software-defined enterprise are largely similar to the software company, albeit with exceptions.",0,0,0,0,1,0
3235,We hope that the software engineering research community builds on the new list of questions to create a useful body of knowledge.,0,0,0,0,0,1
3236,"Whenever a new software-verification technique is developed, additional effort is necessary to extend the new program analysis to an interprocedural one, such that it supports recursive procedures.",1,0,0,0,0,0
3237,We would like to reduce that additional effort.,0,1,0,0,0,0
3238,"Our contribution is an approach to extend an existing analysis in a modular and domain-independent way to an interprocedural analysis without large changes: We present interprocedural block-abstraction memoization (BAM), which is a technique for procedure summarization to analyze (recursive) procedures.",0,1,1,0,0,0
3239,"For recursive programs, a fix-point algorithm terminates the recursion if every procedure is sufficiently unrolled and summarized to cover the abstract state space.",0,0,1,0,0,0
3240,"BAM Interprocedural works for data-flow analysis and for model checking, and is independent from the underlying abstract domain.",0,0,1,0,0,0
3241,"To witness that our interprocedural analysis is generic and configurable, we defined and evaluated the approach for three completely different abstract domains: predicate abstraction, explicit values, and intervals.",0,0,0,1,0,0
3242,The interprocedural BAM-based analysis is implemented in the open-source verification framework CPAchecker.,0,0,1,0,0,0
3243,The evaluation shows that the overhead for modularity and domain-independence is not prohibitively large and the analysis is still competitive with other state-of-the-art software-verification tools.,0,0,0,0,1,0
3244,Approximation is a technique that optimizes the balance between application outcome quality and its resource usage.,1,0,0,0,0,0
3245,"Trading quality for performance has been investigated for single application scenarios, but not for environments where multiple approximate applications may run concurrently on the same machine, interfering with each other by sharing machine resources.",1,0,0,0,0,0
3246,"Applying existing, single application techniques to this multi-programming environment may lead to configuration space size explosion, or result in poor overall application quality outcomes.",1,0,0,0,0,0
3247,Our new RAPID-M system is the first cross-application con-figuration management framework.,0,0,1,0,0,0
3248,"It reduces the problem size by clustering configurations of individual applications into local""similarity buckets"".",0,0,1,0,0,0
3249,The global cross-applications configuration selection is based on these local bucket spaces.,0,0,1,0,0,0
3250,"RAPID-M dynamically assigns buckets to applications such that overall quality is maximized while respecting individual application cost budgets.Once assigned a bucket, reconfigurations within buckets may be performed locally with minimal impact on global selections.",0,0,1,0,0,0
3251,"Experimental results using six configurable applications show that even large configuration spaces of complex applications can be clustered into a small number of buckets, resulting in search space size reductions of up to 9 orders of magnitude for our six applications.",0,0,0,1,1,0
3252,RAPID-M constructs performance cost models with an average prediction error of ≤3%.,0,0,0,0,1,0
3253,"For our application execution traces, RAPID-M dynamically selects configurations that lower the budget violation rate by 33.9% with an average budget exceeding rate of 6.6% as compared to other possible approaches.",0,0,0,0,1,0
3254,RAPID-M successfully finishes 22.75% more executions which translates to a 1.52X global output quality increase under high system loads.,0,0,0,0,1,0
3255,Theo verhead ofRAPID-Mis within≤1% of application execution times.,0,0,0,0,1,0
3256,"Summer of code programs connect students to open source software (OSS) projects, typically during the summer break from school.",1,0,0,0,0,0
3257,"Analyzing consolidated summer of code programs can reveal how college students, who these programs usually target, can be motivated to participate in OSS, and what onboarding strategies OSS communities adopt to receive these students.",1,0,0,0,0,0
3258,"In this paper, we study the well-established Google Summer of Code (GSoC) and devise an integrated engagement theory grounded in multiple data sources to explain motivation and onboarding in this context.",0,1,1,0,0,0
3259,"Our analysis shows that OSS communities employ several strategies for planning and executing student participation, socially integrating the students, and rewarding student’s contributions and achievements.",0,0,0,0,1,0
3260,"Students are motivated by a blend of rewards, which are moderated by external factors.",0,0,0,0,1,0
3261,We presented these rewards and the motivation theory to students who had never participated in a summer of code program and collected their shift in motivation after learning about the theory.,0,0,0,0,1,0
3262,"New students can benefit from the former students' experiences detailed in our results, and OSS stakeholders can leverage both the insight into students’ motivations for joining such programs as well as the onboarding strategies we identify to devise actions to attract and retain newcomers.",0,0,0,0,0,1
3263,"A large percentage of real-world software configuration issues, such as misconfigurations, involve multiple interdependent configuration parameters.",1,0,0,0,0,0
3264,"However, existing techniques and tools either do not consider dependencies among configuration parameters— termed configuration dependencies—or rely on one or two dependency types and code patterns as input.",1,0,0,0,0,0
3265,"Without rigorous understanding of configuration dependencies, it is hard to deal with many resulting configuration issues.",1,0,0,0,0,0
3266,"This paper presents our study of software configuration dependencies in 16 widely-used cloud and datacenter systems, including dependencies within and across software components.",0,1,1,0,0,0
3267,"To understand types of configuration dependencies, we conduct an exhaustive search of descriptions in structured configuration metadata and unstructured user manuals.",0,0,1,0,0,0
3268,We find and manually analyze 521 configuration dependencies.,0,0,1,0,0,0
3269,We define five types of configuration dependencies and identify their common code patterns.,0,0,1,0,0,0
3270,We report on consequences of not satisfying these dependencies and current software engineering practices for handling the consequences.,0,0,1,0,0,0
3271,"We mechanize the knowledge gained from our study in a tool, cDep, which detects configuration dependencies.",0,0,0,1,0,0
3272,cDep automatically discovers five types of configuration dependencies from bytecode using static program analysis.,0,0,0,1,0,0
3273,We apply cDep to the eight Java and Scala software systems in our study.,0,0,0,1,0,0
3274,cDep finds 87.9% (275/313) of the related subset of dependencies from our study.,0,0,0,0,1,0
3275,"cDep also finds 448 previously undocumented dependencies, with a 6.0% average false positive rate.",0,0,0,0,1,0
3276,"Overall, our results show that configuration dependencies are more prevalent and diverse than previously reported and should henceforth be considered a first-class issue in software configuration engineering.",0,0,0,0,0,1
3277,Data stored in cloud services is highly sensitive and so access to it is controlled via policies written in domain-specific languages (DSLs).,1,0,0,0,0,0
3278,"The expressiveness of these DSLs provides users flexibility to cover a wide variety of uses cases, however, unintended misconfigurations can lead to potential security issues.",1,0,0,0,0,0
3279,"We introduce Block Public Access, a tool that formally verifies policies to ensure that they only allow access to trusted principals, i.e. that they prohibit access to the general public.",0,1,1,0,0,0
3280,"To this end, we formalize the notion of Trust Safety that formally characterizes whether or not a policy allows unconstrained (public) access.",0,0,1,0,0,0
3281,"Next, we present a method to compile the policy down to a logical formula whose unsatisfiability can be (1) checked by SMT and (2) ensures Trust Safety.",0,0,1,0,0,0
3282,"The constructs of the policy DSLs render unsatisfiability checking PSPACE-complete, which precludes verifying the millions of requests per second seen at cloud scale.",0,0,1,0,0,0
3283,"Hence, we present an approach that leverages the structure of the policy DSL to compute a much smaller residual policy that corresponds only to untrusted accesses.",0,0,1,0,0,0
3284,"Our approach allows Block Public Access to, in the common case, syntactically verify Trust Safety without having to query the SMT solver.",0,0,1,0,0,0
3285,"We have implemented Block Public Access and present an evaluation showing how the above optimization yields a low-latency policy verifier that the S3 team at AWS has integrated into their authorization system, where it is currently in production, analyzing millions of policies everyday to ensure that client buckets do not grant unintended public access.",0,0,0,0,0,1
3286,"We present a new framework and associated synthesis algorithms for program synthesis over noisy data, i.e., data that may contain incorrect/corrupted input-output examples.",0,1,1,0,0,0
3287,This framework is based on an extension of finite tree automata called state-weighted finite tree automata.,0,0,1,0,0,0
3288,We show how to apply this framework to formulate and solve a variety of program synthesis problems over noisy data.,0,1,0,0,0,0
3289,"Results from our implemented system running on problems from the SyGuS 2018 benchmark suite highlight its ability to successfully synthesize programs in the face of noisy data sets, including the ability to synthesize a correct program even when every input-output example in the data set is corrupted.",0,0,0,1,1,0
3290,Merging execution paths is a powerful technique for reducing path explosion in symbolic execution.,1,0,0,0,0,0
3291,"One approach, introduced and dubbed “veritesting” by Avgerinos et al., works by translating abounded control flow region into a single constraint.",1,0,0,0,0,0
3292,This approach is a convenient way to achieve path merging as a modification to a pre-existing single-path symbolic execution engine.,1,0,0,0,0,0
3293,"Previous work evaluated this approach for symbolic execution of binary code, but different design considerations apply when building tools for other languages.",1,0,0,0,0,0
3294,"In this paper, we extend the previous approach for symbolic execution of Java.",0,1,0,0,0,0
3295,"Because Java code typically contains many small dynamically dispatched methods, it is important to include them in multi-path regions; we introduce dynamic inlining of method-regions to do so modularly.",0,0,1,0,0,0
3296,"Java’s typed memory structure is very different from the binary representation, but we show how the idea of static single assignment (SSA) form can be applied to object references to statically account for aliasing.",0,0,1,0,0,0
3297,"We have implemented our algorithms in Java Ranger, an extension to the widely used Symbolic Pathfinder tool.",0,0,1,0,0,0
3298,"In a set of nine benchmarks, Java Ranger reduces the running time and number of execution paths by a total of 38% and 71% respectively as compared to SPF.",0,0,0,0,1,0
3299,"Our results are a significant improvement over the performance of JBMC, a recently released verification tool for Java bytecode.",0,0,0,0,1,0
3300,We also participated in a static verification competition at a top theory conference where other participants included state-of-the-art Java verifiers.,0,0,0,0,0,1
3301,JR won first place in the competition’s Java verification track.,0,0,0,0,0,1
3302,"In this paper, we present the first exploratory study of deprecated Python library APIs to understand the status quo of API deprecation in the realm of Python libraries.",0,1,1,1,0,0
3303,"Specifically, we aim to comprehend how deprecated library APIs are declared and documented in practice by their maintainers, and how library users react to them.",0,1,1,0,0,0
3304,"By thoroughly looking into six reputed Python libraries and 1,200 GitHub projects, we experimentally observe that API deprecation is poorly handled by library contributors, which subsequently introduce difficulties for Python developers to resolve the usage of deprecated library APIs.",0,0,0,1,1,0
3305,This empirical evidence suggests that our community should take immediate actions to appropriately handle the deprecation of Python library APIs.,0,0,0,0,0,1
3306,Software verification approaches aim to check a software component under analysis for all possible environments.,1,0,0,0,0,0
3307,"In reality, however, components are expected to operate within a larger system and are required to satisfy their requirements only when their inputs are constrained by environment assumptions.",1,0,0,0,0,0
3308,"In this paper, we propose EPIcuRus, an approach to automatically synthesize environment assumptions for a component under analysis (i.e., conditions on the component inputs under which the component is guaranteed to satisfy its requirements).",0,1,1,0,0,0
3309,"EPIcuRus combines search-based testing, machine learning and model checking.",0,0,1,0,0,0
3310,The core of EPIcuRus is a decision tree algorithm that infers environment assumptions from a set of test results including test cases and their verdicts.,0,0,1,0,0,0
3311,"The test cases are generated using search-based testing, and the assumptions inferred by decision trees are validated through model checking.",0,0,1,0,0,0
3312,"In order to improve the efficiency and effectiveness of the assumption generation process, we propose a novel test case generation technique, namely Important Features Boundary Test (IFBT), that guides the test generation based on the feedback produced by machine learning.",0,0,1,0,0,0
3313,We evaluated EPIcuRus by assessing its effectiveness in computing assumptions on a set of study subjects that include 18 requirements of four industrial models.,0,0,0,1,0,0
3314,"We show that, for each of the 18 requirements, EPIcuRus was able to compute an assumption to ensure the satisfaction of that requirement, and further, ≈78% of these assumptions were computed in one hour.",0,0,0,0,1,0
3315,Modern software is bloated.,1,0,0,0,0,0
3316,"Demand for new functionality has led developers to include more and more features, many of which become unneeded or unused as software evolves.",1,0,0,0,0,0
3317,"This phenomenon, known as software bloat, results in software consuming more resources than it otherwise needs to.",1,0,0,0,0,0
3318,How to effectively and automatically debloat software is a long-standing problem in software engineering.,1,0,0,0,0,0
3319,Various debloating techniques have been proposed since the late 1990s.,1,0,0,0,0,0
3320,"However, many of these techniques are built upon pure static analysis and have yet to be extended and evaluated in the context of modern Java applications where dynamic language features are prevalent.",1,0,0,0,0,0
3321,"To this end, we develop an end-to-end bytecode debloating framework called JShrink.",0,1,1,0,0,0
3322,It augments traditional static reachability analysis with dynamic profiling and type dependency analysis and renovates existing bytecode transformations to account for new language features in modern Java.,0,0,1,0,0,0
3323,We highlight several nuanced technical challenges that must be handled properly and examine behavior preservation of debloated software via regression testing.,0,0,1,0,0,0
3324,"We find that (1) JShrink is able to debloat our real-world Java benchmark suite by up to 47% (14% on average); (2) accounting for dynamic language features is indeed crucial to ensure behavior preservation---reducing 98% of test failures incurred by a purely static equivalent, Jax, and 84% for ProGuard; and (3) compared with purely dynamic approaches, integrating static analysis with dynamic profiling makes the debloated software more robust to unseen test executions---in 22 out of 26 projects, the debloated software ran successfully under new tests.",0,0,0,0,1,0
3325,"In large-scale cloud systems, unplanned service interruptions and outages may cause severe degradation of service availability.",1,0,0,0,0,0
3326,"Such incidents can occur in a bursty manner, which will deteriorate user satisfaction.",1,0,0,0,0,0
3327,Identifying incidents rapidly and accurately is critical to the operation and maintenance of a cloud system.,1,0,0,0,0,0
3328,"In industrial practice, incidents are typically detected through analyzing the issue reports, which are generated over time by monitoring cloud services.",1,0,0,0,0,0
3329,Identifying incidents in a large number of issue reports is quite challenging.,1,0,0,0,0,0
3330,An issue report is typically multi-dimensional: it has many categorical attributes.,1,0,0,0,0,0
3331,It is difficult to identify a specific attribute combination that indicates an incident.,1,0,0,0,0,0
3332,"Existing methods generally rely on pruning-based search, which is time-consuming given high-dimensional data, thus not practical to incident detection in large-scale cloud systems.",1,0,0,0,0,0
3333,"In this paper, we propose MID (Multi-dimensional Incident Detection), a novel framework for identifying incidents from large-amount, multi-dimensional issue reports effectively and efficiently.",0,1,1,0,0,0
3334,Key to the MID design is encoding the problem into a combinatorial optimization problem.,0,0,1,0,0,0
3335,"Then a specific-tailored meta-heuristic search method is designed, which can rapidly identify attribute combinations that indicate incidents.",0,0,1,0,0,0
3336,We evaluate MID with extensive experiments using both synthetic data and real-world data collected from a large-scale production cloud system.,0,0,0,1,0,0
3337,The experimental results show that MID significantly outperforms the current state-of-the-art methods in terms of effectiveness and efficiency.,0,0,0,0,1,0
3338,"Additionally, MID has been successfully applied to Microsoft's cloud systems and helped greatly reduce manual maintenance effort.",0,0,0,0,1,0
3339,"Robots that support humans by performing useful tasks (a.k.a., service robots) are booming worldwide.",1,0,0,0,0,0
3340,"In contrast to industrial robots, the development of service robots comes with severe software engineering challenges, since they require high levels of robustness and autonomy to operate in highly heterogeneous environments.",1,0,0,0,0,0
3341,"As a domain with critical safety implications, service robotics faces a need for sound software development practices.",1,0,0,0,0,0
3342,"In this paper, we present the first large-scale empirical study to assess the state of the art and practice of robotics software engineering.",0,1,1,1,0,0
3343,We conducted 18 semi-structured interviews with industrial practitioners working in 15 companies from 9 different countries and a survey with 156 respondents from 26 countries from the robotics domain.,0,0,0,1,0,0
3344,"Our results provide a comprehensive picture of (i) the practices applied by robotics industrial and academic practitioners, including processes, paradigms, languages, tools, frameworks, and reuse practices, (ii) the distinguishing characteristics of robotics software engineering, and (iii) recurrent challenges usually faced, together with adopted solutions.",0,0,0,0,1,0
3345,"The paper concludes by discussing observations, derived hypotheses, and proposed actions for researchers and practitioners.",0,0,0,0,0,1
3346,"Keeping a good influx of newcomers is critical for open source software projects' survival, while newcomers face many barriers to contributing to a project for the first time.",1,0,0,0,0,0
3347,"To support newcomers onboarding, GitHub encourages projects to apply labels such as good first issue (GFI) to tag issues suitable for newcomers.",1,0,0,0,0,0
3348,"However, many newcomers still fail to contribute even after many attempts, which not only reduces the enthusiasm of newcomers to contribute but makes the efforts of project members in vain.",1,0,0,0,0,0
3349,"To better support the onboarding of newcomers, this paper reports a preliminary study on this mechanism from its application status, effect, problems, and best practices.",0,1,1,1,0,0
3350,"By analyzing 9,368 GFIs from 816 popular GitHub projects and conducting email surveys with newcomers and project members, we obtain the following results.",0,0,0,1,0,0
3351,"We find that more and more projects are applying this mechanism in the past decade, especially the popular projects.",0,0,0,0,1,0
3352,"Compared to common issues, GFIs usually need more days to be solved.",0,0,0,0,1,0
3353,"While some newcomers really join the projects through GFIs, almost half of GFIs are not solved by newcomers.",0,0,0,0,1,0
3354,"We also discover a series of problems covering mechanism (e.g., inappropriate GFIs), project (e.g., insufficient GFIs) and newcomer (e.g., uneven skills) that makes this mechanism ineffective.",0,0,0,0,1,0
3355,"We discover the practices that may address the problems, including identifying GFIs that have informative description and available support, and require limited scope and skill, etc.",0,0,0,0,1,0
3356,"Newcomer onboarding is an important but challenging question in open source projects and our work enables a better understanding of GFI mechanism and its problems, as well as highlights ways in improving them.",0,0,0,0,0,1
3357,"JavaScript is widely used for implementing client-side web applications, and it is common to include JavaScript code from many different hosts.",1,0,0,0,0,0
3358,"However, in a web browser, all the scripts loaded in the same frame share a single global namespace.",1,0,0,0,0,0
3359,"As a result, a script may read or even overwrite the global objects or functions in other scripts, causing unexpected behaviors.",1,0,0,0,0,0
3360,"For example, a script can redefine a function in a different script as an object, so that any call of that function would cause an exception at run time.",1,0,0,0,0,0
3361,We systematically investigate the client-side JavaScript code integrity problem caused by JavaScript global identifier conflicts in this paper.,0,1,0,0,0,0
3362,"We developed a browser-based analysis framework, JSObserver, to collect and analyze the write operations to global memory locations by JavaScript code.",0,0,1,0,0,0
3363,"We identified three categories of conflicts using JSObserver on the Alexa top 100K websites, and detected 145,918 conflicts on 31,615 websites.",0,0,0,0,1,0
3364,We reveal that JavaScript global identifier conflicts are prevalent and could cause behavior deviation at run time.,0,0,0,0,1,0
3365,"In particular, we discovered that 1,611 redefined functions were called after being overwritten, and many scripts modified the value of cookies or redefined cookie-related functions.",0,0,0,0,1,0
3366,Our research demonstrated that JavaScript global identifier conflict is an emerging threat to both the web users and the integrity of web applications.,0,0,0,0,0,1
3367,Good documentation offers the promise of enabling developers to easily understand design decisions.,1,0,0,0,0,0
3368,"Unfortunately, in practice, design documents are often rarely updated, becoming inaccurate, incomplete, and untrustworthy.",1,0,0,0,0,0
3369,A better solution is to enable developers to write down design rules which are checked against code for consistency.,1,0,0,0,0,0
3370,"But existing rule checkers require learning specialized query languages or program analysis frameworks, creating a barrier to writing project-specific rules.",1,0,0,0,0,0
3371,We introduce two new techniques for authoring design rules: snippet-based authoring and semi-natural-language authoring.,0,1,1,0,0,0
3372,"In snippet-based authoring, developers specify characteristics of elements to match by writing partial code snippets.",0,0,1,0,0,0
3373,"In semi-natural language authoring, a textual representation offers a representation for understanding design rules and resolving ambiguities.",0,0,1,0,0,0
3374,We implemented these approaches in RulePad.,0,0,1,0,0,0
3375,"To evaluate RulePad, we conducted a between-subjects study with 14 participants comparing RulePad to the PMD Designer, a utility for writing rules in a popular rule checker.",0,0,0,1,0,0
3376,We found that those with RulePad were able to successfully author 13 times more query elements in significantly less time and reported being significantly more willing to use RulePad in their everyday work.,0,0,0,0,1,0
3377,Loop invariant generation has long been a challenging problem.,1,0,0,0,0,0
3378,Black-box learning has recently emerged as a promising method for inferring loop invariants.,1,0,0,0,0,0
3379,"However, the performance depends heavily on the quality of collected examples.",1,0,0,0,0,0
3380,"In many cases, only after tens or even hundreds of constraint queries, can a feasible invariant be successfully inferred.",1,0,0,0,0,0
3381,"To reduce the gigantic number of constraint queries and improve the performance of black-box learning, we introduce interval counterexamples into the learning framework.",0,1,1,0,0,0
3382,Each interval counterexample represents a set of counterexamples from constraint solvers.,0,0,1,0,0,0
3383,We propose three different generalization techniques to compute interval counterexamples.,0,0,1,0,0,0
3384,The existing decision tree algorithm is also improved to adapt interval counterexamples.,0,0,1,0,0,0
3385,We evaluate our techniques and report over 40% improvement on learning rounds and verification time over the state-of-the-art approach.,0,0,0,1,1,0
3386,Software systems are designed and implemented with assumptions about the environment.,1,0,0,0,0,0
3387,"However, once the system is deployed, the actual environment may deviate from its expected behavior, possibly undermining desired properties of the system.",1,0,0,0,0,0
3388,"To enable systematic design of systems that are robust against potential environmental deviations, we propose a rigorous notion of robustness for software systems.",0,1,1,0,0,0
3389,"In particular, the robustness of a system is defined as the largest set of deviating environmental behaviors under which the system is capable of guaranteeing a desired property.",0,0,1,0,0,0
3390,"We describe a new set of design analysis problems based on our notion of robustness, and a technique for automatically computing robustness of a system given its behavior description.",0,0,1,0,0,0
3391,We demonstrate potential applications of our robustness notion on two case studies involving network protocols and safety-critical interfaces.,0,0,0,1,0,0
3392,"We present HOMI, a new technique to enhance symbolic execution by maintaining only a small number of promising states.",0,1,1,0,0,0
3393,"In practice, symbolic execution typically maintains as many states as possible in a fear of losing important states.",1,0,0,0,0,0
3394,"In this paper, however, we show that only a tiny subset of the states plays a significant role in increasing code coverage or reaching bug points.",0,1,0,0,0,0
3395,"Based on this observation, HOMI aims to minimize the total number of states while keeping “promising” states during symbolic execution.",0,0,1,0,0,0
3396,We identify promising states by a learning algorithm that continuously updates the probabilistic pruning strategy based on data accumulated during the testing process.,0,0,1,0,0,0
3397,Experimental results show that HOMI greatly increases code coverage and the ability to find bugs of KLEE on open-source C programs.,0,0,0,1,1,0
3398,Equivalence checking techniques help establish whether two versions of a program exhibit the same behavior.,1,0,0,0,0,0
3399,The majority of popular techniques for formally proving/refuting equivalence relies on symbolic execution – a static analysis approach that reasons about program behaviors in terms of symbolic input variables.,1,0,0,0,0,0
3400,"Yet, symbolic execution is difficult to scale in practice due to complex programming constructs, such as loops and non-linear arithmetic.",1,0,0,0,0,0
3401,"This paper proposes an approach, named ARDiff, for improving the scalability of symbolic-execution-based equivalence checking techniques when comparing syntactically-similar versions of a program, e.g., for verifying the correctness of code upgrades and refactoring.",0,1,1,0,0,0
3402,"Our approach relies on a set of novel heuristics to determine which parts of the versions’ common code can be effectively pruned during the analysis, reducing the analysis complexity without sacrificing its effectiveness.",0,0,1,0,0,0
3403,"Furthermore, we devise a new equivalence checking benchmark, extending existing benchmarks with a set of real-life methods containing complex math functions and loops.",0,0,1,0,0,0
3404,"We evaluate the effectiveness and efficiency of ARDiff on this benchmark and show that it outperforms existing method-level equivalence checking techniques by solving 86% of all equivalent and 55% of non-equivalent cases, compared with 47% to 69% for equivalent and 38% to 52% for non-equivalent cases in related work.",0,0,0,1,1,0
3405,"The software development profession suffers from severe gender biases, which could be explicit and implicit.",1,0,0,0,0,0
3406,"However, SE literature has not systematically explored and evaluated the methods for reducing gender biases, especially for implicit gender biases.",1,0,0,0,0,0
3407,This paper reports on a field experiment to examine whether the intergroup contact theory could reduce implicit gender biases in software development.,0,1,1,1,0,0
3408,"In the field experiment, 280 undergraduate students taking a project-centric introductory software engineering course were assigned to 70 teams with different contact configurations.",0,0,0,1,0,0
3409,We measured and compared their explicit and implicit gender biases before and after contacts in their teams.,0,0,0,1,0,0
3410,The study yields a rich set of findings.,0,0,0,0,1,0
3411,"First, we confirmed the positive effects of intergroup contact theory in reducing gender biases, particularly the implicit gender biases in both general and SE-specific contexts.",0,0,0,0,1,0
3412,We further revealed that such effects were subjected to different contact configurations.,0,0,0,0,1,0
3413,The intergroup contact theory's effects were maximized in teams where the number of females is greater than or equal to the number of males.,0,0,0,0,1,0
3414,"When the female is the minority group in a team, contacts among members contribute to reducing male members' implicit gender biases but fail to result in the same scale of effects on female members' implicit gender biases.",0,0,0,0,1,0
3415,The findings provide insights into using intergroup contact theory in reducing implicit gender biases in software development contexts.,0,0,0,0,0,1
3416,"Current approaches combining multiple static analyses deriving different, independent properties focus either on modularity or performance.",1,0,0,0,0,0
3417,"Whereas declarative approaches facilitate modularity and automated, analysis-independent optimizations, imperative approaches foster manual, analysis-specific optimizations.",1,0,0,0,0,0
3418,"In this paper, we present a novel approach to static analyses that leverages the modularity of blackboard systems and combines declarative and imperative techniques.",0,1,1,0,0,0
3419,"Our approach allows exchangeability, and pluggable extension of analyses in order to improve sound(i)ness, precision, and scalability and explicitly enables the combination of otherwise incompatible analyses.",0,0,1,0,0,0
3420,"With our approach integrated in the OPAL framework, we were able to implement various dissimilar analyses, including a points-to analysis that outperforms an equivalent analysis from Doop, the state-of-the-art points-to analysis framework.",0,0,0,0,0,1
3421,"When software products and services are developed and maintained over longer time, software engineering practices tend to drift away from both structured and agile methods.",1,0,0,0,0,0
3422,"Nonetheless, in many cases the evolving practices are far from ad hoc or chaotic.",1,0,0,0,0,0
3423,How are the teams involved able to coordinate their joint development?This article reports on an ethnographic study of a small team at a successful provider of software as a service.,0,1,1,1,0,0
3424,What struck us was the very explicit way in which the team adopted and adapted their practices to fit the needs of the evolving development.,0,0,1,0,0,0
3425,"The discussion relates the findings to the concepts of social practices and methods in software engineering, and explores the differences between degraded behavior and the coordinated evolution of development practices.",0,0,1,0,0,0
3426,"The analysis helps to better understand how software engineering practices evolve, and thus provides a starting point for rethinking software engineering methods and their relation to software engineering practice.",0,0,0,0,0,1
3427,Background.,1,0,0,0,0,0
3428,Artifact evaluation has been introduced into the software engineering and programming languages research community with a pilot at ESEC/FSE 2011 and has since then enjoyed a healthy adoption throughout the conference landscape.,1,0,0,0,0,0
3429,Objective.,0,1,0,0,0,0
3430,"In this qualitative study, we examine the expectations of the community toward research artifacts and their evaluation processes.",0,1,1,0,0,0
3431,Method.,0,0,0,1,0,0
3432,We conducted a survey including all members of artifact evaluation committees of major conferences in the software engineering and programming language field since the first pilot and compared the answers to expectations set by calls for artifacts and reviewing guidelines.,0,0,0,1,0,0
3433,Results.,0,0,0,0,1,0
3434,"While we find that some expectations exceed the ones expressed in calls and reviewing guidelines, there is no consensus on quality thresholds for artifacts in general.",0,0,0,0,1,0
3435,"We observe very specific quality expectations for specific artifact types for review and later usage, but also a lack of their communication in calls.",0,0,0,0,1,0
3436,We also find problematic inconsistencies in the terminology used to express artifact evaluation’s most important purpose – replicability.,0,0,0,0,1,0
3437,Conclusion.,0,0,0,0,0,1
3438,We derive several actionable suggestions which can help to mature artifact evaluation in the inspected community and also to aid its introduction into other communities in computer science.,0,0,0,0,0,1
3439,"In large-scale online service systems, incidents occur frequently due to a variety of causes, from updates of software and hardware to changes in operation environment.",1,0,0,0,0,0
3440,These incidents could significantly degrade system’s availability and customers’ satisfaction.,1,0,0,0,0,0
3441,Some incidents are linked because they are duplicate or inter-related.,1,0,0,0,0,0
3442,The linked incidents can greatly help on-call engineers find mitigation solutions and identify the root causes.,1,0,0,0,0,0
3443,"In this work, we investigate the incidents and their links in a representative real-world incident management (IcM) system.",0,1,1,0,0,0
3444,"Based on the identified indicators of linked incidents, we further propose LiDAR (Linked Incident identification with DAta-driven Representation), a deep learning based approach to incident linking.",0,0,1,0,0,0
3445,"More specifically, we incorporate the textual description of incidents and structural information extracted from historical linked incidents to identify possible links among a large number of incidents.",0,0,1,0,0,0
3446,"To show the effectiveness of our method, we apply our method to a real-world IcM system and find that our method outperforms other state-of-the-art methods.",0,0,0,1,1,0
